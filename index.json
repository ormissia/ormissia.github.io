[{"categories":null,"contents":" 基础类型内存宽度以及表示范围 bool\n1Byte true/false uint8\n1Byte 0-255 uint16\n2Byte 0-65535 uint32\n4Byte 0-4294967295 uint64\n8Byte 0-18446744073709551615 int8\n1Byte -128-127 int16\n2Byte -32768-32767 int32\n4Byte -2147483648-2147483647 int64\n6Byte -9223372036854775808-9223372036854775807 byte\n1Byte 类似 uint8 rune\n4Byte 类似 int32 uint\n4Byte / 8Byte 32 或 64 位 int\n4Byte / 8Byte 与 uint 一样大小 float32\n4Byte float64\n8Byte string\n1Byte （英文） / 2Byte-4Byte（中文，取决于字符编码类型） 切片拼接 slice1 := []int{0, 1, 2, 3} slice2 := []int{3, 4, 5} slice1 = append(slice1, slice2...) fmt.Println(slice1) //[0 1 2 3 3 4 5] bit Byte bit：计算机记忆的最小单位，一个bit可以代表0或1\nByte：一个Byte由8bits所组成\n1Byte=8Bits\n1KB=1024Bytes\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/go/basic/basic/","summary":"基础类型内存宽度以及表示范围 bool\n1Byte true/false uint8\n1Byte 0-255 uint16\n2Byte 0-65535 uint32\n4Byte 0-4294967295 uint64\n8Byte 0-18446744073709551615 int8\n1Byte -128-127 int16\n2Byte -32768-32767 int32\n4Byte -2147483648-2147483647 int64\n6Byte -9223372036854775808-9223372036854775807 byte\n1Byte 类似 uint8 rune\n4Byte 类似 int32 uint\n4Byte / 8Byte 32 或 64 位 int\n4Byte / 8Byte 与 uint 一样大小 float32\n4Byte float64\n8Byte string\n1Byte （英文） / 2Byte-4Byte（中文，取决于字符编码类型） 切片拼接 slice1 := []int{0, 1, 2, 3} slice2 := []int{3, 4, 5} slice1 = append(slice1, slice2.","tags":null,"title":"Basic"},{"categories":null,"contents":" 时间转换 字符串转时间\ntime.Parse() 时间转字符串\ntime.Format() 时间转时间戳\nTime.Unix() 时间戳转时间\ntime.Unix() 计时 朴素方法\nstartTime := time.Now() //do something time.Sleep(time.Second) duration := time.Since(startTime) fmt.Printf(\u0026#34;经过时间：%v\\n\u0026#34;, duration) //经过时间：1.005046959s 简洁方法\n// TimeCost 耗时统计函数 func TimeCost(start time.Time) { duration := time.Since(start) fmt.Printf(\u0026#34;经过时间：%v\\n\u0026#34;, duration) } defer TimeCost(time.Now()) //do something time.Sleep(time.Second) //经过时间：1.005054375s 优雅方法\n// TimeCost 耗时统计函数 func TimeCost() func() { start := time.Now() return func() { duration := time.Since(start) fmt.Printf(\u0026#34;经过时间：%v\\n\u0026#34;, duration) } } defer TimeCost()() //do something time.Sleep(time.Second) //经过时间：1.005033916s 时间的加减法 // Add 时间相加 now := time.Now() // ParseDuration parses a duration string. // A duration string is a possibly signed sequence of decimal numbers, // each with optional fraction and a unit suffix, // such as \u0026#34;300ms\u0026#34;, \u0026#34;-1.5h\u0026#34; or \u0026#34;2h45m\u0026#34;. // Valid time units are \u0026#34;ns\u0026#34;, \u0026#34;us\u0026#34; (or \u0026#34;µs\u0026#34;), \u0026#34;ms\u0026#34;, \u0026#34;s\u0026#34;, \u0026#34;m\u0026#34;, \u0026#34;h\u0026#34;. // 10分钟前 m, _ := time.ParseDuration(\u0026#34;-1m\u0026#34;) m1 := now.Add(m) fmt.Println(m1) // 8个小时前 h, _ := time.ParseDuration(\u0026#34;-1h\u0026#34;) h1 := now.Add(8 * h) fmt.Println(h1) // 一天前 d, _ := time.ParseDuration(\u0026#34;-24h\u0026#34;) d1 := now.Add(d) fmt.Println(d1) // 10分钟后 mm, _ := time.ParseDuration(\u0026#34;1m\u0026#34;) mm1 := now.Add(mm) fmt.Println(mm1) // 8小时后 hh, _ := time.ParseDuration(\u0026#34;1h\u0026#34;) hh1 := now.Add(hh) fmt.Println(hh1) // 一天后 dd, _ := time.ParseDuration(\u0026#34;24h\u0026#34;) dd1 := now.Add(dd) fmt.Println(dd1) // Sub 计算两个时间差 subM := now.Sub(m1) fmt.Println(subM.Minutes(), \u0026#34;分钟\u0026#34;) sumH := now.Sub(h1) fmt.Println(sumH.Hours(), \u0026#34;小时\u0026#34;) sumD := now.Sub(d1) fmt.Printf(\u0026#34;%v 天\\n\u0026#34;, sumD.Hours()/24) ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/go/advance/time/","summary":"时间转换 字符串转时间\ntime.Parse() 时间转字符串\ntime.Format() 时间转时间戳\nTime.Unix() 时间戳转时间\ntime.Unix() 计时 朴素方法\nstartTime := time.Now() //do something time.Sleep(time.Second) duration := time.Since(startTime) fmt.Printf(\u0026#34;经过时间：%v\\n\u0026#34;, duration) //经过时间：1.005046959s 简洁方法\n// TimeCost 耗时统计函数 func TimeCost(start time.Time) { duration := time.Since(start) fmt.Printf(\u0026#34;经过时间：%v\\n\u0026#34;, duration) } defer TimeCost(time.Now()) //do something time.Sleep(time.Second) //经过时间：1.005054375s 优雅方法\n// TimeCost 耗时统计函数 func TimeCost() func() { start := time.Now() return func() { duration := time.Since(start) fmt.Printf(\u0026#34;经过时间：%v\\n\u0026#34;, duration) } } defer TimeCost()() //do something time.Sleep(time.Second) //经过时间：1.","tags":null,"title":"time"},{"categories":null,"contents":" go get 下载指定版本 go get github.com/ormissia/go-opv@v0.0.2 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/go/advance/gomod/","summary":" go get 下载指定版本 go get github.com/ormissia/go-opv@v0.0.2 ","tags":null,"title":"go mod"},{"categories":null,"contents":" go chan close 在go的chan中，chan被关闭后，消费者会继续读取channel中的消息。直到消息被全部读取之后使用i, ok := \u0026lt;-ch得到的ok才会变为false\n下面是测试代码以及运行时控制台打印结果：\nfunc main() { ch := make(chan int, 3) go producer(ch) for { i, ok := \u0026lt;-ch fmt.Printf(\u0026#34;consume msg: %d\\tok: %v\\n\u0026#34;, i, ok) time.Sleep(time.Second * 3) } } func producer(ch chan int) { for i := 0; i \u0026lt; 10; i++ { ch \u0026lt;- i fmt.Printf(\u0026#34;produce msg: %d\\n\u0026#34;, i) time.Sleep(time.Second) } close(ch) fmt.Println(\u0026#34;chan closed\u0026#34;) } 输出结果\nproduce msg: 0 consume msg: 0\tok: true produce msg: 1 produce msg: 2 consume msg: 1\tok: true produce msg: 3 produce msg: 4 consume msg: 2\tok: true produce msg: 5 consume msg: 3\tok: true produce msg: 6 consume msg: 4\tok: true produce msg: 7 consume msg: 5\tok: true produce msg: 8 consume msg: 6\tok: true produce msg: 9 chan closed consume msg: 7\tok: true consume msg: 8\tok: true consume msg: 9\tok: true consume msg: 0\tok: false consume msg: 0\tok: false ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/go/advance/chan/","summary":" go chan close 在go的chan中，chan被关闭后，消费者会继续读取channel中的消息。直到消息被全部读取之后使用i, ok := \u0026lt;-ch得到的ok才会变为false\n下面是测试代码以及运行时控制台打印结果：\nfunc main() { ch := make(chan int, 3) go producer(ch) for { i, ok := \u0026lt;-ch fmt.Printf(\u0026#34;consume msg: %d\\tok: %v\\n\u0026#34;, i, ok) time.Sleep(time.Second * 3) } } func producer(ch chan int) { for i := 0; i \u0026lt; 10; i++ { ch \u0026lt;- i fmt.Printf(\u0026#34;produce msg: %d\\n\u0026#34;, i) time.Sleep(time.Second) } close(ch) fmt.Println(\u0026#34;chan closed\u0026#34;) } 输出结果\nproduce msg: 0 consume msg: 0\tok: true produce msg: 1 produce msg: 2 consume msg: 1\tok: true produce msg: 3 produce msg: 4 consume msg: 2\tok: true produce msg: 5 consume msg: 3\tok: true produce msg: 6 consume msg: 4\tok: true produce msg: 7 consume msg: 5\tok: true produce msg: 8 consume msg: 6\tok: true produce msg: 9 chan closed consume msg: 7\tok: true consume msg: 8\tok: true consume msg: 9\tok: true consume msg: 0\tok: false consume msg: 0\tok: false ","tags":null,"title":"go chan"},{"categories":null,"contents":" 异或 异或运算法则：无进位相加 异或运算性质： 0 ^ N = N N ^ N = 0 满足交换律和结合律 a := 0b1100 b := 0b1001 fmt.Printf(\u0026#34;%b\u0026#34;,a^b) //101 简单应用：不申请额外内存交换两个变量的值\na := 0b1100 b := 0b1001 a = a ^ b b = a ^ b //b = (a ^ b) ^ b = a a = a ^ b //a = (a ^ b) ^ a = b fmt.Printf(\u0026#34;a:%b,b:%b\u0026#34;, a, b) //a:1001,b:1100 堆 堆的实质是一棵完全二叉树\n堆可分为两种类型：\n大根堆：所有子树的根节点均为最大值 小根堆：所有子树的根节点均为最小值 一般情况下堆可以用一个有序数组来存储\n[0\u0026hellip;i\u0026hellip;n] i节点的左孩子index为2*i+1，右孩子为2i+2，父节点为(i-1)/2\n也有一种特例是从1开始(位运算比加减法快)\n[01\u0026hellip;i\u0026hellip;n] i节点的左孩子index为2*i即i\u0026lt;\u0026lt;1，右孩子为2i+1即i\u0026lt;\u0026lt;1|1，父节点为i/2\n堆的基本操作： 上浮 下沉 堆的插入弹出 插入 在最后插入节点 依次上浮 弹出 弹出根节点 将最后一个节点放入根节点 将根节点下沉 堆排序 依次弹出根节点 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/go/algorithm/basic/","summary":"异或 异或运算法则：无进位相加 异或运算性质： 0 ^ N = N N ^ N = 0 满足交换律和结合律 a := 0b1100 b := 0b1001 fmt.Printf(\u0026#34;%b\u0026#34;,a^b) //101 简单应用：不申请额外内存交换两个变量的值\na := 0b1100 b := 0b1001 a = a ^ b b = a ^ b //b = (a ^ b) ^ b = a a = a ^ b //a = (a ^ b) ^ a = b fmt.Printf(\u0026#34;a:%b,b:%b\u0026#34;, a, b) //a:1001,b:1100 堆 堆的实质是一棵完全二叉树\n堆可分为两种类型：","tags":null,"title":"Basic"},{"categories":null,"contents":" Strings test\nString str = \u0026#34;123\u0026#34;; ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/java/basic/basic_type/","summary":" Strings test\nString str = \u0026#34;123\u0026#34;; ","tags":null,"title":"Basic Types"},{"categories":null,"contents":" 函数 函数参数为val类型，且可以给出默认值\ndef test(a: Int, b: Int = 1, c: Int = 2): Unit = { println(s\u0026#34;$a $b $c\u0026#34;) } test(1, 2) //1 2 2 test(1, c = 4) //1 1 4 匿名函数 函数是带有参数的表达式。\n(x: Int) =\u0026gt; x + 1 方法 方法的表现和行为和函数非常类似，但是它们之间有一些关键的差别。\n方法由def关键字定义。def后面跟着一个名字、参数列表、返回类型和方法体。\ndef addThenMultiply(x: Int, y: Int)(multiplier: Int): Int = (x + y) * multiplier println(addThenMultiply(1, 2)(3)) // 9 字符串拼接 val a = 1 val b = 2 val c = s\u0026#34;$a+$b=${a + b}\u0026#34; 对象 约等于static单例对象\nobject TestObj { def main(args: Array[String]): Unit = { val a = 1 val b = 2 val c = s\u0026#34;$a+$b=${a + b}\u0026#34; println(c) } } 类 可以使用class关键字定义一个类，后面跟着它的名字和构造参数。\n类里裸露的代码是默认构造中的 类名构造器中的参数就是类的成员属性，默认是val类型，且是private 只有在类名构造器中的参数可以设置成var，其他方法函数中的参数都是val类型的，且不允许设置成var类型 class Greeter(prefix: String, var suffix: String) { var name = \u0026#34;name\u0026#34; def greet(name: String): Unit = println(prefix + name + suffix) } 循环 scala中嵌套for循环可以写到一起，循环上可以加守卫（条件）。 循环结果可以通过yield收集到一个集合中\n// val value = for (i \u0026lt;- 1 to 9; j \u0026lt;- 1 to i) yield { val value = for (i \u0026lt;- 1 to 9; j \u0026lt;- 1 to 10 if (j \u0026lt;= i)) yield { i * j } for (i \u0026lt;- value) { println(i) } 偏应用函数 类似于重新封装一下函数\ndef log(date: Date, logType: String, msg: String): Unit = { println(s\u0026#34;$date\\t$logType\\t$msg\u0026#34;) } val info = log(_, \u0026#34;info\u0026#34;, _) info(new Date, \u0026#34;this is a info msg\u0026#34;) //Thu Jul 22 23:14:04 CST 2021\tinfo\tthis is a info msg 可变长度参数以及foreach def foreachTest(a: Int*): Unit = { //for (i \u0026lt;- a) { // print(i) //} //a.foreach((x: Int) =\u0026gt; { // print(x) //}) //a.foreach(print(_)) a.foreach(print) } foreachTest(1, 2, 3, 4, 5) //12345 高阶函数 函数作为参数\ndef computer(a: Int, b: Int, f: (Int, Int) =\u0026gt; Int): Unit = { val res = f(a, b) println(res) } computer(1, 2, (x: Int, y: Int) =\u0026gt; {x + y}) //3 computer(1, 2, _ + _) //3 函数作为返回值\ndef factory(i: String): (Int, Int) =\u0026gt; Int = { def plus(x: Int, y: Int): Int = { x + y } if (i.equals(\u0026#34;+\u0026#34;)) { plus } else { _ * _ } } val plus = factory(\u0026#34;+\u0026#34;) computer(1,2,plus) //3 柯里化 多个参数列表\ndef testFunc(a:Int*)(b:Int*)(c:String*): Unit ={ a.foreach(print) b.foreach(print) c.foreach(print) } testFunc(1,2,3)(2,3,4)(\u0026#34;3\u0026#34;,\u0026#34;4\u0026#34;,\u0026#34;5\u0026#34;) //123234345 数组 数组 scala中泛型是[]，数组用()\nval约等于final，不可变描述的是val指定的引用（字面值、地址）\nval arr1 = Array[Int](1, 2, 3) arr1(1) = 99 println(arr1(1)) //99 遍历\nfor (elem \u0026lt;- arr1) {} //foreach需要函数接收元素 arr1.foreach(println) 链表 scala中collections中有两个包：immutable,mutable，默认是不可变的immutable\nval list1 = List(1, 2, 3, 4) //++ += ++: :++ val list2 = new ListBuffer[Int] list2.+=(1) list2.+=(2) list2.+=(3) val list1 = List(1, 2, 3, 4) val list2 = list1.map(_ * 2) list2.foreach(print) //2468 Set Set\n不可变的\nval set1 = Set(1, 2, 3, 4, 1, 2) //1 2 3 4 可变的\nval set2 = mutable.Set(1, 2, 3, 4, 1, 2) set2.add(1) set2.add(5) //1 2 3 4 5 Map Map\nval map1 = Map((\u0026#34;a\u0026#34;, 1), \u0026#34;b\u0026#34; -\u0026gt; 2, (\u0026#34;c\u0026#34;, 3), (\u0026#34;a\u0026#34;, 4)) map1.foreach(print) //(a,4)(b,2)(c,3) println(map1.get(\u0026#34;a\u0026#34;)) //Some(4) println(map1.get(\u0026#34;d\u0026#34;)) //None println(map1.getOrElse(\u0026#34;a\u0026#34;, \u0026#34;test\u0026#34;)) //4 println(map1.getOrElse(\u0026#34;d\u0026#34;, \u0026#34;test\u0026#34;)) //test val keys = map1.keys keys.foreach(println) 遍历\nfor (m \u0026lt;- map1) { print(s\u0026#34;$m\u0026#34;) } for (k \u0026lt;- keys) { print(s\u0026#34;($k,${map1(k)})\u0026#34;) } 可变的\nval map2 = mutable.Map((\u0026#34;a\u0026#34;, 1), \u0026#34;b\u0026#34; -\u0026gt; 2, (\u0026#34;c\u0026#34;, 3), (\u0026#34;a\u0026#34;, 4)) map2.put(\u0026#34;a\u0026#34;, 5) 案例类 模式匹配 特质 偏函数 隐式转换 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/scala/basic/basic_type/","summary":"函数 函数参数为val类型，且可以给出默认值\ndef test(a: Int, b: Int = 1, c: Int = 2): Unit = { println(s\u0026#34;$a $b $c\u0026#34;) } test(1, 2) //1 2 2 test(1, c = 4) //1 1 4 匿名函数 函数是带有参数的表达式。\n(x: Int) =\u0026gt; x + 1 方法 方法的表现和行为和函数非常类似，但是它们之间有一些关键的差别。\n方法由def关键字定义。def后面跟着一个名字、参数列表、返回类型和方法体。\ndef addThenMultiply(x: Int, y: Int)(multiplier: Int): Int = (x + y) * multiplier println(addThenMultiply(1, 2)(3)) // 9 字符串拼接 val a = 1 val b = 2 val c = s\u0026#34;$a+$b=${a + b}\u0026#34; 对象 约等于static单例对象","tags":null,"title":"Basic Types"},{"categories":null,"contents":" 函数 在 python 中，类型属于对象，变量是没有类型的：\na=[1,2,3] a=\u0026#34;ormissia\u0026#34; 以上代码中，[1,2,3]是List类型，\u0026quot;ormissia\u0026quot;是String类型，而变量a是没有类型，他仅仅是一个对象的引用（一个指针），可以是指向List类型对象，也可以是指向String类型对象。\n可更改(mutable)与不可更改(immutable)对象 在python中，strings，tuples和numbers是不可更改的对象，而list，dict等则是可以修改的对象。\n不可变类型：变量赋值a=5后再赋值a=10，这里实际是新生成一个int值对象10，再让a指向它，而5被丢弃，不是改变a的值，相当于新生成了a。\n可变类型：变量赋值la = [1,2,3,4]后再赋值la[2] = 5则是将list la的第三个元素值更改，本身la没有动，只是其内部的一部分值被修改了。\npython函数的参数传递： 不可变类型：类似C++的值传递，如整数、字符串、元组。如fun(a)，传递的只是a的值，没有影响a对象本身。如果在fun(a)内部修改a的值，则是新生成一个a的对象。\n可变类型：类似C++的引用传递，如列表，字典。如fun(la)，则是将la真正的传过去，修改后fun外部的la也会受影响\npython中一切都是对象，严格意义我们不能说值传递还是引用传递，我们应该说传不可变对象和传可变对象。\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/python/basic/basic/","summary":"函数 在 python 中，类型属于对象，变量是没有类型的：\na=[1,2,3] a=\u0026#34;ormissia\u0026#34; 以上代码中，[1,2,3]是List类型，\u0026quot;ormissia\u0026quot;是String类型，而变量a是没有类型，他仅仅是一个对象的引用（一个指针），可以是指向List类型对象，也可以是指向String类型对象。\n可更改(mutable)与不可更改(immutable)对象 在python中，strings，tuples和numbers是不可更改的对象，而list，dict等则是可以修改的对象。\n不可变类型：变量赋值a=5后再赋值a=10，这里实际是新生成一个int值对象10，再让a指向它，而5被丢弃，不是改变a的值，相当于新生成了a。\n可变类型：变量赋值la = [1,2,3,4]后再赋值la[2] = 5则是将list la的第三个元素值更改，本身la没有动，只是其内部的一部分值被修改了。\npython函数的参数传递： 不可变类型：类似C++的值传递，如整数、字符串、元组。如fun(a)，传递的只是a的值，没有影响a对象本身。如果在fun(a)内部修改a的值，则是新生成一个a的对象。\n可变类型：类似C++的引用传递，如列表，字典。如fun(la)，则是将la真正的传过去，修改后fun外部的la也会受影响\npython中一切都是对象，严格意义我们不能说值传递还是引用传递，我们应该说传不可变对象和传可变对象。","tags":null,"title":"Basic"},{"categories":null,"contents":" 函数 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/js/basic/basic/","summary":" 函数 ","tags":null,"title":"Basic"},{"categories":null,"contents":" 按年月日分组聚合 group by date_format(field_name, format); 根据format字符串格式化date值。下列修饰符可以被用在format字符串中：\n%M 月名字(January……December) %W 星期名字(Sunday……Saturday) %D 有英语前缀的月份的日期(1st, 2nd, 3rd, 等等。） %Y 年, 数字, 4 位 %y 年, 数字, 2 位 %a 缩写的星期名字(Sun……Sat) %d 月份中的天数, 数字(00……31) %e 月份中的天数, 数字(0……31) %m 月, 数字(01……12) %c 月, 数字(1……12) %b 缩写的月份名字(Jan……Dec) %j 一年中的天数(001……366) %H 小时(00……23) %k 小时(0……23) %h 小时(01……12) %I 小时(01……12) %l 小时(1……12) %i 分钟, 数字(00……59) %r 时间,12 小时(hh:mm:ss [AP]M) %T 时间,24 小时(hh:mm:ss) %S 秒(00……59) %s 秒(00……59) %p AM或PM %w 一个星期中的天数(0=Sunday ……6=Saturday ） %U 星期(0……52), 这里星期天是星期的第一天 %u 星期(0……52), 这里星期一是星期的第一天 %% 一个文字“%” count统计不重复个数 select count(distinct (field_name)) from table_name sum结果为null时置为0 SQL中使用sum统计总数时:sum(col_name)，如果某列不符合sum的条件（比如某列中含有NULL元素，或者不是数值类型，或者没有符合where条件的行），那么会返回NULL 有的时候不希望sum的结果为NULL，可以做如下的处理：\nSELECT COALESCE(sum(col_name), 0) FROM Table 此外还有ISNULL(SQL Server)，NVL(Oracle)以及IFNULL(MySQL)的用法，起到同样的效果\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/sql/dml/dml/","summary":"按年月日分组聚合 group by date_format(field_name, format); 根据format字符串格式化date值。下列修饰符可以被用在format字符串中：\n%M 月名字(January……December) %W 星期名字(Sunday……Saturday) %D 有英语前缀的月份的日期(1st, 2nd, 3rd, 等等。） %Y 年, 数字, 4 位 %y 年, 数字, 2 位 %a 缩写的星期名字(Sun……Sat) %d 月份中的天数, 数字(00……31) %e 月份中的天数, 数字(0……31) %m 月, 数字(01……12) %c 月, 数字(1……12) %b 缩写的月份名字(Jan……Dec) %j 一年中的天数(001……366) %H 小时(00……23) %k 小时(0……23) %h 小时(01……12) %I 小时(01……12) %l 小时(1……12) %i 分钟, 数字(00……59) %r 时间,12 小时(hh:mm:ss [AP]M) %T 时间,24 小时(hh:mm:ss) %S 秒(00……59) %s 秒(00……59) %p AM或PM %w 一个星期中的天数(0=Sunday ……6=Saturday ） %U 星期(0……52), 这里星期天是星期的第一天 %u 星期(0……52), 这里星期一是星期的第一天 %% 一个文字“%” count统计不重复个数 select count(distinct (field_name)) from table_name sum结果为null时置为0 SQL中使用sum统计总数时:sum(col_name)，如果某列不符合sum的条件（比如某列中含有NULL元素，或者不是数值类型，或者没有符合where条件的行），那么会返回NULL 有的时候不希望sum的结果为NULL，可以做如下的处理：","tags":null,"title":"SQL DML"},{"categories":null,"contents":" 快捷键 回到命令行开头\u0026ndash;Home\nCtrl+a 回到命令行的尾部\u0026ndash;End\nCtrl+e 删除光标前边的所有字符\nCtrl+u 删除光标后边的所有字符\nCtrl+k 删除光标前的一个单词\nCtrl+w 输入曾经的命令下的某个单词或字母，按照单词的匹配history\nCtrl+r cat 在cat输出时候显示行数\ncat -n maim.go wc 统计文件行、单词、字符数量 格式：\nusage: wc [-clmw] [file ...] 统计main.go的行、单词、字符数量\nwc main.go 选项：\n-l 统计行数 -c 统计字符数 -w 统计单词数 -L 统计最长的行的字符数 nc 简单的文件传输工具\n接收方\nnc -l [port] \u0026gt; filename 发送方\nnc [ip] [port] \u0026lt; filename gzip 解压*.gz的压缩文件\n与*.tar.gz文件不同，*.gz文件需要用gzip来解压\ngzip -d filename hostnamectl 修改hostname，重启也生效\nhostnamectl set-hostname CentOS 查看hostname\nhostname echo -n：不换行 -e：支持扩展属性\n# 红色显示OK echo -e \u0026#34;\\033[31mOK\\033[0m\u0026#34; # 绿色显示OK echo -e \u0026#34;\\033[32mOK\\033[0m\u0026#34; tr 删除多余重复字符串\n# 删除多余的空格 echo \u0026#34;a b c\u0026#34; | tr -s \u0026#34; \u0026#34; # 输出：a b c # 删除多余的a echo \u0026#34;aaaaacccdetaaadfa c\u0026#34; | tr -s \u0026#34;a\u0026#34; # 输出：acccdetadfa c cut # 以冒号为分隔，过滤第一列 cut -d: -f1 /etc/passwd # 输出当前系统下所有用户名 date 查看系统时间\ndate # Tue Oct 12 13:36:24 CST 2021 tzselect 查看时区\nls -l /etc/localtime # lrwxrwxrwx. 1 root root 33 Oct 12 11:32 /etc/localtime -\u0026gt; /usr/share/zoneinfo/Asia/Shanghai 获取TZ时区\ntzselect 输出：\nPlease identify a location so that time zone rules can be set correctly. Please select a continent, ocean, \u0026#34;coord\u0026#34;, or \u0026#34;TZ\u0026#34;. 1) Africa 2) Americas 3) Antarctica 4) Asia 5) Atlantic Ocean 6) Australia 7) Europe 8) Indian Ocean 9) Pacific Ocean 10) coord - I want to use geographical coordinates. 11) TZ - I want to specify the time zone using the Posix TZ format. #? # 选择数字，依次选择地区、国家、城市，即可得到对应时区 # Asia/Shanghai 修改系统时区（所有用户生效）\nrm -f /etc/localtime ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/linux/shell/basic/","summary":"快捷键 回到命令行开头\u0026ndash;Home\nCtrl+a 回到命令行的尾部\u0026ndash;End\nCtrl+e 删除光标前边的所有字符\nCtrl+u 删除光标后边的所有字符\nCtrl+k 删除光标前的一个单词\nCtrl+w 输入曾经的命令下的某个单词或字母，按照单词的匹配history\nCtrl+r cat 在cat输出时候显示行数\ncat -n maim.go wc 统计文件行、单词、字符数量 格式：\nusage: wc [-clmw] [file ...] 统计main.go的行、单词、字符数量\nwc main.go 选项：\n-l 统计行数 -c 统计字符数 -w 统计单词数 -L 统计最长的行的字符数 nc 简单的文件传输工具\n接收方\nnc -l [port] \u0026gt; filename 发送方\nnc [ip] [port] \u0026lt; filename gzip 解压*.gz的压缩文件\n与*.tar.gz文件不同，*.gz文件需要用gzip来解压\ngzip -d filename hostnamectl 修改hostname，重启也生效\nhostnamectl set-hostname CentOS 查看hostname\nhostname echo -n：不换行 -e：支持扩展属性\n# 红色显示OK echo -e \u0026#34;\\033[31mOK\\033[0m\u0026#34; # 绿色显示OK echo -e \u0026#34;\\033[32mOK\\033[0m\u0026#34; tr 删除多余重复字符串","tags":null,"title":"Basic"},{"categories":null,"contents":" xargs xargs是给命令传递参数的一个过滤器，可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据，一般是和管道一起使用。 格式:\nsomecommand | xargs [-item] [command] 选项：\n-a file 从文件中读入作为 stdin -e flag ，注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。 -p 当每次执行一个argument的时候询问一次用户。 -n num 后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的。 -t 表示先打印命令，然后再执行。 -i 或者是-I，这得看linux支持了，将xargs的每项名称，一般是一行一行赋值给 {}，可以用 {} 代替。 -r no-run-if-empty 当xargs的输入为空的时候则停止xargs，不用再去执行了。 -s num 命令行的最大字符数，指的是 xargs 后面那个命令的最大命令行字符数。 -L num 从标准输入一次读取 num 行送给 command 命令。 -l 同 -L。 -d delim 分隔符，默认的xargs分隔符是回车，argument的分隔符是空格，这里修改的是xargs的分隔符。 -x exit的意思，主要是配合-s使用。。 top Linux top命令VIRT,RES,SHR,DATA的含义:\nVIRT:virtual memory usage虚拟内存 进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据等 假如进程申请100m的内存，但实际只使用了10m，那么它会增长100m，而不是实际的使用量 RES:resident memory usage常驻内存 进程当前使用的内存大小，但不包括swap out 包含其他进程的共享 如果申请100m的内存，实际使用10m，它只增长10m，与VIRT相反 关于库占用内存的情况，它只统计加载的库文件所占内存大小 SHR:shared memory共享内存 除了自身进程的共享内存，也包括其他进程的共享内存 虽然进程只使用了几个共享库的函数，但它包含了整个共享库的大小 计算某个进程所占的物理内存大小公式：RES – SHR swap out后，它将会降下来 top运行中可以通过top的内部命令对进程的显示方式进行控制。内部命令如下：\ns – 改变画面更新频率\nl – 关闭或开启第一部分第一行 top 信息的表示\nt – 关闭或开启第一部分第二行 Tasks 和第三行 Cpus 信息的表示\nm – 关闭或开启第一部分第四行 Mem 和 第五行 Swap 信息的表示\nN – 以 PID 的大小的顺序排列表示进程列表\nP – 以 CPU 占用率大小的顺序排列进程列表\nM – 以内存占用率大小的顺序排列进程列表\nh – 显示帮助\nn – 设置在进程列表所显示进程的数量\nq – 退出 top\n序号 列名 含义\na PID 进程id\nb PPID 父进程id\nc RUSER Real user name\nd UID 进程所有者的用户id\ne USER 进程所有者的用户名\nf GROUP 进程所有者的组名\ng TTY 启动进程的终端名。不是从终端启动的进程则显示为 ?\nh PR 优先级\ni NI nice值。负值表示高优先级，正值表示低优先级\nj P 最后使用的CPU，仅在多CPU环境下有意义\nk %CPU 上次更新到现在的CPU时间占用百分比\nl TIME 进程使用的CPU时间总计，单位秒\nm TIME+ 进程使用的CPU时间总计，单位1/100秒\nn %MEM 进程使用的物理内存百分比\no VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES\np SWAP 进程使用的虚拟内存中，被换出的大小，单位kb。\nq RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA\nr CODE 可执行代码占用的物理内存大小，单位kb\ns DATA 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb\nt SHR 共享内存大小，单位kb\nu nFLT 页面错误次数\nv nDRT 最后一次写入到现在，被修改过的页面数。\nw S 进程状态。（D=不可中断的睡眠状态，R=运行，S=睡眠，T=跟踪/停止，Z=僵尸进程）\nx COMMAND 命令名/命令行\ny WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名\nz Flags 任务标志，参考 sched.h\n默认情况下仅显示比较重要的 PID、USER、PR、NI、VIRT、RES、SHR、S、%CPU、%MEM、TIME+、COMMAND 列。可以通过下面的快捷键来更改显示内容。\n通过f键可以选择显示的内容。按f键之后会显示列的列表，按a-z即可显示或隐藏对应的列，最后按回车键确定。 按o键可以改变列的显示顺序。按小写的a-z可以将相应的列向右移动，而大写的A-Z可以将相应的列向左移动。最后按回车键确定。 按大写的F或O键，然后按a-z可以将进程按照相应的列进行排序。而大写的R键可以将当前的排序倒转。\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/linux/shell/advance/","summary":"xargs xargs是给命令传递参数的一个过滤器，可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据，一般是和管道一起使用。 格式:\nsomecommand | xargs [-item] [command] 选项：\n-a file 从文件中读入作为 stdin -e flag ，注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。 -p 当每次执行一个argument的时候询问一次用户。 -n num 后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的。 -t 表示先打印命令，然后再执行。 -i 或者是-I，这得看linux支持了，将xargs的每项名称，一般是一行一行赋值给 {}，可以用 {} 代替。 -r no-run-if-empty 当xargs的输入为空的时候则停止xargs，不用再去执行了。 -s num 命令行的最大字符数，指的是 xargs 后面那个命令的最大命令行字符数。 -L num 从标准输入一次读取 num 行送给 command 命令。 -l 同 -L。 -d delim 分隔符，默认的xargs分隔符是回车，argument的分隔符是空格，这里修改的是xargs的分隔符。 -x exit的意思，主要是配合-s使用。。 top Linux top命令VIRT,RES,SHR,DATA的含义:\nVIRT:virtual memory usage虚拟内存 进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据等 假如进程申请100m的内存，但实际只使用了10m，那么它会增长100m，而不是实际的使用量 RES:resident memory usage常驻内存 进程当前使用的内存大小，但不包括swap out 包含其他进程的共享 如果申请100m的内存，实际使用10m，它只增长10m，与VIRT相反 关于库占用内存的情况，它只统计加载的库文件所占内存大小 SHR:shared memory共享内存 除了自身进程的共享内存，也包括其他进程的共享内存 虽然进程只使用了几个共享库的函数，但它包含了整个共享库的大小 计算某个进程所占的物理内存大小公式：RES – SHR swap out后，它将会降下来 top运行中可以通过top的内部命令对进程的显示方式进行控制。内部命令如下：","tags":null,"title":"Advance"},{"categories":null,"contents":" 命令 显示行号\n:set number 在vi中执行shell命令\n:!ls-l 将shell命令的结果插入到当前行的下一行\n:r !date //读取系统时间并插入到当前行的下一行 将起始行号和结束行号指定的范围中的内容输入到shell命令command处理，并将处理结果替换起始行号和结束行号指定的范围中的内容\n:62,72 !sort //将62行到72行的内容进行排序 当前光标所在行，除可以指定行号外，也可以用.表示\n:. !tr [a-z] [A-Z] //将当前行的小写转为大写 将起始行号和结束行号所指定的范围的内容作为命令command的输入，不会改变当前编辑的文件的内容\n:62,72 w !sort //将62行到72行的内容进行排序，但排序的结果并不会直接输出到当前编辑的文件中，而是显示在vim敲命令的区域 将某一行作为shell命令执行\n:62 w !shell //将会把第62行的内容作为shell命令来执行并显示结果，而且不会改变当前编辑的文件的内容 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/linux/shell/vi/","summary":" 命令 显示行号\n:set number 在vi中执行shell命令\n:!ls-l 将shell命令的结果插入到当前行的下一行\n:r !date //读取系统时间并插入到当前行的下一行 将起始行号和结束行号指定的范围中的内容输入到shell命令command处理，并将处理结果替换起始行号和结束行号指定的范围中的内容\n:62,72 !sort //将62行到72行的内容进行排序 当前光标所在行，除可以指定行号外，也可以用.表示\n:. !tr [a-z] [A-Z] //将当前行的小写转为大写 将起始行号和结束行号所指定的范围的内容作为命令command的输入，不会改变当前编辑的文件的内容\n:62,72 w !sort //将62行到72行的内容进行排序，但排序的结果并不会直接输出到当前编辑的文件中，而是显示在vim敲命令的区域 将某一行作为shell命令执行\n:62 w !shell //将会把第62行的内容作为shell命令来执行并显示结果，而且不会改变当前编辑的文件的内容 ","tags":null,"title":"vi"},{"categories":null,"contents":" 脚本执行方式 需要可执行权限 相对路径执行 绝对路径执行 不需要可执行权限 sh 脚本文件名 source 脚本文件名 // 不会启动子进程，通过pstree查看进程树 定义变量 定义变量：变量名=变量值 取消变量：unset 变量名 注意事项： =两边不能有空格 不能使用关键字做变量名，如：ls、cd等 如果变量名已存在，则会覆盖之前的变量值 变量名称由字母、数字、下划线组成，不能以数字开头 变量类型 环境变量：变量名通常大写，由操作系统维护 位置变量：shell内置变量，存储脚本执行时的参数 使用$n表示，n为数字序列号：$1、$2、\u0026hellip;、${10}、${11}、\u0026hellip; 预定义变量：shell内置变量，可以直接调用但是不能赋值或修改' $0：存储所在的进程或脚本名 $$：当前进程的PID号 $?：命令执行后的返回状态，0-正常，其他-异常 $#：已加载的位置变量的个数 $*：所有位置变量的值 自定义变量：用户自主设置 多种引号的区别 双引号：允许扩展，以$引用其他变量 单引号：禁用扩展，将$视为普通字符 反引号：将命令执行的输出作为变量值，$()与反引号等效 变量的作用范围 局部变量：新定义的变量默认只在当前Shell中有效，无法在子Shell环境中使用 全局变量：在当前Shell以及子Shell中均有效（export a=1：定义全局变量a） read标准输入取值 read从键盘读入变量值完成赋值\n格式：read [参数] [变量名] 参数： -p：提示信息 -t：指定超时秒数 -s：设置是否在终端显示输入的内容 变量作用范围 局部变量 新定义的变量默认只在当前Shell环境中有效，无法在子Shell环境中使用 全局变量 全局变量在当前Shell及子Shell中均有效，定义格式：export a=1 数学运算 整数运算\n使用$[]或$(())表达式\n格式：$[整数1 运算符 整数2]\n小数运算\nBash内建机制仅支持整数运算，不支持小数运算 可以通过计算器软件bc实现小数计算\n如果没有该软件需要使用yum安装 bc支持交互式和非交互式两种方式计算，scale=n可以约束小数位\nbc也支持比较操作： \u0026gt;,\u0026gt;=,\u0026lt;,\u0026lt;=,==,!= 表达式成立返回1，否则返回0\n字符串 字符串比较\n中括号与字符串之间和运算符与字符串之间均有有个空格\n是否为空：[ -z 字符串 ]\n等于：[ 字符串1 == 字符串2 ]\n不等于：[ 字符串1 ！= 字符串2 ]\n整数值比较 [ 整数值1 操作符 整数值2 ]\n-eq 等于（equal） -ne 不等于（not equal） -ge 大于等于（greater or equal） -le 小于等于（less or equal） -gt 大于（greater than） -lt 小于（less than）\n文件状态测试 [ 操作符 文件或目录 ]\n-e 判断对象是否存在（exit） -d 判断对象是否为目录（directory） -f 判断对象是否为一般文件（file） -r 判断对象是否有可读权限（read） -w 判断对象是否有可写权限（write） -x 判断对象是否有可执行权限（excute）\n组合多个命令 ;：顺序执行 ||：前面执行失败继续执行 \u0026amp;\u0026amp;：前面执行成功继续执行 数组 存储多个数据的集合\ntest=(1 2 3) echo ${test[0]} 函数 语法格式\nfunction 函数名{ #命令序列 } 函数名(){ #命令序列 } 调用\n函数名 参数1 参数2 ... 传递的值作为函数的位置参数\n中断与退出 continue：结束单次循环 break：跳出循环体 exit：退出脚本 子串截取 ${变量:起始位置:长度}\nab=123456 # 统计ab长度 echo ${#ab} # 输出：6 echo ${ab:2:5} # 输出：3456 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/linux/shell/script/","summary":"脚本执行方式 需要可执行权限 相对路径执行 绝对路径执行 不需要可执行权限 sh 脚本文件名 source 脚本文件名 // 不会启动子进程，通过pstree查看进程树 定义变量 定义变量：变量名=变量值 取消变量：unset 变量名 注意事项： =两边不能有空格 不能使用关键字做变量名，如：ls、cd等 如果变量名已存在，则会覆盖之前的变量值 变量名称由字母、数字、下划线组成，不能以数字开头 变量类型 环境变量：变量名通常大写，由操作系统维护 位置变量：shell内置变量，存储脚本执行时的参数 使用$n表示，n为数字序列号：$1、$2、\u0026hellip;、${10}、${11}、\u0026hellip; 预定义变量：shell内置变量，可以直接调用但是不能赋值或修改' $0：存储所在的进程或脚本名 $$：当前进程的PID号 $?：命令执行后的返回状态，0-正常，其他-异常 $#：已加载的位置变量的个数 $*：所有位置变量的值 自定义变量：用户自主设置 多种引号的区别 双引号：允许扩展，以$引用其他变量 单引号：禁用扩展，将$视为普通字符 反引号：将命令执行的输出作为变量值，$()与反引号等效 变量的作用范围 局部变量：新定义的变量默认只在当前Shell中有效，无法在子Shell环境中使用 全局变量：在当前Shell以及子Shell中均有效（export a=1：定义全局变量a） read标准输入取值 read从键盘读入变量值完成赋值\n格式：read [参数] [变量名] 参数： -p：提示信息 -t：指定超时秒数 -s：设置是否在终端显示输入的内容 变量作用范围 局部变量 新定义的变量默认只在当前Shell环境中有效，无法在子Shell环境中使用 全局变量 全局变量在当前Shell及子Shell中均有效，定义格式：export a=1 数学运算 整数运算\n使用$[]或$(())表达式\n格式：$[整数1 运算符 整数2]\n小数运算\nBash内建机制仅支持整数运算，不支持小数运算 可以通过计算器软件bc实现小数计算\n如果没有该软件需要使用yum安装 bc支持交互式和非交互式两种方式计算，scale=n可以约束小数位\nbc也支持比较操作： \u0026gt;,\u0026gt;=,\u0026lt;,\u0026lt;=,==,!= 表达式成立返回1，否则返回0\n字符串 字符串比较","tags":null,"title":"Script"},{"categories":null,"contents":" 内存 一般来说内存占用大小有如下规律：VSS \u0026gt;= RSS \u0026gt;= PSS \u0026gt;= USS\nVSS - Virtual Set Size 虚拟耗用内存（包含共享库占用的内存） RSS - Resident Set Size 实际使用物理内存（包含共享库占用的内存） PSS - Proportional Set Size 实际使用的物理内存（比例分配共享库占用的内存） USS - Unique Set Size 进程独自占用的物理内存（不包含共享库占用的内存） RSS / VSZ\nRSS是Resident Set Size（常驻内存大小）的缩写，用于表示进程使用了多少内存（RAM中的物理内存）， RSS不包含已经被换出的内存。RSS包含了它所链接的动态库并且被加载到物理内存中的内存。RSS还包含栈内存和堆内存。 VSZ是Virtual Memory Size（虚拟内存大小）的缩写。它包含了进程所能访问的所有内存，包含了被换出的内存， 被分配但是还没有被使用的内存，以及动态库中的内存。 假设进程A的二进制文件是500K，并且链接了一个2500K的动态库，堆和栈共使用了200K，其中100K在内存中（剩下的被换出或者不再被使用）， 一共加载了动态库中的1000K内容以及二进制文件中的400K内容至内存中，那么：\nRSS: 400K + 1000K + 100K = 1500K VSZ: 500K + 2500K + 200K = 3200K 由于部分内存是共享的，被多个进程使用，所以如果将所有进程的RSS值加起来可能会大于系统的内存总量。\n申请过的内存如果程序没有实际使用，则可能不显示在RSS里。比如说一个程序，预先申请了一大批内存， 过了一段时间才使用，你会发现RSS会增长而VSZ保持不变。\n还有一个概念是PSS，它是proportional set size（proportional是成比例的意思）的缩写。 这是一种新的度量方式。它将动态库所使用的内存按比例划分。比如我们前面例子中的动态库如果是被两个进程使用，那么：\nPSS: 400K + (1000K/2) + 100K = 400K + 500K + 100K = 1000K 一个进程中的多个线程共享同样的地址空间。所以一个进程中的多个线程的RSS，VSZ，PSS是完全相同的。linux下可以使用ps或者top命令查看这些信息。\n英文原文\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/linux/system/system/","summary":"内存 一般来说内存占用大小有如下规律：VSS \u0026gt;= RSS \u0026gt;= PSS \u0026gt;= USS\nVSS - Virtual Set Size 虚拟耗用内存（包含共享库占用的内存） RSS - Resident Set Size 实际使用物理内存（包含共享库占用的内存） PSS - Proportional Set Size 实际使用的物理内存（比例分配共享库占用的内存） USS - Unique Set Size 进程独自占用的物理内存（不包含共享库占用的内存） RSS / VSZ\nRSS是Resident Set Size（常驻内存大小）的缩写，用于表示进程使用了多少内存（RAM中的物理内存）， RSS不包含已经被换出的内存。RSS包含了它所链接的动态库并且被加载到物理内存中的内存。RSS还包含栈内存和堆内存。 VSZ是Virtual Memory Size（虚拟内存大小）的缩写。它包含了进程所能访问的所有内存，包含了被换出的内存， 被分配但是还没有被使用的内存，以及动态库中的内存。 假设进程A的二进制文件是500K，并且链接了一个2500K的动态库，堆和栈共使用了200K，其中100K在内存中（剩下的被换出或者不再被使用）， 一共加载了动态库中的1000K内容以及二进制文件中的400K内容至内存中，那么：\nRSS: 400K + 1000K + 100K = 1500K VSZ: 500K + 2500K + 200K = 3200K 由于部分内存是共享的，被多个进程使用，所以如果将所有进程的RSS值加起来可能会大于系统的内存总量。\n申请过的内存如果程序没有实际使用，则可能不显示在RSS里。比如说一个程序，预先申请了一大批内存， 过了一段时间才使用，你会发现RSS会增长而VSZ保持不变。\n还有一个概念是PSS，它是proportional set size（proportional是成比例的意思）的缩写。 这是一种新的度量方式。它将动态库所使用的内存按比例划分。比如我们前面例子中的动态库如果是被两个进程使用，那么：\nPSS: 400K + (1000K/2) + 100K = 400K + 500K + 100K = 1000K 一个进程中的多个线程共享同样的地址空间。所以一个进程中的多个线程的RSS，VSZ，PSS是完全相同的。linux下可以使用ps或者top命令查看这些信息。","tags":null,"title":"Memory"},{"categories":null,"contents":" shell 在hbase的shell中scan时指定列\nscan \u0026#39;table_name\u0026#39;,{STARTROW=\u0026gt;\u0026#39;start_row\u0026#39;,ENDROW=\u0026gt;\u0026#39;end_row\u0026#39;,LIMIT=\u0026gt;100,COLUMNS=\u0026gt;[\u0026#39;info:type\u0026#39;]} COLUMNS=\u0026gt;['info:type']中参数为数组，可以指定列簇名和列名\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/hbase/shell/basic/","summary":"shell 在hbase的shell中scan时指定列\nscan \u0026#39;table_name\u0026#39;,{STARTROW=\u0026gt;\u0026#39;start_row\u0026#39;,ENDROW=\u0026gt;\u0026#39;end_row\u0026#39;,LIMIT=\u0026gt;100,COLUMNS=\u0026gt;[\u0026#39;info:type\u0026#39;]} COLUMNS=\u0026gt;['info:type']中参数为数组，可以指定列簇名和列名","tags":null,"title":"Basic"},{"categories":null,"contents":" shell 查询消费者组\nkafka-consumer-groups.sh --bootstrap-server bigdata7:9092 --list kafka-consumer-groups.sh --bootstrap-server bigdata7:9092 --describe --group group_name 删除消费者组\nkafka-consumer-groups.sh --bootstrap-server bigdata7:9092 --delete --group group_name 查看topic消息数量\nkafka-run-class.sh kafka.tools.GetOffsetShell --bootstrap-server bigdata7:9092 --topic topic_name --time -1 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/kafka/shell/basic/","summary":" shell 查询消费者组\nkafka-consumer-groups.sh --bootstrap-server bigdata7:9092 --list kafka-consumer-groups.sh --bootstrap-server bigdata7:9092 --describe --group group_name 删除消费者组\nkafka-consumer-groups.sh --bootstrap-server bigdata7:9092 --delete --group group_name 查看topic消息数量\nkafka-run-class.sh kafka.tools.GetOffsetShell --bootstrap-server bigdata7:9092 --topic topic_name --time -1 ","tags":null,"title":"Basic"},{"categories":null,"contents":" #golang #cache_line\n开发中不可避免地会遇到需要对全局变量加锁的情况，而一旦并发量高了之后，加锁的变量有可能变成服务的性能瓶颈所在。所以千方百计地寻找优化方法。\n改变锁的类型 如果业务中的全局变量是读多写少的应用场景，我们可以将互斥锁改为读写锁。即读取时对变量加读锁，这样可以支持多个线程并发读取同一个变量。而只有变量需要修改时才加写锁，保证写的时候不会被其他线程读取到错误的值。\n互斥锁：\nfunc DoWork() { lock.Lock() defer lock.Unlock() // do something... } 读写锁：\nfunc Read() { lock.RLock() defer lock.RUnlock() // read global variable } func Write() { lock.Lock() defer lock.Unlock() // write global variable } 降低锁住的代码块长度 在Go中，我们常常会利用defer关键字的特性，写出如下的代码：\nfunc Write() { lock.Lock() defer lock.Unlock() // do something... } 但在实际代码中，如果对全局变量读写前后会有较长时间去做其他工作的情况下，就会造成极大的性能损耗。加锁之后没有立即对全局变量进行读写，或者对全局变量读写完之后没有立即释放锁，都会使其他线程没有办法立即抢到锁，从而拉低了整个系统的并发性能。\n根据这个逻辑，可以将上述代码改成如下格式：\nfunc Write() { // do something... lock.Lock() // read or write global variable lock.Unlock() // do something... } 但至此，也还是简单的从代码执行流程上进行了一个简单的优化。\n对数据切片 除了修改锁的类型以及修改\u0026rsquo;锁住\u0026rsquo;的代码块长度，我们还可以通过一些其他方式降低锁的粒度。\n假设我们的全局变量是一个map，我们可以对key做一个哈希后取模的操作，将原来一个map的数据分开写到多个map中。这样同一个大集合中的数据便支持了同时对多个数据进行写入而互不影响。\n取模是为了将key分到不同数据分片上，而取模之前的哈希操作是为了将不同的key均分到所有数据分片上。诚然，热点key（同一个key）还是会到同一个数据分片上。\n我们可以参考(Prometheus源码)[https://github.com/prometheus/prometheus/blob/6e3a0efe40918f72edfc89bc150bc0ece1a8c46f/tsdb/head.go#L1333] 中的写法，写出如下简化版代码：\npackage main import \u0026#34;sync\u0026#34; const ( defaultStripSize = 1 \u0026lt;\u0026lt; 16 defaultStripMask = defaultStripSize - 1 ) type stripLock struct { sync.RWMutex _ [40]byte } type StripMap struct { locks []stripLock buckets []map[uint64]interface{} } func DefaultStripMap() *StripMap { s := \u0026amp;StripMap{ locks: make([]stripLock, defaultStripSize), buckets: make([]map[uint64]interface{}, defaultStripSize), } for i := range s.buckets { s.buckets[i] = make(map[uint64]interface{}) } return s } func (s *StripMap) Set(key uint64, value interface{}) { s.locks[key\u0026amp;defaultStripMask].RLock() defer s.locks[key\u0026amp;defaultStripMask].RUnlock() s.buckets[key\u0026amp;defaultStripMask][key] = value } func (s *StripMap) Get(key uint64) (interface{}, bool) { s.locks[key\u0026amp;defaultStripMask].RLock() defer s.locks[key\u0026amp;defaultStripMask].RUnlock() v, ok := s.buckets[key\u0026amp;defaultStripMask][key] return v, ok } func (s *StripMap) Remove(key uint64) { s.locks[key\u0026amp;defaultStripMask].Lock() defer s.locks[key\u0026amp;defaultStripMask].Unlock() delete(s.buckets[key\u0026amp;defaultStripMask], key) } 在这个例子中只是简单的对key做了一个取模的操作，并没有进行哈希。如果实际业务中需要，可以采取先哈希再取模的操作。\n在上述示例代码中，有两个点可以值得我们学习，下面进行逐一分析\n使用位运算代替取模操作 a % b = a \u0026amp; (b-1)当且仅当b = 2^n时成立\nb = 2 ^ n可以写为b = 1 \u0026lt;\u0026lt; n即1左移n位。\n因而b / a即为b在二进制下向右移动n位，b % a就是a中被右移走的低n位。\nb - 1即为1 \u0026lt;\u0026lt; n - 1，二进制表示下即为n个1。\n举个栗子：\n假设n = 10 b = 2 ^ 10 = 1 \u0026lt;\u0026lt; 10 = 10 000 000 000(二进制) b - 1 = 2 ^ 10 - 1 = 1 \u0026lt;\u0026lt; 10 - 1 = 1 111 111 111(二进制) b - 1 的二进制表示即为n个1 因此key对defaultStripSize做取模操作即可写为key\u0026amp;(defaultStripSize - 1)\nCache Line 在上面的示例代码中如果不了解的话可以看到一个很奇怪的结构：\ntype stripLock struct { sync.RWMutex _ [40]byte } 其中的_ [40]byte第一次看到的时候觉得十分的困惑，这样写不是白白浪费内存么。后来发现这个写法的作用是为了提高性能而采取的措施。\ntype stripLock struct { sync.RWMutex _ [40]byte } sl := stripLock{} fmt.Println(unsafe.Sizeof(sl)) 这段代码输出为：64\n名词解析 接下来我们大概了解一下CPU中缓存工作的机制：\nCPU中缓存的最小单元是cache line，现在的处理器中的cache line通常都是64byte。因此当CPU从内存中读取数据时会读取该变量周围所有的东西。\n也就是说core1要读取变量a的时候会将a临近的b一起加载到缓存中来。\n如果同一个变量位于不同核心的cache中时，就会产生一些问题。\ncore1将变量a修改\ncore2读取变量b，这时即使b没有发生改变，也会因为在同一个cache line中其他值的改变而导致cache line丢失。所以core2会重新从内存中加载cache line中所有的变量。\n这就是所谓的假共享：一个核心的更新会导致其他核心也更新缓存。\n所以我们应尽量避免由于一个核心的修改导致其他核心重新从内存中读取数据，因为从内存中读取数据的效率要远远低于从缓存中读取数据。\n解决这个问题的办法通常是缓存填充：在变量之间填充一些无意义的变量，这将迫使一个变量单独一个核心的缓存行。这样当其他核心更新变量时，不会使该核心从内存中重新加载数据。\n验证 这是一个Go写的benchmark\n这里有个小小的花絮，由于我用的电脑是M1的CPU，而M1是基于ARM的架构。因此在这里呈现出了跟预期相反的测试结果：\n问题原因是有些处理器比如ARM、RISC-V不允许未对齐的内存访问，不会产生跨cache line的原子访问，所以不会产生split lock，而 X86 是支持的。\n而我在同事的X86电脑上得出的测试结果则是跟预期相符的。\n❯ go test -v -bench=. -benchmem -count=5 goos: darwinv -bench=. -benchmem -count=5 goarch: arm64 pkg: awesomeProject BenchmarkNoPad BenchmarkNoPad-8 1000000000 0.09975 ns/op 0 B/op 0 allocs/op BenchmarkNoPad-8 1000000000 0.09889 ns/op 0 B/op 0 allocs/op BenchmarkNoPad-8 1000000000 0.09750 ns/op 0 B/op 0 allocs/op BenchmarkNoPad-8 1000000000 0.09979 ns/op 0 B/op 0 allocs/op BenchmarkNoPad-8 1000000000 0.09916 ns/op 0 B/op 0 allocs/op BenchmarkPad BenchmarkPad-8 1000000000 0.1105 ns/op 0 B/op 0 allocs/op BenchmarkPad-8 1000000000 0.1095 ns/op 0 B/op 0 allocs/op BenchmarkPad-8 1000000000 0.1098 ns/op 0 B/op 0 allocs/op BenchmarkPad-8 1000000000 0.1095 ns/op 0 B/op 0 allocs/op BenchmarkPad-8 1000000000 0.1090 ns/op 0 B/op 0 allocs/op PASS ok awesomeProject 10.660s 延伸 当我看到上文提到的缓存填充时，第一感觉跟内存对齐有点类似，这里就重新总结一下。\n内存对齐 Go中数据类型占用内存空间大小可以参考：链接\n对齐系数 在了解如何对齐之前,我们需要了解\u0026quot;对齐系数\u0026quot;这个概念,unsafe 标准库提供了Alignof方法,可以返回一个类型的对齐系数一般来说,对齐系数在我们常用的平台的系数如下:\n32 位：4 64 位：8 对齐规则 在了解完大小和对齐系数以后,我们就可以利用对齐规则对结构体进行内存对齐:\n结构体的成员变量，第一个成员变量的偏移量为0。往后的每个成员变量的对齐值必须为编译器默认对齐长度（#pragma pack(n)）或当前成员变量类型的长度（unsafe.Sizeof），取最小值作为当前类型的对齐值。其偏移量必须为对齐值的整数倍 结构体本身，对齐值必须为编译器默认对齐长度（#pragma pack(n)）或结构体的所有成员变量类型中的最大长度，取最大数的最小整数倍作为对齐值 结合以上两点，可得知若编译器默认对齐长度（#pragma pack(n)）超过结构体内成员变量的类型最大长度时，默认对齐长度是没有任何意义的. 其中#pragma pack(n)的取值就是我们前面介绍的操作系统一般情况下的取值，即32位为4，64位为8.\n举个栗子 type Ex struct { a bool d int32 c int8 b int64 e byte } fmt.Println(unsafe.Sizeof(Ex{})) 以上代码输出结果为：32\n根据对齐规则可知，内存布局如下：\naxxx|bbbb|cxxx|xxxx|dddd|dddd|e… 但是由于整个结构体也需要对齐，可以得出，最终的内存布局为：\naxxx|bbbb|cxxx|xxxx|dddd|dddd|exxx|xxxx 对比 cache line是为了解决不同变量之在多个CPU核心之间共享的问题 内存对齐是为了解决同一个结构体内部访问效率等问题 参考链接 prometheus源码示例 What’s false sharing and how to solve it (using Golang as example) Golang和假共享(false sharing) Golang 内存对齐和伪共享False Sharing 深入剖析 split locks，i++ 可能导致的灾难 ","date":"May 13, 2022","hero":"/posts/knowledge/2001-go/007-cacheline/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2001-go/007-cacheline/","summary":"#golang #cache_line\n开发中不可避免地会遇到需要对全局变量加锁的情况，而一旦并发量高了之后，加锁的变量有可能变成服务的性能瓶颈所在。所以千方百计地寻找优化方法。\n改变锁的类型 如果业务中的全局变量是读多写少的应用场景，我们可以将互斥锁改为读写锁。即读取时对变量加读锁，这样可以支持多个线程并发读取同一个变量。而只有变量需要修改时才加写锁，保证写的时候不会被其他线程读取到错误的值。\n互斥锁：\nfunc DoWork() { lock.Lock() defer lock.Unlock() // do something... } 读写锁：\nfunc Read() { lock.RLock() defer lock.RUnlock() // read global variable } func Write() { lock.Lock() defer lock.Unlock() // write global variable } 降低锁住的代码块长度 在Go中，我们常常会利用defer关键字的特性，写出如下的代码：\nfunc Write() { lock.Lock() defer lock.Unlock() // do something... } 但在实际代码中，如果对全局变量读写前后会有较长时间去做其他工作的情况下，就会造成极大的性能损耗。加锁之后没有立即对全局变量进行读写，或者对全局变量读写完之后没有立即释放锁，都会使其他线程没有办法立即抢到锁，从而拉低了整个系统的并发性能。\n根据这个逻辑，可以将上述代码改成如下格式：\nfunc Write() { // do something... lock.Lock() // read or write global variable lock.Unlock() // do something.","tags":null,"title":"全局变量加锁的优化"},{"categories":null,"contents":" #golang\n前面几次着重讨论了在分布式系统中出现错误之后该如何处理。虽然长篇累牍谈了很多，但所谈到的情况还是过于乐观，现实则会更加复杂。我们可以根据墨菲定律做一个非常悲观的假定：即所有可能出错的事情最终一定会出错。\n作为开发者，我们的核心任务是构建可靠的系统，即使系统面临各种出错的可能，也需要完成预定的工作（确保满足用户期望）。\n所以，首先我们要充分认识目前所面临的挑战。\n比如：故障可能来自网络问题，以及时钟与时序问题等等\u0026hellip;\u0026hellip;\n在有一段工作经历中，我们的线上系统使用的是公有云，其中用到了不同地区的实例。两地区之间使用的是一条百兆带宽的专线。某个星期天的下午，领导通知我们有个服务出问题了，我查了程序日志之后，看到有许多访问上游服务网络超时的日志，即网络问题。随机运维查看之后告诉我们，上面提到的那条百兆专线被跑满了。至此，服务出问题的罪魁祸首已经找到——网络原因。当然，带宽被占满是由于业务增长还是某些服务出现bug抑或是恶意攻击，这就是另一个话题了。\n所以，在我看来，所谓网络的不可靠性并不一定特指网络本身出了什么问题。\n故障与部分失效 我们所开发的单点程序，通常会以一种确定的方式运行：要么工作，要么出错。单台节点上的软件通常不应该出现模棱两可的现象。而在分布式系统中，可能会出现系统的一部分正常工作，但其他部分出现难以预测的故障，我们称之为\u0026quot;部分失效\u0026quot;。\n问题的难点就在于这种部分失效是不确定的：如果涉及多个节点和网络，几乎肯定会碰到有时网络正常，有时则莫名地失败。\n正是由于这种不确定性和部分失效大大提高了分布式系统的复杂性。\n不可靠的网络 我们目前关注的主要是分布式无共享系统，即通过网络连接多个节点。所以网络是跨节点通信的唯一途径，并且每台机器都有自己的内存和磁盘，一台机器不能直接访问另一台机器的内存或磁盘除非通过网络向对方发出请求。\n诚然，无共享并不是构建集群系统的唯一方式，但却是当下构建互联网服务的主流方式。主要因为：硬件成本低廉，可以采用跨区域多数据中心来实现高可靠性，同时也可以给不同地域的用户提供更高的访问效率。\n在我们的网络中一个节点发送数据到另一个节点，但是网络并不能保证他什么时候到达，甚至于，不能保证何时到达。\n发送请求等待响应的过程中，有很多错误可能出现：\n请求已经丢失（比如有人拔了网线，当然在系统上云之后这种物理层面的小问题，基本可以由底层的虚拟化系统来避免和保障） 请求可能在某个队列中等待，无法马上发送或响应（比如网络发送方或接收方已经超负荷，正如文章开头所提到的例子） 远程接收节点可能已经失效（比如依赖的上游服务崩溃，不过目前基于kubernetes的系统可以在一定程度上保障服务的稳定性） 远程节点可能暂时无法响应（比如正在运行长时间的垃圾回收。可以对服务进行内存的调优，可以在基于kubernetes的系统限制内存大小同时增加实例数等等） 远程接收节点已经完成了请求处理，但回复却在网络中丢失（比如交换机配置错误） 远程接收节点已经完成了请求处理，但回复却被延迟处理（比如网络或发送者的机器超出负荷） 处理类似的问题通常可以采用超市机制：在等待一段时间之后，如果仍然没有收到回复则选择放弃，并认为响应不会到达。\n检测故障 许多系统都有自动检测节点失效这种的功能，比如\n在ES中节点超过1分钟无响应则踢出集群，而后数据分片在正常的节点上进行重建。 在kubernetes中节点失效后，集群也会自动将失效节点的任务自动负载到其他节点之上。 超时与无限期的延迟 如果超时是故障检测唯一可行的方法，那么超时应该设置多长呢？很不幸，这并没有一个标准的答案。在上面提到的ES的例子是采用了一分钟的时间，延迟1分钟是为了防止偶尔的网络延迟等，因为将某个节点踢出集群后数据分片在集群中重新分配是需要消耗资源的。\n设置较长超时则意味着更长时间的等待，才能宣告节点失效（在这期间，用户只能等待或者看到错误信息）。而较短的超时设置可以帮助更快地检测故障，但可能会出现误判，例如实际上节点只是出现短暂的性能波动（由于节点或者网络上的高负载峰值）。\n参考链接 《数据密集型应用系统设计》\n","date":"May 3, 2022","hero":"/posts/booknotes/6001-ddia/003-ddia/head.svg","permalink":"https://ormissia.github.io/posts/booknotes/6001-ddia/003-ddia/","summary":"#golang\n前面几次着重讨论了在分布式系统中出现错误之后该如何处理。虽然长篇累牍谈了很多，但所谈到的情况还是过于乐观，现实则会更加复杂。我们可以根据墨菲定律做一个非常悲观的假定：即所有可能出错的事情最终一定会出错。\n作为开发者，我们的核心任务是构建可靠的系统，即使系统面临各种出错的可能，也需要完成预定的工作（确保满足用户期望）。\n所以，首先我们要充分认识目前所面临的挑战。\n比如：故障可能来自网络问题，以及时钟与时序问题等等\u0026hellip;\u0026hellip;\n在有一段工作经历中，我们的线上系统使用的是公有云，其中用到了不同地区的实例。两地区之间使用的是一条百兆带宽的专线。某个星期天的下午，领导通知我们有个服务出问题了，我查了程序日志之后，看到有许多访问上游服务网络超时的日志，即网络问题。随机运维查看之后告诉我们，上面提到的那条百兆专线被跑满了。至此，服务出问题的罪魁祸首已经找到——网络原因。当然，带宽被占满是由于业务增长还是某些服务出现bug抑或是恶意攻击，这就是另一个话题了。\n所以，在我看来，所谓网络的不可靠性并不一定特指网络本身出了什么问题。\n故障与部分失效 我们所开发的单点程序，通常会以一种确定的方式运行：要么工作，要么出错。单台节点上的软件通常不应该出现模棱两可的现象。而在分布式系统中，可能会出现系统的一部分正常工作，但其他部分出现难以预测的故障，我们称之为\u0026quot;部分失效\u0026quot;。\n问题的难点就在于这种部分失效是不确定的：如果涉及多个节点和网络，几乎肯定会碰到有时网络正常，有时则莫名地失败。\n正是由于这种不确定性和部分失效大大提高了分布式系统的复杂性。\n不可靠的网络 我们目前关注的主要是分布式无共享系统，即通过网络连接多个节点。所以网络是跨节点通信的唯一途径，并且每台机器都有自己的内存和磁盘，一台机器不能直接访问另一台机器的内存或磁盘除非通过网络向对方发出请求。\n诚然，无共享并不是构建集群系统的唯一方式，但却是当下构建互联网服务的主流方式。主要因为：硬件成本低廉，可以采用跨区域多数据中心来实现高可靠性，同时也可以给不同地域的用户提供更高的访问效率。\n在我们的网络中一个节点发送数据到另一个节点，但是网络并不能保证他什么时候到达，甚至于，不能保证何时到达。\n发送请求等待响应的过程中，有很多错误可能出现：\n请求已经丢失（比如有人拔了网线，当然在系统上云之后这种物理层面的小问题，基本可以由底层的虚拟化系统来避免和保障） 请求可能在某个队列中等待，无法马上发送或响应（比如网络发送方或接收方已经超负荷，正如文章开头所提到的例子） 远程接收节点可能已经失效（比如依赖的上游服务崩溃，不过目前基于kubernetes的系统可以在一定程度上保障服务的稳定性） 远程节点可能暂时无法响应（比如正在运行长时间的垃圾回收。可以对服务进行内存的调优，可以在基于kubernetes的系统限制内存大小同时增加实例数等等） 远程接收节点已经完成了请求处理，但回复却在网络中丢失（比如交换机配置错误） 远程接收节点已经完成了请求处理，但回复却被延迟处理（比如网络或发送者的机器超出负荷） 处理类似的问题通常可以采用超市机制：在等待一段时间之后，如果仍然没有收到回复则选择放弃，并认为响应不会到达。\n检测故障 许多系统都有自动检测节点失效这种的功能，比如\n在ES中节点超过1分钟无响应则踢出集群，而后数据分片在正常的节点上进行重建。 在kubernetes中节点失效后，集群也会自动将失效节点的任务自动负载到其他节点之上。 超时与无限期的延迟 如果超时是故障检测唯一可行的方法，那么超时应该设置多长呢？很不幸，这并没有一个标准的答案。在上面提到的ES的例子是采用了一分钟的时间，延迟1分钟是为了防止偶尔的网络延迟等，因为将某个节点踢出集群后数据分片在集群中重新分配是需要消耗资源的。\n设置较长超时则意味着更长时间的等待，才能宣告节点失效（在这期间，用户只能等待或者看到错误信息）。而较短的超时设置可以帮助更快地检测故障，但可能会出现误判，例如实际上节点只是出现短暂的性能波动（由于节点或者网络上的高负载峰值）。\n参考链接 《数据密集型应用系统设计》","tags":null,"title":"数据密集型应用系统设计(DDIA)读书笔记"},{"categories":null,"contents":" #golang\n上一次我们主要从书中学习了主从架构消息同步相关的内容，而书中后面提到了多主节点复制（如多数据中心等）和无主节点复制（书中提到的Riak、Dynamo等并不了解，我认为最近比较火的一些区块链技术也是一些无主节点复制）。这两种模式在实际中（至少在我的认知范围内中小体量的公司基本不会维护一些多数据中心的场景）并不常见，这里不再过多讨论。\n在一个单独的主从复制架构中，主节点和所有从节点都需要保存全量的数据。在项目初期，如果对未来的数据增量没有一个相对准确的判断，在业务发展一段时间之后应用就会遇到性能瓶颈，同时也有可能面临扩容困难等一系列问题。因此，分片的机制应运而生。\n数据分区与数据复制 分区通常与复制相结合，即每一个分区的复制都是一个完整的主从架构的复制，而每个分区都会在多个节点上拥有相同的（不考虑微观上的延迟）副本，这意味着某条记录属于特定分区，而同样的内容会被保存到不同节点上以提高系统的容错性，这样即使某一个节点失效也不会影响整个集群的运行。\n键-值数据的分区 面对海量的数据如何决定哪一条记录该放在哪个分区上呢？分区的主要目标就是将数据和查询负载均匀地分布在所有节点上。\n而如果分区不均匀，就会出现某些分区节点比其他分区承担了更多的任务，即为数据倾斜。数据倾斜会导致分区效率严重下降以至于丧失了既定的目标。\n避免热点最简单的办法是将数据随机分配到所有节点上。这种方法可以比较均匀地分布数据，但也有一个致命的缺点：如此写入到集群中的数据是无法通过特定key来读取的，因为没有办法知道数据保存在哪个节点上，所以不得不查询所有节点。\n简单的改进方法可以通过key来分配分区，比如a-z的单词根据首字母分配到26个节点上。\n基于关键字区间分区 假如上述根据单纯根据首字母字来分区时没有26个节点，那就需要将某些临近的字母放到同一个分区中，比如ab放到第一个分区，cd放到第二个分区\u0026hellip;\u0026hellip;依次类推，26个字母需要13个节点即可放完。\n但是基于关键字区间的分区也存在缺点，某些访问模式会导致热点。假如使用时间戳作为关键字，每一天的数据写入到一个分区中时，就会使这个分区成为热点。而其他分区始终处于空闲状态。\n为了避免上述问题，可以在时间戳以外加入其他内容，比如数据类型等\n基于关键字哈希值分区 对于上述数据倾斜与热点问题，许多分布式系统采用了基于关键字哈希函数的方式来分区。\n一个好的哈希函数可以处理数据倾斜并使其均匀分布，这样从整体来看可以使数据均匀的分布到所有分区上。\n负载倾斜与热点 如上所述，基于哈希的分区方法可以减轻热点，但依然无法完全避免。一个极端情况是所有读写都是针对同一个key进行的，则最终的请求都会被路由到同一个分区中。比如某个明星又离婚了等等\u0026hellip;\n而最让人困扰的是，数据倾斜的问题不光会出现在这些基础设施（指分布式存储，一些消息中间件等）中，也会出现在我们的应用层中。比如，为了防止数据乱序（有时候乱序的数据会给下游处理带来压力，比如Flink处理乱序数据产生的延迟问题。再者相同key发往不同分区时也会使Flink处理数据时产生大量的Shuffle带来的网络IO压力）从而采用哈希等方法将数据写入kafka的partition中。\n即使采用了哈希分区的方法，如果出现某个热点key产生大量数据，就会造成数据倾斜。严重时将导致Kafka集群中某几个节点（主分片和所有副本所在的节点）磁盘被写满，进而导致整个集群不可用引发生产故障。\n针对这个特特定的场景，由于同一key的数据可以在较长一段时间后忍受分区发生改变，因此可以在几个小时以后改变一次分区选择规则。诚然，这个办法并不能推广到所有数据倾斜问题的解决中。\n分区与二级索引 上面讨论的分区方案都依赖于键值的数据模型（其实我个人认为，多数数据存储莫不如此，即便是回到MySQL也是通过主键查询，要么回表，再要么全表扫描）。键值模型相对简单，即都是通过关键字来访问记录。但是涉及到二级索引，情况就会变得复杂。\n考虑到其复杂性，部分存储并不支持二级索引，如HBase作为一个面向列的存储，为了兼顾大数据量写入和OLAP场景的应用，并不支持二级索引。但是二级索引则是ES等一些全文搜索引擎的根本值所在。\n而二级索引也是需要存储到不同分区中的，目前主要有两种方法来支持二级索引进行分区：\n基于文档的分区 基于此条的分区 基于文档分区的二级索引 基于文档的分区是将所有二级索引在每个分区中都存了一个词条，而每个分区中的二级索引只记录自己分区的数据。\n如果需要通过二级索引查询数据，就需要每一个分区的二级索引，再做统一处理。因此会导致读延迟显著放大。\n基于此条的二级索引分区 基于词条的二级索引分区即与数据分区类似，二级索引的词条被放入所有分区，每个词条只存在于某一个分区（不考虑副本）。\n这种方法对比前者，好处就是读取更为高效，不需要遍历所有分区的二级索引。相反这种方案写入性能相对较低，因为一个文档里面可能涉及到多个二级索引，而二级索引的分区又可能完全不同甚至不在同一节点上，由此势必引入显著的写放大。\n而正因如此，实践中对全局二级索引的更新往往都是异步的。\n参考链接 《数据密集型应用系统设计》\n","date":"May 1, 2022","hero":"/posts/booknotes/6001-ddia/002-ddia/head.svg","permalink":"https://ormissia.github.io/posts/booknotes/6001-ddia/002-ddia/","summary":"#golang\n上一次我们主要从书中学习了主从架构消息同步相关的内容，而书中后面提到了多主节点复制（如多数据中心等）和无主节点复制（书中提到的Riak、Dynamo等并不了解，我认为最近比较火的一些区块链技术也是一些无主节点复制）。这两种模式在实际中（至少在我的认知范围内中小体量的公司基本不会维护一些多数据中心的场景）并不常见，这里不再过多讨论。\n在一个单独的主从复制架构中，主节点和所有从节点都需要保存全量的数据。在项目初期，如果对未来的数据增量没有一个相对准确的判断，在业务发展一段时间之后应用就会遇到性能瓶颈，同时也有可能面临扩容困难等一系列问题。因此，分片的机制应运而生。\n数据分区与数据复制 分区通常与复制相结合，即每一个分区的复制都是一个完整的主从架构的复制，而每个分区都会在多个节点上拥有相同的（不考虑微观上的延迟）副本，这意味着某条记录属于特定分区，而同样的内容会被保存到不同节点上以提高系统的容错性，这样即使某一个节点失效也不会影响整个集群的运行。\n键-值数据的分区 面对海量的数据如何决定哪一条记录该放在哪个分区上呢？分区的主要目标就是将数据和查询负载均匀地分布在所有节点上。\n而如果分区不均匀，就会出现某些分区节点比其他分区承担了更多的任务，即为数据倾斜。数据倾斜会导致分区效率严重下降以至于丧失了既定的目标。\n避免热点最简单的办法是将数据随机分配到所有节点上。这种方法可以比较均匀地分布数据，但也有一个致命的缺点：如此写入到集群中的数据是无法通过特定key来读取的，因为没有办法知道数据保存在哪个节点上，所以不得不查询所有节点。\n简单的改进方法可以通过key来分配分区，比如a-z的单词根据首字母分配到26个节点上。\n基于关键字区间分区 假如上述根据单纯根据首字母字来分区时没有26个节点，那就需要将某些临近的字母放到同一个分区中，比如ab放到第一个分区，cd放到第二个分区\u0026hellip;\u0026hellip;依次类推，26个字母需要13个节点即可放完。\n但是基于关键字区间的分区也存在缺点，某些访问模式会导致热点。假如使用时间戳作为关键字，每一天的数据写入到一个分区中时，就会使这个分区成为热点。而其他分区始终处于空闲状态。\n为了避免上述问题，可以在时间戳以外加入其他内容，比如数据类型等\n基于关键字哈希值分区 对于上述数据倾斜与热点问题，许多分布式系统采用了基于关键字哈希函数的方式来分区。\n一个好的哈希函数可以处理数据倾斜并使其均匀分布，这样从整体来看可以使数据均匀的分布到所有分区上。\n负载倾斜与热点 如上所述，基于哈希的分区方法可以减轻热点，但依然无法完全避免。一个极端情况是所有读写都是针对同一个key进行的，则最终的请求都会被路由到同一个分区中。比如某个明星又离婚了等等\u0026hellip;\n而最让人困扰的是，数据倾斜的问题不光会出现在这些基础设施（指分布式存储，一些消息中间件等）中，也会出现在我们的应用层中。比如，为了防止数据乱序（有时候乱序的数据会给下游处理带来压力，比如Flink处理乱序数据产生的延迟问题。再者相同key发往不同分区时也会使Flink处理数据时产生大量的Shuffle带来的网络IO压力）从而采用哈希等方法将数据写入kafka的partition中。\n即使采用了哈希分区的方法，如果出现某个热点key产生大量数据，就会造成数据倾斜。严重时将导致Kafka集群中某几个节点（主分片和所有副本所在的节点）磁盘被写满，进而导致整个集群不可用引发生产故障。\n针对这个特特定的场景，由于同一key的数据可以在较长一段时间后忍受分区发生改变，因此可以在几个小时以后改变一次分区选择规则。诚然，这个办法并不能推广到所有数据倾斜问题的解决中。\n分区与二级索引 上面讨论的分区方案都依赖于键值的数据模型（其实我个人认为，多数数据存储莫不如此，即便是回到MySQL也是通过主键查询，要么回表，再要么全表扫描）。键值模型相对简单，即都是通过关键字来访问记录。但是涉及到二级索引，情况就会变得复杂。\n考虑到其复杂性，部分存储并不支持二级索引，如HBase作为一个面向列的存储，为了兼顾大数据量写入和OLAP场景的应用，并不支持二级索引。但是二级索引则是ES等一些全文搜索引擎的根本值所在。\n而二级索引也是需要存储到不同分区中的，目前主要有两种方法来支持二级索引进行分区：\n基于文档的分区 基于此条的分区 基于文档分区的二级索引 基于文档的分区是将所有二级索引在每个分区中都存了一个词条，而每个分区中的二级索引只记录自己分区的数据。\n如果需要通过二级索引查询数据，就需要每一个分区的二级索引，再做统一处理。因此会导致读延迟显著放大。\n基于此条的二级索引分区 基于词条的二级索引分区即与数据分区类似，二级索引的词条被放入所有分区，每个词条只存在于某一个分区（不考虑副本）。\n这种方法对比前者，好处就是读取更为高效，不需要遍历所有分区的二级索引。相反这种方案写入性能相对较低，因为一个文档里面可能涉及到多个二级索引，而二级索引的分区又可能完全不同甚至不在同一节点上，由此势必引入显著的写放大。\n而正因如此，实践中对全局二级索引的更新往往都是异步的。\n参考链接 《数据密集型应用系统设计》","tags":null,"title":"数据密集型应用系统设计(DDIA)读书笔记"},{"categories":null,"contents":" #golang\n通常在生产中存储结构化数据最常用的是MySQL，而MySQL底层存储用的数据结构是B+树。当并发量达到一定程度之后通常会将单点的MySQL拆分成主从架构（在这之前可以加入内存型缓存如Redis等，属于不同层级的解决办法，不在此文讨论范畴）。\n问题产生 在主从架构中主要问题之一有复制滞后。\n这里以MySQL集群为例，主从复制要求所有写请求都经由主节点，而从节点只接收只读的查询请求（这一点在ES/Kafka的多副本分片中也有类似体现，主分片写入，从分片只支持读取）。对于读操作密集的负载（如web），这是一个不错的选择。\n在这种扩展体系下，只需增加更多的从节点，就可以提高读请求的吞吐量。但是，这种方法在实际生产中只能用于异步复制，如果试图同步所有的从副本（即强一致性），则单个副本的写入失败将使数据在整个集群中写入失败。并且节点越多，发生故障的概率越高，所以以完全同步来设计系统在现实中反而非常不可靠。\n在Kafka集群中为了提高消息吞吐量时与副本同步相关的设置通常会将acks设置为1或者0（1/0的区别在于leader是否落盘），partition的leader收到数据后即代表集群收到消息\n说回到MySQL的主从集群，从上文中得到的结论，如果采用异步复制的话，很不幸如果一个应用正好从一个异步的从节点中读取数据，而该副本落后于主节点，这时应用读到的是过期的消息，表现在用户面前就会产生薛定谔的数据，即在同一时刻查询会出现两种截然不同的数据。\n不过这个不一致的状态只是暂时的，经过一段时间之后，从节点的数据会更新到与主节点保持一致，即最终一致性。\n解决办法 由于网络等原因导致的不一致性，不仅仅是存在于理论中，其是个实实在在的现实问题。下面分析复制滞后可能出现的问题，并找出相应的解决思路。\n读自己的写 举个栗子：\n当用户提交一些数据，然后刷新页面查看刚刚修改的内容时，例如用户信息，或者是对于一些帖子的评论等。提交新数据必须发送到主节点，但是当用户取数据时，数据可能来自从节点。\n当集群是异步复制时就会出现问题，用户在数据写入到主节点而尚未达到从节点时刷新页面，看到的是数据修改之前的状态。这将给用户带来困惑。延伸到一些库存类型的应用，其实并不会导致超卖。如果用户看到是旧状态，误认为操作失败重新走了一遍流程，这时写入请求依然是访问到主节点，而主节点的数据是最新的，会返回失败。而这将进一步给用户带来困扰。\n对于这种情况，我们需要\u0026quot;写后读一致性\u0026quot;，该机制保证用户重新加载页面，总是能看到自己最新更新的数据。但对于其他用户看这条信息没有任何保证\n方案一 总是从主节点读取用户可能会修改的信息，否则在从节点读取。即，从用户访问自己的信息时候从主节点读取，访问其他人的信息时候在从节点读取。\n方案二 在客户端记住最近更新的时间戳，并附带在请求中。如果查到的数据不够新，则从其他副本中重新查询，或者直接从主节点中查询。\n方案三 如果副本分布在多个数据中心（地理位置上的多个机房）等，就必须把请求路由到主节点所在的数据中心。至少目前还没有接触过这种项目，没有很深的理解，不过多讨论这种情况。\n此外，依然存在一些其他问题需要考虑，如用户在多个设备上登录，这样一个设备就无法知道其他设备上进行了什么操作，如果采用方案二的话，依然会出现不一致。\n单调读 在上述第二个例子中，出现了用户数据向后回滚的情况。\n假设用户从不同副本进行了多次读取，用户刷新了一个网页，该请求可能会被随机路由到某一个从节点。用户2345先后在两个从节点上执行了两次完全相同的查询（先是少量滞后的从节点，然后是滞后很大的从节点），则很有可能出现以下情况。\n第一个查询返回了最近用户1234所添加的评论，但第二个查询结果代表了更早时间点的状态。如果第一个查询没有返回任何内容，用户2345并不知道用户1234最近的评论，情况还好。但当用户2345看到了用户1234的评论之后，紧接着评论又消失了，就会感到十分困惑。\n阿b(bilibili)的评论系统在使用中出现过类型的现象，但不清楚是否是由于审核等一些其他因素造成的。总之是在一个新视频发布后去刷新评论，第一次看到有人评论了，再次刷新评论又消失了。\n单调读一致性可以确保不会发生这种异常。这是一个比强一致性弱，但比最终一致性强的保证。即保证用户依次进行多次读取，绝不会看到回滚的现象。\n实现单调读的一种方式是，确保每个用户总是从固定的同一副本执行读操作（不同的用户当然可以从不同的副本读取）。例如，使用用户ID的哈希来决定去哪个副本读取消息，但如果该副本失效，系统必须要有能力将查询重新路由到其他有效的副本上。\n前缀一致读 第三个由于复制滞后导致反常的例子。\n比如A和B之间以下的对话：\nA： 请问B，你能听到吗？ B： 你好A，我能听到 这两句话之间存在因果关系，即B听到了A的问题，然后再去回答。\n现在如果有第三人在通过从节点上收听上述对话。假设B发的消息先同步了，观察者看到的对话就变成了这样：\nB： 你好A，我能听到 A： 请问B，你能听到吗？ 这逻辑就变得混乱了。\n防止这种异常需要引入另一种保证：前缀一致读。该保证是说，对于一系列按照某个顺序发生的写请求，那么读取这些内容时必须要按照当时写入的顺序\n小结 上面讨论的是在保证最终一致性异步复制的情况下发生的。当系统决不能忍受这些问题时，那就必须采用强一致性，但随之而来的就是写入性能低下，故障率高，一个节点故障引发整个集群不可用等各种问题。都需要在应用开始进行得失的平衡。\n再举个栗子：\n在kafka这种对写入性能要求极高的应用中，如果发送的消息不是特别重要，有要求极高吞吐量的时候，比如日志收集等，则可以设置为Leader收到消息即代表成功 而在ES中，则必须要求数据分片的所有副本都写入成功才返回成功，采用了强一致性。而ES采用了健康检查，超过1分钟不活跃的节点就剔除集群等机制，从而保证了数据可以实时地写入。 延伸 结合到实际工作中的项目分析，也存在类似问题。\n下面举两个类似的栗子：\n例一 在某基础信息管理平台中需要一个模糊搜索的功能，各方面平衡之后采用在应用内存中使用前缀树的方式做缓存。由于应用是多实例的，这时数据的增删改就会在多实例之间存在一个短暂的不一致。\n例二 在某数据处理应用中，由于每一条数据中需要有多个（一到十几不等）条目访问缓存。开始的时候将缓存放在Redis里，而应用访问Redis的时间大概需要十几到几十毫秒的时间，这样每一条数据的处理时间就在几十毫秒到几百毫秒之间。而使用多线程处理，则会造成消息的严重乱序。\n测试下来，程序每秒只能处理不超过20条数据，大大影响了效率。而后将缓存改到内存中，省掉了访问Redis的时间，再结合Kafka的一些优化策略，极大的提高了应用吞吐量。测试后每秒大概可以处理几千条数据。缓存放到程序内存中之后，也同样会出现缓存不一致的问题。\n下面是这两个应用中采用的一个缓存架构图：\n在这个架构中，如果某个实例接收Redis消息慢了，就会出现不同实例间的数据不一致\n参考链接 《数据密集型应用系统设计》\n","date":"April 30, 2022","hero":"/posts/booknotes/6001-ddia/001-ddia/head.svg","permalink":"https://ormissia.github.io/posts/booknotes/6001-ddia/001-ddia/","summary":"#golang\n通常在生产中存储结构化数据最常用的是MySQL，而MySQL底层存储用的数据结构是B+树。当并发量达到一定程度之后通常会将单点的MySQL拆分成主从架构（在这之前可以加入内存型缓存如Redis等，属于不同层级的解决办法，不在此文讨论范畴）。\n问题产生 在主从架构中主要问题之一有复制滞后。\n这里以MySQL集群为例，主从复制要求所有写请求都经由主节点，而从节点只接收只读的查询请求（这一点在ES/Kafka的多副本分片中也有类似体现，主分片写入，从分片只支持读取）。对于读操作密集的负载（如web），这是一个不错的选择。\n在这种扩展体系下，只需增加更多的从节点，就可以提高读请求的吞吐量。但是，这种方法在实际生产中只能用于异步复制，如果试图同步所有的从副本（即强一致性），则单个副本的写入失败将使数据在整个集群中写入失败。并且节点越多，发生故障的概率越高，所以以完全同步来设计系统在现实中反而非常不可靠。\n在Kafka集群中为了提高消息吞吐量时与副本同步相关的设置通常会将acks设置为1或者0（1/0的区别在于leader是否落盘），partition的leader收到数据后即代表集群收到消息\n说回到MySQL的主从集群，从上文中得到的结论，如果采用异步复制的话，很不幸如果一个应用正好从一个异步的从节点中读取数据，而该副本落后于主节点，这时应用读到的是过期的消息，表现在用户面前就会产生薛定谔的数据，即在同一时刻查询会出现两种截然不同的数据。\n不过这个不一致的状态只是暂时的，经过一段时间之后，从节点的数据会更新到与主节点保持一致，即最终一致性。\n解决办法 由于网络等原因导致的不一致性，不仅仅是存在于理论中，其是个实实在在的现实问题。下面分析复制滞后可能出现的问题，并找出相应的解决思路。\n读自己的写 举个栗子：\n当用户提交一些数据，然后刷新页面查看刚刚修改的内容时，例如用户信息，或者是对于一些帖子的评论等。提交新数据必须发送到主节点，但是当用户取数据时，数据可能来自从节点。\n当集群是异步复制时就会出现问题，用户在数据写入到主节点而尚未达到从节点时刷新页面，看到的是数据修改之前的状态。这将给用户带来困惑。延伸到一些库存类型的应用，其实并不会导致超卖。如果用户看到是旧状态，误认为操作失败重新走了一遍流程，这时写入请求依然是访问到主节点，而主节点的数据是最新的，会返回失败。而这将进一步给用户带来困扰。\n对于这种情况，我们需要\u0026quot;写后读一致性\u0026quot;，该机制保证用户重新加载页面，总是能看到自己最新更新的数据。但对于其他用户看这条信息没有任何保证\n方案一 总是从主节点读取用户可能会修改的信息，否则在从节点读取。即，从用户访问自己的信息时候从主节点读取，访问其他人的信息时候在从节点读取。\n方案二 在客户端记住最近更新的时间戳，并附带在请求中。如果查到的数据不够新，则从其他副本中重新查询，或者直接从主节点中查询。\n方案三 如果副本分布在多个数据中心（地理位置上的多个机房）等，就必须把请求路由到主节点所在的数据中心。至少目前还没有接触过这种项目，没有很深的理解，不过多讨论这种情况。\n此外，依然存在一些其他问题需要考虑，如用户在多个设备上登录，这样一个设备就无法知道其他设备上进行了什么操作，如果采用方案二的话，依然会出现不一致。\n单调读 在上述第二个例子中，出现了用户数据向后回滚的情况。\n假设用户从不同副本进行了多次读取，用户刷新了一个网页，该请求可能会被随机路由到某一个从节点。用户2345先后在两个从节点上执行了两次完全相同的查询（先是少量滞后的从节点，然后是滞后很大的从节点），则很有可能出现以下情况。\n第一个查询返回了最近用户1234所添加的评论，但第二个查询结果代表了更早时间点的状态。如果第一个查询没有返回任何内容，用户2345并不知道用户1234最近的评论，情况还好。但当用户2345看到了用户1234的评论之后，紧接着评论又消失了，就会感到十分困惑。\n阿b(bilibili)的评论系统在使用中出现过类型的现象，但不清楚是否是由于审核等一些其他因素造成的。总之是在一个新视频发布后去刷新评论，第一次看到有人评论了，再次刷新评论又消失了。\n单调读一致性可以确保不会发生这种异常。这是一个比强一致性弱，但比最终一致性强的保证。即保证用户依次进行多次读取，绝不会看到回滚的现象。\n实现单调读的一种方式是，确保每个用户总是从固定的同一副本执行读操作（不同的用户当然可以从不同的副本读取）。例如，使用用户ID的哈希来决定去哪个副本读取消息，但如果该副本失效，系统必须要有能力将查询重新路由到其他有效的副本上。\n前缀一致读 第三个由于复制滞后导致反常的例子。\n比如A和B之间以下的对话：\nA： 请问B，你能听到吗？ B： 你好A，我能听到 这两句话之间存在因果关系，即B听到了A的问题，然后再去回答。\n现在如果有第三人在通过从节点上收听上述对话。假设B发的消息先同步了，观察者看到的对话就变成了这样：\nB： 你好A，我能听到 A： 请问B，你能听到吗？ 这逻辑就变得混乱了。\n防止这种异常需要引入另一种保证：前缀一致读。该保证是说，对于一系列按照某个顺序发生的写请求，那么读取这些内容时必须要按照当时写入的顺序\n小结 上面讨论的是在保证最终一致性异步复制的情况下发生的。当系统决不能忍受这些问题时，那就必须采用强一致性，但随之而来的就是写入性能低下，故障率高，一个节点故障引发整个集群不可用等各种问题。都需要在应用开始进行得失的平衡。\n再举个栗子：\n在kafka这种对写入性能要求极高的应用中，如果发送的消息不是特别重要，有要求极高吞吐量的时候，比如日志收集等，则可以设置为Leader收到消息即代表成功 而在ES中，则必须要求数据分片的所有副本都写入成功才返回成功，采用了强一致性。而ES采用了健康检查，超过1分钟不活跃的节点就剔除集群等机制，从而保证了数据可以实时地写入。 延伸 结合到实际工作中的项目分析，也存在类似问题。\n下面举两个类似的栗子：\n例一 在某基础信息管理平台中需要一个模糊搜索的功能，各方面平衡之后采用在应用内存中使用前缀树的方式做缓存。由于应用是多实例的，这时数据的增删改就会在多实例之间存在一个短暂的不一致。\n例二 在某数据处理应用中，由于每一条数据中需要有多个（一到十几不等）条目访问缓存。开始的时候将缓存放在Redis里，而应用访问Redis的时间大概需要十几到几十毫秒的时间，这样每一条数据的处理时间就在几十毫秒到几百毫秒之间。而使用多线程处理，则会造成消息的严重乱序。\n测试下来，程序每秒只能处理不超过20条数据，大大影响了效率。而后将缓存改到内存中，省掉了访问Redis的时间，再结合Kafka的一些优化策略，极大的提高了应用吞吐量。测试后每秒大概可以处理几千条数据。缓存放到程序内存中之后，也同样会出现缓存不一致的问题。\n下面是这两个应用中采用的一个缓存架构图：\n在这个架构中，如果某个实例接收Redis消息慢了，就会出现不同实例间的数据不一致\n参考链接 《数据密集型应用系统设计》","tags":null,"title":"数据密集型应用系统设计(DDIA)读书笔记"},{"categories":null,"contents":" #http-code\nhttp协议（超文本传输协议） 是客户端和服务器端两者通信共同遵循的一些规则。主要内容是定义了客户端如何向服务器请求资源，服务器如何响应客户端请求。\n请求中的POST与GET方法的区别\nget是从服务器上获取数据，post是向服务器传送数据。 在客户端，Get方式在通过URL提交数据，数据在URL中可以看到；POST方式，数据放置在HTML HEADER内提交。 对于get方式，服务器端用Request.QueryString获取变量的值，对于post方式，服务器端用Request.Form获取提交的数据。 GET方式提交的数据最多只能有1024字节，而POST则没有此限制。 安全性问题。正如在（1）中提到，使用 GET 的时候，参数会显示在地址栏上，而 Post 不会。所以，如果这些数据是中文数据而且是非敏感数据，那么使用 GET；如果用户输入的数据不是中文字符而且包含敏感数据，那么还是使用 post为好。 HTTP 1.0 HTTP 1.0规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接\n当一个网页文件中包含了很多图像的地址的时候，那就需要很多次的HTTP请求和响应，每次请求和响应都需要一个单独的连接，每次连接只是传输一个文档和图像，上一次和下一次请求完全分离。即使图像文件都很小，但是客户端和服务器端每次建立和关闭连接却是一个相对比较费时的过程，并且会严重影响客户机和服务器的性能。当一个网页文件中包含JS文件，CSS文件等内容时，也会出现类似上述的情况。\nHTTP 1.1 为了克服HTTP 1.0的这个缺陷，HTTP 1.1支持持久连接（HTTP/1.1的默认模式使用带流水线的持久连接），在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。一个包含有许多图像的网页文件的多个请求和应答可以在一个连接中传输，但每个单独的网页文件的请求和应答仍然需要使用各自的连接。\nHTTP 1.1还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容，这样也显著地减少了整个下载过程所需要的时间。\n在HTTP 1.1，request和response头中都有可能出现一个connection的头，此header的含义是当client和server通信时对于长链接如何进行处理。\n在HTTP 1.1中，client和server都是默认对方支持长链接的， 如果client使用HTTP 1.1协议，但又不希望使用长链接，则需要在header中指明connection的值为close；如果server方也不想支持长链接，则在response中也需要明确说明connection的值为close。不论request还是response的header中包含了值为close的connection，都表明当前正在使用的tcp链接在当天请求处理完毕后会被断掉。以后client再进行新的请求时就必须创建新的tcp链接了。\nHTTP 1.1在继承了HTTP 1.0优点的基础上，也克服了HTTP 1.0的性能问题。\nHTTP 1.1通过增加更多的请求头和响应头来改进和扩充HTTP 1.0的功能。如，HTTP 1.0不支持Host请求头字段，浏览器无法使用主机头名来明确表示要访问服务器上的哪个WEB站点，这样就无法使用WEB服务器在同一个IP地址和端口号上配置多个虚拟WEB站点。在HTTP 1.1中增加Host请求头字段后，WEB浏览器可以使用主机头名来明确表示要访问服务器上的哪个WEB站点，这才实现了在一台WEB服务器上可以在同一个IP地址和端口号上使用不同的主机名来创建多个虚拟WEB站点。HTTP 1.1的持续连接，也需要增加新的请求头来帮助实现，例如，Connection请求头的值为Keep-Alive时，客户端通知服务器返回本次请求结果后保持连接；Connection请求头的值为close时，客户端通知服务器返回本次请求结果后关闭连接。HTTP 1.1还提供了与身份认证、状态管理和Cache缓存等机制相关的请求头和响应头。HTTP 1.0不支持文件断点续传，RANGE:bytes是HTTP 1.1新增内容，HTTP 1.0每次传送文件都是从文件头开始，即0字节处开始。RANGE:bytes=XXXX表示要求服务器从文件XXXX字节处开始传送，这就是我们平时所说的断点续传。\nHTTP 1.1和HTTP 1.0协议的区别 缓存处理 带宽优化及网络连接的使用 错误通知的管理 消息在网络中的发送 互联网地址的维护 安全性及完整性 HTTP 1.x和HTTP 2协议的区别 二进制分帧：HTTP 2采用二进制格式传输数据，而非HTTP 1.x的文本格式 头部压缩：头部表在HTTP 2的连接存续期内始终存在，由客户端和服务器共同渐进地更新。请求一发送了所有的头部字段，第二个请求则只需要发送差异数据，这样可以减少冗余数据，降低开销 多路复用：直白的说就是所有的请求都是通过一个TCP连接并发完成。HTTP 1.x虽然通过pipeline也能并发请求，但是多个请求之间的响应会被阻塞的，所以pipeline至今也没有被普及应用，而HTTP 2做到了真正的并发请求。同时，流还支持优先级和流量控制。 服务器推送：服务端能够更快的把资源推送给客户端。例如服务端可以主动把JS和CSS文件推送给客户端，而不需要客户端解析HTML再发送这些请求。当客户端需要的时候，它已经在客户端了。 HTTP 2主要是HTTP 1.x在底层传输机制上的完全重构，HTTP 2是基本兼容HTTP 1.x的语义。Content-Type仍然是Content-Type，只不过它不再是文本传输了。\nHTTP和HTTPS协议的区别 HTTP的URL以http://开头，而HTTPS的URL以https://开头 HTTP是不安全的，而HTTPS是安全的 HTTP标准端口是80，而HTTPS的标准端口是443 在OSI网络模型中，HTTP工作于应用层，而HTTPS的安全传输机制工作在传输层 HTTP无法加密，而HTTPS对传输的数据进行加密 HTTP无需证书，而HTTPS需要CA机构颁发的SSL证书 常用的请求方式 GET:请求获取Request-URI所标识的资源 POST:在Request-URI所标识的资源后附加新的数据 HEAD:请求获取由Request-URI所标识的资源的响应消息报头 PUT:请求服务器存储一个资源，并用Request-URI作为其标识 DELETE:请求服务器删除Request-URI所标识的资源 TRACE:请求服务器回送收到的请求信息，主要用于测试或诊断 CONNECT:保留将来使用 OPTIONS:请求查询服务器的性能，或者查询与资源相关的选项和需求 GET方法：在浏览器的地址栏中输入网址的方式访问网页时，浏览器采用GET方法向服务器获取资源，POST方法要求被请求服务器接受附在请求后面的数据，常用于提交表单。GET是用于获取数据的，POST一般用于将数据发给服务器之用。\nHTTP响应状态码 1XX:信息性状态码 2XX:成功状态码 3XX:重定向状态码 4XX:客户端错误状态码 5XX:服务端错误状态码 常见的状态码 2XX 200:表示从客户端发出的请求在服务端正常被处理且返回 204:表示服务器接收的请求已成功处理，但在返回的响应报文中不含实体的主体部分。比如，当从浏览器发出请求处理后，返回204响应，那么浏览器显示的页面不发生更新 206:该状态码表示客户端进行了范围请求，而服务器成功执行了这部分的GET请求 3XX 301:永久性重定向。该状态码表示请求的资源已经被分配了新的URI，以后应使用资源现在所指的URI。 当指定的资源路径的最后忘记添加斜杠\u0026quot;/\u0026quot;，就会产生301状态码 302:临时性重定向。该状态码表示请求的资源已被分配了新的URI，希望用户(本次)能使用新的URI访问 303:该状态码表示由于请求对应的资源存在另外一个URI，应使用GET方法定向获取请求的资源。 303状态码和302状态码有着相同的功能，但303状态码明确表明客户端应当采用GET方法获取资源。 当301，302，303响应状态码返回时，几乎所有的浏览器都会把POST改成GET，并删除请求报文的主体，之后请求会自动再次发送。 301，302标准是禁止将POST方法改变成GET方法的，但实际上使用时大家都会这么做。 304:该状态码表示客户端发送附带条件的请求时，服务器端允许请求访问资源，但未满足条件的情况。304状态码返回时，不包含任何响应的主体部分。304虽然被划分在3XX类别中，但是和重定向没有关系 307:临时重定向。该状态码与302 Found有着相同的含义。307会遵照浏览器标准，不会从POST变成GET 4XX 400:该状态码表示请求报文中存在语法错误。当错误发生时，需要修改请求的内容后再次放松请求 401:该状态码表示发送的请求需要有通过HTTP认证的认证信息，另外若之前已进行过1此请求，则表示用户认证失败 403:该状态码表明对请求资源的访问被服务器拒绝了 404:该状态码表明服务器上无法找到请求的资源 5XX 500:该状态码表明服务器端在执行请求时发生了错误 503:该状态码表明服务器暂时处于超负载或正在进行停机维护，现在无法处理请求 参考连接 综合阐述http1.0/1.1/2和https 说说 HTTP1.0/1.1/2.0 的区别 ","date":"March 31, 2022","hero":"/posts/knowledge/2004-network/002-http_statuscode/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2004-network/002-http_statuscode/","summary":"#http-code\nhttp协议（超文本传输协议） 是客户端和服务器端两者通信共同遵循的一些规则。主要内容是定义了客户端如何向服务器请求资源，服务器如何响应客户端请求。\n请求中的POST与GET方法的区别\nget是从服务器上获取数据，post是向服务器传送数据。 在客户端，Get方式在通过URL提交数据，数据在URL中可以看到；POST方式，数据放置在HTML HEADER内提交。 对于get方式，服务器端用Request.QueryString获取变量的值，对于post方式，服务器端用Request.Form获取提交的数据。 GET方式提交的数据最多只能有1024字节，而POST则没有此限制。 安全性问题。正如在（1）中提到，使用 GET 的时候，参数会显示在地址栏上，而 Post 不会。所以，如果这些数据是中文数据而且是非敏感数据，那么使用 GET；如果用户输入的数据不是中文字符而且包含敏感数据，那么还是使用 post为好。 HTTP 1.0 HTTP 1.0规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接\n当一个网页文件中包含了很多图像的地址的时候，那就需要很多次的HTTP请求和响应，每次请求和响应都需要一个单独的连接，每次连接只是传输一个文档和图像，上一次和下一次请求完全分离。即使图像文件都很小，但是客户端和服务器端每次建立和关闭连接却是一个相对比较费时的过程，并且会严重影响客户机和服务器的性能。当一个网页文件中包含JS文件，CSS文件等内容时，也会出现类似上述的情况。\nHTTP 1.1 为了克服HTTP 1.0的这个缺陷，HTTP 1.1支持持久连接（HTTP/1.1的默认模式使用带流水线的持久连接），在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。一个包含有许多图像的网页文件的多个请求和应答可以在一个连接中传输，但每个单独的网页文件的请求和应答仍然需要使用各自的连接。\nHTTP 1.1还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容，这样也显著地减少了整个下载过程所需要的时间。\n在HTTP 1.1，request和response头中都有可能出现一个connection的头，此header的含义是当client和server通信时对于长链接如何进行处理。\n在HTTP 1.1中，client和server都是默认对方支持长链接的， 如果client使用HTTP 1.1协议，但又不希望使用长链接，则需要在header中指明connection的值为close；如果server方也不想支持长链接，则在response中也需要明确说明connection的值为close。不论request还是response的header中包含了值为close的connection，都表明当前正在使用的tcp链接在当天请求处理完毕后会被断掉。以后client再进行新的请求时就必须创建新的tcp链接了。\nHTTP 1.1在继承了HTTP 1.0优点的基础上，也克服了HTTP 1.0的性能问题。\nHTTP 1.1通过增加更多的请求头和响应头来改进和扩充HTTP 1.0的功能。如，HTTP 1.0不支持Host请求头字段，浏览器无法使用主机头名来明确表示要访问服务器上的哪个WEB站点，这样就无法使用WEB服务器在同一个IP地址和端口号上配置多个虚拟WEB站点。在HTTP 1.1中增加Host请求头字段后，WEB浏览器可以使用主机头名来明确表示要访问服务器上的哪个WEB站点，这才实现了在一台WEB服务器上可以在同一个IP地址和端口号上使用不同的主机名来创建多个虚拟WEB站点。HTTP 1.1的持续连接，也需要增加新的请求头来帮助实现，例如，Connection请求头的值为Keep-Alive时，客户端通知服务器返回本次请求结果后保持连接；Connection请求头的值为close时，客户端通知服务器返回本次请求结果后关闭连接。HTTP 1.1还提供了与身份认证、状态管理和Cache缓存等机制相关的请求头和响应头。HTTP 1.0不支持文件断点续传，RANGE:bytes是HTTP 1.1新增内容，HTTP 1.0每次传送文件都是从文件头开始，即0字节处开始。RANGE:bytes=XXXX表示要求服务器从文件XXXX字节处开始传送，这就是我们平时所说的断点续传。\nHTTP 1.1和HTTP 1.0协议的区别 缓存处理 带宽优化及网络连接的使用 错误通知的管理 消息在网络中的发送 互联网地址的维护 安全性及完整性 HTTP 1.x和HTTP 2协议的区别 二进制分帧：HTTP 2采用二进制格式传输数据，而非HTTP 1.x的文本格式 头部压缩：头部表在HTTP 2的连接存续期内始终存在，由客户端和服务器共同渐进地更新。请求一发送了所有的头部字段，第二个请求则只需要发送差异数据，这样可以减少冗余数据，降低开销 多路复用：直白的说就是所有的请求都是通过一个TCP连接并发完成。HTTP 1.x虽然通过pipeline也能并发请求，但是多个请求之间的响应会被阻塞的，所以pipeline至今也没有被普及应用，而HTTP 2做到了真正的并发请求。同时，流还支持优先级和流量控制。 服务器推送：服务端能够更快的把资源推送给客户端。例如服务端可以主动把JS和CSS文件推送给客户端，而不需要客户端解析HTML再发送这些请求。当客户端需要的时候，它已经在客户端了。 HTTP 2主要是HTTP 1.","tags":null,"title":"HTTP笔记"},{"categories":null,"contents":" #golang #atomic\n互斥锁跟原子操作的区别 在并发编程里，Go语言sync包里的同步原语Mutex是我们经常用来保证并发安全的，但是他跟atomic包在使用目的和底层实现上都不一样：\n使用目的 互斥锁是用来保护一段逻辑，原子操作用于对一个变量的更新保护。\n底层实现 Mutex由操作系统的调度器实现，而atomic包中的原子操作则由底层硬件指令直接提供支持，这些指令在执行的过程中是不允许中断的，因此原子操作可以在lock-free的情况下保证并发安全，并且它的性能也能做到随CPU个数的增多而线性扩展。\n对于一个变量更新的保护，原子操作通常会更有效率，并且更能利用计算机多核的优势。\n性能测试对比 互斥锁性能测试 使用sync包下面互斥锁的多线程加法操作\nfunc syncAdd(param int64) int64 { var wg sync.WaitGroup lock := sync.Mutex{} for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func() { for i := 0; i \u0026lt; 1000000; i++ { lock.Lock() param++ lock.Unlock() } wg.Done() }() } wg.Wait() return param } Benchmark测试方法\nfunc BenchmarkSync(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { flag := int64(0) res := syncAdd(flag) if res != 10000000 { b.Errorf(\u0026#34;calculate result err: %d\\n\u0026#34;, res) } } } 测试结果：\n根据运行环境和硬件性能会有所不同，这里是在相同环境下的对比\n第一次 goos: darwin goarch: arm64 pkg: wire/atomic_test BenchmarkSync BenchmarkSync-8 2\t862741542 ns/op PASS 第二次 goos: darwin goarch: arm64 pkg: wire/atomic_test BenchmarkSync BenchmarkSync-8 2\t875432729 ns/op PASS 第三次 goos: darwin goarch: arm64 pkg: wire/atomic_test BenchmarkSync BenchmarkSync-8 2\t836373292 ns/op PASS 三次取平均：(862741542 + 875432729 + 836373292) / 3 = 858182521 ns/op\n原子操作性能测试 使用atomic包下面原子操作的多线程加法操作\nfunc atomicAdd(param int64) int64 { var wg sync.WaitGroup for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func() { for i := 0; i \u0026lt; 1000000; i++ { atomic.AddInt64(\u0026amp;param, 1) } wg.Done() }() } wg.Wait() return param } Benchmark测试方法\nfunc BenchmarkAtomic(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { flag := int64(0) res := atomicAdd(flag) if res != 10000000 { b.Errorf(\u0026#34;calculate result err: %d\\n\u0026#34;, res) } } } 测试结果：\n根据运行环境和硬件性能会有所不同，这里是在相同环境下的对比\n第一次 goos: darwin goarch: arm64 pkg: wire/atomic_test BenchmarkAtomic BenchmarkAtomic-8 4\t359013958 ns/op PASS 第二次 goos: darwin goarch: arm64 pkg: wire/atomic_test BenchmarkAtomic BenchmarkAtomic-8 3\t359734514 ns/op PASS 第三次 goos: darwin goarch: arm64 pkg: wire/atomic_test BenchmarkAtomic BenchmarkAtomic-8 4\t359007542 ns/op PASS 三次取平均：(359013958 + 359734514 + 359007542) / 3 = 359252004 ns/op\n测试结果对比 根据测试结果数据使用互斥锁做累加每次循环耗时858182521 ns，而使用原子操作做累加每次耗时359252004 ns。\n这也印证了之前说过的：互斥锁适用于来保护一段逻辑，原子操作适用于于对一个变量的更新保护。\n原理浅析 参考： 互斥锁跟原子操作的区别-底层实现\n参考链接 Golang五种原子性操作的用法详解 ","date":"March 30, 2022","hero":"/posts/knowledge/2001-go/006-atomic/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2001-go/006-atomic/","summary":"#golang #atomic\n互斥锁跟原子操作的区别 在并发编程里，Go语言sync包里的同步原语Mutex是我们经常用来保证并发安全的，但是他跟atomic包在使用目的和底层实现上都不一样：\n使用目的 互斥锁是用来保护一段逻辑，原子操作用于对一个变量的更新保护。\n底层实现 Mutex由操作系统的调度器实现，而atomic包中的原子操作则由底层硬件指令直接提供支持，这些指令在执行的过程中是不允许中断的，因此原子操作可以在lock-free的情况下保证并发安全，并且它的性能也能做到随CPU个数的增多而线性扩展。\n对于一个变量更新的保护，原子操作通常会更有效率，并且更能利用计算机多核的优势。\n性能测试对比 互斥锁性能测试 使用sync包下面互斥锁的多线程加法操作\nfunc syncAdd(param int64) int64 { var wg sync.WaitGroup lock := sync.Mutex{} for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func() { for i := 0; i \u0026lt; 1000000; i++ { lock.Lock() param++ lock.Unlock() } wg.Done() }() } wg.Wait() return param } Benchmark测试方法\nfunc BenchmarkSync(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { flag := int64(0) res := syncAdd(flag) if res !","tags":null,"title":"Golang中的原子操作"},{"categories":null,"contents":"#redis #cache #db\n缓存一致性 形成原因 数据增删修操作造成的缓存内容与持久层内容的不一致\n解决办法 先更新缓存后更新数据库：更新缓存后程序异常终止或持久化失败导致数据未持久化 先更新数据库后更新缓存：更新数据库后程序异常终止或更新缓存失败导致缓存数据与数据库不一致。解决办法：先更新缓存，后将数据修改操作写入持久化队列，比如Kafka，让下游服务执行持久化操作 缓存穿透 针对多个key\n形成原因 缓存穿透是指查询一个不存在的数据，由于缓存是不命中时，去存储层（如MySQL）查找数据。如果从存储层查不到数据没有写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，导致缓存穿透。流量一旦大了之后，容易导致DB宕机，进而影响整个业务。利用不存在的key频繁攻击应用，这就是漏洞。\n解决办法 使用布隆过滤器，如果从DB中没有查到则添加到布隆过滤器中。但由于布隆过滤器中存储的内容是不能修改的，需要注意使用场景。如果当前查询不存在的key以后会出现再实际数据中，使用布隆过滤器会导致改条数据无法查询到。 缓存不存在的key，如果从DB中没有查询到该数据，则将对应的key写入缓存中，并加一个合适的过期时间。value内容写一个不存在的标记，当程序读到该内容后，即知道这条key不存在对应的内容直接返回，不会将流量打入存储层。 缓存雪崩 多个key相同的过期时间\n形成原因 缓存雪崩是指多个key在相同时间过期，导致缓存在某一时刻同时失效。请求全部转发到DB，DB瞬时压力过高宕机导致服务不可用。\n解决办法 使用队列，将需要缓存的数据发往一个统一的队列中，依次写缓存。 随机过期时间，比如一个key需要缓存一小时，则在一小时的基础上随机±5分钟，这样可以一定程度上解决一批key集中过期的问题 缓存击穿 针对一个key\n形成原因 某个设置了过期时间的key，在过期后某一时间有大量并发请求进来。而在第一个请求进来，从DB中查完还没来得及写入缓存中时后面的并发请求也进来了，就会造成同一个key并发访问DB，瞬间打垮存储层。\n一般突然出现的热点key容易造成这种问题。\n解决办法 使用分布式互斥锁，当一个key在缓存中没有查询到时，先去抢这个key的锁，抢到则去存储层进行查询，没有抢到则去缓存中查询，根据实际情况如果一次没有查找到可以循环查找几次（毕竟查数据库需要耗时）。 其他 数据的缓存策略，有时也需要根据实际业务来设定。比如一些热点key设置为永不过期，但永不过期也会给缓存的存储带来压力，而给key设置过期时间，又会带来以上几种问题。抑或是缓存设置永不过期，使用异步线程定期删除一些没有访问的key。\n写代码的时候需要一个指导思想，但同时亦不可死搬教条。\n","date":"March 11, 2022","hero":"/posts/knowledge/2009-redis/001-cache/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2009-redis/001-cache/","summary":"#redis #cache #db\n缓存一致性 形成原因 数据增删修操作造成的缓存内容与持久层内容的不一致\n解决办法 先更新缓存后更新数据库：更新缓存后程序异常终止或持久化失败导致数据未持久化 先更新数据库后更新缓存：更新数据库后程序异常终止或更新缓存失败导致缓存数据与数据库不一致。解决办法：先更新缓存，后将数据修改操作写入持久化队列，比如Kafka，让下游服务执行持久化操作 缓存穿透 针对多个key\n形成原因 缓存穿透是指查询一个不存在的数据，由于缓存是不命中时，去存储层（如MySQL）查找数据。如果从存储层查不到数据没有写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，导致缓存穿透。流量一旦大了之后，容易导致DB宕机，进而影响整个业务。利用不存在的key频繁攻击应用，这就是漏洞。\n解决办法 使用布隆过滤器，如果从DB中没有查到则添加到布隆过滤器中。但由于布隆过滤器中存储的内容是不能修改的，需要注意使用场景。如果当前查询不存在的key以后会出现再实际数据中，使用布隆过滤器会导致改条数据无法查询到。 缓存不存在的key，如果从DB中没有查询到该数据，则将对应的key写入缓存中，并加一个合适的过期时间。value内容写一个不存在的标记，当程序读到该内容后，即知道这条key不存在对应的内容直接返回，不会将流量打入存储层。 缓存雪崩 多个key相同的过期时间\n形成原因 缓存雪崩是指多个key在相同时间过期，导致缓存在某一时刻同时失效。请求全部转发到DB，DB瞬时压力过高宕机导致服务不可用。\n解决办法 使用队列，将需要缓存的数据发往一个统一的队列中，依次写缓存。 随机过期时间，比如一个key需要缓存一小时，则在一小时的基础上随机±5分钟，这样可以一定程度上解决一批key集中过期的问题 缓存击穿 针对一个key\n形成原因 某个设置了过期时间的key，在过期后某一时间有大量并发请求进来。而在第一个请求进来，从DB中查完还没来得及写入缓存中时后面的并发请求也进来了，就会造成同一个key并发访问DB，瞬间打垮存储层。\n一般突然出现的热点key容易造成这种问题。\n解决办法 使用分布式互斥锁，当一个key在缓存中没有查询到时，先去抢这个key的锁，抢到则去存储层进行查询，没有抢到则去缓存中查询，根据实际情况如果一次没有查找到可以循环查找几次（毕竟查数据库需要耗时）。 其他 数据的缓存策略，有时也需要根据实际业务来设定。比如一些热点key设置为永不过期，但永不过期也会给缓存的存储带来压力，而给key设置过期时间，又会带来以上几种问题。抑或是缓存设置永不过期，使用异步线程定期删除一些没有访问的key。\n写代码的时候需要一个指导思想，但同时亦不可死搬教条。","tags":null,"title":"Redis缓存相关问题"},{"categories":null,"contents":" #oauth\nPKCE全称是Proof Key for Code Exchange，在2015年发布，它是OAuth 2.0核心的一个扩展协议，所以可以和现有的授权模式结合使用，比如Authorization Code+PKCE， 这也是最佳实践，PKCE最初是为移动设备应用和本地应用创建的， 主要是为了减少公共客户端的授权码拦截攻击。 在最新的OAuth 2.1规范中，推荐所有客户端都使用PKCE，而不仅仅是公共客户端，并且移除了Implicit隐式和Password模式，那之前使用这两种模式的客户端怎么办? 是的，现在都可以尝试使用Authorization Code+PKCE的授权模式。那PKCE为什么有这种魔力呢? 实际上它的原理是客户端提供一个自创建的证明给授权服务器，授权服务器通过它来验证客户端，把访问令牌(access_token)颁发给真实的客户端而不是伪造的。\n客户端类型 上面说到了PKCE主要是为了减少公共客户端的授权码拦截攻击，那就有必要介绍下两种客户端类型了。\nOAuth 2.0核心规范定义了两种客户端类型， confidential 机密的， 和 public 公开的， 区分这两种类型的方法是， 判断这个客户端是否有能力维护自己的机密性凭据 client_secret。\nconfidential\n对于一个普通的web站点来说，虽然用户可以访问到前端页面，但是数据都来自服务器的后端api服务，前端只是获取授权码code，通过code换取access_token这一步是在后端的api完成的，由于是内部的服务器，客户端有能力维护密码或者密钥信息，这种是机密的的客户端。 public\n客户端本身没有能力保存密钥信息，比如桌面软件，手机App，单页面程序(SPA)，因为这些应用是发布出去的，实际上也就没有安全可言，恶意攻击者可以通过反编译等手段查看到客户端的密钥，这种是公开的客户端。 在OAuth 2.0授权码模式（Authorization Code）中，客户端通过授权码code向授权服务器获取访问令牌(access_token)时，同时还需要在请求中携带客户端密钥(client_secret)，授权服务器对其进行验证，保证access_token颁发给了合法的客户端，对于公开的客户端来说，本身就有密钥泄露的风险，所以就不能使用常规OAuth 2.0的授权码模式，于是就针对这种不能使用client_secret的场景，衍生出了Implicit隐式模式，这种模式从一开始就是不安全的。在经过一段时间之后，PKCE扩展协议推出，就是为了解决公开客户端的授权安全问题。\n授权码拦截攻击 上面是OAuth 2.0授权码模式的完整流程，授权码拦截攻击就是图中的C步骤发生的，也就是授权服务器返回给客户端授权码的时候，这么多步骤中为什么C步骤是不安全的呢?在OAuth 2.0核心规范中，要求授权服务器的anthorize endpoint和token endpoint必须使用TLS（安全传输层协议）保护，但是授权服务器携带授权码code返回到客户端的回调地址时，有可能不受TLS的保护，恶意程序就可以在这个过程中拦截授权码code，拿到code之后，接下来就是通过code向授权服务器换取访问令牌access_token，对于机密的客户端来说，请求access_token时需要携带客户端的密钥client_secret，而密钥保存在后端服务器上，所以恶意程序通过拦截拿到授权码code也没有用，而对于公开的客户端（手机App，桌面应用）来说，本身没有能力保护client_secret，因为可以通过反编译等手段，拿到客户端client_secret，也就可以通过授权码code换取access_token，到这一步，恶意应用就可以拿着token请求资源服务器了。\nstate参数，在OAuth 2.0核心协议中，通过code换取token步骤中，推荐使用state参数，把请求和响应关联起来，可以防止跨站点请求伪造-CSRF攻击，但是state并不能防止上面的授权码拦截攻击，因为请求和响应并没有被伪造，而是响应的授权码被恶意程序拦截。\nPKCE 协议流程 PKCE协议本身是对OAuth 2.0的扩展，它和之前的授权码流程大体上是一致的。区别在于，在向授权服务器的authorize endpoint请求时，需要额外的code_challenge和code_challenge_method参数，向token endpoint请求时，需要额外的code_verifier参数，最后授权服务器会对这三个参数进行对比验证，通过后颁发令牌。\n原理分析 上面我们说了授权码拦截攻击，它是指在整个授权流程中，只需要拦截到从授权服务器回调给客户端的授权码code，就可以去授权服务器申请令牌了，因为客户端是公开的，就算有密钥client_secret也是形同虚设，恶意程序拿到访问令牌后，就可以光明正大的请求资源服务器了。\nPKCE是怎么做的呢?既然固定的client_secret是不安全的，那就每次请求生成一个随机的密钥（code_verifier），第一次请求到授权服务器的authorize endpoint时，携带code_challenge和code_challenge_method，也就是code_verifier转换后的值和转换方法，然后授权服务器需要把这两个参数缓存起来，第二次请求到token endpoint时，携带生成的随机密钥的原始值(code_verifier)，然后授权服务器使用下面的方法进行验证:\nplain\ncode_challenge = code_verifier sha256\ncode_challenge = BASE64URL-ENCODE(SHA256(ASCII(code_verifier))) 通过后才颁发令牌，那向授权服务器authorize endpoint和token endpoint发起的这两次请求，该如何关联起来呢?通过授权码code即可，所以就算恶意程序拦截到了授权码code，但是没有code_verifier，也是不能获取访问令牌的，当然PKCE也可以用在机密（confidential）的客户端，那就是client_secret+code_verifier双重密钥了。\n参考连接 oauth文档 ","date":"February 10, 2022","hero":"/posts/knowledge/2004-network/001-oauth/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2004-network/001-oauth/","summary":" #oauth\nPKCE全称是Proof Key for Code Exchange，在2015年发布，它是OAuth 2.0核心的一个扩展协议，所以可以和现有的授权模式结合使用，比如Authorization Code+PKCE， 这也是最佳实践，PKCE最初是为移动设备应用和本地应用创建的， 主要是为了减少公共客户端的授权码拦截攻击。 在最新的OAuth 2.1规范中，推荐所有客户端都使用PKCE，而不仅仅是公共客户端，并且移除了Implicit隐式和Password模式，那之前使用这两种模式的客户端怎么办? 是的，现在都可以尝试使用Authorization Code+PKCE的授权模式。那PKCE为什么有这种魔力呢? 实际上它的原理是客户端提供一个自创建的证明给授权服务器，授权服务器通过它来验证客户端，把访问令牌(access_token)颁发给真实的客户端而不是伪造的。\n客户端类型 上面说到了PKCE主要是为了减少公共客户端的授权码拦截攻击，那就有必要介绍下两种客户端类型了。\nOAuth 2.0核心规范定义了两种客户端类型， confidential 机密的， 和 public 公开的， 区分这两种类型的方法是， 判断这个客户端是否有能力维护自己的机密性凭据 client_secret。\nconfidential\n对于一个普通的web站点来说，虽然用户可以访问到前端页面，但是数据都来自服务器的后端api服务，前端只是获取授权码code，通过code换取access_token这一步是在后端的api完成的，由于是内部的服务器，客户端有能力维护密码或者密钥信息，这种是机密的的客户端。 public\n客户端本身没有能力保存密钥信息，比如桌面软件，手机App，单页面程序(SPA)，因为这些应用是发布出去的，实际上也就没有安全可言，恶意攻击者可以通过反编译等手段查看到客户端的密钥，这种是公开的客户端。 在OAuth 2.0授权码模式（Authorization Code）中，客户端通过授权码code向授权服务器获取访问令牌(access_token)时，同时还需要在请求中携带客户端密钥(client_secret)，授权服务器对其进行验证，保证access_token颁发给了合法的客户端，对于公开的客户端来说，本身就有密钥泄露的风险，所以就不能使用常规OAuth 2.0的授权码模式，于是就针对这种不能使用client_secret的场景，衍生出了Implicit隐式模式，这种模式从一开始就是不安全的。在经过一段时间之后，PKCE扩展协议推出，就是为了解决公开客户端的授权安全问题。\n授权码拦截攻击 上面是OAuth 2.0授权码模式的完整流程，授权码拦截攻击就是图中的C步骤发生的，也就是授权服务器返回给客户端授权码的时候，这么多步骤中为什么C步骤是不安全的呢?在OAuth 2.0核心规范中，要求授权服务器的anthorize endpoint和token endpoint必须使用TLS（安全传输层协议）保护，但是授权服务器携带授权码code返回到客户端的回调地址时，有可能不受TLS的保护，恶意程序就可以在这个过程中拦截授权码code，拿到code之后，接下来就是通过code向授权服务器换取访问令牌access_token，对于机密的客户端来说，请求access_token时需要携带客户端的密钥client_secret，而密钥保存在后端服务器上，所以恶意程序通过拦截拿到授权码code也没有用，而对于公开的客户端（手机App，桌面应用）来说，本身没有能力保护client_secret，因为可以通过反编译等手段，拿到客户端client_secret，也就可以通过授权码code换取access_token，到这一步，恶意应用就可以拿着token请求资源服务器了。\nstate参数，在OAuth 2.0核心协议中，通过code换取token步骤中，推荐使用state参数，把请求和响应关联起来，可以防止跨站点请求伪造-CSRF攻击，但是state并不能防止上面的授权码拦截攻击，因为请求和响应并没有被伪造，而是响应的授权码被恶意程序拦截。\nPKCE 协议流程 PKCE协议本身是对OAuth 2.0的扩展，它和之前的授权码流程大体上是一致的。区别在于，在向授权服务器的authorize endpoint请求时，需要额外的code_challenge和code_challenge_method参数，向token endpoint请求时，需要额外的code_verifier参数，最后授权服务器会对这三个参数进行对比验证，通过后颁发令牌。\n原理分析 上面我们说了授权码拦截攻击，它是指在整个授权流程中，只需要拦截到从授权服务器回调给客户端的授权码code，就可以去授权服务器申请令牌了，因为客户端是公开的，就算有密钥client_secret也是形同虚设，恶意程序拿到访问令牌后，就可以光明正大的请求资源服务器了。\nPKCE是怎么做的呢?既然固定的client_secret是不安全的，那就每次请求生成一个随机的密钥（code_verifier），第一次请求到授权服务器的authorize endpoint时，携带code_challenge和code_challenge_method，也就是code_verifier转换后的值和转换方法，然后授权服务器需要把这两个参数缓存起来，第二次请求到token endpoint时，携带生成的随机密钥的原始值(code_verifier)，然后授权服务器使用下面的方法进行验证:\nplain\ncode_challenge = code_verifier sha256\ncode_challenge = BASE64URL-ENCODE(SHA256(ASCII(code_verifier))) 通过后才颁发令牌，那向授权服务器authorize endpoint和token endpoint发起的这两次请求，该如何关联起来呢?通过授权码code即可，所以就算恶意程序拦截到了授权码code，但是没有code_verifier，也是不能获取访问令牌的，当然PKCE也可以用在机密（confidential）的客户端，那就是client_secret+code_verifier双重密钥了。\n参考连接 oauth文档 ","tags":null,"title":"OAuth 2.0扩展协议PKCE"},{"categories":null,"contents":" 与MySQL类似，Redis安装完也不能直接使用，默认的配置文件有几处需要修改\n使用yum安装的Redis默认配置文件路径：/etc/redis.conf\n允许访问地址 # bind 127.0.0.1 将只限本地访问的配置注释掉\n修改保护模式 protected-mode no 将保护模式修改为no\n启用守护进程 daemonize yes 将守护进程设置为yes\n","date":"January 13, 2022","hero":"/posts/deployment/3008-linux-redis/head.svg","permalink":"https://ormissia.github.io/posts/deployment/3008-linux-redis/","summary":"与MySQL类似，Redis安装完也不能直接使用，默认的配置文件有几处需要修改\n使用yum安装的Redis默认配置文件路径：/etc/redis.conf\n允许访问地址 # bind 127.0.0.1 将只限本地访问的配置注释掉\n修改保护模式 protected-mode no 将保护模式修改为no\n启用守护进程 daemonize yes 将守护进程设置为yes","tags":null,"title":"Redis默认配置文件修改"},{"categories":null,"contents":"网络IO模型演进历程 阻塞IO BIO(Blocking IO) 非阻塞IO NIO(Nonblocking IO) IO多路复用第一版 select/poll/epoll 异步IO AIO(Async IO) BIO 阻塞 IO，顾名思义当用户发生了系统调用后，如果数据未从网卡到达内核态，内核态数据未准备好，此时会一直阻塞。直到数据就绪，然后从内核态拷贝到用户态再返回。\nBIO缺点，能支持的并发连接数比较少： 一台服务器能分配的线程数是有限的 大量线程频繁切换上下文会影响性能 核心矛盾：一个client分配一个线程是因为处理客户端读写是阻塞式的，为避免该阻塞影响接受后续新的client的连接，所以将阻塞逻辑交由单独的线程处理。\nNIO 非阻塞 IO：见名知意，就是在第一阶段(网卡-内核态)数据未到达时不等待，然后直接返回。因此非阻塞 IO 需要不断的用户发起请求，轮询内核。\n优点 将socket设为非阻塞后，在读取时如果数据未就绪就直接返回。可以通过一个线程管理多个client连接。 缺点 需要不断轮询内核，数据是否已经就绪，会造成很多无效的，太频繁的系统调用(system call)而造成资源浪费。 select/poll/epoll select 和 poll 的区别 select 能处理的最大连接，默认是 1024 个，可以通过修改配置来改变，但终究是有限个；而 poll 理论上可以支持无限个 select 和 poll 在管理海量的连接时，会频繁的从用户态拷贝到内核态，比较消耗资源 epoll对文件描述符的操作有两种模式： LT（level trigger）和 ET（edge trigger）。\nLT模式：当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用 epoll_wait 时，会再次响应应用程序并通知此事件。 ET模式：当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用 epoll_wait 时，不会再次响应应用程序并通知此事件。 简言之：边沿触发仅触发一次，水平触发会一直触发。\nepoll高效的本质在于：\n减少了用户态和内核态的文件句柄拷贝 减少了对可读可写文件句柄的遍历 mmap 加速了内核与用户空间的信息传递，epoll是通过内核与用户mmap同一块内存，避免了无谓的内存拷贝 IO性能不会随着监听的文件描述的数量增长而下降 使用红黑树存储fd，以及对应的回调函数，其插入，查找，删除的性能不错，相比于hash，不必预先分配很多的空间 - select poll epoll 操作方式 遍历 遍历 回调 底层实现 数组 链表 哈希表 IO效率 每次调用都进行线性遍历，时间复杂度为O(n) 每次调用都进行线性遍历，时间复杂度为O(n) 事件通知方式，每当fd就绪，系统注册的回调函数就会被调用，将就绪fd放到rdllist里面。时间复杂度O(1) 最大连接数 1024（x86）或 2048（x64） 无上限 无上限 fd拷贝 每次调用select，都需要把fd集合从用户态拷贝到内核态 每次调用poll，都需要把fd集合从用户态拷贝到内核态 调用epoll_ctl时拷贝进内核并保存，之后每次epoll_wait不拷贝 AIO 参考连接 Chapter 6. I/O Multiplexing: The select and poll Functions epoll(7) — Linux manual page The C10K problem ","date":"January 1, 2022","hero":"/posts/knowledge/2005-operating-system/001-io-network/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2005-operating-system/001-io-network/","summary":"网络IO模型演进历程 阻塞IO BIO(Blocking IO) 非阻塞IO NIO(Nonblocking IO) IO多路复用第一版 select/poll/epoll 异步IO AIO(Async IO) BIO 阻塞 IO，顾名思义当用户发生了系统调用后，如果数据未从网卡到达内核态，内核态数据未准备好，此时会一直阻塞。直到数据就绪，然后从内核态拷贝到用户态再返回。\nBIO缺点，能支持的并发连接数比较少： 一台服务器能分配的线程数是有限的 大量线程频繁切换上下文会影响性能 核心矛盾：一个client分配一个线程是因为处理客户端读写是阻塞式的，为避免该阻塞影响接受后续新的client的连接，所以将阻塞逻辑交由单独的线程处理。\nNIO 非阻塞 IO：见名知意，就是在第一阶段(网卡-内核态)数据未到达时不等待，然后直接返回。因此非阻塞 IO 需要不断的用户发起请求，轮询内核。\n优点 将socket设为非阻塞后，在读取时如果数据未就绪就直接返回。可以通过一个线程管理多个client连接。 缺点 需要不断轮询内核，数据是否已经就绪，会造成很多无效的，太频繁的系统调用(system call)而造成资源浪费。 select/poll/epoll select 和 poll 的区别 select 能处理的最大连接，默认是 1024 个，可以通过修改配置来改变，但终究是有限个；而 poll 理论上可以支持无限个 select 和 poll 在管理海量的连接时，会频繁的从用户态拷贝到内核态，比较消耗资源 epoll对文件描述符的操作有两种模式： LT（level trigger）和 ET（edge trigger）。\nLT模式：当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用 epoll_wait 时，会再次响应应用程序并通知此事件。 ET模式：当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用 epoll_wait 时，不会再次响应应用程序并通知此事件。 简言之：边沿触发仅触发一次，水平触发会一直触发。\nepoll高效的本质在于：\n减少了用户态和内核态的文件句柄拷贝 减少了对可读可写文件句柄的遍历 mmap 加速了内核与用户空间的信息传递，epoll是通过内核与用户mmap同一块内存，避免了无谓的内存拷贝 IO性能不会随着监听的文件描述的数量增长而下降 使用红黑树存储fd，以及对应的回调函数，其插入，查找，删除的性能不错，相比于hash，不必预先分配很多的空间 - select poll epoll 操作方式 遍历 遍历 回调 底层实现 数组 链表 哈希表 IO效率 每次调用都进行线性遍历，时间复杂度为O(n) 每次调用都进行线性遍历，时间复杂度为O(n) 事件通知方式，每当fd就绪，系统注册的回调函数就会被调用，将就绪fd放到rdllist里面。时间复杂度O(1) 最大连接数 1024（x86）或 2048（x64） 无上限 无上限 fd拷贝 每次调用select，都需要把fd集合从用户态拷贝到内核态 每次调用poll，都需要把fd集合从用户态拷贝到内核态 调用epoll_ctl时拷贝进内核并保存，之后每次epoll_wait不拷贝 AIO 参考连接 Chapter 6.","tags":null,"title":"网络IO演进历程"},{"categories":null,"contents":" #javascript #js #react\n初始化React项目 npm install -g react npm install -g react-dom npm install -g react-scripts npm install -g create-react-app create-react-app hello-react cd hello-react npm start 更新package.json npm install -g npm-check-updates ncu # 或者npm-check-updates ncu -u to upgrade package.json npm install ","date":"December 23, 2021","hero":"/posts/knowledge/2011-react-note/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2011-react-note/","summary":" #javascript #js #react\n初始化React项目 npm install -g react npm install -g react-dom npm install -g react-scripts npm install -g create-react-app create-react-app hello-react cd hello-react npm start 更新package.json npm install -g npm-check-updates ncu # 或者npm-check-updates ncu -u to upgrade package.json npm install ","tags":null,"title":"React学习笔记"},{"categories":null,"contents":" #mysql #macos\n一般MySQL 8.x安装完在select语句中使用group by时会报错，需要在my.cnf中配置设置sql_model参数。在Linux中，这个文件通常位于/etc目录下，而在Mac上，却不在这里。\n在Mac本地安装的测试用的MySQL数据库，安装完成之后需要进行如下设置\n设置sql_model 关闭ONLY_FULL_GROUP_BY模式\n在sql命令行中查询sql_mode配置\nselect @@sql_mode; mysql\u0026gt; select @@sql_mode; +-----------------------------------------------------------------------------------------------------------------------+ | @@sql_mode | +-----------------------------------------------------------------------------------------------------------------------+ | ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION | +-----------------------------------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) 去掉第一项后得到：\nSTRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION 使用mysql --help命令获取my.cnf配置文件所在位置\n# ... Default options are read from the following files in the given order: /etc/my.cnf /etc/mysql/my.cnf /opt/homebrew/etc/my.cnf ~/.my.cnf The following groups are read: mysql client # ... 我安装的MySQL在/opt/homebrew/etc/my.cnf目录下，添加一行：\nsql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION 重启MySQL，问题解决\nmysql.server restart 设置开机启动 cp /opt/homebrew/Cellar/mysql/8.0.27/homebrew.mxcl.mysql.plist ~/Library/LaunchAgents launchctl load -w ~/Library/LaunchAgents/homebrew.mxcl.mysql.plist ","date":"December 20, 2021","hero":"/posts/problems/5006-mysql-brew-conf/head.svg","permalink":"https://ormissia.github.io/posts/problems/5006-mysql-brew-conf/","summary":"#mysql #macos\n一般MySQL 8.x安装完在select语句中使用group by时会报错，需要在my.cnf中配置设置sql_model参数。在Linux中，这个文件通常位于/etc目录下，而在Mac上，却不在这里。\n在Mac本地安装的测试用的MySQL数据库，安装完成之后需要进行如下设置\n设置sql_model 关闭ONLY_FULL_GROUP_BY模式\n在sql命令行中查询sql_mode配置\nselect @@sql_mode; mysql\u0026gt; select @@sql_mode; +-----------------------------------------------------------------------------------------------------------------------+ | @@sql_mode | +-----------------------------------------------------------------------------------------------------------------------+ | ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION | +-----------------------------------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) 去掉第一项后得到：\nSTRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION 使用mysql --help命令获取my.cnf配置文件所在位置\n# ... Default options are read from the following files in the given order: /etc/my.cnf /etc/mysql/my.cnf /opt/homebrew/etc/my.cnf ~/.my.cnf The following groups are read: mysql client # ... 我安装的MySQL在/opt/homebrew/etc/my.cnf目录下，添加一行：\nsql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION 重启MySQL，问题解决\nmysql.server restart 设置开机启动 cp /opt/homebrew/Cellar/mysql/8.0.27/homebrew.mxcl.mysql.plist ~/Library/LaunchAgents launchctl load -w ~/Library/LaunchAgents/homebrew.","tags":null,"title":"修改Mac上brew安装的MySQL配置"},{"categories":null,"contents":" #kubernetes #k8s\n为系统守护进程预留计算资源 开启服务拓扑 Master节点的高可用 Service 的 DNS ","date":"November 4, 2021","hero":"/posts/knowledge/2007-kubernetes/001-link-index/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2007-kubernetes/001-link-index/","summary":" #kubernetes #k8s\n为系统守护进程预留计算资源 开启服务拓扑 Master节点的高可用 Service 的 DNS ","tags":null,"title":"Kubernetes文档索引"},{"categories":null,"contents":" #docker\n问题现象 国内某些网络环境下，会出现docker pull无法拉取镜像的情况\n解决办法 修改Docker镜像源\n新建或修改\nvi /etc/docker/daemon.json { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;http://hub-mirror.c.163.com\u0026#34; ] } 最后重启Docker\nsystemctl restart docker.service ","date":"November 4, 2021","hero":"/posts/problems/5005-docker-image-source/head.svg","permalink":"https://ormissia.github.io/posts/problems/5005-docker-image-source/","summary":" #docker\n问题现象 国内某些网络环境下，会出现docker pull无法拉取镜像的情况\n解决办法 修改Docker镜像源\n新建或修改\nvi /etc/docker/daemon.json { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;http://hub-mirror.c.163.com\u0026#34; ] } 最后重启Docker\nsystemctl restart docker.service ","tags":null,"title":"修改Docker镜像源"},{"categories":null,"contents":" #kubernetes #k8s\n连接一些多实例的服务（比如Kafka、ES）时，通常是在client端做负载均衡。\n假如这种集群又恰好跑在k8s中，如果是普通业务类型的服务，通常是创建一个Service来做为一个代理去访问不同实例，从而达到负载均衡的目的。\n但是诸如如：Kafka、ES类型的服务，还用Service来做负载均衡，显然就不那么合理了（诚然，Kafka、ES这种东西多半是不会跑在k8s上的，这里只是作为一个引子，不在本文讨论的范畴）。\n实验环境 多实例服务whoami在kube-test-1的命名空间下 多实例服务whoami以StatefulSet方式部署，设置为3个实例，会自动创建whoami-0、whoami-1以及whoami-2三个Pod 给StatefulSet创建Headless类型的Service 模拟客户端使用Nginx镜像，部署在kube-test-2的命名空间下（使用curl命令模拟） 本实验创建资源使用的k8s dashboard，创建的资源默认放在选中的明明空间下，因此yml文件中未指定namespace。\nServer cluster 服务端模拟相关资源在kube-test-1下创建\nStatefulSet 使用traefik/whoami镜像来模拟服务端\n这里使用StatefulSet的方式创建服务端。spec.replicas设为3，此时会自动创建whoami-0、whoami-1以及whoami-2三个Pod。\napiVersion: apps/v1 kind: StatefulSet metadata: name: whoami labels: app: whoami spec: replicas: 3 selector: matchLabels: app: whoami serviceName: whoami template: metadata: name: whoami labels: app: whoami spec: containers: - name: whoami image: traefik/whoami ports: - containerPort: 80 注意这里的spec.serviceName必须与下面的Service名字相同，否则调用时候pod的subdomain只能使用IP\n$ k get pod -n kube-test-1 -o wide | grep whoami whoami-0 1/1 Running 0 29m 10.244.1.220 node2 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; whoami-1 1/1 Running 0 29m 10.244.0.52 node1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; whoami-2 1/1 Running 0 29m 10.244.1.221 node2 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; Headless 使用Headless的方式向外暴露Pod，不允许使用Service的负载均衡\napiVersion: v1 kind: Service metadata: name: whoami spec: clusterIP: None ports: - port: 80 selector: app: whoami $ k get service -n kube-test-1 -o wide | grep whoami whoami ClusterIP None \u0026lt;none\u0026gt; 80/TCP 10s app=whoami Client 客户端模拟相关资源在kube-test-2下创建\napiVersion: apps/v1 kind: Deployment metadata: name: nginx labels: app: nginx spec: selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx nginx用来模拟客户端，调用镜像自带的curl命令\n进入nginx容器\n$ k exec -it nginx-6799fc88d8-cgvtp -n kube-test-2 /bin/bash 使用curl命令分别调用几个服务端\n$ curl whoami-0.whoami.kube-test-1.svc.cluster.local Hostname: whoami-0 IP: 127.0.0.1 IP: 10.244.1.220 RemoteAddr: 10.244.0.53:39400 GET / HTTP/1.1 Host: whoami-0.whoami.kube-test-1.svc.cluster.local User-Agent: curl/7.64.0 Accept: */* $ curl whoami-1.whoami.kube-test-1.svc.cluster.local Hostname: whoami-1 IP: 127.0.0.1 IP: 10.244.0.52 RemoteAddr: 10.244.0.53:40354 GET / HTTP/1.1 Host: whoami-1.whoami.kube-test-1.svc.cluster.local User-Agent: curl/7.64.0 Accept: */* $ curl whoami-2.whoami.kube-test-1.svc.cluster.local Hostname: whoami-2 IP: 127.0.0.1 IP: 10.244.1.221 RemoteAddr: 10.244.0.53:38370 GET / HTTP/1.1 Host: whoami-2.whoami.kube-test-1.svc.cluster.local User-Agent: curl/7.64.0 Accept: */* 可以看到分别访问到三个不同的服务端pod了。\n总结 访问的url格式为：\npod-ip-address.deployment-name.my-namespace.svc.cluster-domain.example 参考链接 k8s 文档：A/AAAA 记录 ","date":"November 1, 2021","hero":"/posts/knowledge/2007-kubernetes/002-handless-statefullset/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2007-kubernetes/002-handless-statefullset/","summary":"#kubernetes #k8s\n连接一些多实例的服务（比如Kafka、ES）时，通常是在client端做负载均衡。\n假如这种集群又恰好跑在k8s中，如果是普通业务类型的服务，通常是创建一个Service来做为一个代理去访问不同实例，从而达到负载均衡的目的。\n但是诸如如：Kafka、ES类型的服务，还用Service来做负载均衡，显然就不那么合理了（诚然，Kafka、ES这种东西多半是不会跑在k8s上的，这里只是作为一个引子，不在本文讨论的范畴）。\n实验环境 多实例服务whoami在kube-test-1的命名空间下 多实例服务whoami以StatefulSet方式部署，设置为3个实例，会自动创建whoami-0、whoami-1以及whoami-2三个Pod 给StatefulSet创建Headless类型的Service 模拟客户端使用Nginx镜像，部署在kube-test-2的命名空间下（使用curl命令模拟） 本实验创建资源使用的k8s dashboard，创建的资源默认放在选中的明明空间下，因此yml文件中未指定namespace。\nServer cluster 服务端模拟相关资源在kube-test-1下创建\nStatefulSet 使用traefik/whoami镜像来模拟服务端\n这里使用StatefulSet的方式创建服务端。spec.replicas设为3，此时会自动创建whoami-0、whoami-1以及whoami-2三个Pod。\napiVersion: apps/v1 kind: StatefulSet metadata: name: whoami labels: app: whoami spec: replicas: 3 selector: matchLabels: app: whoami serviceName: whoami template: metadata: name: whoami labels: app: whoami spec: containers: - name: whoami image: traefik/whoami ports: - containerPort: 80 注意这里的spec.serviceName必须与下面的Service名字相同，否则调用时候pod的subdomain只能使用IP\n$ k get pod -n kube-test-1 -o wide | grep whoami whoami-0 1/1 Running 0 29m 10.","tags":null,"title":"k8s中通过Headless连接StatefulSet"},{"categories":null,"contents":" #kubernetes #k8s #token #dashboard\n问题现象 kubernetes的dashboard登录token过期时间太短，不操作没一会就需要重新登录\n解决办法 修改kubernetes-dashboard的deployment，加入一条arg参数：\n- \u0026#39;--token-ttl=10800\u0026#39; ","date":"November 1, 2021","hero":"/posts/problems/5004-kubernetes-dashboard-token/head.svg","permalink":"https://ormissia.github.io/posts/problems/5004-kubernetes-dashboard-token/","summary":" #kubernetes #k8s #token #dashboard\n问题现象 kubernetes的dashboard登录token过期时间太短，不操作没一会就需要重新登录\n解决办法 修改kubernetes-dashboard的deployment，加入一条arg参数：\n- \u0026#39;--token-ttl=10800\u0026#39; ","tags":null,"title":"k8s dashboard token过期时间太短"},{"categories":null,"contents":" #elasticsearch #elastic #db #search-engine #lucene\n搜索类型 搜索引擎：百度、搜狗、谷歌、必应 垂直领域：各大电商平台、OA系统、站内搜索 商业智能：数据分析、数据挖掘、用户画像 GitHub：千亿+行代码秒查 日志系统：ELK ES特点 搜索、聚合分析、大数据存储 分布式、高性能、高可用、可伸缩、易维护 支持文本搜索、结构化数据、非结构化数据、地理位置搜索等 ES单机部署 同一节点启动不同服务 ./bin/elasticsearch -E path.data=data1 -E path.logs=log1 -E node.name=node1 -E cluster.name=ormissia_test ./bin/elasticsearch -E path.data=data2 -E path.logs=log2 -E node.name=node2 -E cluster.name=ormissia_test http://localhost:9200/ http://localhost:9201/ 不同节点启动同一服务 open ./elasticsearch_node1/bin/elasticsearch open ./elasticsearch_node2/bin/elasticsearch open ./elasticsearch_node3/bin/elasticsearch open ./elasticsearch_node4/bin/elasticsearch open ./elasticsearch_node5/bin/elasticsearch open ./kibana-7.15.1-darwin-x86_64/bin/kibana elasticsearch-head插件 GitHub Repository\ngit clone git://github.com/mobz/elasticsearch-head.git cd elasticsearch-head npm install npm run start 默认端口：9100\n如果集群无法连接，需要修改ES配置文件\nhttp.cors.enabled: true http.cors.allow-origin: \u0026#34;*\u0026#34; elasticsearch-head也可以以Chrome插件的方式安装\n集群健康值检查 健康值状态 Grenn：所有Primary和Replica均为active，集群健康 Yellow：至少有一个Replica不可用，但是所有Primary均为active，数据仍然是可以保证完整性的 Red：至少有一个Primary为不可用状态，数据不完整，集群不可用 Replica是不可以写的\n健康值检查 _cat/health GET _cat/health?v epoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent 1634624559 06:22:39 elasticsearch green 5 5 24 12 0 0 0 0 - 100.0% 格林尼治时间 集群名称 集群状态 节点数 数据节点 分片 Primary 准备执行任务数 最大任务等待时间 当前活动分片百分比 _cluster/health GET _cluster/health { \u0026#34;cluster_name\u0026#34; : \u0026#34;elasticsearch\u0026#34;, \u0026#34;status\u0026#34; : \u0026#34;green\u0026#34;, \u0026#34;timed_out\u0026#34; : false, \u0026#34;number_of_nodes\u0026#34; : 5, \u0026#34;number_of_data_nodes\u0026#34; : 5, \u0026#34;active_primary_shards\u0026#34; : 12, \u0026#34;active_shards\u0026#34; : 24, \u0026#34;relocating_shards\u0026#34; : 0, \u0026#34;initializing_shards\u0026#34; : 0, \u0026#34;unassigned_shards\u0026#34; : 0, \u0026#34;delayed_unassigned_shards\u0026#34; : 0, \u0026#34;number_of_pending_tasks\u0026#34; : 0, \u0026#34;number_of_in_flight_fetch\u0026#34; : 0, \u0026#34;task_max_waiting_in_queue_millis\u0026#34; : 0, \u0026#34;active_shards_percent_as_number\u0026#34; : 100.0 } 注释\n# \u0026#34;relocating_shards\u0026#34; : 0, 迁移中 # \u0026#34;initializing_shards\u0026#34; : 0, 初始化中 # \u0026#34;unassigned_shards\u0026#34; : 0, 未分配的 搜索引擎 搜索引擎类别 全文搜索引擎：自然语言处理（NLP）、爬虫、网页处理、大数据处理，如谷歌、百度、搜狗、必应等 垂直搜索引擎：有明确目的的搜索行为，如各大电商网站、OA系统、站内搜索、视频网站等 搜索引擎要求 查询速度快 高效的压缩算法 快速的编码和解码速度 结果准确 BM25评分算法（7.0之后） TF-IDF 检验结果丰富 召回率 Lucene 以MySQL为例的数据库组成结构\nMySQL索引面临大数据检索的问题：\n索引失效 精准度差 大数据量下索引性能变低 Lucene使用倒排索引解决了上述问题\n倒排索引核心算法 倒排索引表的压缩算法 FOR: Frame Of Reference RBM: RoaringBitMap 词项索引的检索原理 FST: Finit state Transducers FOR RBM FST FSA：有限状态接收机 FST：有限状态转换机\nFST最重要的功能是实现key到value的映射，相当于HashMap。\nFST的查询比HashMap要慢一点，但FST的内存消耗要比HashMap少很多。\nFST在Lucene中被大量使用，如：倒排索引的存储，同义词词典的存储，搜索关键词建议等\nNode 节点\nAcr 出度 freezeTail 尾部冻结\n通用最小化算法：BitMap\nES简单的CRUD 示例使用Kibana的Dev Tools操作\n创建索引 创建test索引\nPUT /test 查询索引 查询test索引\nGET /test 添加一条文档 创建索引为1的一条文档\nPUT /test/_doc/1 { \u0026#34;name\u0026#34;: \u0026#34;xiaoming\u0026#34;, \u0026#34;age\u0026#34;: 123, \u0026#34;tag\u0026#34;: [ \u0026#34;pople\u0026#34;, \u0026#34;student\u0026#34; ] } 查询文档 根据索引查询文档\nGET /test/_doc/1 修改文档 根据索引修改文档\nPOST /test/_update/1 { \u0026#34;doc\u0026#34;: { \u0026#34;age\u0026#34;: 222 } } Mapping 定义ES索引中字段类型等信息的映射，映射是定义文档及其包含的字段的存储和索引方式的过程，换句话来说，Mapping相当于传统关系型数据库中的DDL建表语句。\n在Mapping里也包含了一些属性，比如字段名称、类型、字段使用的分词器、是否评分、是否创建索引等属性，并且在ES中一个字段可以有多个类型。\nMapping类型：\nDynamic mapping：动态映射 Explicit mapping：显式映射 查看Mapping GET /index/_mapping 数据类型 基础类型 数字类型：long、integer、short、byte、double、float、half_float、scaled_float、unsigned_long Keywords： Keywords适用于索引结构化的字段，可以用于过滤、排序、聚合。keyword类型的字段只能通过精确值（exact value）搜索到。id应该用keyword constant_keyword：始终包含相同值的关键字字段 wildcard：可针对类似grep的通配符查询优化日志行和类似的关键字值 Dates（时间类型）：包括Date和 Date nanoseconds Alias：为现有字段定义别名 Binary：二进制 Range：区间类型，integer_range、float_range、long_range、double_range、date_range text：当一个字段是要被全文搜索的，比如Email内容、产品描述，这些字段应该使用text类型。设置text类型以后，字段内容会被分析，在生成倒排索引以前，字符串会被分析器分成一个一个词项。text类型的字段不用于排序，很少用于聚合。（解释一下为啥不会为text创建正排索引：大量堆空间，尤其是在加载高基数text字段时。字段数据一旦加载到堆中，就在该段的生命周期内保持在那里。同样，加载字段数据是一个昂贵的过程，可能导致用户遇到延迟问题。这就是默认情况下禁用字段数据的原因） 对象关系类型 Object：用于单个JSON对象 Nested：用于JSON对象数组 flattened：允许将整个JSON对象索引为单个字段。 结构化类型 Geopoint：纬度/经度积分 Geoshape：用于多边形等复杂形状 Point：笛卡尔坐标点 Shape：笛卡尔任意几何图形 特殊类型 IP：用于IPv4和IPv6地址 Completion：提供自动完成建议 // TODO Token count：计算字符串中令牌的数量 \u0026hellip; Array（数组）：在ES中，数组不需要专用的字段数据类型。默认情况下，任何字段都可以包含零个或多个值，但是，数组中的所有值都必须具有相同的数据类型。 版本新增 Date nanoseconds \u0026hellip; 除了支持的映射参数之外，无法更改现有字段的映射或字段类型。更改现有字段可能会使已编入索引的数据无效。\nDynamic mapping字段对应关系 内容 类型 整数 long 浮点数 float true/false boolean 日期 date 数组 取决于数组中的第一个有效值 对象 object 字符串 如果不是数字和日期类型，那会被映射为text和keyword两个类型 除了上述字段类型之外，其他类型都必须显式映射，也就是必须手工指定，因为其他类型ES无法自动识别。\nExplicit mapping显式映射 PUT /my-index-000001 { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;age\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;email\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; } } } } 再次注明：除了支持的映射参数之外，无法更改现有字段的映射或字段类型。更改现有字段可能会使已编入索引的数据无效。\n参数 index：是否对创建对当前字段创建倒排索引，默认true，如果不创建索引，该字段不会通过索引被搜索到,但是仍然会在source元数据中展示 analyzer：指定分析器，Character filter、Tokenizer、Token filters boost：对当前字段相关度的评分权重，默认1 coerce：是否允许强制类型转换 true “1”=\u0026gt; 1 false “1”=\u0026lt; 1 doc_values：为了提升排序和聚合效率，默认true，如果确定不需要对字段进行排序或聚合，也不需要通过脚本访问字段值，则可以禁用doc值以节省磁盘空间（不支持text和annotated_text） dynamic：控制是否可以动态添加新字段 true：新检测到的字段将添加到映射中。（默认） false：新检测到的字段将被忽略。这些字段将不会被索引，因此将无法搜索，但仍会出现在_source返回的匹配项中。这些字段不会添加到映射中，必须显式添加新字段。 strict：如果检测到新字段，则会引发异常并拒绝文档。必须将新字段显式添加到映射中 eager_global_ordinals：用于聚合的字段上，优化聚合性能。 Frozen indices：冻结索引，有些索引使用率很高，会被保存在内存中，有些使用率特别低，宁愿在使用的时候重新创建，在使用完毕后丢弃数据，Frozen indices的数据命中频率小，不适用于高搜索负载，数据不会被保存在内存中，堆空间占用比普通索引少得多，Frozen indices是只读的，请求可能是秒级或者分钟级。eager_global_ordinals不适用于Frozen indices enable：是否创建倒排索引，可以对字段操作，也可以对索引操作，如果不创建索引，仍然可以检索并在_source元数据中展示，谨慎使用，该状态无法修改。 fielddata：查询时内存数据结构，在首次用当前字段聚合、排序或者在脚本中使用时，需要字段为fielddata数据结构，并且创建倒排索引保存到堆中。 fields：给field创建多字段，用于不同目的（全文检索或者聚合分析排序） format：格式化 \u0026#34;date\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;yyyy-MM-dd\u0026#34; } norms：是否禁用评分（在filter和聚合字段上应该禁用）。 null_value：为null值设置默认值 search_analyzer：设置单独的查询时分析器 store：设置字段是否仅查询 \u0026hellip; Query DSL(Domain Specific Language) 查询上下文 使用query关键字进行检索，倾向于相关度搜索，需要计算相关度评分。\n相关度评分_score 相关度评分用于对搜索结果排序，评分越高则认为其结果和搜索的预期值相关度越高，即越符合搜索预期值。在7.x之前相关度评分默认使用TF/IDF算法计算而来，7.x之后默认为BM25。\n相关度评分为搜索结果的排序依据，默认情况下评分越高，则结果越靠前。\n元数据_source 禁用_source\nGET product/_search { \u0026#34;_source\u0026#34;: false, \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } } 好处：节省存储开销 坏处： 不支持update、update_by_query和reindex API。 不支持高亮。 不支持reindex、更改mapping分析器和版本升级。 通过查看索引时使用的原始文档来调试查询或聚合的功能。 将来有可能自动修复索引损坏。 总结：如果只是为了节省磁盘，可以压缩索引比禁用_source更好。\n数据源过滤器\nIncluding：结果中返回哪些field Excluding：结果中不要返回哪些field，不返回的field不代表不能通过该字段进行检索，因为元数据不存在不代表索引不存在 在mapping中定义过滤：支持通配符，但是这种方式不推荐，因为mapping不可变\nGET product/_search { \u0026#34;_source\u0026#34;: [\u0026#34;owner.name\u0026#34;,\u0026#34;owner.sex\u0026#34;], \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } } 常用过滤规则\n\u0026#34;_source\u0026#34;: \u0026#34;false\u0026#34;, \u0026#34;_source\u0026#34;: \u0026#34;obj.*\u0026#34;, \u0026#34;_source\u0026#34;: [ \u0026#34;obj1.\\*\u0026#34;, \u0026#34;obj2.\\*\u0026#34; ], \u0026#34;_source\u0026#34;: { \u0026#34;includes\u0026#34;: [ \u0026#34;obj1.\\*\u0026#34;, \u0026#34;obj2.\\*\u0026#34; ], \u0026#34;excludes\u0026#34;: [ \u0026#34;*.description\u0026#34; ] } Query String 查询所有：GET /product/_search 带参数：GET /product/_search?q=name:productname 分页：GET /product/_search?from=0\u0026amp;size=2\u0026amp;sort=price:asc 精准匹配：GET /product/_search?q=date:2021-10-21 _all搜索（相当于在所有有索引的字段中检索）：GET /product/_search?q=2021-06-01 全文检索-Fulltext query GET index/_search { \u0026#34;query\u0026#34;: { *** } } 示例\nGET product/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;huahua blue cat\u0026#34; } } } match：匹配包含某个term的子句 match_all：匹配所有结果的子句 multi_match：多字段条件 match_phrase：短语查询，分词结果必须在被检索字段的分词中都包含，而且顺序必须相同，而且默认必须都是连续的 精准查询-Term query term：匹配和搜索词项完全相等的结果\nterm和match_phrase区别: match_phrase会将检索关键词分词,match_phrase的分词结果必须在被检索字段的分词中都包含，而且顺序必须相同，而且默认必须都是连续的 term搜索不会将搜索词分词 term和keyword区别 term是对于搜索词不分词, keyword是字段类型,是对于source data中的字段值不分词 # term GET product/_search { \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;xiaomi phone\u0026#34; } } } #term和match_phrase区别 GET product/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_phrase\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;blue cat\u0026#34; } } } #term和keyword的区别 GET product/_search { \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;name.keyword\u0026#34;: \u0026#34;blue cat\u0026#34; } } } terms：匹配和搜索词项列表中任意项匹配的结果（数据中的tags字段只要有任意一项就可以查到）\nGET product/_search { \u0026#34;query\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;tags\u0026#34;: [ \u0026#34;aaaaaa\u0026#34;, \u0026#34;cat\u0026#34; ], \u0026#34;boost\u0026#34;: 1.0 } } } range：范围查找\nGET /_search { \u0026#34;query\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;price\u0026#34;: { \u0026#34;gte\u0026#34;: 1000, \u0026#34;lte\u0026#34;: 20000 } } } } GET product/_search { \u0026#34;query\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;date\u0026#34;: { \u0026#34;time_zone\u0026#34;: \u0026#34;+08:00\u0026#34;, \u0026#34;gte\u0026#34;: \u0026#34;2021-10-21\u0026#34;, \u0026#34;lt\u0026#34;: \u0026#34;2021-10-21\u0026#34; } } } } GET product/_search { \u0026#34;query\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;date\u0026#34;: { \u0026#34;gte\u0026#34;: \u0026#34;now-1d/d\u0026#34;, \u0026#34;lt\u0026#34;: \u0026#34;now/d\u0026#34; } } } } 过滤器-Filter query和filter的主要区别在：filter是结果导向的而query是过程导向。query倾向于“当前文档和查询的语句的相关度”而filter倾向于“当前文档和查询的条件是不是相符”。即在查询过程中，query是要对查询的每个结果计算相关性得分的，而filter不会。另外filter有相应的缓存机制，可以提高查询效率。\nGET product/_search { \u0026#34;query\u0026#34;: { \u0026#34;constant_score\u0026#34;: { \u0026#34;filter\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;phone\u0026#34; } }, \u0026#34;boost\u0026#34;: 1.2 } } } 组合查询-Bool query 可以组合多个查询条件，bool查询也是采用more_matches_is_better的机制，因此满足must和should子句的文档将会合并起来计算分值\nmust：必须满足子句（查询）必须出现在匹配的文档中，并将有助于得分。 filter：过滤器，不计算相关度分数，cache子句（查询）必须出现在匹配的文档中。但是不像must查询的分数将被忽略。Filter子句在filter上下文中执行，这意味着计分被忽略，并且子句被考虑用于缓存。 should：可能满足，or子句（查询）应出现在匹配的文档中。 must_not：必须不满足，不计算相关度分数，not子句（查询）不得出现在匹配的文档中。子句在过滤器上下文中执行，这意味着计分被忽略，并且子句被视为用于缓存。由于忽略计分，因此将返回所有文档的分数。 minimum_should_match：参数指定should返回的文档必须匹配的子句的数量或百分比。如果bool查询包含至少一个should子句，而没有must或 filter子句，则默认值为1。否则，默认值为0\n分词器 normalization 文档规范化,提高召回率 拼写错误、形容词、单复数、动词、大小写、分词、称谓等转换成标准词汇\nGET _analyze { \u0026#34;text\u0026#34;: \u0026#34;Mr. Ma is an excellent teacher\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;pattern\u0026#34; } character filter 字符过滤器 分词之前的预处理，过滤无用字符\nHTML Strip PUT test_index { \u0026#34;settings\u0026#34;: { \u0026#34;analysis\u0026#34;: { \u0026#34;char_filter\u0026#34;: { \u0026#34;my_char_filter\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;html_strip\u0026#34;, \u0026#34;escaped_tags\u0026#34;: [ \u0026#34;a\u0026#34; ] } }, \u0026#34;analyzer\u0026#34;: { \u0026#34;my_analyzer\u0026#34;: { \u0026#34;tokenizer\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;char_filter\u0026#34;: \u0026#34;my_char_filter\u0026#34; } } } } } GET test_index/_analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;my_analyzer\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;\u0026lt;p\u0026gt;I\u0026amp;apos;m so \u0026lt;a\u0026gt;happy\u0026lt;/a\u0026gt;!\u0026lt;/p\u0026gt;\u0026#34; } Mapping PUT test_index { \u0026#34;settings\u0026#34;: { \u0026#34;analysis\u0026#34;: { \u0026#34;char_filter\u0026#34;: { \u0026#34;my_char_filter\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;mapping\u0026#34;, \u0026#34;mappings\u0026#34;:[ \u0026#34;滚 =\u0026gt; *\u0026#34;, \u0026#34;垃圾 =\u0026gt; **\u0026#34; ] } }, \u0026#34;analyzer\u0026#34;: { \u0026#34;my_analyzer\u0026#34;: { \u0026#34;tokenizer\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;char_filter\u0026#34;: \u0026#34;my_char_filter\u0026#34; } } } } } GET test_index/_analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;my_analyzer\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;滚！你就是个垃圾\u0026#34; } Pattern Replace PUT test_index { \u0026#34;settings\u0026#34;: { \u0026#34;analysis\u0026#34;: { \u0026#34;char_filter\u0026#34;: { \u0026#34;my_char_filter\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;pattern_replace\u0026#34;, \u0026#34;pattern\u0026#34;:\u0026#34;(\\\\d{3})\\\\d{4}(\\\\d{4})\u0026#34;, \u0026#34;replacement\u0026#34;:\u0026#34;$1****$2\u0026#34; } }, \u0026#34;analyzer\u0026#34;: { \u0026#34;my_analyzer\u0026#34;: { \u0026#34;tokenizer\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;char_filter\u0026#34;: \u0026#34;my_char_filter\u0026#34; } } } } } GET test_index/_analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;my_analyzer\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;手机号是：15633334444\u0026#34; } token filter 令牌过滤器 停用词、时态转换、大小写转换、同义词转换、语气词处理等。比如：has=\u0026gt;have him=\u0026gt;he apples=\u0026gt;apple the/oh/a=\u0026gt;干掉\ntokenizer 分词器 常见分词器\nstandard analyzer：默认分词器，中文支持的不理想，会逐字拆分。 pattern tokenizer：以正则匹配分隔符，把文本拆分成若干词项。 simple pattern tokenizer：以正则匹配词项，速度比pattern tokenizer快。 whitespace analyzer：以空白符分隔 custom analyzer 自定义分词器\nchar_filter：内置或自定义字符过滤器 。 token filter：内置或自定义token filter 。 tokenizer：内置或自定义分词器。 ik分词（中文分词器） 安装 下载对应版本，解压后放到ES的plugins文件夹下面\nes-root/plugins/ \u0026amp;\u0026amp; mkdir ik 重启ES\nGET test_index/_analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34;, \u0026#34;text\u0026#34;: [ \u0026#34;我爱中华人民共和国\u0026#34; ] } 文件 IKAnalyzer.cfg.xml：IK分词配置文件 main.dic：主词库 stopword.dic：英文停用词，不会建立在倒排索引中 特殊词库： quantifier.dic：特殊词库：计量单位等 suffix.dic：特殊词库：行政单位 surname.dic：特殊词库：百家姓 preposition：特殊词库：语气词 自定义词库：网络词汇、流行词、自造词等 热更新 远程词库文件 词库的管理不方便，要操作直接操作磁盘文件，检索页很麻烦 文件的读写没有专门的优化性能不好 多一层接口调用和网络传输 ik访问数据库 聚合查询 用于进行聚合的字段必须是exact value，分词字段不可进行聚合。 对于text字段如果需要使用聚合，需要开启fielddata，但是通常不建议，因为fielddata是将聚合使用的数据结构由磁盘（doc_values）变为了堆内存（field_data），大数据的聚合操作很容易导致OOM。\n聚合分类 分桶聚合Bucket agregations：类比SQL中的group by的作用，主要用于统计不同类型数据的数量 指标聚合Metrics agregations：主要用于最大值、最小值、平均值、字段之和等指标的统计 管道聚合Pipeline agregations：用于对聚合的结果进行二次聚合，如要统计绑定数量最多的标签bucket，就是要先按照标签进行分桶，再在分桶的结果上计算最大值。 桶聚合： 场景：用于统计不同种类的文档的数量，可进行嵌套统计。\n函数：terms\n注意：聚合字段必须是exact value，如keyword\n指标聚合 场景：用于统计某个指标，如最大值、最小值、平均值，可以结合桶聚合一起使用，如按照商品类型分桶，统计每个桶的平均价格。\n函数：平均值：Avg、最大值：Max、最小值：Min、求和：Sum、详细信息：Stats、数量：Value count\n管道聚合 场景：用于对聚合查询的二次聚合，如统计平均价格最低的商品分类，即先按照商品分类进行桶聚合，并计算其平均价格，然后对其平均价格计算最小值聚合\n函数：Min bucket：最小桶、Max bucket：最大桶、Avg bucket：桶平均值、Sum bucket：桶求和、Stats bucket：桶信息\n注意：buckets_path为管道聚合的关键字，其值从当前聚合统计的聚合函数开始计算为第一级。比如下面例子中，my_aggs和my_min_bucket同级，my_aggs就是buckets_path值的起始值。\n脚本查询 Scripting是Elasticsearch支持的一种专门用于复杂场景下支持自定义编程的强大的脚本功能，ES支持多种脚本语言，如painless，其语法类似于Java,也有注释、关键字、类型、变量、函数等，其就要相对于其他脚本高出几倍的性能，并且安全可靠，可以用于内联和存储脚本。\n支持的语言 groovy：ES 1.4.x-5.0的默认脚本语言 painless：Elasticsearch现在的默认脚本语言 expression：每个文档的开销较低：表达式的作用更多，可以非常快速地执行，甚至比编写native脚本还要快，支持javascript语法的子集：单个表达式。缺点：只能访问数字，布尔值，日期和geo_point字段，存储的字段不可用 mustache：脚本模板 模糊查询 搜索推荐 数据建模 ES学习总结 通用最小化算法：BitMap 倒排索引压缩算法中的RBM算法中用到了Bitmap，在Redis的布隆过滤器中也用到了\n倒排索引的 ，在Linux文件权限中也用到了\n参考链接 Elastic stack版本支持 Elasticsearch Head GitHub Repository ik分词器 ","date":"October 19, 2021","hero":"/posts/knowledge/2010-elastic/001-elasticstack-es/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2010-elastic/001-elasticstack-es/","summary":"#elasticsearch #elastic #db #search-engine #lucene\n搜索类型 搜索引擎：百度、搜狗、谷歌、必应 垂直领域：各大电商平台、OA系统、站内搜索 商业智能：数据分析、数据挖掘、用户画像 GitHub：千亿+行代码秒查 日志系统：ELK ES特点 搜索、聚合分析、大数据存储 分布式、高性能、高可用、可伸缩、易维护 支持文本搜索、结构化数据、非结构化数据、地理位置搜索等 ES单机部署 同一节点启动不同服务 ./bin/elasticsearch -E path.data=data1 -E path.logs=log1 -E node.name=node1 -E cluster.name=ormissia_test ./bin/elasticsearch -E path.data=data2 -E path.logs=log2 -E node.name=node2 -E cluster.name=ormissia_test http://localhost:9200/ http://localhost:9201/ 不同节点启动同一服务 open ./elasticsearch_node1/bin/elasticsearch open ./elasticsearch_node2/bin/elasticsearch open ./elasticsearch_node3/bin/elasticsearch open ./elasticsearch_node4/bin/elasticsearch open ./elasticsearch_node5/bin/elasticsearch open ./kibana-7.15.1-darwin-x86_64/bin/kibana elasticsearch-head插件 GitHub Repository\ngit clone git://github.com/mobz/elasticsearch-head.git cd elasticsearch-head npm install npm run start 默认端口：9100\n如果集群无法连接，需要修改ES配置文件\nhttp.cors.enabled: true http.cors.allow-origin: \u0026#34;*\u0026#34; elasticsearch-head也可以以Chrome插件的方式安装","tags":null,"title":"Elasticsearch"},{"categories":null,"contents":" 此次安装的平台是基于ARM架构的RedHat系Linux系统平台，参照Kubernetes官方文档进行的。\n本文档流程与X86架构的没有区别，官方文档中个别步骤中的命令需要区分所使用的包对应的平台。\n初始化环境 防火墙 systemctl stop firewalld.service systemctl disable firewalld.service SELinux vi /etc/selinux/config SELINUX=disabled Swap vi /etc/fstab 注释掉swap这一行\n/.swapfile\tnone\tswap\tsw,comment=cloudconfig\t0\t0 重启之后查看关闭是否成功\nfree -m 显示如下内容，swap关闭成功\ntotal used free shared buff/cache available Mem: 23114 402 22299 32 411 20597 Swap: 0 0 0 ulimit echo \u0026#34;ulimit -n 65535\u0026#34; \u0026gt;\u0026gt; /etc/profile echo \u0026#34;*\thard\tnofile\t65535\u0026#34; \u0026gt;\u0026gt; /etc/security/limits.conf 重启之后检查是否配置成功\nulimit -n SSH免密（非必须） 执行命令，一路回车，即可获得当前节点的公钥\nssh-keygen -t rsa cat id_rsa.pub iptables 查看br_netfilter模块是否开启\nlsmod | grep br_netfilter 如果没有看到输出则执行命令开启\nmodprobe br_netfilter 作为Linux节点的iptables正确查看桥接流量的要求，应该确保net.bridge.bridge-nf-call-iptables在sysctl配置中设置为1\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system 安装Docker yum install -y yum-utils yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo yum install docker-ce docker-ce-cli containerd.io -y systemctl start docker systemctl enable docker 修改Docker Cgroup Driver 为 systemd（大坑一）\nvi /usr/lib/systemd/system/docker.service 修改配置文件中的启动参数\n#ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --exec-opt native.cgroupdriver=systemd 重启Docker\nsystemctl daemon-reload systemctl restart docker 安装Kubernetes kubeadm：引导集群的命令。 kubelet：在集群中的所有机器上运行的组件，并执行诸如启动Pod和容器之类的操作。 kubectl：用于与集群通信的命令行实用程序 使用yum安装，添加yum源\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\\$basearch enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg exclude=kubelet kubeadm kubectl EOF 安装并启动\nyum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes systemctl enable --now kubelet 至此，集群中所有节点都是相同操作\n初始化master 使用kubeadm作为集群的初始化工具\nkubeadm init --kubernetes-version=v1.22.2 --pod-network-cidr=10.244.0.0/16 成功初始化之后会出现提示，其中有三个需要手动执行，最后一个是需要在从节点上执行（此处有坑）\nYour Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join --control-plane 10.0.0.105:6443 --token axqrzz.ouonxxxxxxgdvgjz \\ --discovery-token-ca-cert-hash sha256:3a57ff0d78b1f85xxxxxxxxxxxxxxxxxxxxe0f90f47037a31a33 手动执行\nmkdir -p #HOME/.kube sudo cp -i /etc/kubernetes/admin.conf #HOME/.kube/config sudo chown #(id -u):#(id -g) #HOME/.kube/config kubeadm join --control-plane 10.0.0.105:6443 --token axqrzz.ouonxxxxxxgdvgjz \\ --discovery-token-ca-cert-hash sha256:3a57ff0d78b1f85xxxxxxxxxxxxxxxxxxxxe0f90f47037a31a33 使用kubectl get nodes命令查看节点\nNAME STATUS ROLES AGE VERSION arm-node-1 NotReady control-plane,master 1m v1.22.2 此时可以看到master处于NotReady状态\n查看集群中pod状态\n这是后期补的，所以时间很久\nkubectl get pod --all-namespaces # 输出 NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-78fcd69978-2vcqt 1/1 Pending 1 (126m ago) 12h kube-system coredns-78fcd69978-xg98g 1/1 Pending 1 (126m ago) 12h kube-system etcd-arm-node-1 1/1 Running 2 (126m ago) 12h kube-system kube-apiserver-arm-node-1 1/1 Running 2 (126m ago) 12h kube-system kube-controller-manager-arm-node-1 1/1 Running 2 (126m ago) 12h kube-system kube-proxy-q5m5k 1/1 Running 1 (126m ago) 12h kube-system kube-scheduler-arm-node-1 1/1 Running 2 (126m ago) 12h 可以看到两个coredns的pod处于Pending状态，这是由于缺少网络组件\n这里我们选择安装flannel\n大坑二\nkubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml 执行这条命令之后查看pod状态会出现ErrImagePull的提示\n原因是rancher/flannel-cni-plugin:v1.2的镜像拉取不到\n到网上查了一番，看好多是相同的报错，但是因为quay.io/coreos/flannel的镜像拉不到，于是我手动拉了一下rancher/flannel-cni-plugin这个镜像\ndocker pull rancher/flannel-cni-plugin:v1.2 # 输出 Error response from daemon: pull access denied for rancher/flannel-cni-plugin, repository does not exist or may require \u0026#39;docker login\u0026#39;: denied: requested access to the resource is denied 咦？找不到镜像？ 于是我去Docker Hub的页面去搜了一下，居然没有这个镜像\n真是啥坑都有\n去flannel-io/flannel的issue中看了一下，最新的一条就是这个相同的问题\n好吧，删掉换个旧版本重新来过\n在GitHub的flannel-io/flannel仓库中切到v0.14.1版本中看了一下，没有使用到rancher/flannel-cni-plugin这个镜像\nkubectl delete -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/release/v0.14.1/Documentation/kube-flannel.yml 这回成功了，重新查看pod和节点状态\nkubectl get pod --all-namespaces # 输出 NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-78fcd69978-2vcqt 1/1 Running 1 (126m ago) 12h kube-system coredns-78fcd69978-xg98g 1/1 Running 1 (126m ago) 12h kube-system etcd-arm-node-1 1/1 Running 2 (126m ago) 12h kube-system kube-apiserver-arm-node-1 1/1 Running 2 (126m ago) 12h kube-system kube-controller-manager-arm-node-1 1/1 Running 2 (126m ago) 12h kube-system kube-flannel-ds-kdpgp 1/1 Running 1 (126m ago) 3h32m kube-system kube-proxy-q5m5k 1/1 Running 1 (126m ago) 12h kube-system kube-scheduler-arm-node-1 1/1 Running 2 (126m ago) 12h kubectl get nodes # 输出 NAME STATUS ROLES AGE VERSION arm-node-1 Ready control-plane,master 13h v1.22.2 初始化从节点（大坑三） 对于从节点，安装完kubeadm，kubelet，kebectl三个组件后，直接运行master节点kubeadm init完成之后的输出结果中的最后一条命令\nkubeadm join --control-plane 10.0.0.105:6443 --token axqrzz.ouonxxxxxxgdvgjz \\ --discovery-token-ca-cert-hash sha256:3a57ff0d78b1f85xxxxxxxxxxxxxxxxxxxxe0f90f47037a31a33 但是这里我踩到一个坑，复制的这条命令粘贴到命令行中后，在第二行开头会莫名其妙多出来一个.\n造成执行kubeadm join时一直报参数数量的错误\naccepts at most 1 arg(s), received 3 To see the stack trace of this error execute with --v=5 or higher 这个问题也查了好久，最后将命令改为一行去执行\nkubeadm join --control-plane 10.0.0.105:6443 --token axqrzz.ouonxxxxxxgdvgjz --discovery-token-ca-cert-hash sha256:3a57ff0d78b1f85xxxxxxxxxxxxxxxxxxxxe0f90f47037a31a33 命令执行返回加入集群成功后查看节点状态\nkubectl get nodes # 输出 NAME STATUS ROLES AGE VERSION arm-node-1 Ready control-plane,master 13h v1.22.2 arm-node-2 Ready \u0026lt;none\u0026gt; 170m v1.22.2 可以看到从节点成功加入主节点\n安装Dashboard 安装服务 kubectl -n kubernetes-dashboard get secret $(kubectl -n kubernetes-dashboard get sa/admin-user -o jsonpath=\u0026#34;{.secrets[0].name}\u0026#34;) -o go-template=\u0026#34;{{.data.token | base64decode}}\u0026#34; 创建权限及用户 apiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kubernetes-dashboard apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard 获取Token kubectl -n kubernetes-dashboard get secret $(kubectl -n kubernetes-dashboard get sa/admin-user -o jsonpath=\u0026#34;{.secrets[0].name}\u0026#34;) -o go-template=\u0026#34;{{.data.token | base64decode}}\u0026#34; 安装Metrics Server Kubernetes Metrics Server是Cluster的核心监控数据的聚合器，kubeadm默认是不部署的。 Metrics Server供Dashboard等其他组件使用，是一个扩展的APIServer，依赖于API Aggregator。 Metrics API只可以查询当前的度量数据，并不保存历史数据。 Metrics API URI为/apis/metrics.k8s.io/，在k8s.io/metrics下维护。 必须部署metrics-server才能使用该API，metrics-server通过调用kubelet Summary API获取数据。 修改API Server 检查API Server是否开启了Aggregator Routing：查看API Server是否具有--enable-aggregator-routing=true选项。\nps -ef | grep apiserver | grep routing 如果没有输出，直接修改/etc/kubernetes/manifests/kube-apiserver.yaml\nvi /etc/kubernetes/manifests/kube-apiserver.yaml 修改每个API Server的kube-apiserver.yaml\n修改manifests配置后API Server会自动重启生效\n# ...省略 spec: containers: - command: - kube-apiserver - --enable-aggregator-routing=true # 加入这一行 # ...省略 部署到k8s 从GitHub上下载的部署文件需要修改一下\n# ...省略 spec: selector: matchLabels: k8s-app: metrics-server strategy: rollingUpdate: maxUnavailable: 0 template: metadata: labels: k8s-app: metrics-server spec: containers: - args: - --cert-dir=/tmp - --secure-port=443 - --kubelet-preferred-address-types=InternalIP # 删掉 ExternalIP,Hostname这两个 - --kubelet-use-node-status-port - --kubelet-insecure-tls # 加上该启动参数 image: k8s.gcr.io/metrics-server/metrics-server:v0.5.1 # 镜像版本自己选择 # ...省略 完整部署文件见附录\n验证安装工 使用命令查看节点负载 kubectl top nodes # 输出 NAME CPU(cores) CPU% MEMORY(bytes) MEMORY% node1 117m 5% 1959Mi 25% node2 29m 2% 1640Mi 21% node3 43m 4% 1694Mi 22% 到Dashboard查看资源占用情况 参考链接 k8s官网 kubectl开启shell自动补全 k8s dashboard repository k8s metrics-server repository Docker 文档 Docker Hub flannel GitHub v0.14.1 kube-flannel.yml 附录 v0.14.1/kube-flannel.yml # v0.14.1/kube-flannel.yml --- apiVersion: policy/v1beta1 kind: PodSecurityPolicy metadata: name: psp.flannel.unprivileged annotations: seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default spec: privileged: false volumes: - configMap - secret - emptyDir - hostPath allowedHostPaths: - pathPrefix: \u0026#34;/etc/cni/net.d\u0026#34; - pathPrefix: \u0026#34;/etc/kube-flannel\u0026#34; - pathPrefix: \u0026#34;/run/flannel\u0026#34; readOnlyRootFilesystem: false # Users and groups runAsUser: rule: RunAsAny supplementalGroups: rule: RunAsAny fsGroup: rule: RunAsAny # Privilege Escalation allowPrivilegeEscalation: false defaultAllowPrivilegeEscalation: false # Capabilities allowedCapabilities: [\u0026#39;NET_ADMIN\u0026#39;, \u0026#39;NET_RAW\u0026#39;] defaultAddCapabilities: [] requiredDropCapabilities: [] # Host namespaces hostPID: false hostIPC: false hostNetwork: true hostPorts: - min: 0 max: 65535 # SELinux seLinux: # SELinux is unused in CaaSP rule: \u0026#39;RunAsAny\u0026#39; --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: flannel rules: - apiGroups: [\u0026#39;extensions\u0026#39;] resources: [\u0026#39;podsecuritypolicies\u0026#39;] verbs: [\u0026#39;use\u0026#39;] resourceNames: [\u0026#39;psp.flannel.unprivileged\u0026#39;] - apiGroups: - \u0026#34;\u0026#34; resources: - pods verbs: - get - apiGroups: - \u0026#34;\u0026#34; resources: - nodes verbs: - list - watch - apiGroups: - \u0026#34;\u0026#34; resources: - nodes/status verbs: - patch --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: flannel roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: flannel subjects: - kind: ServiceAccount name: flannel namespace: kube-system --- apiVersion: v1 kind: ServiceAccount metadata: name: flannel namespace: kube-system --- kind: ConfigMap apiVersion: v1 metadata: name: kube-flannel-cfg namespace: kube-system labels: tier: node app: flannel data: cni-conf.json: | { \u0026#34;name\u0026#34;: \u0026#34;cbr0\u0026#34;, \u0026#34;cniVersion\u0026#34;: \u0026#34;0.3.1\u0026#34;, \u0026#34;plugins\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;flannel\u0026#34;, \u0026#34;delegate\u0026#34;: { \u0026#34;hairpinMode\u0026#34;: true, \u0026#34;isDefaultGateway\u0026#34;: true } }, { \u0026#34;type\u0026#34;: \u0026#34;portmap\u0026#34;, \u0026#34;capabilities\u0026#34;: { \u0026#34;portMappings\u0026#34;: true } } ] } net-conf.json: | { \u0026#34;Network\u0026#34;: \u0026#34;10.244.0.0/16\u0026#34;, \u0026#34;Backend\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;vxlan\u0026#34; } } --- apiVersion: apps/v1 kind: DaemonSet metadata: name: kube-flannel-ds namespace: kube-system labels: tier: node app: flannel spec: selector: matchLabels: app: flannel template: metadata: labels: tier: node app: flannel spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/os operator: In values: - linux hostNetwork: true priorityClassName: system-node-critical tolerations: - operator: Exists effect: NoSchedule serviceAccountName: flannel initContainers: - name: install-cni image: quay.io/coreos/flannel:v0.14.0 command: - cp args: - -f - /etc/kube-flannel/cni-conf.json - /etc/cni/net.d/10-flannel.conflist volumeMounts: - name: cni mountPath: /etc/cni/net.d - name: flannel-cfg mountPath: /etc/kube-flannel/ containers: - name: kube-flannel image: quay.io/coreos/flannel:v0.14.0 command: - /opt/bin/flanneld args: - --ip-masq - --kube-subnet-mgr resources: requests: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; limits: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; securityContext: privileged: false capabilities: add: [\u0026#34;NET_ADMIN\u0026#34;, \u0026#34;NET_RAW\u0026#34;] env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace volumeMounts: - name: run mountPath: /run/flannel - name: flannel-cfg mountPath: /etc/kube-flannel/ volumes: - name: run hostPath: path: /run/flannel - name: cni hostPath: path: /etc/cni/net.d - name: flannel-cfg configMap: name: kube-flannel-cfg v0.5.1/metrics-server.yml # v0.5.1/metrics-server.yml apiVersion: v1 kind: ServiceAccount metadata: labels: k8s-app: metrics-server name: metrics-server namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: k8s-app: metrics-server rbac.authorization.k8s.io/aggregate-to-admin: \u0026#34;true\u0026#34; rbac.authorization.k8s.io/aggregate-to-edit: \u0026#34;true\u0026#34; rbac.authorization.k8s.io/aggregate-to-view: \u0026#34;true\u0026#34; name: system:aggregated-metrics-reader rules: - apiGroups: - metrics.k8s.io resources: - pods - nodes verbs: - get - list - watch --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: k8s-app: metrics-server name: system:metrics-server rules: - apiGroups: - \u0026#34;\u0026#34; resources: - pods - nodes - nodes/stats - namespaces - configmaps verbs: - get - list - watch --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: labels: k8s-app: metrics-server name: metrics-server-auth-reader namespace: kube-system roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: extension-apiserver-authentication-reader subjects: - kind: ServiceAccount name: metrics-server namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: labels: k8s-app: metrics-server name: metrics-server:system:auth-delegator roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:auth-delegator subjects: - kind: ServiceAccount name: metrics-server namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: labels: k8s-app: metrics-server name: system:metrics-server roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:metrics-server subjects: - kind: ServiceAccount name: metrics-server namespace: kube-system --- apiVersion: v1 kind: Service metadata: labels: k8s-app: metrics-server name: metrics-server namespace: kube-system spec: ports: - name: https port: 443 protocol: TCP targetPort: https selector: k8s-app: metrics-server --- apiVersion: apps/v1 kind: Deployment metadata: labels: k8s-app: metrics-server name: metrics-server namespace: kube-system spec: replicas: 1 selector: matchLabels: k8s-app: metrics-server strategy: rollingUpdate: maxUnavailable: 0 template: metadata: labels: k8s-app: metrics-server spec: containers: - args: - --cert-dir=/tmp - --secure-port=443 - --kubelet-insecure-tls - --kubelet-preferred-address-types=InternalIP - --kubelet-use-node-status-port - --metric-resolution=15s image: k8s.gcr.io/metrics-server/metrics-server:v0.5.1 imagePullPolicy: IfNotPresent livenessProbe: failureThreshold: 3 httpGet: path: /livez port: https scheme: HTTPS periodSeconds: 10 name: metrics-server ports: - containerPort: 443 name: https protocol: TCP readinessProbe: failureThreshold: 3 httpGet: path: /readyz port: https scheme: HTTPS initialDelaySeconds: 20 periodSeconds: 10 resources: requests: cpu: 100m memory: 200Mi securityContext: readOnlyRootFilesystem: true runAsNonRoot: true runAsUser: 1000 volumeMounts: - mountPath: /tmp name: tmp-dir nodeSelector: kubernetes.io/os: linux priorityClassName: system-cluster-critical serviceAccountName: metrics-server volumes: - emptyDir: {} name: tmp-dir --- apiVersion: apiregistration.k8s.io/v1 kind: APIService metadata: labels: k8s-app: metrics-server name: v1beta1.metrics.k8s.io spec: group: metrics.k8s.io groupPriorityMinimum: 100 insecureSkipTLSVerify: true service: name: metrics-server namespace: kube-system version: v1beta1 versionPriority: 100 ","date":"October 14, 2021","hero":"/posts/deployment/3007-linux-kubernetes/head.svg","permalink":"https://ormissia.github.io/posts/deployment/3007-linux-kubernetes/","summary":"此次安装的平台是基于ARM架构的RedHat系Linux系统平台，参照Kubernetes官方文档进行的。\n本文档流程与X86架构的没有区别，官方文档中个别步骤中的命令需要区分所使用的包对应的平台。\n初始化环境 防火墙 systemctl stop firewalld.service systemctl disable firewalld.service SELinux vi /etc/selinux/config SELINUX=disabled Swap vi /etc/fstab 注释掉swap这一行\n/.swapfile\tnone\tswap\tsw,comment=cloudconfig\t0\t0 重启之后查看关闭是否成功\nfree -m 显示如下内容，swap关闭成功\ntotal used free shared buff/cache available Mem: 23114 402 22299 32 411 20597 Swap: 0 0 0 ulimit echo \u0026#34;ulimit -n 65535\u0026#34; \u0026gt;\u0026gt; /etc/profile echo \u0026#34;*\thard\tnofile\t65535\u0026#34; \u0026gt;\u0026gt; /etc/security/limits.conf 重启之后检查是否配置成功\nulimit -n SSH免密（非必须） 执行命令，一路回车，即可获得当前节点的公钥\nssh-keygen -t rsa cat id_rsa.pub iptables 查看br_netfilter模块是否开启","tags":null,"title":"Linux部署Kubernetes流程"},{"categories":null,"contents":" #elastic #elasticsearch\n问题现象 按照ES官网文档介绍的安装步骤，使用yum的方式进行安装。安装完成之后，使用如下命令启动：\nsystemctl start elasticsearch.service 控制台阻塞一会后，显示启动失败，使用如下命令查看状态：\nsystemctl status elasticsearch.service 查询状态为：\nWarning: The unit file, source configuration file or drop-ins of elasticsearch.service changed on disk. Run \u0026#39;systemctl daemon-reload\u0026#39; to reload units. ● elasticsearch.service - Elasticsearch Loaded: loaded (/usr/lib/systemd/system/elasticsearch.service; disabled; vendor preset: disabled) Active: failed (Result: timeout) since Thu 2021-10-14 00:42:40 CST; 2min 15s ago Docs: https://www.elastic.co Main PID: 2547 (code=exited, status=143) Oct 14 00:41:22 gateway systemd[1]: Starting Elasticsearch... Oct 14 00:41:29 gateway bash[2547]: [0.003s][warning][logging] Output options for existing outputs are ignored. Oct 14 00:41:35 gateway systemd[1]: elasticsearch.service: Current command vanished from the unit file, execution of the command list won\u0026#39;t be resumed. Oct 14 00:42:37 gateway systemd[1]: elasticsearch.service: start operation timed out. Terminating. Oct 14 00:42:40 gateway systemd[1]: elasticsearch.service: Failed with result \u0026#39;timeout\u0026#39;. Oct 14 00:42:40 gateway systemd[1]: Failed to start Elasticsearch. 注意第四行Active: failed (Result: timeout)中的这个timeout，后面会成为关键，只是刚开始的时候没注意到。\n初步分析 首先到ES的日志目录/var/log/elasticsearch/下查看日志。\n主要有这几个文件：\nelasticsearch.log elasticsearch_server.json gc.log* 全部找了一遍，也没有发现ERROR的日志。\n内存不足 找不到报错的信息，就只能先猜测一下最可能的原因了。\n起初以为是内存的问题，因为这台服务器内存比较小，而且已经再跑了一些其他服务了。回去重新查看日志，也没有发现OOM的日志。\n于是先在本地下了一个ES程序测试一下。\n参照官网的堆内存设置文档\n选择以临时环境变量的设置方式启动ES：\nES_JAVA_OPTS=\u0026#34;-Xms2g -Xmx2g\u0026#34; ./bin/elasticsearch 逐步调整堆内存大小，最后发现设置在150m的时候ES能正常启动，设置在100m的时候则会报OOM:\n[2021-10-14T10:12:20,583][INFO ][o.e.m.j.JvmGcMonitorService] [MacBook-Pro.local] [gc][5] overhead, spent [430ms] collecting in the last [1.1s] java.lang.OutOfMemoryError: Java heap space Dumping heap to data/java_pid24385.hprof ... Heap dump file created [152347235 bytes in 3.515 secs] [2021-10-14T10:12:26,083][WARN ][o.e.m.j.JvmGcMonitorService] [MacBook-Pro.local] [gc][6] overhead, spent [4.4s] collecting in the last [5.1s] 再回去复查服务器上的日志，并没有发现类似日志。再结合elasticsearch.log文件中，每次ES启动是的日志：\n# 前后省略 [2021-10-14T00:07:25,348][INFO ][o.e.n.Node] [gateway] JVM arguments [... -Xms346m, -Xmx346m, -XX:+UseG1GC, ...] 可以看到，服务器上ES运行的默认设置是取的当前空闲内存的值作为-Xms和-Xmx的参数。\n因此，基本可以排除服务器上ES无法启动是由于内存不足造成的。\nSELinux 既然不是内存造成的，又没有ERROR日志（这是最奇怪的）。接下来稍微有点病急乱投医了。\n猜测是SELinux造成的一切问题。\n查看SELinux是否开启，执行：\n/usr/sbin/sestatus -v 输出：\nSELinux status: enabled SELinuxfs mount: /sys/fs/selinux SELinux root directory: /etc/selinux Loaded policy name: targeted Current mode: enforcing Mode from config file: error (Success) Policy MLS status: enabled Policy deny_unknown status: allowed Memory protection checking: actual (secure) Max kernel policy version: 33 # 以下省略 # ... 可以看到SELinux是开启状态,于是编辑/etc/selinux/config文件，根据注释修改SELINUX的值：\nSELINUX=disabled 重启之后重新查看SELinux的开启状态：\n/usr/sbin/sestatus -v # 输出 SELinux status: disabled 可以看到SELinux已经关闭了。再次启动ES，依然无法启动。\n所以可以排除是SELinux造成的无法启动。\n文件打开数量限制 怀疑是Linux最大文件打开数量限制造成的问题，使用命令查看:\nulimit -n 输出：\n1024 可以看到系统默认设置只有1024，将其临时改大一些：\nulimit -n 65535 重新启动ES，发现仍然无法启动。\n所以，排除这个原因。\n文件权限 检查ES程序用到的几个文件夹的所有者：\n/usr/share/elasticsearch /etc/elasticsearch /var/log/elasticsearch 发现没有问题，所有者和所属组均是elasticsearch，也可以排除权限不足的问题。\nES无法使用root用户启动，使用root启动时会报错。\n进一步分析 上面的问题都排除了，不是内存不足的问题，也不是系统限制，也没有权限相关的问题。最最最神奇的是，没有ERROR的日志，一切就仿佛是正常启动和停止。\n但是这明显不是正常的程序终止。\nTIME OUT 来来回回想了好久，又回到开头提到的使用systemctl查看到的程序状态：\n# 省略... Active: failed (Result: timeout) since Thu 2021-10-14 00:42:40 CST; 2min 15s ago # 省略... Main PID: 2547 (code=exited, status=143) Oct 14 00:41:22 gateway systemd[1]: Starting Elasticsearch... Oct 14 00:41:29 gateway bash[2547]: [0.003s][warning][logging] Output options for existing outputs are ignored. Oct 14 00:41:35 gateway systemd[1]: elasticsearch.service: Current command vanished from the unit file, execution of the command list won\u0026#39;t be resumed. Oct 14 00:42:37 gateway systemd[1]: elasticsearch.service: start operation timed out. Terminating. Oct 14 00:42:40 gateway systemd[1]: elasticsearch.service: Failed with result \u0026#39;timeout\u0026#39;. Oct 14 00:42:40 gateway systemd[1]: Failed to start Elasticsearch. 唯一的失败提示就是这个timeout，不明白程序启动为啥会timeout。\n修改程序启动方式 不过抱着试试看的心态，死马当活马医了。\n搜了一下，还真有类似问题：\nelasticsearch service start operation timed out. Terminating.报错问题处理\n在CSDN上看到了一个同样的问题，他的修改方式是将systemd配置文件中ExecStart后面的命令改为后台启动：\nvi /usr/lib/systemd/system/elasticsearch.service 修改：\n# 省略... ExecStart=/usr/share/elasticsearch/bin/systemd-entrypoint -p ${PID_DIR}/elasticsearch.pid --quiet # 修改为 ExecStart=/bin/bash -c \u0026#34;/usr/share/elasticsearch/bin/systemd-entrypoint -p ${PID_DIR}/elasticsearch.pid --quiet \u0026amp;\u0026#34; # 省略... 改完之后重新加载配置文件：\nsystemctl daemon-reload 再次启动ES，发现依然超时。\n再次强化了我对CSDN的负面印象，90%的东西递归转载，9%的东西扯淡，剩下1%的东西是概念性的知识\n修改超时时间 重新捋了一下思维，在服务器上程序是通过systemctl启动的，而使用的配置文件就是/usr/lib/systemd/system/elasticsearch.service。\n因此造成超时极有可能是这个配置文件的原因。\n重新仔细查看这个配置文件，发现有下面这几行：\n# 省略... # Allow a slow startup before the systemd notifier module kicks in to extend the timeout TimeoutStartSec=75 # 省略... 参考systemd.service对TimeoutStartSec的解释，发现这个参数设置的就是该服务允许的最大启动时长。\n一旦启动时间超过这个值就会失败，与timeout的错误提示吻合。 并且由于我使用的这台服务器性能比价孱弱，极有可能在默认限制75S内无法完成ES的启动，造成超时。 至此原因逐渐明朗，于是直接将其改为：\nTimeoutStartSec=1000 再次启动ES并查看状态：\n● elasticsearch.service - Elasticsearch Loaded: loaded (/usr/lib/systemd/system/elasticsearch.service; enabled; vendor preset: disabled) Active: active (running) since Thu 2021-10-14 00:54:54 CST; 10h ago Docs: https://www.elastic.co Main PID: 2968 (java) Tasks: 61 (limit: 4574) Memory: 218.5M CGroup: /system.slice/elasticsearch.service ├─2968 /usr/share/elasticsearch/jdk/bin/java -Xshare:auto -Des.networkaddress.cache.ttl=60 -Des.networkaddress.cache.negative.ttl=10 -XX:+Al\u0026gt; └─3134 /usr/share/elasticsearch/modules/x-pack-ml/platform/linux-x86_64/bin/controller 使用:9200端口查看ES运行状态：\ncurl 127.0.0.1:9200 返回：\n{ \u0026#34;name\u0026#34; : \u0026#34;gateway\u0026#34;, \u0026#34;cluster_name\u0026#34; : \u0026#34;elasticsearch\u0026#34;, \u0026#34;cluster_uuid\u0026#34; : \u0026#34;jrP00kvxxxxxxxbjr6aPg\u0026#34;, \u0026#34;version\u0026#34; : { \u0026#34;number\u0026#34; : \u0026#34;7.15.0\u0026#34;, \u0026#34;build_flavor\u0026#34; : \u0026#34;default\u0026#34;, \u0026#34;build_type\u0026#34; : \u0026#34;rpm\u0026#34;, \u0026#34;build_hash\u0026#34; : \u0026#34;79d65f6e35xxxxxxxxxxxxxxc7c21073d89aa29\u0026#34;, \u0026#34;build_date\u0026#34; : \u0026#34;2021-09-16T03:05:29.143308416Z\u0026#34;, \u0026#34;build_snapshot\u0026#34; : false, \u0026#34;lucene_version\u0026#34; : \u0026#34;8.9.0\u0026#34;, \u0026#34;minimum_wire_compatibility_version\u0026#34; : \u0026#34;6.8.0\u0026#34;, \u0026#34;minimum_index_compatibility_version\u0026#34; : \u0026#34;6.0.0-beta1\u0026#34; }, \u0026#34;tagline\u0026#34; : \u0026#34;You Know, for Search\u0026#34; } 可以看到ES的版本，以及使用的lucene的版本等相关信息。\nES启动成功，问题解决！\n尾巴 由于在上面启动ES的时候CPU和内存总是飚高：\n经常会将网关Traefik挤死，结合服务器资源和目前实际使用强度，因此将ES的堆内存设置在180M：\ncd /etc/elasticsearch/ cp jvm.options jvm.options.d/jvm.options vi jvm.options.d/jvm.options 将-Xms和-Xmx的值设置为180m，重启几次ES。网关等其他程序没有再出现被kill掉的情况。\n-Xms180m -Xmx180m 总结 这次问题解决的历程比较曲折，由于对Linux系统程序运行提示了解的不够多，经验不够，造成一开始走了一些弯路。\n参考链接 ES JVM配置文档 systemd.service ","date":"October 14, 2021","hero":"/posts/problems/5003-elasticsearch-start-failed/head.svg","permalink":"https://ormissia.github.io/posts/problems/5003-elasticsearch-start-failed/","summary":"#elastic #elasticsearch\n问题现象 按照ES官网文档介绍的安装步骤，使用yum的方式进行安装。安装完成之后，使用如下命令启动：\nsystemctl start elasticsearch.service 控制台阻塞一会后，显示启动失败，使用如下命令查看状态：\nsystemctl status elasticsearch.service 查询状态为：\nWarning: The unit file, source configuration file or drop-ins of elasticsearch.service changed on disk. Run \u0026#39;systemctl daemon-reload\u0026#39; to reload units. ● elasticsearch.service - Elasticsearch Loaded: loaded (/usr/lib/systemd/system/elasticsearch.service; disabled; vendor preset: disabled) Active: failed (Result: timeout) since Thu 2021-10-14 00:42:40 CST; 2min 15s ago Docs: https://www.elastic.co Main PID: 2547 (code=exited, status=143) Oct 14 00:41:22 gateway systemd[1]: Starting Elasticsearch... Oct 14 00:41:29 gateway bash[2547]: [0.","tags":null,"title":"CentOS安装完ES无法启动"},{"categories":null,"contents":"Elasticsearch Deployment\u0026amp;Service apiVersion: apps/v1 kind: StatefulSet metadata: labels: app: elasticsearch role: master name: elasticsearch-master spec: replicas: 3 revisionHistoryLimit: 10 selector: matchLabels: app: elasticsearch role: master serviceName: es-master template: metadata: labels: app: elasticsearch role: master spec: serviceAccountName: elasticsearch-admin affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - topologyKey: kubernetes.io/hostname labelSelector: matchExpressions: - key: role operator: In values: - master containers: - name: elasticsearch-master image: elasticsearch:7.14.2 lifecycle: postStart: exec: command: [ \u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;sysctl -w vm.max_map_count=262144; ulimit -l unlimited; chown -R elasticsearch:elasticsearch /usr/share/elasticsearch/data;\u0026#34; ] ports: - containerPort: 9200 protocol: TCP - containerPort: 9300 protocol: TCP resources: limits: cpu: 100m memory: 1Gi requests: cpu: 10m memory: 512Mi env: - name: MY_POD_NAME valueFrom: fieldRef: fieldPath: metadata.name apiVersion: v1 - name: path.data value: /usr/share/elasticsearch/data/${MY_POD_NAME} - name: cluster.name value: elasticsearch-k8s-cluster - name: discovery.seed_hosts value: elasticsearch-discovery - name: node.master value: \u0026#34;true\u0026#34; - name: node.data value: \u0026#34;false\u0026#34; - name: node.ingest value: \u0026#34;false\u0026#34; - name: ES_JAVA_OPTS value: \u0026#34;-Xms512m -Xmx512m\u0026#34; - name: cluster.initial_master_nodes value: elasticsearch-master-0,elasticsearch-master-1,elasticsearch-master-2 # - name: xpack.security.enabled # value: \u0026#34;true\u0026#34; # - name: xpack.security.transport.ssl.enabled # value: \u0026#34;true\u0026#34; securityContext: privileged: true volumeMounts: - mountPath: /usr/share/elasticsearch/data name: es-master-pvc - mountPath: /usr/share/elasticsearch/plugins name: es-plugins-pvc volumes: - name: es-master-pvc persistentVolumeClaim: claimName: es-master-pvc - name: es-plugins-pvc persistentVolumeClaim: claimName: es-plugins-pvc --- apiVersion: v1 kind: Service metadata: name: elasticsearch-discovery spec: ports: - port: 9300 selector: app: elasticsearch --- apiVersion: apps/v1 kind: StatefulSet metadata: labels: app: elasticsearch role: data name: elasticsearch-data spec: replicas: 4 revisionHistoryLimit: 10 selector: matchLabels: app: elasticsearch role: data serviceName: es-data template: metadata: labels: app: elasticsearch role: data spec: serviceAccountName: elasticsearch-admin affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - podAffinityTerm: topologyKey: kubernetes.io/hostname labelSelector: matchExpressions: - key: role operator: In values: - data weight: 100 containers: - name: elasticsearch-data image: elasticsearch:7.14.2 lifecycle: postStart: exec: command: [ \u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;sysctl -w vm.max_map_count=262144; ulimit -l unlimited; chown -R elasticsearch:elasticsearch /usr/share/elasticsearch;\u0026#34; ] ports: - containerPort: 9200 protocol: TCP - containerPort: 9300 protocol: TCP resources: limits: cpu: 100m memory: 1Gi requests: cpu: 10m memory: 512Mi env: - name: MY_POD_NAME valueFrom: fieldRef: fieldPath: metadata.name apiVersion: v1 - name: path.data value: /usr/share/elasticsearch/data/${MY_POD_NAME} - name: cluster.name value: elasticsearch-k8s-cluster - name: discovery.seed_hosts value: elasticsearch-discovery - name: node.master value: \u0026#34;false\u0026#34; - name: node.data value: \u0026#34;true\u0026#34; - name: ES_JAVA_OPTS value: \u0026#34;-Xms300m -Xmx300m\u0026#34; - name: cluster.initial_master_nodes value: elasticsearch-master-0,elasticsearch-master-1,elasticsearch-master-2 # - name: xpack.security.enabled # value: \u0026#34;true\u0026#34; # - name: xpack.security.transport.ssl.enabled # value: \u0026#34;true\u0026#34; securityContext: privileged: true volumeMounts: - mountPath: /usr/share/elasticsearch/data name: es-data-pvc - mountPath: /usr/share/elasticsearch/plugins name: es-plugins-pvc volumes: - name: es-data-pvc persistentVolumeClaim: claimName: es-data-pvc - name: es-plugins-pvc persistentVolumeClaim: claimName: es-plugins-pvc --- apiVersion: v1 kind: Service metadata: name: elasticsearch spec: type: ClusterIP ports: - port: 9200 targetPort: 9200 protocol: TCP name: http selector: app: elasticsearch role: data RBAC apiVersion: v1 kind: ServiceAccount metadata: name: elasticsearch-admin --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: elasticearch-admin roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: elasticsearch-admin namespace: kube-elastic PV\u0026amp;PVC apiVersion: v1 kind: PersistentVolume metadata: name: es-master-pv spec: capacity: storage: 512Mi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain storageClassName: es-master-pv nfs: path: /data/nfs/kubernetes/elastic/elasticsearch/master server: node1 --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: es-master-pvc spec: accessModes: - ReadWriteMany resources: requests: storage: 512Mi storageClassName: es-master-pv --- apiVersion: v1 kind: PersistentVolume metadata: name: es-data-pv spec: capacity: storage: 5Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain storageClassName: es-data-pv nfs: path: /data/nfs/kubernetes/elastic/elasticsearch/data server: node1 --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: es-data-pvc spec: accessModes: - ReadWriteMany resources: requests: storage: 5Gi storageClassName: es-data-pv --- apiVersion: v1 kind: PersistentVolume metadata: name: es-plugins-pv spec: capacity: storage: 512Mi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain storageClassName: es-plugins-pv nfs: path: /data/nfs/kubernetes/elastic/elasticsearch/plugins server: node1 --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: es-plugins-pvc spec: accessModes: - ReadWriteMany resources: requests: storage: 512Mi storageClassName: es-plugins-pv Ingress kind: Ingress apiVersion: networking.k8s.io/v1 metadata: name: elasticsearch-ingress annotations: traefik.ingress.kubernetes.io/router.entrypoints: web spec: rules: - host: elasticsearch.ormissia.com http: paths: - path: / pathType: Prefix backend: service: name: elasticsearch port: number: 9200 Kibana Deployment\u0026amp;Service apiVersion: apps/v1 kind: Deployment metadata: labels: app: kibana name: kibana spec: replicas: 1 selector: matchLabels: app: kibana template: metadata: labels: app: kibana spec: containers: - name: kibana image: kibana:7.14.2 ports: - containerPort: 5601 protocol: TCP resources: limits: cpu: 100m memory: 600Gi requests: cpu: 10m memory: 400Mi env: - name: ELASTICSEARCH_URL value: http://elasticsearch:9200 - name: I18N_LOCALE value: zh-CN - name: SERVER_PUBLICBASEURL value: https://kibana.ormissia.com --- apiVersion: v1 kind: Service metadata: name: kibana spec: type: ClusterIP ports: - port: 5601 targetPort: 5601 protocol: TCP selector: app: kibana PV\u0026amp;PVC apiVersion: v1 kind: PersistentVolume metadata: name: kibana-pv spec: capacity: storage: 512Mi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain storageClassName: kibana-pv nfs: path: /data/nfs/kubernetes/elastic/kibana server: node1 --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: kibana-pvc spec: accessModes: - ReadWriteMany resources: requests: storage: 512Mi storageClassName: kibana-pv Ingress kind: Ingress apiVersion: networking.k8s.io/v1 metadata: name: kibana-ingress annotations: traefik.ingress.kubernetes.io/router.entrypoints: web spec: rules: - host: kibana.ormissia.com http: paths: - path: / pathType: Prefix backend: service: name: kibana port: number: 5601 ","date":"October 13, 2021","hero":"/posts/deployment/3006-linux-elk/head.svg","permalink":"https://ormissia.github.io/posts/deployment/3006-linux-elk/","summary":"Elasticsearch Deployment\u0026amp;Service apiVersion: apps/v1 kind: StatefulSet metadata: labels: app: elasticsearch role: master name: elasticsearch-master spec: replicas: 3 revisionHistoryLimit: 10 selector: matchLabels: app: elasticsearch role: master serviceName: es-master template: metadata: labels: app: elasticsearch role: master spec: serviceAccountName: elasticsearch-admin affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - topologyKey: kubernetes.io/hostname labelSelector: matchExpressions: - key: role operator: In values: - master containers: - name: elasticsearch-master image: elasticsearch:7.14.2 lifecycle: postStart: exec: command: [ \u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;sysctl -w vm.max_map_count=262144; ulimit -l unlimited; chown -R elasticsearch:elasticsearch /usr/share/elasticsearch/data;\u0026#34; ] ports: - containerPort: 9200 protocol: TCP - containerPort: 9300 protocol: TCP resources: limits: cpu: 100m memory: 1Gi requests: cpu: 10m memory: 512Mi env: - name: MY_POD_NAME valueFrom: fieldRef: fieldPath: metadata.","tags":null,"title":"ELK部署流程"},{"categories":null,"contents":"程序下载 wget https://github.com/prometheus/prometheus/releases/download/v2.30.3/prometheus-2.30.3.linux-amd64.tar.gz 解压并移动 tar -zxvf prometheus-2.30.3.linux-amd64.tar.gz mv prometheus-2.30.3.linux-amd64 /usr/local/prometheus 添加到系统服务 Unit配置文件 vi /usr/lib/systemd/system/prometheus.service [Unit] Description=Prometheus Documentation=https://prometheus.io [Service] Type=simple ExecStart=/usr/local/prometheus/prometheus \\ --config.file=/usr/local/prometheus/prometheus.yml \\ --storage.tsdb.path=/usr/local/prometheus/data Restart=on-failure WatchdogSec=10s [Install] WantedBy=multi-user.target 启动程序 sudo systemctl daemon-reload sudo systemctl start prometheus.service sudo systemctl status prometheus.service 开机自启 sudo systemctl enable prometheus.service 简单使用 Prometheus默认端口是9090，程序启动之后从浏览器访问页面。\n输入以下表达式来绘制在自抓取Prometheus中发生的每秒HTTP请求率返回状态代码200的图表：\nrate(promhttp_metric_handler_requests_total{code=\u0026#34;200\u0026#34;}[1m]) 配置文件 重新加载 curl -X POST http://127.0.0.1:9090/-/reload Kubernetes部署脚本 Deployment\u0026amp;Service apiVersion: apps/v1 kind: Deployment metadata: name: prometheus labels: app: prometheus spec: replicas: 1 strategy: rollingUpdate: maxSurge: 1 maxUnavailable: 1 type: RollingUpdate selector: matchLabels: app: prometheus template: metadata: labels: app: prometheus spec: initContainers: - name: prometheus-data-permission-setup image: busybox command: [\u0026#34;/bin/chmod\u0026#34;,\u0026#34;-R\u0026#34;,\u0026#34;777\u0026#34;, \u0026#34;/data\u0026#34;] volumeMounts: - name: prometheus-data mountPath: /data containers: - name: prometheus image: prom/prometheus args: - \u0026#39;--storage.tsdb.path=/prometheus\u0026#39; - \u0026#39;--config.file=/etc/prometheus/prometheus.yml\u0026#39; command: - /bin/prometheus ports: - name: web containerPort: 9090 resources: limits: cpu: 20m memory: 150Mi requests: cpu: 5m memory: 80Mi volumeMounts: - name: config-volume mountPath: /etc/prometheus - name: prometheus-data mountPath: /prometheus restartPolicy: Always securityContext: {} terminationGracePeriodSeconds: 30 serviceAccountName: prometheus volumes: - name: config-volume configMap: name: prometheus-config - name: prometheus-data persistentVolumeClaim: claimName: prometheus-pvc --- apiVersion: v1 kind: Service metadata: name: prometheus spec: type: ClusterIP selector: app: prometheus ports: - port: 9090 targetPort: 9090 protocol: TCP RBAC apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: prometheus rules: - apiGroups: - \u0026#34;\u0026#34; resources: - nodes - nodes/proxy - services - endpoints - pods verbs: - get - list - watch - apiGroups: - extensions resources: - ingresses verbs: - get - list - watch - nonResourceURLs: - /metrics verbs: - get --- apiVersion: v1 kind: ServiceAccount metadata: name: prometheus --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: prometheus roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: prometheus subjects: - kind: ServiceAccount name: prometheus namespace: kube-basic PV\u0026amp;PVC apiVersion: v1 kind: PersistentVolume metadata: name: node1-prometheus-pv spec: capacity: storage: 2Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain storageClassName: node1-prometheus-pv nfs: path: /data/nfs/kubernetes/prometheus server: node1 --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: prometheus-pvc spec: accessModes: - ReadWriteMany resources: requests: storage: 2Gi storageClassName: node1-prometheus-pv Ingress kind: Ingress apiVersion: networking.k8s.io/v1 metadata: name: prometheus-ingress annotations: traefik.ingress.kubernetes.io/router.entrypoints: web spec: rules: - host: prometheus.ormissia.com http: paths: - path: / pathType: Prefix backend: service: name: prometheus port: number: 9090 Node Exporter Deployment\u0026amp;Service apiVersion: apps/v1 kind: DaemonSet metadata: name: node-exporter labels: app: node-exporter spec: selector: matchLabels: app: node-exporter template: metadata: labels: app: node-exporter spec: hostPID: true hostIPC: true hostNetwork: true tolerations: - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule containers: - name: node-exporter image: prom/node-exporter ports: - containerPort: 9100 resources: limits: cpu: 10m memory: 30Mi requests: cpu: 2m memory: 10Mi securityContext: privileged: true args: - --path.procfs - /host/proc - --path.sysfs - /host/sys - --path.rootfs - /host/root - --collector.filesystem.ignored-mount-points - ^/(sys|proc|dev|host|etc)($|/) - --collector.processes volumeMounts: - mountPath: /host/dev name: dev - mountPath: /host/proc name: proc - mountPath: /host/sys name: sys - mountPath: /host/root name: rootfs volumes: - name: proc hostPath: path: /proc - name: dev hostPath: path: /dev - name: sys hostPath: path: /sys - name: rootfs hostPath: path: / Prometheus Config # my global config global: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Alertmanager configuration alerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093 # Load rules once and periodically evaluate them according to the global \u0026#39;evaluation_interval\u0026#39;. rule_files: # - \u0026#34;first_rules.yml\u0026#34; # - \u0026#34;second_rules.yml\u0026#34; # A scrape configuration containing exactly one endpoint to scrape: # Here it\u0026#39;s Prometheus itself. scrape_configs: # The job name is added as a label `job=\u0026lt;job_name\u0026gt;` to any timeseries scraped from this config. - job_name: \u0026#34;prometheus\u0026#34; # metrics_path defaults to \u0026#39;/metrics\u0026#39; # scheme defaults to \u0026#39;http\u0026#39;. static_configs: - targets: [\u0026#34;localhost:9090\u0026#34;] - job_name: \u0026#34;node1-exporter\u0026#34; static_configs: - targets: [\u0026#34;gateway-node-exporter:9100\u0026#34;] relabel_configs: - source_labels: [__address__] regex: (.*) replacement: gateway target_label: instance action: replace - job_name: \u0026#39;kubernetes-node-exporter\u0026#39; kubernetes_sd_configs: - role: node relabel_configs: - source_labels: [__address__] regex: \u0026#39;(.*):10250\u0026#39; replacement: \u0026#39;${1}:9100\u0026#39; target_label: __address__ action: replace - source_labels: [__meta_kubernetes_node_name] action: replace target_label: node - action: labelmap regex: __meta_kubernetes_node_label_(.+) - source_labels: [__meta_kubernetes_node_address_InternalIP] action: replace target_label: ip 参考链接 Prometheus官网 Prometheus下载页面 Prometheus文档\n","date":"October 9, 2021","hero":"/posts/deployment/3005-linux-prometheus/head.png","permalink":"https://ormissia.github.io/posts/deployment/3005-linux-prometheus/","summary":"程序下载 wget https://github.com/prometheus/prometheus/releases/download/v2.30.3/prometheus-2.30.3.linux-amd64.tar.gz 解压并移动 tar -zxvf prometheus-2.30.3.linux-amd64.tar.gz mv prometheus-2.30.3.linux-amd64 /usr/local/prometheus 添加到系统服务 Unit配置文件 vi /usr/lib/systemd/system/prometheus.service [Unit] Description=Prometheus Documentation=https://prometheus.io [Service] Type=simple ExecStart=/usr/local/prometheus/prometheus \\ --config.file=/usr/local/prometheus/prometheus.yml \\ --storage.tsdb.path=/usr/local/prometheus/data Restart=on-failure WatchdogSec=10s [Install] WantedBy=multi-user.target 启动程序 sudo systemctl daemon-reload sudo systemctl start prometheus.service sudo systemctl status prometheus.service 开机自启 sudo systemctl enable prometheus.service 简单使用 Prometheus默认端口是9090，程序启动之后从浏览器访问页面。\n输入以下表达式来绘制在自抓取Prometheus中发生的每秒HTTP请求率返回状态代码200的图表：\nrate(promhttp_metric_handler_requests_total{code=\u0026#34;200\u0026#34;}[1m]) 配置文件 重新加载 curl -X POST http://127.0.0.1:9090/-/reload Kubernetes部署脚本 Deployment\u0026amp;Service apiVersion: apps/v1 kind: Deployment metadata: name: prometheus labels: app: prometheus spec: replicas: 1 strategy: rollingUpdate: maxSurge: 1 maxUnavailable: 1 type: RollingUpdate selector: matchLabels: app: prometheus template: metadata: labels: app: prometheus spec: initContainers: - name: prometheus-data-permission-setup image: busybox command: [\u0026#34;/bin/chmod\u0026#34;,\u0026#34;-R\u0026#34;,\u0026#34;777\u0026#34;, \u0026#34;/data\u0026#34;] volumeMounts: - name: prometheus-data mountPath: /data containers: - name: prometheus image: prom/prometheus args: - \u0026#39;--storage.","tags":null,"title":"Prometheus部署流程"},{"categories":null,"contents":"Grafana的安装比较简单，打开官网下载页面，选择对应的系统以及需要的版本号，按照指引执行命令即可。\n程序下载 wget https://dl.grafana.com/enterprise/release/grafana-enterprise-8.2.0-1.x86_64.rpm sudo yum install grafana-enterprise-8.2.0-1.x86_64.rpm 启动程序 sudo systemctl daemon-reload sudo systemctl start grafana-server sudo systemctl status grafana-server 验证 Grafana默认端口为:3000，默认用户名密码均为admin，程序启动后即可通过3000端口访问管理页面。\n开机自启 sudo systemctl enable grafana-server Kubernetes部署脚本 Deployment\u0026amp;Service apiVersion: apps/v1 kind: Deployment metadata: name: grafana labels: app: grafana spec: selector: matchLabels: app: grafana template: metadata: labels: app: grafana spec: affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - podAffinityTerm: topologyKey: kubernetes.io/hostname labelSelector: matchExpressions: - key: role operator: In values: - data weight: 100 containers: - name: grafana image: grafana/grafana-enterprise ports: - containerPort: 3000 env: - name: GF_PATHS_CONFIG value: /etc/grafana/grafana.ini - name: GF_PATHS_DATA value: /var/lib/grafana - name: GF_PATHS_HOME value: /usr/share/grafana - name: GF_PATHS_LOGS value: /var/log/grafana - name: GF_PATHS_PLUGINS value: /var/lib/grafana/plugins - name: GF_PATHS_PROVISIONING value: /etc/grafana/provisioning volumeMounts: - mountPath: /etc/grafana/ name: grafana-conf-dir - mountPath: /var/lib/grafana name: grafana-conf-dir volumes: - name: grafana-conf-dir persistentVolumeClaim: claimName: grafana-pvc --- apiVersion: v1 kind: Service metadata: name: grafana spec: type: ClusterIP selector: app: grafana ports: - port: 3000 targetPort: 3000 protocol: TCP PV\u0026amp;PVC apiVersion: v1 kind: PersistentVolume metadata: name: node1-grafana-pv spec: capacity: storage: 1Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain storageClassName: node1-grafana-pv nfs: path: /data/nfs/kubernetes/grafana server: node1 --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: grafana-pvc spec: accessModes: - ReadWriteMany resources: requests: storage: 1Gi storageClassName: node1-grafana-pv Ingress kind: Ingress apiVersion: networking.k8s.io/v1 metadata: name: grafana-ingress annotations: traefik.ingress.kubernetes.io/router.entrypoints: web spec: rules: - host: grafana.ormissia.com http: paths: - path: / pathType: Prefix backend: service: name: grafana port: number: 3000 参考连接 Grafana官网 Grafana下载页面 Grafana安装文档 ","date":"October 9, 2021","hero":"/posts/deployment/3004-linux-grafana/head.png","permalink":"https://ormissia.github.io/posts/deployment/3004-linux-grafana/","summary":"Grafana的安装比较简单，打开官网下载页面，选择对应的系统以及需要的版本号，按照指引执行命令即可。\n程序下载 wget https://dl.grafana.com/enterprise/release/grafana-enterprise-8.2.0-1.x86_64.rpm sudo yum install grafana-enterprise-8.2.0-1.x86_64.rpm 启动程序 sudo systemctl daemon-reload sudo systemctl start grafana-server sudo systemctl status grafana-server 验证 Grafana默认端口为:3000，默认用户名密码均为admin，程序启动后即可通过3000端口访问管理页面。\n开机自启 sudo systemctl enable grafana-server Kubernetes部署脚本 Deployment\u0026amp;Service apiVersion: apps/v1 kind: Deployment metadata: name: grafana labels: app: grafana spec: selector: matchLabels: app: grafana template: metadata: labels: app: grafana spec: affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - podAffinityTerm: topologyKey: kubernetes.io/hostname labelSelector: matchExpressions: - key: role operator: In values: - data weight: 100 containers: - name: grafana image: grafana/grafana-enterprise ports: - containerPort: 3000 env: - name: GF_PATHS_CONFIG value: /etc/grafana/grafana.","tags":null,"title":"Grafana部署流程"},{"categories":null,"contents":" Traefik is an open-source Edge Router that makes publishing your services a fun and easy experience. It receives requests on behalf of your system and finds out which components are responsible for handling them. What sets Traefik apart, besides its many features, is that it automatically discovers the right configuration for your services. The magic happens when Traefik inspects your infrastructure, where it finds relevant information and discovers which service serves which request. Traefik is natively compliant with every major cluster technology, such as Kubernetes, Docker, Docker Swarm, AWS, Mesos, Marathon, and the list goes on; and can handle many at the same time. (It even works for legacy software running on bare metal.) With Traefik, there is no need to maintain and synchronize a separate configuration file: everything happens automatically, in real time (no restarts, no connection interruptions). With Traefik, you spend time developing and deploying new features to your system, not on configuring and maintaining its working state. Developing Traefik, our main goal is to make it simple to use, and we\u0026rsquo;re sure you\u0026rsquo;ll enjoy it.\n\u0026ndash; The Traefik Maintainer Team\n结尾附Traefik作为Kubernetes Controller的部署脚本\n程序下载 由于Traefik是由Golang语言所编写，程序是二进制包的形式。直接到Traefik在GitHub仓库的releases中下载即可。\n我使用的是基于x86的64位Linux系统，所以在这里选择的是linux_amd64版本的包\nwget https://github.com/traefik/traefik/releases/download/v2.5.3/traefik_v2.5.3_linux_amd64.tar.gz 解压得到程序\ntar -zxvf traefik_v2.5.3_linux_amd64.tar.gz 将程序重命名为traefik并放到/usr/local/bin/目录下\n静态配置 静态配置是Traefik在程序启动的时候从配置文件、环境变量或启动参数中加载到内存中的配置参数。如果需要修改，则需要重启Traefik。\n静态配置的官方文档\n根据文档介绍，Traefik会从以下几个目录读取名为traefik.yml（或traefik.yaml或traefik.toml）的静态配置文件：\n/etc/traefik/ $XDG_CONFIG_HOME/ $HOME/.config/ .(Traefik程序运行的当前目录) 或者在启动的时候以参数形式指定静态配置文件：\ntraefik --configFile=foo/bar/myconfigfile.yml 代理端口 使用entryPoints向外暴露端口\nentryPoints: web: address: \u0026#34;:80\u0026#34; websecure: address: \u0026#34;:443\u0026#34; 添加动态配置 Traefik支持动态配置，即配置修改后Traefik可以自动重新加载，我在这里选择了从文件读取动态配置，通过providers添加动态配置的配置文件的路径或文件名，在这里我使用了目录的形式（dictory和filename二选一）。\n这里也可以修改动态配置的重新加载间隔时间，默认是2S，我在这里使用了默认配置，不做修改。\nproviders: file: directory: /etc/traefik/dynamic-conf watch: true 开启API 在这里可以开启Traefik的dashboard以及api\napi: insecure: true dashboard默认使用的是8080端口，如果要修改，则需要在entryPoints下添加名为traefik的端口配置：\nentryPoints: traefik: address: \u0026#34;:10000\u0026#34; 程序日志 Traefik支持将程序运行的日志输出到文件，通过log标签可以设置日志输出文件，输出格式以及日志级别。\nlog: filePath: /etc/traefik/traefik.log format: json level: ERROR 访问日志 Traefik支持将访问日志输出到文件，通过accessLog配置\naccessLog: filePath: /etc/traefik/access.log format: json 监控 // TODO\nmetrics: prometheus: addRoutersLabels: true entryPoint: metrics 动态配置 动态配置中存储的是路由、服务、中间件等配置信息，是可以在程序运行时动态修改的值。\n以下是Traefik所支持的动态配置提供者：\nProvider Type Configuration Type Provider Name Docker Orchestrator Label docker Kubernetes IngressRoute Orchestrator Custom Resource kubernetescrd Kubernetes Ingress Orchestrator Ingress kubernetes Kubernetes Gateway API Orchestrator Gateway API Resource kubernetesgateway Consul Catalog Orchestrator Label consulcatalog ECS Orchestrator Label ecs Marathon Orchestrator Label marathon Rancher Orchestrator Label rancher File Manual YAML/TOML format file Consul KV KV consul Etcd KV KV etcd ZooKeeper KV KV zookeeper Redis KV KV redis HTTP Manual JSON format http 我在这里选择了File类型的提供者，以下均为File类型的介绍\n路由 路由类型分为三种，分别为：http、tcp、udp\n在这里我使用的是HTTP的路由功能：\nhttp: routers: router-traefik: rule: HostRegexp(`traefik.{domain:.*}`) service: traefik router-grafana: rule: HostRegexp(`grafana.{domain:.*}`) service: grafana service指向的是下面定义的Service的名称\n路由规则 路由规则是指，Traefik接收到的请求，根据给定规则路由到不同的服务中。\nTraefik一共支持以下规则：\nRule Description Headers(`key`, `value`) Check if there is a key keydefined in the headers, with the value value HeadersRegexp(`key`, `regexp`) Check if there is a key keydefined in the headers, with a value that matches the regular expression regexp Host(`example.com`, \u0026hellip;) Check if the request domain (host header value) targets one of the given domains. HostHeader(`example.com`, \u0026hellip;) Check if the request domain (host header value) targets one of the given domains. HostRegexp(`example.com`, `{subdomain:[a-z]+}.example.com`, \u0026hellip;) Check if the request domain matches the given regexp. Method(`GET`, \u0026hellip;) Check if the request method is one of the given methods (GET, POST, PUT, DELETE, PATCH, HEAD) Path(`/path`, `/articles/{cat:[a-z]+}/{id:[0-9]+}`, \u0026hellip;) Match exact request path. It accepts a sequence of literal and regular expression paths. PathPrefix(`/products/`, `/articles/{cat:[a-z]+}/{id:[0-9]+}`) Match request prefix path. It accepts a sequence of literal and regular expression prefix paths. Query(`foo=bar`, `bar=baz`) Match Query String parameters. It accepts a sequence of key=value pairs. ClientIP(`10.0.0.0/16`, `::1`) Match if the request client IP is one of the given IP/CIDR. It accepts IPv4, IPv6 and CIDR formats 我这这里主要会用到HostRegexp和PathPrefix，即对请求url的两种使用正则的过滤规则，前者用于匹配二级域名，后者用于将不同路径的请求转发至不同服务。\n这个正则配起来稍微有点小坑，哈哈。我研究了好久才搞明白要怎么写。\n为了对Host和Path使用正则表达式，需要声明一个任意命名的变量，然后跟上用冒号分隔的正则表达式，所有这些都用花括号括起来。\n示例：HostRegexp(`grafana.{domain:.*}`)\n服务 服务负责配置如何到达实际的服务，最终将处理传入的请求。使用service定义：\nhttp: services: traefik: loadBalancer: servers: - url: \u0026#34;http://127.0.0.1:10000\u0026#34; 我们将上面开启的Traefik的监控面板作为服务封装了起来，只要路由到traefik这个服务上，即可访问监控面板。\n在这里也可以实现负载均衡等功能，可以参照官网介绍\n开机启动 有了上次部署Nginx的经验，这里我们完全采用Systemd来管理。即，使用systemctl命令来管理服务。\n原理 Systemd默认从目录/etc/systemd/system/读取配置文件。但是，里面存放的大部分文件都是符号链接，指向目录/usr/lib/systemd/system/，真正的配置文件存放在那个目录\nsystemctl enable命令用于在上面两个目录之间，建立符号链接关系。\nsystemctl enable traefik.service # 等同于 ln -s \u0026#39;/usr/lib/systemd/system/traefik.service\u0026#39; \u0026#39;/etc/systemd/system/multi-user.target.wants/traefik.service\u0026#39; Unit配置文件 下面是Traefik源码仓库中给出的traefik.service 示例，其中有几个需要注意的点：\nType：程序启动方式 ExecStart：程序运行的命令，在这里直接指向程序本身 WatchdogSec：程序检测时间 [Unit] Description=Traefik instance Documentation=https://doc.traefik.io Wants=network-online.target [Service] Environment=\u0026#34;ACME_DNS_API_BASE=https://auth.acme-dns.io\u0026#34; \u0026#34;ACME_DNS_STORAGE_PATH=/etc/traefik/acme/dns.json\u0026#34; # Run traefik as its own user (create new user with: groupadd traefik \u0026amp;\u0026amp; useradd -g traefik traefik -s /sbin/nologin) # User=traefik # Group=traefik Type=simple Restart=on-failure ExecStart=/usr/sbin/traefik-lb WatchdogSec=10s RestartSec=10s [Install] WantedBy=multi-user.target 作为服务开启 systemctl start traefik.service 设置开机启动 systemctl enable traefik.service 查看运行状态 systemctl status traefik.service 文件汇总 root ├─ etc │\t└─ traefik │\t├─ access.log // 访问日志 │\t├─ dynamic_conf // 动态配置存放文件夹 │\t│\t└─ dynamic_conf.yml // 动态配置文件 │\t├─ traefik.log // 程序日志 │\t└─ traefik.yml // 静态配置文件 └─ usr └─ local └─ bin └─ traefik // 程序本身 静态配置 ## Static configuration entryPoints: web: address: \u0026#34;:80\u0026#34; websecure: address: \u0026#34;:443\u0026#34; traefik: address: \u0026#34;:10000\u0026#34; metrics: address: \u0026#34;:8082\u0026#34; # 动态配置的配置 providers: file: directory: /etc/traefik/dynamic-conf watch: true # API api: insecure: true # 运行日志 log: filePath: /etc/traefik/traefik.log format: json level: ERROR # 访问日志 accessLog: filePath: /etc/traefik/access.log format: json # 监控 metrics: prometheus: addRoutersLabels: true entryPoint: metrics 动态配置 ## Dynamic configuration http: routers: router-traefik: rule: HostRegexp(`traefik.{domain:.*}`) service: traefik router-grafana: rule: HostRegexp(`grafana.{domain:.*}`) service: grafana router-prometheus: rule: HostRegexp(`prometheus.{domain:.*}`) service: prometheus services: traefik: loadBalancer: servers: - url: \u0026#34;http://127.0.0.1:10000\u0026#34; grafana: loadBalancer: servers: - url: \u0026#34;http://127.0.0.1:3000\u0026#34; prometheus: loadBalancer: servers: - url: \u0026#34;http://127.0.0.1:9090\u0026#34; 至此，我们已经配置完成了Traefik的基础功能，实现了路由，日志，开机启动等功能\n中间件 从图中基本可以明白中间件的作用，也可以理解成拦截器，亦或者是类似于Spring中的切面。\nTraefik中有几种可用的中间件：一些可以修改请求、请求头，一些负责重定向，一些可以添加身份验证等等。\n中间件的配置格式类似于Service，大致是先定义，再使用。\n下面是一个官网给出的示例：\n# As YAML Configuration File http: routers: router1: service: myService middlewares: - \u0026#34;foo-add-prefix\u0026#34; rule: \u0026#34;Host(`example.com`)\u0026#34; middlewares: foo-add-prefix: addPrefix: prefix: \u0026#34;/foo\u0026#34; services: service1: loadBalancer: servers: - url: \u0026#34;http://127.0.0.1:80\u0026#34; 页面访问认证 由于Traefik的管理页面给有给出登录的功能，因此这里使用官方提供的BasicAuth中间件来实现访问认证的功能。\n定义权限认证中间件 定义名为traefik-auth的中间件：\n## Dynamic configuration http: # ... middlewares: traefik-auth: basicAuth: users: - \u0026#34;test:$apr1$cxKgflNX$3PWH2/iPEdZrBEWYGfSBm.\u0026#34; user下面的密码使用htpasswd生成\n给对应路由添加中间件 给路由添加中间件\n## Dynamic configuration http: routers: router-traefik: middlewares: - traefik-auth rule: Host(`traefik.ormissia.com`) service: traefik 这样在访问相应路由的时候会经过basicAuth的中间件，在浏览器弹出窗口输入之前使用htpasswd生成的用户名密码即可。\n配置获取免费证书 在这里我面选择让Traefik自动获取免费证书，并且申请泛域名的证书。\n端口重定向 将80端口的流量重定向到443端口，并开启http代理的tls\n## Static configuration entryPoints: web: address: \u0026#34;:80\u0026#34; http: redirections: entryPoint: to: websecure scheme: https websecure: address: \u0026#34;:443\u0026#34; http: tls: {} 这个时候我们将80代理到了443，因此访问页面会显示成这样：\n接下来我们给Traefik添加自动获取证书的功能\n开启ACME # certificate certificatesResolvers: myresolver: acme: email: example@email.com storage: /etc/traefik/acme/acme.json dnsChallenge: provider: acme-dns 这里面有三个属性是必填的：\nemail：邮箱 storage：证书存储文件 dnsChallenge：由于我们选择申请泛域名的证书，目前只有dnsChallenge支持申请泛域名。 storage 创建一个文件，权限必须是600，里面主要用来存证书的信息，信息格式为json。\ncd /etc/traefik/acme/ touch acme.json \u0026amp;\u0026amp; chmod 600 acme.json dnsChallenge dnsChallenge支持各种不同的provider，具体可以参考官网介绍，这里就不再贴了。\n如果自己的域名在表格中有对应的云厂商，可以使用对应的provider。这里虽然我使用的这个域名是阿里云上的，只是感觉创建token或者RAM账户有点难于管理，而且要设置一些权限等等。 因此这里我选择了通用的方式，使用acme-dns作为provider。\n使用acme-dns作为provider，需要添加两个环境变量：\nACME_DNS_API_BASE：这里我使用了acme-dns官方提供的地址-https://auth.acme-dns.io ACME_DNS_STORAGE_PATH：这个文件存储了从上一个url中获取的DNS信息，需要手动创建一下 由于未知原因，这里我在/etc/profile中添加对应环境变量并且使用source编译之后，Traefik运行时候未能正确读取到，因此我选择将两个变量写入systemd的配置文件中：\nvi /usr/lib/systemd/system/traefik.service [Unit] # ... [Service] Environment=\u0026#34;ACME_DNS_API_BASE=https://auth.acme-dns.io\u0026#34; \u0026#34;ACME_DNS_STORAGE_PATH=/etc/traefik/acme/dns.json\u0026#34; # ... [Install] # ... 直接在服务的配置文件中添加，这样在Traefik启动的时候就能正确读取到两个环境变量了。\n添加CNAME解析 当完成上面的配置之后，运行一下Traefik之后，/etc/traefik/acme/dns.json会获得对应信息：\n{ \u0026#34;ormissia.com\u0026#34;:{ \u0026#34;fulldomain\u0026#34;:\u0026#34;123.auth.acme-dns.io\u0026#34;, \u0026#34;subdomain\u0026#34;:\u0026#34;123\u0026#34;, \u0026#34;username\u0026#34;:\u0026#34;123\u0026#34;, \u0026#34;password\u0026#34;:\u0026#34;123\u0026#34;, \u0026#34;server_url\u0026#34;:\u0026#34;https://auth.acme-dns.io\u0026#34; } } 取fulldomain的值，到自己的域名管理添加一条CNAME类型的解析：_acme-challenge.ormissia.com指向上面得到的fulldomain的值即可。\n等待片刻执行下面命令查看解析是否成功：\ndig _acme-challenge.ormissia.com 可以看到返回值中有这样一行：\n;; ANSWER SECTION: _acme-challenge.ormissia.com. 600 IN\tCNAME\t123.auth.acme-dns.io. 即代表解析成功。\n重启Traefik之后，刷新页面，即可以从浏览器中看到证书获取成功。\nKubernetes部署脚本 RBAC # rbac.yml --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: traefik-ingress-controller rules: - apiGroups: - \u0026#34;\u0026#34; resources: - services - endpoints - secrets verbs: - get - list - watch - apiGroups: - extensions - networking.k8s.io resources: - ingresses - ingressclasses verbs: - get - list - watch - apiGroups: - extensions resources: - services - endpoints - ingresses/status verbs: - update - get - list - watch --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: traefik-ingress-controller roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: traefik-ingress-controller subjects: - kind: ServiceAccount name: traefik-ingress-controller namespace: kube-basic Deployment\u0026amp;Service # traefik.yml apiVersion: v1 kind: ServiceAccount metadata: name: traefik-ingress-controller --- kind: Deployment apiVersion: apps/v1 metadata: name: traefik labels: app: traefik spec: replicas: 3 selector: matchLabels: app: traefik template: metadata: labels: app: traefik spec: serviceAccountName: traefik-ingress-controller affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - podAffinityTerm: topologyKey: kubernetes.io/hostname labelSelector: matchExpressions: - key: app operator: In values: - traefik weight: 100 containers: - name: traefik image: traefik ports: - name: web containerPort: 80 resources: limits: cpu: 20m memory: 150Mi requests: cpu: 5m memory: 70Mi args: - --entrypoints.web.address=:80 - --entrypoints.web.http.redirections.entryPoint.to=websecure - --entrypoints.web.http.redirections.entryPoint.scheme=https - --entrypoints.websecure.address=:443 - --providers.kubernetesingress - --providers.kubernetesingress.namespaces=kube-basic,kubernetes-dashboard - --log.level=INFO - --accesslog - --api.insecure=true - --pilot.token=1f36db5d-9f2c-42da-8737-4cf8979de6a4 --- apiVersion: v1 kind: Service metadata: name: traefik spec: type: NodePort selector: app: traefik ports: - protocol: TCP port: 80 name: web targetPort: 80 nodePort: 30000 - protocol: TCP port: 8080 name: admin targetPort: 8080 nodePort: 30001 Ingress # ingress.yml kind: Ingress apiVersion: networking.k8s.io/v1 metadata: name: whoami-ingress annotations: traefik.ingress.kubernetes.io/router.entrypoints: web spec: rules: - host: traefik.ormissia.com http: paths: - path: / pathType: Prefix backend: service: name: traefik port: number: 8080 参考链接 Traefik源码仓库 Traefik官网 Traefik静态配置项-File provider Let\u0026rsquo;s Encrypt Systemd文档 ","date":"October 9, 2021","hero":"/posts/deployment/3003-linux-traefik/head.png","permalink":"https://ormissia.github.io/posts/deployment/3003-linux-traefik/","summary":"Traefik is an open-source Edge Router that makes publishing your services a fun and easy experience. It receives requests on behalf of your system and finds out which components are responsible for handling them. What sets Traefik apart, besides its many features, is that it automatically discovers the right configuration for your services. The magic happens when Traefik inspects your infrastructure, where it finds relevant information and discovers which service serves which request.","tags":null,"title":"Traefik部署流程"},{"categories":null,"contents":"安装依赖 编译工具及库文件 yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 安装PCRE PCRE作用是让Nginx支持Rewrite功能\nPCRE安装包下载地址： https://sourceforge.net/projects/pcre/files/pcre/\n选择对应版本下载即可\n下载PCRE安装包 cd /usr/local/src/ wget http://downloads.sourceforge.net/project/pcre/pcre/8.45/pcre-8.45.tar.gz 解压安装包并进入目录 tar -zxvf pcre-8.45.tar.gz cd pcre-8.45 编译安装 ./configure make \u0026amp;\u0026amp; make install 验证安装 pcre-config --version 可能遇到的问题 安装完成之后有可能找不到命令，查看编译安装时的默认安装目录，将其添加到Linux环境变量PATH即可\n创建管理Nginx的用户和组 创建nginx运行用户nginx并加入到nginx组，不允许nginx用户直接登录系统\ngroupadd nginx useradd -g nginx nginx -s /sbin/nologin 安装Nginx 下载安装包 Nginx下载地址： http://nginx.org/en/download.html\n没有特殊需求的话，选择Stable version稳定版下载即可\ncd /usr/local/src/ wget http://nginx.org/download/nginx-1.20.1.tar.gz 解压安装包并进入目录 tar -zxvf nginx-1.20.1 cd nginx-1.20.1 编译安装 ./configure \\ --prefix=/usr/local/nginx \\ --user=nginx --group=nginx \\ --pid-path=/var/run/nginx/nginx.pid \\ --lock-path=/var/lock/nginx.lock \\ --error-log-path=/var/log/nginx/error.log \\ --http-log-path=/var/log/nginx/access.log \\ --with-http_gzip_static_module \\ --http-client-body-temp-path=/var/temp/nginx/client \\ --http-proxy-temp-path=/var/temp/nginx/proxy \\ --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \\ --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \\ --http-scgi-temp-path=/var/temp/nginx/scgi \\ --with-http_stub_status_module \\ --with-http_ssl_module \\ --with-http_realip_module make \u0026amp;\u0026amp; make install 优化Nginx程序的执行路径 添加软连接到环境变量PATH目录下\nln -s /usr/local/nginx/sbin/nginx /usr/local/sbin/ 添加软连接之后即可直接使用nginx命令启动操作Nginx\nnginx nginx -s reload #重启（修改配置文件后重新加载等） nginx -s quit #退出（处理完所有请求后结束进程） nginx -s stop #停止（直接结束进程） 测试安装 nginx -t 如果报错，一般是缺少配置路径中的文件夹，使用mkdir -p创建即可\n修改之后，正常的提示为：\nnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful 配置开机启动 创建启动脚本 vi /etc/init.d/nginx 脚本内容：\n我这里是修改过的，也可以去官网复制。官网脚本连接\n要注意从官网直接复制的需要修改几处地方，否则运行报错。\nnginx变量的值要改成nginx程序的实际安装路径 NGINX_CONF_FILE变量的值要改成nginx配置文件的路径 lockfile变量的值要改成实际的lockfile文件路径 #!/bin/sh # # nginx - this script starts and stops the nginx daemon # # chkconfig: - 85 15 # description: NGINX is an HTTP(S) server, HTTP(S) reverse \\ # proxy and IMAP/POP3 proxy server # processname: nginx # config: /etc/nginx/nginx.conf # config: /etc/sysconfig/nginx # pidfile: /var/run/nginx.pid # Source function library. . /etc/rc.d/init.d/functions # Source networking configuration. . /etc/sysconfig/network # Check that networking is up. [ \u0026#34;$NETWORKING\u0026#34; = \u0026#34;no\u0026#34; ] \u0026amp;\u0026amp; exit 0 nginx=\u0026#34;/usr/local/nginx/sbin/nginx\u0026#34; prog=$(basename $nginx) NGINX_CONF_FILE=\u0026#34;/usr/local/nginx/conf/nginx.conf\u0026#34; [ -f /etc/sysconfig/nginx ] \u0026amp;\u0026amp; . /etc/sysconfig/nginx lockfile=/var/lock/nginx.lock make_dirs() { # make required directories user=`$nginx -V 2\u0026gt;\u0026amp;1 | grep \u0026#34;configure arguments:.*--user=\u0026#34; | sed \u0026#39;s/[^*]*--user=\\([^ ]*\\).*/\\1/g\u0026#39; -` if [ -n \u0026#34;$user\u0026#34; ]; then if [ -z \u0026#34;`grep $user /etc/passwd`\u0026#34; ]; then useradd -M -s /bin/nologin $user fi options=`$nginx -V 2\u0026gt;\u0026amp;1 | grep \u0026#39;configure arguments:\u0026#39;` for opt in $options; do if [ `echo $opt | grep \u0026#39;.*-temp-path\u0026#39;` ]; then value=`echo $opt | cut -d \u0026#34;=\u0026#34; -f 2` if [ ! -d \u0026#34;$value\u0026#34; ]; then # echo \u0026#34;creating\u0026#34; $value mkdir -p $value \u0026amp;\u0026amp; chown -R $user $value fi fi done fi } start() { [ -x $nginx ] || exit 5 [ -f $NGINX_CONF_FILE ] || exit 6 make_dirs echo -n $\u0026#34;Starting $prog: \u0026#34; daemon $nginx -c $NGINX_CONF_FILE retval=$? echo [ $retval -eq 0 ] \u0026amp;\u0026amp; touch $lockfile return $retval } stop() { echo -n $\u0026#34;Stopping $prog: \u0026#34; killproc $prog -QUIT retval=$? echo [ $retval -eq 0 ] \u0026amp;\u0026amp; rm -f $lockfile return $retval } restart() { configtest || return $? stop sleep 1 start } reload() { configtest || return $? echo -n $\u0026#34;Reloading $prog: \u0026#34; killproc $prog -HUP retval=$? echo } force_reload() { restart } configtest() { $nginx -t -c $NGINX_CONF_FILE } rh_status() { status $prog } rh_status_q() { rh_status \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 } case \u0026#34;$1\u0026#34; in start) rh_status_q \u0026amp;\u0026amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart|configtest) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $\u0026#34;Usage: $0 {start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest}\u0026#34; exit 2 esac 修改脚本权限 cd /etc/init.d/ chmod 755 nginx 这个脚本可用来直接操作Nginx，直接执行脚本会提示需要输入\n将Nginx加入到系统服务中 chkconfig --add nginx 设为开机启动 chkconfig nginx on 重启系统后生效\n重启后，即可使用systemctl命令管理nginx服务\nsystemctl status nginx.service systemctl start nginx.service systemctl stop nginx.service 可能遇到的问题 如果使用 命令查看nginx服务状态时的提示：\n● nginx.service - SYSV: NGINX is an HTTP(S) server, HTTP(S) reverse proxy and IMAP/POP3 proxy server Loaded: loaded (/etc/rc.d/init.d/nginx; generated) Active: inactive (dead) Docs: man:systemd-sysv-generator(8) 是因为系统安装了httpd，卸载即可\nyum remove httpd -y 验证安装 执行\ncurl 127.0.0.1 从返回结果中可以看到，成功拿到Nginx的默认页面了，安装成功\n也可以在外网通过服务IP访问，需要注意Linux防火墙、云服务器出站入站规则等限制\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;If you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;For online documentation and support please refer to \u0026lt;a href=\u0026#34;http://nginx.org/\u0026#34;\u0026gt;nginx.org\u0026lt;/a\u0026gt;.\u0026lt;br/\u0026gt; Commercial support is available at \u0026lt;a href=\u0026#34;http://nginx.com/\u0026#34;\u0026gt;nginx.com\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ","date":"October 8, 2021","hero":"/posts/deployment/3002-linux-nginx/head.svg","permalink":"https://ormissia.github.io/posts/deployment/3002-linux-nginx/","summary":"安装依赖 编译工具及库文件 yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 安装PCRE PCRE作用是让Nginx支持Rewrite功能\nPCRE安装包下载地址： https://sourceforge.net/projects/pcre/files/pcre/\n选择对应版本下载即可\n下载PCRE安装包 cd /usr/local/src/ wget http://downloads.sourceforge.net/project/pcre/pcre/8.45/pcre-8.45.tar.gz 解压安装包并进入目录 tar -zxvf pcre-8.45.tar.gz cd pcre-8.45 编译安装 ./configure make \u0026amp;\u0026amp; make install 验证安装 pcre-config --version 可能遇到的问题 安装完成之后有可能找不到命令，查看编译安装时的默认安装目录，将其添加到Linux环境变量PATH即可\n创建管理Nginx的用户和组 创建nginx运行用户nginx并加入到nginx组，不允许nginx用户直接登录系统\ngroupadd nginx useradd -g nginx nginx -s /sbin/nologin 安装Nginx 下载安装包 Nginx下载地址： http://nginx.org/en/download.html\n没有特殊需求的话，选择Stable version稳定版下载即可\ncd /usr/local/src/ wget http://nginx.org/download/nginx-1.20.1.tar.gz 解压安装包并进入目录 tar -zxvf nginx-1.20.1 cd nginx-1.20.1 编译安装 ./configure \\ --prefix=/usr/local/nginx \\ --user=nginx --group=nginx \\ --pid-path=/var/run/nginx/nginx.","tags":null,"title":"Linux部署Nginx流程"},{"categories":null,"contents":" #hadoop #hdfs\nHDFS架构 HDFS是一个主从（Master/Slaves）架构 由一个NameNode和一些DataNode组成 面向文件包含：文件元数据（metadata）和文件数据（data） NameNode负责存储和管理文件元数据，并维护了一个层次型的文件目录树 DataNode负责存储文件数据（block块），并提供block的读写 DataNode与NameNode维持心跳，并汇报自己持有的block信息 Client和NameNode交互文件元数据和DataNode交互文件block数据 目录树结构 角色即进程\nHadoop集群中HDFS节点角色 Master Standy ","date":"September 24, 2021","hero":"/posts/knowledge/2006-hadoop/2007-hadoop-hdfs/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2006-hadoop/2007-hadoop-hdfs/","summary":" #hadoop #hdfs\nHDFS架构 HDFS是一个主从（Master/Slaves）架构 由一个NameNode和一些DataNode组成 面向文件包含：文件元数据（metadata）和文件数据（data） NameNode负责存储和管理文件元数据，并维护了一个层次型的文件目录树 DataNode负责存储文件数据（block块），并提供block的读写 DataNode与NameNode维持心跳，并汇报自己持有的block信息 Client和NameNode交互文件元数据和DataNode交互文件block数据 目录树结构 角色即进程\nHadoop集群中HDFS节点角色 Master Standy ","tags":null,"title":"HDFS基础知识"},{"categories":null,"contents":" 结合上次Golang服务内存增长的分析，近期线上多个服务出现内存持续增长的问题，就这个现象分析一下Prometheus+Grafana的监控问题\n#kubernetes #k8s #内存分析 #oom #golang #grafana\n问题现象 近期在Grafana上显示生产环境多个服务出现内存持续增长的问题，有Golang的服务，也有JAVA的服务。都是服务重启之后，内存来到一个最低水平， 随着服务运行时间增长，pod的内存占用也随之水涨船高。直到内存占用增长到pod限制的上限附近，内存才出现回收的迹象，并且回收幅度不是特别明显， 但同时又不会出现OOM。\nGolang某个服务内存占用情况 JAVA某个服务内存占用情况 简单分析 记一次线上的内存持续增长问题\n↑这个是初次遇到这个问题时候的分析，当时以为是代码写的有漏洞，程序发生了内存泄漏。于是祭出了pprof分析了一顿，结果可想而知，当然是没看出有问题。\n现在是多个服务都出现类似问题，那这个情况相对也就比较值得重视了。之前那个服务是因为日志写的比较多，造成磁盘IO比较大。同样的， 近期发现的这几个内存持续不断增长的服务也都是日志量比较大的。\n进一步分析 集群日志架构 所有pod中的日志都是写入挂载到/data/log目录的物理机磁盘中，因此所有写日志的操作都会有磁盘IO。日志量越大的pod，磁盘IO相应地也越高。\n集群监控 普通pod监控采用了常见的Prometheus+Grafana的方案。\n数据源计算方式 监控数据是采集的kubernetes中监控程序cadvisor上报的container_memory_working_set_bytes字段（ 表格参照 ）\n查看cadvisor源码中setMemoryStats 可知，container_memory_working_set_bytes字段是cgroup memory.usage_in_bytes（RSS + Cache）与memory.stat total_inactive_file二者的差值\nfunc setMemoryStats(s *cgroups.Stats, ret *info.ContainerStats) { // ... // ... inactiveFileKeyName := \u0026#34;total_inactive_file\u0026#34; if cgroups.IsCgroup2UnifiedMode() { inactiveFileKeyName = \u0026#34;inactive_file\u0026#34; } workingSet := ret.Memory.Usage if v, ok := s.MemoryStats.Stats[inactiveFileKeyName]; ok { if workingSet \u0026lt; v { workingSet = 0 } else { workingSet -= v } } ret.Memory.WorkingSet = workingSet } 而memory.usage_in_bytes的统计数据是包含了所有的file cache的，total_active_file和total_inactive_file都属于file cache的一部分， 但是这两个数据并不是Pod中的程序真正占用的内存，只是系统为了提高磁盘IO的效率，将读写过的文件缓存在内存中。file cache并不会随着进程退出而释放，只会当容器销毁或者系统内存不足时才会由系统自动回收。\n所以cadvisor采用memory.usage_in_bytes - total_inactive_file计算出的结果并不是当前Pod中程序所占用的内存，当Pod内存资源紧张时total_active_file也是可回收利用的。\n验证结论 准备环境 去测试环境找到一个服务重启一下，并进入容器命令行\n准备一个较大的文件 找一个比较大的文件，这里找了一个8M左右的日志文件\n/app # ls -lah /data/log/xxxx.log -rw-r--r-- 1 root root 8.2M May 31 10:54 /data/log/xxxx.log 查看内存数据 在容器中进入/sys/fs/cgroup/memory/目录，并查看cat memory.stat内容\n/app # cd /sys/fs/cgroup/memory/ /sys/fs/cgroup/memory # cat memory.stat cache 38195200 rss 13484032 rss_huge 0 mapped_file 495616 swap 0 pgpgin 1550811 pgpgout 1538194 pgfault 1512338 pgmajfault 36 inactive_anon 0 active_anon 13422592 inactive_file 12058624 active_file 26136576 unevictable 0 hierarchical_memory_limit 314572800 hierarchical_memsw_limit 314572800 total_cache 38195200 total_rss 13484032 total_rss_huge 0 total_mapped_file 495616 total_swap 0 total_pgpgin 1550811 total_pgpgout 1538194 total_pgfault 1512338 total_pgmajfault 36 total_inactive_anon 0 total_active_anon 13422592 total_inactive_file 12058624 total_active_file 26136576 total_unevictable 0 记录此时\ntotal_inactive_file 12058624 Bytes = 11.5M\ntotal_active_file 26136576 Bytes = 24.9M\n遍历日志文件 /sys/fs/cgroup/memory # grep \u0026#34;hello\u0026#34; /data/log/xxx.log 第二次查看内存 /sys/fs/cgroup/memory # cat memory.stat cache 46850048 rss 13500416 rss_huge 0 mapped_file 495616 swap 0 pgpgin 1552994 pgpgout 1538260 pgfault 1512642 pgmajfault 36 inactive_anon 0 active_anon 13459456 inactive_file 20709376 active_file 26140672 unevictable 0 hierarchical_memory_limit 314572800 hierarchical_memsw_limit 314572800 total_cache 46850048 total_rss 13500416 total_rss_huge 0 total_mapped_file 495616 total_swap 0 total_pgpgin 1552994 total_pgpgout 1538260 total_pgfault 1512642 total_pgmajfault 36 total_inactive_anon 0 total_active_anon 13459456 total_inactive_file 20709376 total_active_file 26140672 total_unevictable 0 记录此时\ntotal_inactive_file 20709376 Bytes = 19.6M\ntotal_active_file 26140672 Bytes = 24.9M\n此时total_inactive_file占用较上次增加大约8M左右，即遍历过的日志文件的大小。\n第二次遍历日志文件 对同一个文件第二次遍历访问\n/sys/fs/cgroup/memory # grep \u0026#34;hello\u0026#34; /data/log/xxx.log 第三次查看内存 /sys/fs/cgroup/memory # cat memory.stat cache 46850048 rss 13504512 rss_huge 0 mapped_file 495616 swap 0 pgpgin 1553058 pgpgout 1538323 pgfault 1512941 pgmajfault 36 inactive_anon 0 active_anon 13459456 inactive_file 12025856 active_file 34824192 unevictable 0 hierarchical_memory_limit 314572800 hierarchical_memsw_limit 314572800 total_cache 46850048 total_rss 13504512 total_rss_huge 0 total_mapped_file 495616 total_swap 0 total_pgpgin 1553058 total_pgpgout 1538323 total_pgfault 1512941 total_pgmajfault 36 total_inactive_anon 0 total_active_anon 13459456 total_inactive_file 12025856 total_active_file 34824192 total_unevictable 0 记录此时\ntotal_inactive_file 12025856 Bytes = 11.5M\ntotal_active_file 34824192 Bytes = 33.2M\n此时total_inactive_file较上次减少8M，而total_active_file较上次增加8M\n查看Grafana 遍历日志文件之前 遍历日志文件之后 此时查看对应服务的Grafana面板可以看到，使用shell的grep命令遍历一个8M多的文件之后，在Pod中内存占用上升了大概8M。 而此时这块内存并没有被Pod中任何程序所引用，只是一个file cache的占用。\n总结 根据上述实验结果可以印证内存持续增长但不会OOM的现象。服务启动并向磁盘中持续追加日志文件，随之file cache持续上涨，直至达到Pod的内存上限之后，会出现GC。\n结论 memory.usage_in_bytes统计包含了Cached和Buffers，Cached中除了mlock_file和Shmem（IPCS shared memory \u0026amp; tmpfs）外， 其他部分file cache是可以回收使用的，Buffers也是可以回收利用的，所以Pod容器所在cgroup实际使用的内存计算公式可以转化为 (因memory.stat未导出SReclaimable，这里忽略SReclaimable)：\nreal_used = memory.usage_in_bytes – (Cached- Shmem - mlock_file + Buffers ) = memory.usage_in_bytes – memory.stat.total_active_file 因此cadvisor中container_memory_working_set_bytes字段在计算实际已使用内存时应该改为：\nreal_used = memory.usage_in_bytes – memory.stat.total_active_file 但是 过程中去kubernetes 的issue 中逛了一圈，发现了几个相关问题的讨论：\nhttps://github.com/kubernetes/kubernetes/issues/43916 https://github.com/kubernetes/kubernetes/issues/104533 其中一个给我笑出声\nkubernetes should not count active_file as used memory, I have been waiting for 4 years!\n等了四年了，这个问题还没有解决。也许，我们从一开始就错了？缓存也应该算是pod内存占用？\n参考 https://lwn.net/Articles/432224/ ","date":"September 22, 2021","hero":"/posts/problems/5002-k8s-memory/head.svg","permalink":"https://ormissia.github.io/posts/problems/5002-k8s-memory/","summary":"结合上次Golang服务内存增长的分析，近期线上多个服务出现内存持续增长的问题，就这个现象分析一下Prometheus+Grafana的监控问题\n#kubernetes #k8s #内存分析 #oom #golang #grafana\n问题现象 近期在Grafana上显示生产环境多个服务出现内存持续增长的问题，有Golang的服务，也有JAVA的服务。都是服务重启之后，内存来到一个最低水平， 随着服务运行时间增长，pod的内存占用也随之水涨船高。直到内存占用增长到pod限制的上限附近，内存才出现回收的迹象，并且回收幅度不是特别明显， 但同时又不会出现OOM。\nGolang某个服务内存占用情况 JAVA某个服务内存占用情况 简单分析 记一次线上的内存持续增长问题\n↑这个是初次遇到这个问题时候的分析，当时以为是代码写的有漏洞，程序发生了内存泄漏。于是祭出了pprof分析了一顿，结果可想而知，当然是没看出有问题。\n现在是多个服务都出现类似问题，那这个情况相对也就比较值得重视了。之前那个服务是因为日志写的比较多，造成磁盘IO比较大。同样的， 近期发现的这几个内存持续不断增长的服务也都是日志量比较大的。\n进一步分析 集群日志架构 所有pod中的日志都是写入挂载到/data/log目录的物理机磁盘中，因此所有写日志的操作都会有磁盘IO。日志量越大的pod，磁盘IO相应地也越高。\n集群监控 普通pod监控采用了常见的Prometheus+Grafana的方案。\n数据源计算方式 监控数据是采集的kubernetes中监控程序cadvisor上报的container_memory_working_set_bytes字段（ 表格参照 ）\n查看cadvisor源码中setMemoryStats 可知，container_memory_working_set_bytes字段是cgroup memory.usage_in_bytes（RSS + Cache）与memory.stat total_inactive_file二者的差值\nfunc setMemoryStats(s *cgroups.Stats, ret *info.ContainerStats) { // ... // ... inactiveFileKeyName := \u0026#34;total_inactive_file\u0026#34; if cgroups.IsCgroup2UnifiedMode() { inactiveFileKeyName = \u0026#34;inactive_file\u0026#34; } workingSet := ret.Memory.Usage if v, ok := s.MemoryStats.Stats[inactiveFileKeyName]; ok { if workingSet \u0026lt; v { workingSet = 0 } else { workingSet -= v } } ret.","tags":null,"title":"Grafana上监控kubernetes中Pod已用内存不准问题分析"},{"categories":null,"contents":" #hadoop\n最近在学习大数据相关的东西，看了HDFS，Hive，HBas，Spark相关的东西，总结一下Hadoop生态中常见的组件。\nHDFS（hadoop分布式文件系统） HDFS是hadoop体系中数据存储管理的基础。他是一个高度容错的系统，能检测和应对硬件故障。\n有以下几个角色：\nclient：切分文件，访问HDFS，与那么弄得交互，获取文件位置信息，与DataNode交互，读取和写入数据。\nnamenode：master节点，在hadoop1.x中只有一个，管理HDFS的名称空间和数据块映射信息，配置副本策略，处理客户 端请求。\nDataNode：slave节点，存储实际的数据，汇报存储信息给namenode。\nsecondary namenode：辅助namenode，分担其工作量：定期合并fsimage和fsedits，推送给namenode；紧急情况下和辅助恢复namenode，但其并非namenode的热备。\nmapreduce（分布式计算框架） mapreduce是一种计算模型，用于处理大数据量的计算。其中map对应数据集上的独立元素进行指定的操作，生成键-值对形式中间，reduce则对中间结果中相同的键的所有值进行规约，以得到最终结果。\njobtracker：master节点，只有一个，管理所有作业，任务/作业的监控，错误处理等，将任务分解成一系列任务，并分派给tasktracker。\ntacktracker：slave节点，运行 map task和reducetask；并与jobtracker交互，汇报任务状态。\nmap task：解析每条数据记录，传递给用户编写的map（）并执行，将输出结果写入到本地磁盘（如果为map—only作业，则直接写入HDFS）。\nreduce task：从map 它深刻地执行结果中，远程读取输入数据，对数据进行排序，将数据分组传递给用户编写的reduce函数执行。\nhive（基于hadoop的数据仓库） 由Facebook开源，最初用于解决海量结构化的日志数据统计问题。\nhive定于了一种类似sql的查询语言（hql）将sql转化为mapreduce任务在hadoop上执行。\nhbase（分布式列存数据库） hbase是一个针对结构化数据的可伸缩，高可靠，高性能，分布式和面向列的动态模式数据库。和传统关系型数据库不同，hbase采用了bigtable的数据模型： 增强了稀疏排序映射表（key/value）。其中，键由行关键字，列关键字和时间戳构成，hbase提供了对大规模数据的随机，实时读写访问，同时，hbase中保 存的数据可以使用mapreduce来处理，它将数据存储和并行计算完美结合在一起。\nzookeeper（分布式协作服务） 解决分布式环境下的数据管理问题：统一命名，状态同步，集群管理，配置同步等。\nsqoop（数据同步工具） sqoop是sql-to-hadoop的缩写，主要用于传统数据库和hadoop之间传输数据。数据的导入和导出本质上是mapreduce程序，充分利用了MR的并行化和容错性。\npig（基于hadoop的数据流系统） 定义了一种数据流语言-pig latin，将脚本转换为mapreduce任务在hadoop上执行。通常用于离线分析。\nmahout（数据挖掘算法库） mahout的主要目标是创建一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建只能应用程序。mahout现在已经包含了聚类，分类， 推荐引擎（协同过滤）和频繁集挖掘等广泛使用的数据挖掘方法。除了算法是，mahout还包含了数据的输入/输出工具，与其他存储系统（如数据库，mongoDB或 Cassandra）集成等数据挖掘支持架构。\nflume（日志收集工具） cloudera开源的日志收集系统，具有分布式，高可靠，高容错，易于定制和扩展的特点。他将数据从产生，传输，处理并写入目标的路径的过程抽象为数据流，在 具体的数据流中，数据源支持在flume中定制数据发送方，从而支持收集各种不同协议数据。\n资源管理器的简单介绍（YARN和mesos） 随着互联网的高速发展，基于数据 密集型应用 的计算框架不断出现，从支持离线处理的mapreduce，到支持在线处理的storm，从迭代式计算框架到 流式处理框 架s4，\u0026hellip;，在大部分互联网公司中，这几种框架可能都会采用，比如对于搜索引擎公司，可能的技术方法如下：网页建索引采用mapreduce框架，自然语言处理/ 数据挖掘采用spark，对性能要求到的数据挖掘算法用mpi等。公司一般将所有的这些框架部署到一个公共的集群中，让它们共享集群的资源，并对资源进行统一使 用，这样便诞生了资源统一管理与调度平台，典型的代表是mesos和yarn。\n其他的一些开源组件： cloudrea impala： 一个开源的查询引擎。与hive相同的元数据，SQL语法，ODBC驱动程序和用户接口，可以直接在HDFS上提供快速，交互式SQL查询。impala不再使用缓慢的 hive+mapreduce批处理，而是通过与商用并行关系数据库中类似的分布式查询引擎。可以直接从HDFS或者Hbase中用select，join和统计函数查询数据，从而 大大降低延迟。\nspark： spark是个开源的数据 分析集群计算框架，最初由加州大学伯克利分校AMPLab，建立于HDFS之上。spark与hadoop一样，用于构建大规模，延迟低的数据分析 应用。spark采用Scala语言实现，使用Scala作为应用框架。\nspark采用基于内存的分布式数据集，优化了迭代式的工作负载以及交互式查询。\n与hadoop不同的是，spark与Scala紧密集成，Scala象管理本地collective对象那样管理分布式数据集。spark支持分布式数据集上的迭代式任务，实际上可 以在hadoop文件系统上与hadoop一起运行（通过YARN,MESOS等实现）。\nstorm storm是一个分布式的，容错的计算系统，storm属于流处理平台，多用于实时计算并更新数据库。storm也可被用于“连续计算”，对数据流做连续查询，在计算 时将结果一流的形式输出给用户。他还可被用于“分布式RPC”,以并行的方式运行昂贵的运算。\nkafka kafka是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的 网站中的所有动作流数据。 这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。 这些数据通常是由于吞吐量的要求 而通过处理日志和日志聚合来解决。 对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka的目的是通 过Hadoop的并行加载机制来统一线上和离线的消息处理，也是为了通过集群来提供实时的消息\n","date":"September 17, 2021","hero":"/posts/knowledge/2006-hadoop/001-env/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2006-hadoop/001-env/","summary":"#hadoop\n最近在学习大数据相关的东西，看了HDFS，Hive，HBas，Spark相关的东西，总结一下Hadoop生态中常见的组件。\nHDFS（hadoop分布式文件系统） HDFS是hadoop体系中数据存储管理的基础。他是一个高度容错的系统，能检测和应对硬件故障。\n有以下几个角色：\nclient：切分文件，访问HDFS，与那么弄得交互，获取文件位置信息，与DataNode交互，读取和写入数据。\nnamenode：master节点，在hadoop1.x中只有一个，管理HDFS的名称空间和数据块映射信息，配置副本策略，处理客户 端请求。\nDataNode：slave节点，存储实际的数据，汇报存储信息给namenode。\nsecondary namenode：辅助namenode，分担其工作量：定期合并fsimage和fsedits，推送给namenode；紧急情况下和辅助恢复namenode，但其并非namenode的热备。\nmapreduce（分布式计算框架） mapreduce是一种计算模型，用于处理大数据量的计算。其中map对应数据集上的独立元素进行指定的操作，生成键-值对形式中间，reduce则对中间结果中相同的键的所有值进行规约，以得到最终结果。\njobtracker：master节点，只有一个，管理所有作业，任务/作业的监控，错误处理等，将任务分解成一系列任务，并分派给tasktracker。\ntacktracker：slave节点，运行 map task和reducetask；并与jobtracker交互，汇报任务状态。\nmap task：解析每条数据记录，传递给用户编写的map（）并执行，将输出结果写入到本地磁盘（如果为map—only作业，则直接写入HDFS）。\nreduce task：从map 它深刻地执行结果中，远程读取输入数据，对数据进行排序，将数据分组传递给用户编写的reduce函数执行。\nhive（基于hadoop的数据仓库） 由Facebook开源，最初用于解决海量结构化的日志数据统计问题。\nhive定于了一种类似sql的查询语言（hql）将sql转化为mapreduce任务在hadoop上执行。\nhbase（分布式列存数据库） hbase是一个针对结构化数据的可伸缩，高可靠，高性能，分布式和面向列的动态模式数据库。和传统关系型数据库不同，hbase采用了bigtable的数据模型： 增强了稀疏排序映射表（key/value）。其中，键由行关键字，列关键字和时间戳构成，hbase提供了对大规模数据的随机，实时读写访问，同时，hbase中保 存的数据可以使用mapreduce来处理，它将数据存储和并行计算完美结合在一起。\nzookeeper（分布式协作服务） 解决分布式环境下的数据管理问题：统一命名，状态同步，集群管理，配置同步等。\nsqoop（数据同步工具） sqoop是sql-to-hadoop的缩写，主要用于传统数据库和hadoop之间传输数据。数据的导入和导出本质上是mapreduce程序，充分利用了MR的并行化和容错性。\npig（基于hadoop的数据流系统） 定义了一种数据流语言-pig latin，将脚本转换为mapreduce任务在hadoop上执行。通常用于离线分析。\nmahout（数据挖掘算法库） mahout的主要目标是创建一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建只能应用程序。mahout现在已经包含了聚类，分类， 推荐引擎（协同过滤）和频繁集挖掘等广泛使用的数据挖掘方法。除了算法是，mahout还包含了数据的输入/输出工具，与其他存储系统（如数据库，mongoDB或 Cassandra）集成等数据挖掘支持架构。\nflume（日志收集工具） cloudera开源的日志收集系统，具有分布式，高可靠，高容错，易于定制和扩展的特点。他将数据从产生，传输，处理并写入目标的路径的过程抽象为数据流，在 具体的数据流中，数据源支持在flume中定制数据发送方，从而支持收集各种不同协议数据。\n资源管理器的简单介绍（YARN和mesos） 随着互联网的高速发展，基于数据 密集型应用 的计算框架不断出现，从支持离线处理的mapreduce，到支持在线处理的storm，从迭代式计算框架到 流式处理框 架s4，\u0026hellip;，在大部分互联网公司中，这几种框架可能都会采用，比如对于搜索引擎公司，可能的技术方法如下：网页建索引采用mapreduce框架，自然语言处理/ 数据挖掘采用spark，对性能要求到的数据挖掘算法用mpi等。公司一般将所有的这些框架部署到一个公共的集群中，让它们共享集群的资源，并对资源进行统一使 用，这样便诞生了资源统一管理与调度平台，典型的代表是mesos和yarn。\n其他的一些开源组件： cloudrea impala： 一个开源的查询引擎。与hive相同的元数据，SQL语法，ODBC驱动程序和用户接口，可以直接在HDFS上提供快速，交互式SQL查询。impala不再使用缓慢的 hive+mapreduce批处理，而是通过与商用并行关系数据库中类似的分布式查询引擎。可以直接从HDFS或者Hbase中用select，join和统计函数查询数据，从而 大大降低延迟。\nspark： spark是个开源的数据 分析集群计算框架，最初由加州大学伯克利分校AMPLab，建立于HDFS之上。spark与hadoop一样，用于构建大规模，延迟低的数据分析 应用。spark采用Scala语言实现，使用Scala作为应用框架。\nspark采用基于内存的分布式数据集，优化了迭代式的工作负载以及交互式查询。\n与hadoop不同的是，spark与Scala紧密集成，Scala象管理本地collective对象那样管理分布式数据集。spark支持分布式数据集上的迭代式任务，实际上可 以在hadoop文件系统上与hadoop一起运行（通过YARN,MESOS等实现）。\nstorm storm是一个分布式的，容错的计算系统，storm属于流处理平台，多用于实时计算并更新数据库。storm也可被用于“连续计算”，对数据流做连续查询，在计算 时将结果一流的形式输出给用户。他还可被用于“分布式RPC”,以并行的方式运行昂贵的运算。\nkafka kafka是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的 网站中的所有动作流数据。 这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。 这些数据通常是由于吞吐量的要求 而通过处理日志和日志聚合来解决。 对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka的目的是通 过Hadoop的并行加载机制来统一线上和离线的消息处理，也是为了通过集群来提供实时的消息","tags":null,"title":"Hadoop生态组件"},{"categories":null,"contents":" #golang #oom #内存分析 #grafana #kubernetes #k8s\n问题现象 前些天从Grafana上看到某一个pod内存涨上去就再没下来（从9/1~9/2之间的一个时间开始），并且看这个趋势涨上去就没有下来的意思。中间有几次pod重新发布 才导致内存恢复到一个比较低的水平，但内存依旧持续上涨。\n初步分析 初步推测大概率与日志有关，此次发版改动了日志输出格式，以及修改了日志没有写入磁盘的问题。\n先把服务稳住 由于清楚问题的大致方向，先将服务中几个打印log比较频繁的位置注释掉，在9/3~9/4之间的一个位置重新发布。从之后的趋势上可以看出，注释掉几个打印日志的 地方之后，内存增长速度明显放缓。\n至此，基本可以确认内存增长与日志相关。\n问题排查 猜测一 回头又捋了几遍代码，也没发现什么端倪。\n于是祭出pprof抓了一下内存分析了一通，依旧无果。\n可以看出，内存占用并没有多高。\n猜测二 在 Go1.12 以前，Go Runtime在Linux上使用的是MADV_DONTNEED策略，可以让RSS下降的比较快，就是效率差点。 在 Go1.12 及以后，Go Runtime专门针对其进行了优化，使用了更为高效的MADV_FREE策略。但这样子所带来的副作用就是RSS不会立刻下降， 要等到系统有内存压力了才会释放占用，RSS才会下降。 查看容器的 Linux 内核版本：\n# 查看命令 uname -a 课件容器版本为3.10.0，但MADV_FREE的策略改变，需要Linux内核在4.5及以上（详细可见go/issues/23687 ）， 因此可以排除。\n猜想三 通过top命令可以通过可以查看容器中程序的内存占用VSZ为711，无法查看RSS，关于RSS和VSZ的区别，可以参考RSS和VSZ\n容器内存判定是通过container_memory_working_set_bytes，而container_memory_working_set_bytes是由cadvisor提供的。\n原因 从cadvisor/issues/638 可得知container_memory_working_set_bytes指标的组 成实际上是RSS + Cache。而Cache高的情况，常见于进程有大量文件IO，占用Cache可能就会比较高，猜测也与Go版本、Linux 内核版本的Cache释放、回收方式有较大关系。 只要是涉及有大量文件IO的服务，基本上是这个问题的老常客了，写这类服务基本写一个中一个，因为这是一个混合问题，像其它单纯操作为主的业务服务就很 “正常”，不会出现内存居高不下。\n没多久看到烤鱼佬的一篇文章，与这个情况类似，他的解决办法也就是写了个脚本，\u0026ldquo;手动\u0026quot;HPA（其实也就是自动重启）。\n总结 虽然这问题时间跨度比较长，整体来讲都是阶段性排查，本质上可以说是对Kubernetes的不熟悉有关。但因为内存居高不下的可能性有很多种，要一个个排查。\n","date":"September 15, 2021","hero":"/posts/problems/5001-go-online-service-oom/head.svg","permalink":"https://ormissia.github.io/posts/problems/5001-go-online-service-oom/","summary":"#golang #oom #内存分析 #grafana #kubernetes #k8s\n问题现象 前些天从Grafana上看到某一个pod内存涨上去就再没下来（从9/1~9/2之间的一个时间开始），并且看这个趋势涨上去就没有下来的意思。中间有几次pod重新发布 才导致内存恢复到一个比较低的水平，但内存依旧持续上涨。\n初步分析 初步推测大概率与日志有关，此次发版改动了日志输出格式，以及修改了日志没有写入磁盘的问题。\n先把服务稳住 由于清楚问题的大致方向，先将服务中几个打印log比较频繁的位置注释掉，在9/3~9/4之间的一个位置重新发布。从之后的趋势上可以看出，注释掉几个打印日志的 地方之后，内存增长速度明显放缓。\n至此，基本可以确认内存增长与日志相关。\n问题排查 猜测一 回头又捋了几遍代码，也没发现什么端倪。\n于是祭出pprof抓了一下内存分析了一通，依旧无果。\n可以看出，内存占用并没有多高。\n猜测二 在 Go1.12 以前，Go Runtime在Linux上使用的是MADV_DONTNEED策略，可以让RSS下降的比较快，就是效率差点。 在 Go1.12 及以后，Go Runtime专门针对其进行了优化，使用了更为高效的MADV_FREE策略。但这样子所带来的副作用就是RSS不会立刻下降， 要等到系统有内存压力了才会释放占用，RSS才会下降。 查看容器的 Linux 内核版本：\n# 查看命令 uname -a 课件容器版本为3.10.0，但MADV_FREE的策略改变，需要Linux内核在4.5及以上（详细可见go/issues/23687 ）， 因此可以排除。\n猜想三 通过top命令可以通过可以查看容器中程序的内存占用VSZ为711，无法查看RSS，关于RSS和VSZ的区别，可以参考RSS和VSZ\n容器内存判定是通过container_memory_working_set_bytes，而container_memory_working_set_bytes是由cadvisor提供的。\n原因 从cadvisor/issues/638 可得知container_memory_working_set_bytes指标的组 成实际上是RSS + Cache。而Cache高的情况，常见于进程有大量文件IO，占用Cache可能就会比较高，猜测也与Go版本、Linux 内核版本的Cache释放、回收方式有较大关系。 只要是涉及有大量文件IO的服务，基本上是这个问题的老常客了，写这类服务基本写一个中一个，因为这是一个混合问题，像其它单纯操作为主的业务服务就很 “正常”，不会出现内存居高不下。\n没多久看到烤鱼佬的一篇文章，与这个情况类似，他的解决办法也就是写了个脚本，\u0026ldquo;手动\u0026quot;HPA（其实也就是自动重启）。\n总结 虽然这问题时间跨度比较长，整体来讲都是阶段性排查，本质上可以说是对Kubernetes的不熟悉有关。但因为内存居高不下的可能性有很多种，要一个个排查。","tags":null,"title":"记一次线上的内存持续增长问题"},{"categories":null,"contents":" #golang #struct-tag #reflect\nStructTag是写在结构体字段类型后面反引号中的内容，用来标记结构体中各字段的属性。\n源码中对struct tag的解释：\nBy convention, tag strings are a concatenation of optionally space-separated key:\u0026ldquo;value\u0026rdquo; pairs. Each key is a non-empty string consisting of non-control characters other than space (U+0020 \u0026rsquo; \u0026lsquo;), quote (U+0022 \u0026lsquo;\u0026quot;\u0026rsquo;), and colon (U+003A \u0026lsquo;:\u0026rsquo;). Each value is quoted using U+0022 \u0026lsquo;\u0026quot;\u0026rsquo; characters and Go string literal syntax.\n简单应用 最常见的，比如json的tag应用：\njson序列化和反序列化时候使用的key都是在struct字段上定义的\npackage main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; ) type User struct { ID int `json:\u0026#34;id\u0026#34;` Username string `json:\u0026#34;username\u0026#34;` Age int `json:\u0026#34;age\u0026#34;` Email string `json:\u0026#34;email\u0026#34;` } func main() { u := User{ ID: 1, Username: \u0026#34;ormissia\u0026#34;, Age: 90, Email: \u0026#34;email@example.com\u0026#34;, } userJson, _ := json.Marshal(u) fmt.Println(string(userJson)) u2Str := `{\u0026#34;id\u0026#34;:2,\u0026#34;username\u0026#34;:\u0026#34;ormissia\u0026#34;,\u0026#34;age\u0026#34;:900,\u0026#34;email\u0026#34;:\u0026#34;ormissia@example.com\u0026#34;}` u2 := new(User) _ = json.Unmarshal([]byte(u2Str), u2) fmt.Printf(\u0026#34;%+v\u0026#34;,u2) } 输出：\n{\u0026#34;id\u0026#34;:1,\u0026#34;username\u0026#34;:\u0026#34;ormissia\u0026#34;,\u0026#34;age\u0026#34;:90,\u0026#34;email\u0026#34;:\u0026#34;email@example.com\u0026#34;} \u0026amp;{ID:2 Username:ormissia Age:900 Email:ormissia@example.com} tag解析原理 通过反射拿到struct tag 示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) type User struct { ID int `json:\u0026#34;id\u0026#34; myTag:\u0026#34;ID\u0026#34;` Username string `json:\u0026#34;username\u0026#34; myTag:\u0026#34;USERNAME\u0026#34;` Age int `json:\u0026#34;age\u0026#34; myTag:\u0026#34;AGE\u0026#34;` Email string `json:\u0026#34;email\u0026#34; myTag:\u0026#34;EMAIL\u0026#34;` } func main() { u := User{1, \u0026#34;ormissia\u0026#34;, 90, \u0026#34;email@example.com\u0026#34;} userTyp := reflect.TypeOf(u) fieldTag := userTyp.Field(0).Tag fmt.Printf(\u0026#34;user field 0 id tag: %s\\n\u0026#34;,fieldTag) value, ok1 := fieldTag.Lookup(\u0026#34;myTag\u0026#34;) fmt.Println(value, ok1) value1, ok2 := fieldTag.Lookup(\u0026#34;other\u0026#34;) fmt.Println(value1, ok2) } 输出：\nuser field 0 id tag: json:\u0026#34;id\u0026#34; myTag:\u0026#34;ID\u0026#34; ID true false 获取tag全部的值 reflect.TypeOf(u).Field(0).Tag 通过Tag即可获取struct定义时候对应字段后面反引号``中全部的值\nTag是通过反射获取到的具体字段StructField 中的属性，类型为自定义string类型：StructTag\ntype StructField struct { // Name is the field name. Name string // PkgPath is the package path that qualifies a lower case (unexported) // field name. It is empty for upper case (exported) field names. // See https://golang.org/ref/spec#Uniqueness_of_identifiers PkgPath string Type Type // field type Tag StructTag // field tag string Offset uintptr // offset within struct, in bytes Index []int // index sequence for Type.FieldByIndex Anonymous bool // is an embedded field } // A StructTag is the tag string in a struct field. // // By convention, tag strings are a concatenation of // optionally space-separated key:\u0026#34;value\u0026#34; pairs. // Each key is a non-empty string consisting of non-control // characters other than space (U+0020 \u0026#39; \u0026#39;), quote (U+0022 \u0026#39;\u0026#34;\u0026#39;), // and colon (U+003A \u0026#39;:\u0026#39;). Each value is quoted using U+0022 \u0026#39;\u0026#34;\u0026#39; // characters and Go string literal syntax. type StructTag string 通过tag的key获取value 而StructTag 有两个通过key获取value的方法： Get 和Lookup 。\nGet 是对Lookup 的一个封装。\nLookup 可以返回当前查询的key是否存在。\nfunc (tag StructTag) Get(key string) string { v, _ := tag.Lookup(key) return v } func (tag StructTag) Lookup(key string) (value string, ok bool) { for tag != \u0026#34;\u0026#34; { // Skip leading space. i := 0 for i \u0026lt; len(tag) \u0026amp;\u0026amp; tag[i] == \u0026#39; \u0026#39; { i++ } tag = tag[i:] if tag == \u0026#34;\u0026#34; { break } i = 0 for i \u0026lt; len(tag) \u0026amp;\u0026amp; tag[i] \u0026gt; \u0026#39; \u0026#39; \u0026amp;\u0026amp; tag[i] != \u0026#39;:\u0026#39; \u0026amp;\u0026amp; tag[i] != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; tag[i] != 0x7f { i++ } if i == 0 || i+1 \u0026gt;= len(tag) || tag[i] != \u0026#39;:\u0026#39; || tag[i+1] != \u0026#39;\u0026#34;\u0026#39; { break } name := string(tag[:i]) tag = tag[i+1:] //... //... } 通过源码，我们可以看出 Lookup 实际上是对tag反引号中整个内容进行查找，通过空格、冒号以及双引号对tag的值进行分割，最后返回。\n使用自定义tag实践 我们可以一个struct参数校验器：go-opv 来简单体验一下自定义tag的使用。\ngo-opv的简单使用示例 go-opv 的简介可以参考我的 另一篇文章 。 只不过，当时还没有添加这个通过struct自定义tag的校验方式，基础功能与现在基本一致。\n仓库go-opv\n以下是一个简单的使用Demo\n在这个示例中，我们指定了struct的tag为go-opv:\u0026quot;ge:0,le:20\u0026quot;，在参数检验过程中，我们会解析这个tag，并从中获取定义的规则。\npackage main import ( \u0026#34;log\u0026#34; go_opv \u0026#34;github.com/ormissia/go-opv\u0026#34; ) type User struct { Name string `go-opv:\u0026#34;ge:0,le:20\u0026#34;` //Name \u0026gt;=0 \u0026amp;\u0026amp; Name \u0026lt;=20 Age int `go-opv:\u0026#34;ge:0,lt:100\u0026#34;` //Age \u0026gt;= 0 \u0026amp;\u0026amp; Age \u0026lt; 100 } func init() { //使用默认配置：struct tag名字为\u0026#34;go-opv\u0026#34;，规则与限定值的分隔符为\u0026#34;:\u0026#34; myVerifier = go_opv.NewVerifier() //初始化一个验证规则：Age字段大于等于0，小于200 userRequestRules = go_opv.Rules{ \u0026#34;Age\u0026#34;: []string{myVerifier.Ge(\u0026#34;0\u0026#34;), myVerifier.Lt(\u0026#34;200\u0026#34;)}, } } var myVerifier go_opv.Verifier var userRequestRules go_opv.Rules func main() { // ShouldBind(\u0026amp;user) in Gin framework or other generated object user := User{ Name: \u0026#34;ormissia\u0026#34;, Age: 190, } //两种验证方式混合,函数参数中传入自定义规则时候会覆盖struct tag上定义的规则 //根据自定义规则Age \u0026gt;= 0 \u0026amp;\u0026amp; Age \u0026lt; 200，Age的值为190，符合规则，验证通过 if err := myVerifier.Verify(user, userRequestRules); err != nil { log.Println(err) } else { log.Println(\u0026#34;pass\u0026#34;) } //只用struct的tag验证 //根据tag上定义的规则Age \u0026gt;= 0 \u0026amp;\u0026amp; Age \u0026lt; 100，Age的值为190，不符合规则，验证不通过 if err := myVerifier.Verify(user); err != nil { log.Println(err) } else { log.Println(\u0026#34;pass\u0026#34;) } } go-opv的简单分析 我们先判断了是否传入了自定义的校验规则（即为自定义规则会覆盖struct上tag定义的规则），如果没有，就去通过反射获取struct上tag定义的规则。 然后生成相对应的规则，继续执行后面的校验逻辑。\nif len(conditions[tagVal.Name]) == 0 { //没有自定义使用tag //`go-opv:\u0026#34;ne:0,eq:10\u0026#34;` //conditionsStr = \u0026#34;ne:0,eq:10\u0026#34; if conditionsStr, ok := tagVal.Tag.Lookup(verifier.tagPrefix); ok \u0026amp;\u0026amp; conditionsStr != \u0026#34;\u0026#34; { conditionStrs := strings.Split(conditionsStr, \u0026#34;,\u0026#34;) conditions[tagVal.Name] = conditionStrs } else { //如果tag也没有定义则去校验下一个字段 continue } } 小结 通过使用encoding/json 包中的json.Marshal() 和json.Unmarshal() ，我们了解了Golang中struct tag的基本概念及用途。 通过对StructField 的分析，我们明白了struct tag工作的基本原理 而通过go-opv 的分析，我们了解了自定义tag的基本使用方法。 参考 go1.16.7 type.go 源码 ","date":"August 13, 2021","hero":"/posts/knowledge/2001-go/005-tag/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2001-go/005-tag/","summary":"#golang #struct-tag #reflect\nStructTag是写在结构体字段类型后面反引号中的内容，用来标记结构体中各字段的属性。\n源码中对struct tag的解释：\nBy convention, tag strings are a concatenation of optionally space-separated key:\u0026ldquo;value\u0026rdquo; pairs. Each key is a non-empty string consisting of non-control characters other than space (U+0020 \u0026rsquo; \u0026lsquo;), quote (U+0022 \u0026lsquo;\u0026quot;\u0026rsquo;), and colon (U+003A \u0026lsquo;:\u0026rsquo;). Each value is quoted using U+0022 \u0026lsquo;\u0026quot;\u0026rsquo; characters and Go string literal syntax.\n简单应用 最常见的，比如json的tag应用：\njson序列化和反序列化时候使用的key都是在struct字段上定义的\npackage main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; ) type User struct { ID int `json:\u0026#34;id\u0026#34;` Username string `json:\u0026#34;username\u0026#34;` Age int `json:\u0026#34;age\u0026#34;` Email string `json:\u0026#34;email\u0026#34;` } func main() { u := User{ ID: 1, Username: \u0026#34;ormissia\u0026#34;, Age: 90, Email: \u0026#34;email@example.","tags":null,"title":"Golang struct tag浅析与自定义tag实践"},{"categories":null,"contents":" 前缀树又称字典树\nTrie的应用 自动补全,例如：在百度搜索的输入框中,输入一个单词的前半部分,能够自动补全出可能的单词结果。 拼写检查，例如：在word中输入一个拼写错误的单词, 能够自动检测出来。 IP路由表，在IP路由表中进行路由匹配时, 要按照最长匹配前缀的原则进行匹配。 T9预测文本，在大多手机输入法中, 都会用9格的那种输入法. 这个输入法能够根据用户在9格上的输入,自动匹配出可能的单词。 填单词游戏，相信大多数人都玩过那种在横竖的格子里填单词的游戏。 ","date":"August 12, 2021","hero":"/posts/algorithm/4002-algorithm-trie/head.svg","permalink":"https://ormissia.github.io/posts/algorithm/4002-algorithm-trie/","summary":" 前缀树又称字典树\nTrie的应用 自动补全,例如：在百度搜索的输入框中,输入一个单词的前半部分,能够自动补全出可能的单词结果。 拼写检查，例如：在word中输入一个拼写错误的单词, 能够自动检测出来。 IP路由表，在IP路由表中进行路由匹配时, 要按照最长匹配前缀的原则进行匹配。 T9预测文本，在大多手机输入法中, 都会用9格的那种输入法. 这个输入法能够根据用户在9格上的输入,自动匹配出可能的单词。 填单词游戏，相信大多数人都玩过那种在横竖的格子里填单词的游戏。 ","tags":null,"title":"前缀树"},{"categories":null,"contents":" 归并排序 思想 整体是递归（当然可以用非递归实现），使左边有序，使右边有序，合并左边右边使整体有序\n具体实现\n核心代码 func merge(arr []interface{}, l, mid, r int, compare Compare) { help := make([]interface{}, r-l+1) i := 0 p1 := l p2 := mid + 1 for p1 \u0026lt;= mid \u0026amp;\u0026amp; p2 \u0026lt;= r { if compare(arr[p1], arr[p2]) { help[i] = arr[p1] p1++ } else { help[i] = arr[p2] p2++ } i++ } //要么p1越界了，要么p2越界了 for p1 \u0026lt;= mid { help[i] = arr[p1] i++ p1++ } for p2 \u0026lt;= r { help[i] = arr[p2] i++ p2++ } for j, _ := range help { arr[l+j] = help[j] } } 递归 核心代码\nfunc mergeProcess(arr []interface{}, l, r int, compare Compare) { if l == r { return } mid := l + ((r - l) \u0026gt;\u0026gt; 1) mergeProcess(arr, l, mid, compare) mergeProcess(arr, mid+1, r, compare) merge(arr, l, mid, r, compare) } 非递归 核心代码：\nn := len(arr) mergeSize := 1 //当前有序的左组长度 for mergeSize \u0026lt; n { l := 0 for l \u0026lt; n { m := l + mergeSize - 1 if m \u0026gt;= n { break } r := m + mergeSize if m+mergeSize \u0026gt; n-1 { r = n - 1 } merge(arr, l, m, r, s.Compare) l = r + 1 } //防止溢出 if mergeSize \u0026gt; n/2 { break } mergeSize \u0026lt;\u0026lt;= 1 } 快速排序 具体实现\n思想 给定一个数组arr和一个整数num，把小于等于num的数放在数组左边，大于num的数放在数组的右边。\n额外空间复杂度是O(1)，时间复杂度O(N)\n核心代码 func netherlandsFlag(arr []interface{}, l, r int, isEqual, isSmall Compare) (i, j int) { if l \u0026gt; r { return -1, -1 } if l == r { return l, r } less := l - 1 //小于arr[R]区\t右边界 more := r //大于arr[R]区\t左边界 index := l for index \u0026lt; more { if isEqual(arr[index], arr[r]) { index++ } else if isSmall(arr[index], arr[r]) { less++ arr[index], arr[less] = arr[less], arr[index] index++ } else { more-- arr[index], arr[more] = arr[more], arr[index] } } arr[more], arr[r] = arr[r], arr[more] return less + 1, more } 递归 核心代码：\nfunc quickProcess(arr []interface{}, l, r int, isEqual, isSmall Compare) { if l \u0026gt;= r { return } n := rand.Intn(r-l+1) + l arr[n], arr[r] = arr[r], arr[n] i, j := netherlandsFlag(arr, l, r, isEqual, isSmall) quickProcess(arr, l, i-1, isEqual, isSmall) quickProcess(arr, j+1, r, isEqual, isSmall) } 堆排序 堆的实质是一棵完全二叉树\n堆可分为两种类型：\n大根堆：所有子树的根节点均为最大值 小根堆：所有子树的根节点均为最小值 一般情况下堆可以用一个有序数组来存储\n[0\u0026hellip;i\u0026hellip;n] i节点的左孩子index为2*i+1，右孩子为2i+2，父节点为(i-1)/2\n也有一种特例是从1开始(位运算比加减法快)\n[01\u0026hellip;i\u0026hellip;n] i节点的左孩子index为2*i即i\u0026lt;\u0026lt;1，右孩子为2i+1即i\u0026lt;\u0026lt;1|1，父节点为i/2\n让整个数组都变成大根堆的结构，建堆的过程： 从上到下的方法：时间复杂度为O(N*logN) 从下到上的方法：时间复杂度为O(N) 把堆的根节点个末尾值交换，减小堆的大小之后，再去调整堆，周而复始，时间复杂度为O(N*logN) 思想 依次弹出根节点，假设将大根堆弹出的值依次放到数组头部，则得到一个由小到大的数组\n适合元素在固定范围内移动\n具体实现\n核心代码 上浮 //上浮（通常是最后一个节点） //停止条件：1.没有父节点大，2.上浮到根节点了 func (h *maxHeap) heapInsert() { index := h.heapSize - 1 for h.comparator(h.Content[(index-1)/2], h.Content[index]) \u0026gt; 0 { h.Content[index], h.Content[(index-1)/2] = h.Content[(index-1)/2], h.Content[index] index = (index - 1) / 2 } } 下沉 //index位置节点不断下沉 //停止条件，1.没有孩子比自己大，2.没有孩子 func (h *maxHeap) heapify(index int) { left := index*2 + 1 for left \u0026lt; h.heapSize { //先比较左右两个孩子，挑出大的那个 largest := left if left+1 \u0026lt; h.heapSize \u0026amp;\u0026amp; h.comparator(h.Content[left], h.Content[left+1]) \u0026gt; 0 { largest = left + 1 } //再比较根节点和大的那个孩子，如果最大的那个孩子也没有index大，就break if h.comparator(h.Content[index], h.Content[largest]) \u0026lt;= 0 { break } h.Content[index], h.Content[largest] = h.Content[largest], h.Content[index] index = largest left = index*2 + 1 } } 插入 func (h *maxHeap) Push(value interface{}) (err error) { if h.IsFull() { return errHeepFull } h.Content[h.heapSize] = value h.heapSize++ h.heapInsert() return nil } 弹出 func (h *maxHeap) Pop() (value interface{}, err error) { if h.IsEmpty() { return nil, errHeepEmpty } value = h.Content[0] h.heapSize-- h.Content[0] = h.Content[h.heapSize] h.heapify(0) return value, nil } 桶排序 排序算法总结 排序算法 时间复杂度 额外空间复杂度 稳定性 选择排序 O(N^2) O(1) 无 冒泡排序 O(N^2) O(1) 有 插入排序 O(N^2) O(1) 有 归并排序 O(N*logN) O(N) 有 随机快排 O(N*logN) O(logN) 无 堆排序 O(N*logN) O(1) 无 计数排序 O(N) O(M) 有 基数排序 O(N) O(N) 有 ","date":"August 7, 2021","hero":"/posts/algorithm/4001-algorithm-sort/head.svg","permalink":"https://ormissia.github.io/posts/algorithm/4001-algorithm-sort/","summary":"归并排序 思想 整体是递归（当然可以用非递归实现），使左边有序，使右边有序，合并左边右边使整体有序\n具体实现\n核心代码 func merge(arr []interface{}, l, mid, r int, compare Compare) { help := make([]interface{}, r-l+1) i := 0 p1 := l p2 := mid + 1 for p1 \u0026lt;= mid \u0026amp;\u0026amp; p2 \u0026lt;= r { if compare(arr[p1], arr[p2]) { help[i] = arr[p1] p1++ } else { help[i] = arr[p2] p2++ } i++ } //要么p1越界了，要么p2越界了 for p1 \u0026lt;= mid { help[i] = arr[p1] i++ p1++ } for p2 \u0026lt;= r { help[i] = arr[p2] i++ p2++ } for j, _ := range help { arr[l+j] = help[j] } } 递归 核心代码","tags":null,"title":"排序算法"},{"categories":null,"contents":" #golang #pprof #内存分析\npprof is a tool for visualization and analysis of profiling data.\npprof reads a collection of profiling samples in profile.proto format and generates reports to visualize and help analyze the data. It can generate both text and graphical reports (through the use of the dot visualization package).\nPProf是用于可视化和分析性能分析数据的工具，PProf以profile.proto读取分析样本的集合，并生成报告以可视化并帮助分析数据（支持文本和图形报告）。\n简介 采集方式 runtime/pprof：采集程序（非Server）的指定区块的运行数据进行分析。 net/http/pprof：基于HTTPServer运行，并且可以采集运行时数据进行分析。 gotest：通过运行测试用例，并指定所需标识来进行采集。 功能 CPUProfiling：CPU分析，按照一定的频率采集所监听的应用程序CPU（含寄存器）的使用情况，可确定应用程序在主动消耗CPU周期时花费时间的位置。 MemoryProfiling：内存分析，在应用程序进行堆分配时记录堆栈跟踪，用于监视当前和历史内存使用情况，以及检查内存泄漏。 BlockProfiling：阻塞分析，记录Goroutine阻塞等待同步（包括定时器通道）的位置，默认不开启，需要调用runtime.SetBlockProfileRate进行设置。 MutexProfiling：互斥锁分析，报告互斥锁的竞争情况，默认不开启，需要调用runtime.SetMutexProfileFraction进行设置。 GoroutineProfiling：Goroutine分析，可以对当前应用程序正在运行的Goroutine进行堆栈跟踪和分析。这项功能在实际排查中会经常用到， 因为很多问题出现时的表象就是Goroutine暴增，而这时候我们要做的事情之一就是查看应用程序中的Goroutine正在做什么事情，因为什么阻塞了， 然后再进行下一步。 简单的例子 注意要在import中引入 _ \u0026quot;net/http/pprof\u0026quot;\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; _ \u0026#34;net/http/pprof\u0026#34; \u0026#34;time\u0026#34; ) func main() { go func() { for { log.Println(\u0026#34;pprof\u0026#34;) time.Sleep(time.Second) } }() if err := http.ListenAndServe(\u0026#34;0.0.0.0:6060\u0026#34;, nil); err != nil { log.Println(err) return } } 通过web页面访问 运行之后打开页面http://127.0.0.1:6060/debug/pprof/\n/debug/pprof/ Types of profiles available: Count\tProfile 0\tallocs 0\tblock 0\tcmdline 5\tgoroutine 0\theap 0\tmutex 0\tprofile 7\tthreadcreate 0\ttrace full goroutine stack dump Profile Descriptions: allocs: A sampling of all past memory allocations block: Stack traces that led to blocking on synchronization primitives cmdline: The command line invocation of the current program goroutine: Stack traces of all current goroutines heap: A sampling of memory allocations of live objects. You can specify the gc GET parameter to run GC before taking the heap sample. mutex: Stack traces of holders of contended mutexes profile: CPU profile. You can specify the duration in the seconds GET parameter. After you get the profile file, use the go tool pprof command to investigate the profile. threadcreate: Stack traces that led to the creation of new OS threads trace: A trace of execution of the current program. You can specify the duration in the seconds GET parameter. After you get the trace file, use the go tool trace command to investigate the trace. 通过终端访问 go tool pprof http://localhost:6060/debug/pprof/profile\\?seconds\\=60 执行该命令后，需等待60秒（可调整seconds的值），pprof会进行CPU Profiling。结束后将默认进入pprof的交互式命令模式， 可以对分析的结果进行查看或导出。\nFetching profile over HTTP from http://localhost:6060/debug/pprof/profile?seconds=60 Saved profile in /Users/orimissia/pprof/pprof.samples.cpu.003.pb.gz Type: cpu Time: Aug 6, 2021 at 2:41pm (CST) Duration: 1mins, Total samples = 10ms (0.017%) Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options) (pprof) 具体可执行pprof help查看命令说明\n(pprof) top10 Showing nodes accounting for 10ms, 100% of 10ms total flat flat% sum% cum cum% 10ms 100% 100% 10ms 100% runtime.kevent 0 0% 100% 10ms 100% runtime.findrunnable 0 0% 100% 10ms 100% runtime.mcall 0 0% 100% 10ms 100% runtime.netpoll 0 0% 100% 10ms 100% runtime.park_m 0 0% 100% 10ms 100% runtime.schedule flat：给定函数上运行耗时 flat%：同上的CPU运行耗时总比例 sum%：给定函数累积使用CPU总比例 cum：当前函数加上它之上的调用运行总耗时 cum%：同上的CPU运行耗时总比例 最后一列为函数名称，在大多数的情况下，我们可以通过这五列得出一个应用程序的运行情况，加以优化。\ngo tool pprof http://localhost:6060/debug/pprof/heap Saved profile in /Users/orimissia/pprof/pprof.alloc_objects.alloc_space.inuse_objects.inuse_space.001.pb.gz Type: inuse_space Time: Aug 6, 2021 at 2:46pm (CST) No samples were found with the default sample value type. Try \u0026#34;sample_index\u0026#34; command to analyze different sample values. Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options) -inuse_space：分析应用程序的常驻内存占用情况 -alloc_objects：分析应用程序的内存临时分配情况 可视化界面 新建测试用例：\npackage main import \u0026#34;testing\u0026#34; const str = \u0026#34;ormissia\u0026#34; func TestAdd(t *testing.T) { s := Con(str) if s == \u0026#34;\u0026#34; { t.Errorf(\u0026#34;Test.Add error!\u0026#34;) } } func BenchmarkAdd(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { Con(str) } } func Con(str string) string { data := []byte(str) sData := string(data) return sData } 执行测试用例\n% go test -bench=. -cpuprofile=cpu.prof goos: darwin goarch: arm64 pkg: awesomeProject/pprof BenchmarkAdd-8 182690547 6.330 ns/op PASS ok awesomeProject/pprof 2.366s 启动pprof可视化界面\n方法一\ngo tool pprof -http=:8080 cpu.prof 方法二\ngo tool pprof cpu.prof (pprof) web 可视化界面\n参考 https://github.com/google/pprof https://golang2.eddycjy.com/posts/ch6/01-pprof-1 ","date":"August 5, 2021","hero":"/posts/knowledge/2001-go/004-pprof/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2001-go/004-pprof/","summary":"#golang #pprof #内存分析\npprof is a tool for visualization and analysis of profiling data.\npprof reads a collection of profiling samples in profile.proto format and generates reports to visualize and help analyze the data. It can generate both text and graphical reports (through the use of the dot visualization package).\nPProf是用于可视化和分析性能分析数据的工具，PProf以profile.proto读取分析样本的集合，并生成报告以可视化并帮助分析数据（支持文本和图形报告）。\n简介 采集方式 runtime/pprof：采集程序（非Server）的指定区块的运行数据进行分析。 net/http/pprof：基于HTTPServer运行，并且可以采集运行时数据进行分析。 gotest：通过运行测试用例，并指定所需标识来进行采集。 功能 CPUProfiling：CPU分析，按照一定的频率采集所监听的应用程序CPU（含寄存器）的使用情况，可确定应用程序在主动消耗CPU周期时花费时间的位置。 MemoryProfiling：内存分析，在应用程序进行堆分配时记录堆栈跟踪，用于监视当前和历史内存使用情况，以及检查内存泄漏。 BlockProfiling：阻塞分析，记录Goroutine阻塞等待同步（包括定时器通道）的位置，默认不开启，需要调用runtime.SetBlockProfileRate进行设置。 MutexProfiling：互斥锁分析，报告互斥锁的竞争情况，默认不开启，需要调用runtime.SetMutexProfileFraction进行设置。 GoroutineProfiling：Goroutine分析，可以对当前应用程序正在运行的Goroutine进行堆栈跟踪和分析。这项功能在实际排查中会经常用到， 因为很多问题出现时的表象就是Goroutine暴增，而这时候我们要做的事情之一就是查看应用程序中的Goroutine正在做什么事情，因为什么阻塞了， 然后再进行下一步。 简单的例子 注意要在import中引入 _ \u0026quot;net/http/pprof\u0026quot;\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; _ \u0026#34;net/http/pprof\u0026#34; \u0026#34;time\u0026#34; ) func main() { go func() { for { log.","tags":null,"title":"Golang性能分析工具-pprof"},{"categories":null,"contents":" #golang #reflect\n反射简介 Golang提供了一种机制，在编译时不知道类型的情况下，可更新变量、运行时查看值、调用方法以及直接对他们的布局进行操作的机制，称为反射。\nreflect 包中的官方注释：Package reflect implements run-time reflection, allowing a program to manipulate objects with arbitrary types. reflect 实现了运行时的反射能力，能够让程序操作不同类型的对象。反射包中有两对非常重要的函数和类型， 两个函数分别是：\nreflect.TypeOf 能获取类型信息 reflect.ValueOf 能获取数据的运行时表示 三大法则 运行时反射是程序在运行期间检查其自身结构的一种方式。反射带来的灵活性是一把双刃剑，反射作为一种元编程方式可以减少重复代码， 但是过量的使用反射会使我们的程序逻辑变得难以理解并且运行缓慢。我们在这一节中会介绍Go语言反射的三大法则，其中包括：\n从interface{}变量可以反射出反射对象； 从反射对象可以获取interface{}变量； 要修改反射对象，其值必须可设置； 第一法则 反射的第一法则是我们能将Go语言的interface{}变量转换成反射对象。很多读者可能会对这以法则产生困惑—为什么是从interface{}变量到反射对象？ 当我们执行reflect.ValueOf(1)时，虽然看起来是获取了基本类型int对应的反射类型，但是由于 reflect.TypeOf 、 reflect.ValueOf 两个方法的入参都是interface{}类型，所以在方法执行的过程中发生了类型转换。\n因为Go语言的函数调用都是值传递的，所以变量会在函数调用时进行类型转换。基本类型int会转换成interface{}类型， 这也就是为什么第一条法则是从接口到反射对象。\n上面提到的reflect.TypeOf 和reflect.ValueOf 函数就能完成这里的转换，如果我们认为Go语言的类型和反射类型处于两个不同的世界，那么这两个函数就是连接这两个世界的桥梁。\n我们可以通过以下例子简单介绍它们的作用， reflect.TypeOf 获取了变量author的类型， reflect.ValueOf 获取了变量的值ormissia。如果我们知道了一个变量的类型和值，那么就意味着我们知道了这个变量的全部信息。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func main() { author := \u0026#34;ormissia\u0026#34; fmt.Println(\u0026#34;TypeOf author:\u0026#34;, reflect.TypeOf(author)) fmt.Println(\u0026#34;ValueOf author:\u0026#34;, reflect.ValueOf(author)) } $ go run main.go TypeOf author: string ValueOf author: ormissia 有了变量的类型之后，我们可以通过Method方法获得类型实现的方法，通过Field获取类型包含的全部字段。对于不同的类型， 我们也可以调用不同的方法获取相关信息：\n结构体：获取字段的数量并通过下标和字段名获取字段StructField； 哈希表：获取哈希表的Key类型； 函数或方法：获取入参和返回值的类型； … 总而言之，使用reflect.TypeOf 和reflect.ValueOf 能够获取Go语言中的变量对应的反射对象。一旦获取了反射对象，我们就能得到跟当前类型相关数据和操作，并可以使用这些运行时获取的结构执行方法。\n第二法则 反射的第二法则是我们可以从反射对象可以获取interface{}变量。既然能够将接口类型的变量转换成反射对象， 那么一定需要其他方法将反射对象还原成接口类型的变量，reflect 中的 reflect.Value.Interface 就能完成这项工作\n不过调用reflect.Value.Interface 方法只能获得interface{}类型的变量，如果想要将其还原成最原始的状态还需要经过如下所示的显式类型转换：\nv := reflect.ValueOf(1) v.Interface().(int) 从反射对象到接口值的过程是从接口值到反射对象的镜面过程，两个过程都需要经历两次转换：\n从接口值到反射对象： 从基本类型到接口类型的类型转换； 从接口类型到反射对象的转换； 从反射对象到接口值： 反射对象转换成接口类型； 通过显式类型转换变成原始类型； 当然不是所有的变量都需要类型转换这一过程。如果变量本身就是interface{}类型的，那么它不需要类型转换，因为类型转换这一过程一般都是隐式的， 所以我不太需要关心它，只有在我们需要将反射对象转换回基本类型时才需要显式的转换操作。\n第三法则 Go语言反射的最后一条法则是与值是否可以被更改有关，如果我们想要更新一个 reflect.Value ， 那么它持有的值一定是可以被更新的，假设我们有以下代码：\nfunc main() { i := 1 v := reflect.ValueOf(i) v.SetInt(10) fmt.Println(i) } $ go run reflect.go panic: reflect: reflect.Value.SetInt using unaddressable value goroutine 1 [running]: reflect.flag.mustBeAssignableSlow(0x82) /usr/local/go/src/reflect/value.go:260 +0x118 reflect.flag.mustBeAssignable(...) /usr/local/go/src/reflect/value.go:247 reflect.Value.SetInt(0x100196bc0, 0x10021f8e8, 0x82, 0xa) /usr/local/go/src/reflect/value.go:1637 +0x30 main.main() /Users/orimissia/workspace/awesomeProject/goroutine/main.go:13 +0xb8 运行上述代码会导致程序崩溃并报出“reflect:reflect.flag.mustBeAssignableusingunaddressablevalue”错误， 仔细思考一下就能够发现出错的原因：由于Go语言的函数调用都是传值的，所以我们得到的反射对象跟最开始的变量没有任何关系， 那么直接修改反射对象无法改变原始变量，程序为了防止错误就会崩溃。\n想要修改原变量只能使用如下的方法：\nfunc main() { i := 1 v := reflect.ValueOf(\u0026amp;i) v.Elem().SetInt(10) fmt.Println(i) } $ go run reflect.go 10 调用reflect.ValueOf 获取变量指针； 调用reflect.Value.Elem 获取指针指向的变量； 调用reflect.Value.SetInt 更新变量的值： 由于Go语言的函数调用都是值传递的，所以我们只能只能用迂回的方式改变原变量：先获取指针对应的 reflect.Value ， 再通过reflect.Value.Elem 方法得到可以被设置的变量，我们可以通过下面的代码理解这个过程：\nfunc main() { i := 1 v := \u0026amp;i *v = 10 } 如果不能直接操作i变量修改其持有的值，我们就只能获取i变量所在地址并使用*v修改所在地址中存储的整数。\n类型和值 Go语言的interface{}类型在语言内部是通过reflect.emptyInterface 结体表示的，其中的rtype字段用于表示变量的类型，另一个word字段指向内部封装的数据：\ntype emptyInterface struct { typ *rtype word unsafe.Pointer } 用于获取变量类型的reflect.TypeOf函数将传入的变量隐式转换成 reflect.emptyInterface 类型并获取其中存储的类型信息reflect.rtype：\nfunc TypeOf(i interface{}) Type { eface := *(*emptyInterface)(unsafe.Pointer(\u0026amp;i)) return toType(eface.typ) } func toType(t *rtype) Type { if t == nil { return nil } return t } reflect.rtype是一个实现了reflect.Type接口的结构体，该结构体实现的 reflect.rtype.String 方法可以帮助我们获取当前类型的名称：\nfunc (t *rtype) String() string { s := t.nameOff(t.str).name() if t.tflag\u0026amp;tflagExtraStar != 0 { return s[1:] } return s } reflect.TypeOf 的实现原理其实并不复杂，它只是将一个interface{}变量转换成了内部的 reflect.emptyInterface 表示，然后从中获取相应的类型信息。\n用于获取接口值reflect.Value 的函数reflect.ValueOf 实现也非常简单，在该函数中我们先调用了 reflect.escapes 保证当前值逃逸到堆上，然后通过 reflect.unpackEface 从接口中获取reflect.Value 结构体：\nfunc ValueOf(i interface{}) Value { if i == nil { return Value{} } escapes(i) return unpackEface(i) } func unpackEface(i interface{}) Value { e := (*emptyInterface)(unsafe.Pointer(\u0026amp;i)) t := e.typ if t == nil { return Value{} } f := flag(t.Kind()) if ifaceIndir(t) { f |= flagIndir } return Value{t, e.word, f} } reflect.unpackEface 会将传入的接口转换成 reflect.emptyInterface， 然后将具体类型和指针包装成 reflect.Value 结构体后返回。\nreflect.TypeOf 和reflect.ValueOf 的实现都很简单。我们已经分析了这两个函数的实现，现在需要了解编译器在调用函数之前做了哪些工作：\npackage main import ( \u0026#34;reflect\u0026#34; ) func main() { i := 20 _ = reflect.TypeOf(i) } $ go build -gcflags=\u0026#34;-S -N\u0026#34; main.go ... MOVQ\t$20, \u0026#34;\u0026#34;..autotmp_20+56(SP) // autotmp = 20 LEAQ\ttype.int(SB), AX // AX = type.int(SB) MOVQ\tAX, \u0026#34;\u0026#34;..autotmp_19+280(SP) // autotmp_19+280(SP) = type.int(SB) LEAQ\t\u0026#34;\u0026#34;..autotmp_20+56(SP), CX // CX = 20 MOVQ\tCX, \u0026#34;\u0026#34;..autotmp_19+288(SP) // autotmp_19+288(SP) = 20 ... 从上面这段截取的汇编语言，我们可以发现在函数调用之前已经发生了类型转换，上述指令将int类型的变量转换成了占用16字节 autotmp_19+280(SP) ~ autotmp_19+288(SP)的接口，两个LEAQ指令分别获取了类型的指针type.int(SB)以及变量i所在的地址。\n当我们想要将一个变量转换成反射对象时，Go语言会在编译期间完成类型转换，将变量的类型和值转换成了interface{}并等待运行期间使用 reflect 包获取接口中存储的信息。\n更新变量 当我们想要更新reflect.Value 时，就需要调用 reflect.Value.Set 更新反射对象，该方法会调用 reflect.flag.mustBeAssignable 和reflect.flag.mustBeExported 分别检查当前反射对象是否是可以被设置的以及字段是否是对外公开的：\nfunc (v Value) Set(x Value) { v.mustBeAssignable() x.mustBeExported() var target unsafe.Pointer if v.kind() == Interface { target = v.ptr } x = x.assignTo(\u0026#34;reflect.Set\u0026#34;, v.typ, target) typedmemmove(v.typ, v.ptr, x.ptr) } reflect.Value.Set 会调用reflect.Value.assignTo 并返回一个新的反射对象，这个返回的反射对象指针会直接覆盖原反射变量。\nfunc (v Value) assignTo(context string, dst *rtype, target unsafe.Pointer) Value { ... switch { case directlyAssignable(dst, v.typ): ... return Value{dst, v.ptr, fl} case implements(dst, v.typ): if v.Kind() == Interface \u0026amp;\u0026amp; v.IsNil() { return Value{dst, nil, flag(Interface)} } x := valueInterface(v, false) if dst.NumMethod() == 0 { *(*interface{})(target) = x } else { ifaceE2I(dst, x, target) } return Value{dst, target, flagIndir | flag(Interface)} } panic(context + \u0026#34;: value of type \u0026#34; + v.typ.String() + \u0026#34; is not assignable to type \u0026#34; + dst.String()) } reflect.Value.assignTo 会根据当前和被设置的反射对象类型创建一个新的 reflect.Value 结构体：\n如果两个反射对象的类型是可以被直接替换，就会直接返回目标反射对象； 如果当前反射对象是接口并且目标对象实现了接口，就会把目标对象简单包装成接口值 在变量更新的过程中， reflect.Value.assignTo 返回的reflect.Value 中的指针会覆盖当前反射对象中的指针实现变量的更新。\n实现协议 reflect 包还为我们提供了 reflect.rtype.Implements 方法可以用于判断某些类型是否遵循特定的接口。在Go语言中获取结构体的反射类型 reflect.Type 还是比较容易的，但是想要获得接口类型需要通过以下方式：\nreflect.TypeOf((*\u0026lt;interface\u0026gt;)(nil)).Elem() 我们通过一个例子在介绍如何判断一个类型是否实现了某个接口。假设我们需要判断如下代码中的CustomError是否实现了Go语言标准库中的error接口：\ntype CustomError struct{} func (*CustomError) Error() string { return \u0026#34;\u0026#34; } func main() { typeOfError := reflect.TypeOf((*error)(nil)).Elem() customErrorPtr := reflect.TypeOf(\u0026amp;CustomError{}) customError := reflect.TypeOf(CustomError{}) fmt.Println(customErrorPtr.Implements(typeOfError)) // #=\u0026gt; true fmt.Println(customError.Implements(typeOfError)) // #=\u0026gt; false } 上述代码的运行结果正如我们在接口一节中介绍的：\nCustomError类型并没有实现error接口 *CustomError指针类型实现了error接口 抛开上述的执行结果不谈，我们来分析一下 reflect.rtype.Implements 方法的工作原理：\nfunc (t *rtype) Implements(u Type) bool { if u == nil { panic(\u0026#34;reflect: nil type passed to Type.Implements\u0026#34;) } if u.Kind() != Interface { panic(\u0026#34;reflect: non-interface type passed to Type.Implements\u0026#34;) } return implements(u.(*rtype), t) } reflect.rtype.Implements 会检查传入的类型是不是接口，如果不是接口或者是空值就会直接崩溃并中止当前程序。在参数没有问题的情况下，上述方法会调用私有函数 reflect.implements 判断类型之间是否有实现关系：\nfunc implements(T, V *rtype) bool { t := (*interfaceType)(unsafe.Pointer(T)) if len(t.methods) == 0 { return true } ... v := V.uncommon() i := 0 vmethods := v.methods() for j := 0; j \u0026lt; int(v.mcount); j++ { tm := \u0026amp;t.methods[i] tmName := t.nameOff(tm.name) vm := vmethods[j] vmName := V.nameOff(vm.name) if vmName.name() == tmName.name() \u0026amp;\u0026amp; V.typeOff(vm.mtyp) == t.typeOff(tm.typ) { if i++; i \u0026gt;= len(t.methods) { return true } } } return false } 如果接口中不包含任何方法，就意味着这是一个空的接口，任意类型都自动实现该接口，这时会直接返回true。\n在其他情况下，由于方法都是按照字母序存储的， reflect.implements 会维护两个用于遍历接口和类型方法的索引i和j判断类型是否实现了接口，因为最多只会进行n次比较（类型的方法数量），所以整个过程的时间复杂度是𝑂(𝑛)。\n方法调用 作为一门静态语言，如果我们想要通过reflect 包利用反射在运行期间执行方法不是一件容易的事情，下面的十几行代码就使用反射来执行Add(0,1)函数：\nfunc Add(a, b int) int { return a + b } func main() { v := reflect.ValueOf(Add) if v.Kind() != reflect.Func { return } t := v.Type() argv := make([]reflect.Value, t.NumIn()) for i := range argv { if t.In(i).Kind() != reflect.Int { return } argv[i] = reflect.ValueOf(i) } result := v.Call(argv) if len(result) != 1 || result[0].Kind() != reflect.Int { return } fmt.Println(result[0].Int()) // #=\u0026gt; 1 } 通过reflect.ValueOf 获取函数Add对应的反射对象； 调用reflect.rtype.NumIn 获取函数的入参个数； 多次调用reflect.ValueOf 函数逐一设置argv数组中的各个参数； 调用反射对象Add的reflect.Value.Call 方法并传入参数列表； 获取返回值数组、验证数组的长度以及类型并打印其中的数据； 使用反射来调用方法非常复杂，原本只需要一行代码就能完成的工作，现在需要十几行代码才能完成，但这也是在静态语言中使用动态特性需要付出的成本。\nfunc (v Value) Call(in []Value) []Value { v.mustBe(Func) v.mustBeExported() return v.call(\u0026#34;Call\u0026#34;, in) } reflect.Value.Call 是运行时调用方法的入口，它通过两个MustBe开头的方法确定了当前反射对象的类型是函数以及可见性，随后调用 reflect.Value.call 完成方法调用，这个私有方法的执行过程会分成以下的几个部分：\n检查输入参数以及类型的合法性； 将传入的reflect.Value 参数数组设置到栈上； 通过函数指针和输入参数调用函数； 从栈上获取函数的返回值； 我们将按照上面的顺序分析使用reflect 进行函数调用的几个过程。\n参数检查 参数检查是通过反射调用方法的第一步，在参数检查期间我们会从反射对象中取出当前的函数指针unsafe.Pointer，如果该函数指针是方法， 那么我们会通过reflect.methodReceiver 获取方法的接收者和函数指针。\nfunc (v Value) call(op string, in []Value) []Value { t := (*funcType)(unsafe.Pointer(v.typ)) ... if v.flag\u0026amp;flagMethod != 0 { rcvr = v rcvrtype, t, fn = methodReceiver(op, v, int(v.flag)\u0026gt;\u0026gt;flagMethodShift) } else { ... } n := t.NumIn() if len(in) \u0026lt; n { panic(\u0026#34;reflect: Call with too few input arguments\u0026#34;) } if len(in) \u0026gt; n { panic(\u0026#34;reflect: Call with too many input arguments\u0026#34;) } for i := 0; i \u0026lt; n; i++ { if xt, targ := in[i].Type(), t.In(i); !xt.AssignableTo(targ) { panic(\u0026#34;reflect: \u0026#34; + op + \u0026#34; using \u0026#34; + xt.String() + \u0026#34; as type \u0026#34; + targ.String()) } } 上述方法还会检查传入参数的个数以及参数的类型与函数签名中的类型是否可以匹配，任何参数的不匹配都会导致整个程序的崩溃中止。\n准备参数 当我们已经对当前方法的参数完成验证后，就会进入函数调用的下一个阶段，为函数调用准备参数，在前面函数调用一节中，我们已经介绍过Go语言的函数调用惯例， 函数或者方法在调用时，所有的参数都会被依次放到栈上。\nnout := t.NumOut() frametype, _, retOffset, _, framePool := funcLayout(t, rcvrtype) var args unsafe.Pointer if nout == 0 { args = framePool.Get().(unsafe.Pointer) } else { args = unsafe_New(frametype) } off := uintptr(0) if rcvrtype != nil { storeRcvr(rcvr, args) off = ptrSize } for i, v := range in { targ := t.In(i).(*rtype) a := uintptr(targ.align) off = (off + a - 1) \u0026amp;^ (a - 1) n := targ.size ... addr := add(args, off, \u0026#34;n \u0026gt; 0\u0026#34;) v = v.assignTo(\u0026#34;reflect.Value.Call\u0026#34;, targ, addr) *(*unsafe.Pointer)(addr) = v.ptr off += n } 通过reflect.funcLayout 计算当前函数需要的参数和返回值的栈布局，也就是每一个参数和返回值所占的空间大小； 如果当前函数有返回值，需要为当前函数的参数和返回值分配一片内存空间args； 如果当前函数是方法，需要向将方法的接收接收者者拷贝到args内存中； 将所有函数的参数按照顺序依次拷贝到对应args内存中 使用reflect.funcLayout 返回的参数计算参数在内存中的位置； 将参数拷贝到内存空间中； 准备参数是计算各个参数和返回值占用的内存空间并将所有的参数都拷贝内存空间对应位置的过程，该过程会考虑函数和方法、返回值数量以及参数类型带来的差异。\n调用函数 准备好调用函数需要的全部参数后，就会通过下面的代码执行函数指针了。我们会向该函数传入栈类型、函数指针、参数和返回值的内存空间、 栈的大小以及返回值的偏移量：\ncall(frametype, fn, args, uint32(frametype.size), uint32(retOffset)) 上述函数实际上并不存在，它会在编译期间链接到 reflect.reflectcall 这个用汇编实现的函数上，我们在这里不会分析该函数的具体实现，感兴趣的读者可以自行了解其实现原理。\n处理返回值 当函数调用结束之后，就会开始处理函数的返回值：\n如果函数没有任何返回值，会直接清空args中的全部内容来释放内存空间； 如果当前函数有返回值； 将args中与输入参数有关的内存空间清空； 创建一个nout长度的切片用于保存由反射对象构成的返回值数组； 从函数对象中获取返回值的类型和内存大小，将args内存中的数据转换成 reflect.Value 类型并存储到切片中； var ret []Value if nout == 0 { typedmemclr(frametype, args) framePool.Put(args) } else { typedmemclrpartial(frametype, args, 0, retOffset) ret = make([]Value, nout) off = retOffset for i := 0; i \u0026lt; nout; i++ { tv := t.Out(i) a := uintptr(tv.Align()) off = (off + a - 1) \u0026amp;^ (a - 1) if tv.Size() != 0 { fl := flagIndir | flag(tv.Kind()) ret[i] = Value{tv.common(), add(args, off, \u0026#34;tv.Size() != 0\u0026#34;), fl} } else { ret[i] = Zero(tv) } off += tv.Size() } } return ret } 由reflect.Value 构成的ret数组会被返回到调用方，到这里为止使用反射实现函数调用的过程就结束了。\n小结 Go语言的reflect 包为我们提供了多种能力，包括如何使用反射来动态修改变量、 判断类型是否实现了某些接口以及动态调用方法等功能，通过分析反射包中方法的原理能帮助我们理解之前看起来比较怪异、令人困惑的现象。\n参考 转载自Draveness Go语言设计与实现 4.3反射 ","date":"August 3, 2021","hero":"/posts/knowledge/2001-go/003-reflect/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2001-go/003-reflect/","summary":"#golang #reflect\n反射简介 Golang提供了一种机制，在编译时不知道类型的情况下，可更新变量、运行时查看值、调用方法以及直接对他们的布局进行操作的机制，称为反射。\nreflect 包中的官方注释：Package reflect implements run-time reflection, allowing a program to manipulate objects with arbitrary types. reflect 实现了运行时的反射能力，能够让程序操作不同类型的对象。反射包中有两对非常重要的函数和类型， 两个函数分别是：\nreflect.TypeOf 能获取类型信息 reflect.ValueOf 能获取数据的运行时表示 三大法则 运行时反射是程序在运行期间检查其自身结构的一种方式。反射带来的灵活性是一把双刃剑，反射作为一种元编程方式可以减少重复代码， 但是过量的使用反射会使我们的程序逻辑变得难以理解并且运行缓慢。我们在这一节中会介绍Go语言反射的三大法则，其中包括：\n从interface{}变量可以反射出反射对象； 从反射对象可以获取interface{}变量； 要修改反射对象，其值必须可设置； 第一法则 反射的第一法则是我们能将Go语言的interface{}变量转换成反射对象。很多读者可能会对这以法则产生困惑—为什么是从interface{}变量到反射对象？ 当我们执行reflect.ValueOf(1)时，虽然看起来是获取了基本类型int对应的反射类型，但是由于 reflect.TypeOf 、 reflect.ValueOf 两个方法的入参都是interface{}类型，所以在方法执行的过程中发生了类型转换。\n因为Go语言的函数调用都是值传递的，所以变量会在函数调用时进行类型转换。基本类型int会转换成interface{}类型， 这也就是为什么第一条法则是从接口到反射对象。\n上面提到的reflect.TypeOf 和reflect.ValueOf 函数就能完成这里的转换，如果我们认为Go语言的类型和反射类型处于两个不同的世界，那么这两个函数就是连接这两个世界的桥梁。\n我们可以通过以下例子简单介绍它们的作用， reflect.TypeOf 获取了变量author的类型， reflect.ValueOf 获取了变量的值ormissia。如果我们知道了一个变量的类型和值，那么就意味着我们知道了这个变量的全部信息。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func main() { author := \u0026#34;ormissia\u0026#34; fmt.Println(\u0026#34;TypeOf author:\u0026#34;, reflect.TypeOf(author)) fmt.Println(\u0026#34;ValueOf author:\u0026#34;, reflect.ValueOf(author)) } $ go run main.","tags":null,"title":"Golang反射"},{"categories":null,"contents":" #golang #reflect\nA：\u0026ldquo;请用一句话让别人知道你写过Golang。\u0026rdquo;\nB：\u0026ldquo;if err!= nil \u0026hellip;\u0026rdquo;\n起因 只要是接触过Golang的人，无不为其if err != nil的语法感到惊奇，或是大加赞赏，或是狠狠痛批。作为使用者，不管喜欢也好，反对也罢， 目前还是要接受这种错误处理模式。\n而最令人头痛的就是请求参数中各种值的校验。比如Get请求中接收分页参数时，需要将string格式的参数转换成int类型，再如时间类型的参数 转换， 诸如此类，等等等等。好家伙，一个接口写完if err != nil的判断占了一多半的行数，看着实在不爽。\n下面就是一个典型的例子，而且这个接口参数还不是特别多\nfunc Export(c *gin.Context) { //删除开头 //... var param map[string]string err := c.ShouldBindJSON(\u0026amp;param) if err != nil { ErrRsponse(c,errCode) return } var vId, userId, userName, format string if v, ok := param[\u0026#34;vId\u0026#34;]; ok { vId = v } else { ErrRsponse(c,errCode) return } if len(vId) == 0 { ErrRsponse(c,errCode) return } if v, ok := param[\u0026#34;userId\u0026#34;]; ok { userId = v } else { ErrRsponse(c,errCode) return } if v, ok := param[\u0026#34;userName\u0026#34;]; ok { userName = v } else { ErrRsponse(c,errCode) return } if v, ok := param[\u0026#34;format\u0026#34;]; ok { format = v } else { ErrRsponse(c,errCode) return } if !file.IsOk(format) { ErrRsponse(c,errCode) return } //... //删除结尾 } 机遇 前几天在看GIN-VUE-ADMIN代码的时候，偶然看到一个通过反射去做参数校验的方式。 嘿，学到了！\n改变 定义规则 校验规则使用一个map存储，key为字段名，value为规则列表，并使用一个string类型的切片来存储。\n后续计划加入tag标签定义规则的功能以及增加通过函数参数的方式，实现自定义规则校验\ntype Rules map[string][]string 支持的规则有：\n不为空 等于、不等于 大于、小于 大于等于、小于等于 对于数值类型为比较值大小，对于字符串或者切片等类型为比较长度大小\n比如调用生成小于规则的方法，则会返回一个小于指定值规则的字符串，用于后面校验器使用\n// Lt \u0026lt; func (verifier verifier) Lt(limit string) string { return fmt.Sprintf(\u0026#34;%s%s%s\u0026#34;, lt, verifier.separator, limit) } 规则定义示例：\nUserRequestRules = go_opv.Rules{ \u0026#34;Name\u0026#34;: {myVerifier.NotEmpty(), myVerifier.Lt(\u0026#34;10\u0026#34;)}, \u0026#34;Age\u0026#34;: {myVerifier.Lt(\u0026#34;100\u0026#34;)}, } //map[Age:[lt#100] Name:[notEmpty lt#10]] 规则含义为Age字段长度或值小于100，Name字段不为空且长度或值小于10。\n验证器 先通过反射获取待检验参数的值和类型，判断是否为struct（目前只实现了对struct校验的功能，计划后续加入对map的校验功能）， 获取struct属性数量并遍历所有属性，并遍历每个字段下所有规则，对定义的每一个规则进行校验是否合格。\nfunc (verifier verifier) Verify(st interface{}, rules Rules) (err error) { typ := reflect.TypeOf(st) val := reflect.ValueOf(st) if val.Kind() != reflect.Struct { return errors.New(\u0026#34;expect struct\u0026#34;) } num := val.NumField() //遍历需要验证对象的所有字段 for i := 0; i \u0026lt; num; i++ { tagVal := typ.Field(i) val := val.Field(i) if len(rules[tagVal.Name]) \u0026gt; 0 { for _, v := range rules[tagVal.Name] { switch { case v == \u0026#34;notEmpty\u0026#34;: if isEmpty(val) { return errors.New(tagVal.Name + \u0026#34; value can not be nil\u0026#34;) } case verifier.conditions[strings.Split(v, verifier.separator)[0]]: if !compareVerify(val, v, verifier.separator) { return errors.New(tagVal.Name + \u0026#34; length or value is illegal,\u0026#34; + v) } } } } } return nil } 规则校验有两种，分别是判空 和条件校验。\n判空是通过反射reflect.Value获得字段值，并通过反射value.Kind()获得字段类型。 最终使用switch分别对不同类型 字段进行判断。\nfunc isEmpty(value reflect.Value) bool { switch value.Kind() { case reflect.String: return value.Len() == 0 case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64: return value.Int() == 0 //此处省略其他类型判断 //... } return reflect.DeepEqual(value.Interface(), reflect.Zero(value.Type()).Interface()) } 条件校验则是通过开始时定义的范围条件进行校验，传入反射reflect.Value获得字段值，定义的规则，以及规则中的分隔符。先通过switch判断其类型， 再通过switch判断条件是大于小于或是其他条件，然后进行相应判断。\nfunc compareVerify(value reflect.Value, verifyStr, separator string) bool { switch value.Kind() { case reflect.String, reflect.Slice, reflect.Array: return compare(value.Len(), verifyStr, separator) //此处省略其他类型判断 //... default: return false } } 封装 为了调用方便，做了一层封装，使用函数选项模式对校验器进行封装，使调用更为方便。\nvar defaultVerifierOptions = verifierOptions{ separator: \u0026#34;:\u0026#34;, conditions: map[string]bool{ eq: true, ne: true, gt: true, lt: true, ge: true, le: true, }, } type VerifierOption func(o *verifierOptions) type verifierOptions struct { conditions map[string]bool separator string } // SetSeparator Default separator is \u0026#34;:\u0026#34;. func SetSeparator(seq string) VerifierOption { return func(o *verifierOptions) { o.separator = seq } } func SwitchEq(sw bool) VerifierOption { return func(o *verifierOptions) { o.conditions[eq] = sw } } //... //此处省略其他参数的设置 type Verifier interface { Verify(obj interface{}, rules Rules) (err error) NotEmpty() string Ne(limit string) string Gt(limit string) string Lt(limit string) string Ge(limit string) string Le(limit string) string } type verifier struct { separator string conditions map[string]bool } func NewVerifier(opts ...VerifierOption) Verifier { options := defaultVerifierOptions for _, opt := range opts { opt(\u0026amp;options) } return verifier{ separator: options.separator, conditions: options.conditions, } } //... //此处省略接口的实现 发布 好了，基本功能完成了，如果仅仅是放在每个项目的utils拷来拷去，显然十分的不优雅。\n那么这就需要发布到pkg.go.dev才能通过go get命令正常被其他项目所引用。\n首先是git commit、git push一把梭将项目整到GitHub上。 由于pkg.go.dev的版本管理机制需要给项目打上tag，git tag v0.0.1基础版本，😋先定个0.0.1吧， 然后git push再走一遍。 当然这时候还没完，需要自己go get一下，加上GitHub仓库名执行一下go get github.com/ormissia/go-opv 这样仓库就可以正常被引用了。而且用不了多久，就可以从pkg.go.dev上搜到相应的项目了。 最后贴一下次项目的连接：go-opv 当然，这个过程中也遇到过小坑。项目中go.mod中的模块名需要写GitHub的仓库地址，对应此项目即为module github.com/ormissia/go-opv。 如果项目版本有更新，打了新的tag之后。可以通过go get github.com/ormissia/go-opv@v0.0.3拉取指定版本，目前尚不清楚 pkg.go.dev是否会自动同步GitHub上最新的tag。\n检验 测试用例？\n好吧，// TODO\n老铁看到底了，来个star吧😁\n↓↓↓↓↓↓↓↓↓\nGitHub仓库\n","date":"July 27, 2021","hero":"/posts/knowledge/2001-go/002-param-verify/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2001-go/002-param-verify/","summary":"#golang #reflect\nA：\u0026ldquo;请用一句话让别人知道你写过Golang。\u0026rdquo;\nB：\u0026ldquo;if err!= nil \u0026hellip;\u0026rdquo;\n起因 只要是接触过Golang的人，无不为其if err != nil的语法感到惊奇，或是大加赞赏，或是狠狠痛批。作为使用者，不管喜欢也好，反对也罢， 目前还是要接受这种错误处理模式。\n而最令人头痛的就是请求参数中各种值的校验。比如Get请求中接收分页参数时，需要将string格式的参数转换成int类型，再如时间类型的参数 转换， 诸如此类，等等等等。好家伙，一个接口写完if err != nil的判断占了一多半的行数，看着实在不爽。\n下面就是一个典型的例子，而且这个接口参数还不是特别多\nfunc Export(c *gin.Context) { //删除开头 //... var param map[string]string err := c.ShouldBindJSON(\u0026amp;param) if err != nil { ErrRsponse(c,errCode) return } var vId, userId, userName, format string if v, ok := param[\u0026#34;vId\u0026#34;]; ok { vId = v } else { ErrRsponse(c,errCode) return } if len(vId) == 0 { ErrRsponse(c,errCode) return } if v, ok := param[\u0026#34;userId\u0026#34;]; ok { userId = v } else { ErrRsponse(c,errCode) return } if v, ok := param[\u0026#34;userName\u0026#34;]; ok { userName = v } else { ErrRsponse(c,errCode) return } if v, ok := param[\u0026#34;format\u0026#34;]; ok { format = v } else { ErrRsponse(c,errCode) return } if !","tags":null,"title":"Golang 实体参数校验"},{"categories":null,"contents":" #golang\n作为 Golang 开发者，遇到的许多问题之一就是尝试将函数的参数设置成可选项。这是一个十分常见的场景，您可以使用一些已经设置默认配置和开箱即用的对象，同时您也可以使用一些更为详细的配置。\n问题出发点 对于许多编程语言来说，这很容易。在 C 语言家族中，您可以提供具有同一个函数但是不同参数的多个版本；在 PHP 之类的语言中，您可以为参数提供默认值，并在调用该方法时将其忽略。但是在 Golang 中，上述的做法都不可以使用。那么您如何创建具有一些其他配置的函数，用户可以根据他的需求（但是仅在需要时）指定一些额外的配置。\n有很多的方法可以做到这一点，但是大多数方法都不是尽如人意，要么需要在服务端的代码中进行大量额外的检查和验证，要么通过传入他们不关心的其他参数来为客户端进行额外的工作。\n下面我将会介绍一些不同的选项，然后为其说明为什么每个选项都不理想，接着我们会逐步构建自己的方式来作为最终的干净解决方案：函数选项模式。\n让我们来看一个例子。比方说，这里有一个叫做StuffClient的服务，它能够胜任一些工作，同时还具有两个配置选项（超时和重试）。\ntype StuffClient interface { DoStuff() error } type stuffClient struct { conn Connection timeout int retries int } 这是个私有的结构体，因此我们应该为它提供某种构造函数：\nfunc NewStuffClient(conn Connection, timeout, retries int) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: timeout, retries: retries, } } 嗯，但是现在我们每次调用NewStuffClient函数时都要提供timeout和retries。因为在大多数情况下，我们只想使用默认值，我们无法使用不同参数数量带定义多个版本的NewStuffClient，否则我们会得到一个类似NewStuffClient redeclared in this block编译错误。\n一个可选方案是创建另一个具有不同名称的构造函数，例如：\nfunc NewStuffClient(conn Connection) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: DEFAULT_TIMEOUT, retries: DEFAULT_RETRIES, } } func NewStuffClientWithOptions(conn Connection, timeout, retries int) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: timeout, retries: retries, } } 但是这么做的话有点蹩脚。我们可以做得更好，如果我们传入了一个配置对象呢:\ntype StuffClientOptions struct { Retries int //number of times to retry the request before giving up Timeout int //connection timeout in seconds } func NewStuffClient(conn Connection, options StuffClientOptions) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: options.Timeout, retries: options.Retries, } } 但是，这也不是很好的做法。现在，我们总是需要创建StuffClientOption这个结构体，即使不想在指定任何选项时还要传递它。另外我们也没有自动填充默认值，除非我们在代码中的某处添加了一堆检查，或者也可以传入一个DefaultStuffClientOptions变量（不过这么做也不好，因为在修改某一处地方后可能会导致其他的问题。）\n所以，更好的解决方法是什么呢？解决这个难题最好的解决方法是使用函数选项模式，它利用了Go对闭包更加方便的支持。让我们保留上述定义的StuffClientOptions，不过我们仍需要为其添加一些内容。\ntype StuffClientOption func(*StuffClientOptions) type StuffClientOptions struct { Retries int //number of times to retry the request before giving up Timeout int //connection timeout in seconds } func WithRetries(r int) StuffClientOption { return func(o *StuffClientOptions) { o.Retries = r } } func WithTimeout(t int) StuffClientOption { return func(o *StuffClientOptions) { o.Timeout = t } } 泥土般芬芳, 不是吗？这到底是怎么回事？基本上，我们有一个结构来定义StuffClient的可用选项。另外，现状我们还定义了一个叫做StuffClientOption的东西（次数是单数），它只是接受我们选项的结构体作为参数的函数。我们还定义了另外两个函数WithRetries和WithTimeout，它们返回一个闭包，现在就是见证奇迹的时刻了！\nvar defaultStuffClientOptions = StuffClientOptions{ Retries: 3, Timeout: 2, } func NewStuffClient(conn Connection, opts ...StuffClientOption) StuffClient { options := defaultStuffClientOptions for _, o := range opts { o(\u0026amp;options) } return \u0026amp;stuffClient{ conn: conn, timeout: options.Timeout, retries: options.Retries, } } 现在，我们定义了一个额外和包含默认选项的没有导出的变量，同时我们已经调整了构造函数，用来接收可变参数。然后, 我们遍历StuffClientOption列表(单数)，针对每一个列表，将列表中返回的闭包使用在我们的options变量（需要记住，这些闭包接收一个StuffClientOptions变量，仅需要在选项的值上做出少许修改）。\n现在我们要做的事情就是使用它！\nx := NewStuffClient(Connection{}) fmt.Println(x) // prints \u0026amp;{{} 2 3} x = NewStuffClient( Connection{}, WithRetries(1), ) fmt.Println(x) // prints \u0026amp;{{} 2 1} x = NewStuffClient( Connection{}, WithRetries(1), WithTimeout(1), ) fmt.Println(x) // prints \u0026amp;{{} 1 1} 函数选项模式 这看起来相当不错，已经可以使用了！而且，它的好处是，我们只需要对代码进行很少的修改，就可以随时随地添加新的选项。\n把这些修改放在一起，就是这样：\nvar defaultStuffClientOptions = StuffClientOptions{ Retries: 3, Timeout: 2, } type StuffClientOption func(*StuffClientOptions) type StuffClientOptions struct { Retries int //number of times to retry the request before giving up Timeout int //connection timeout in seconds } func WithRetries(r int) StuffClientOption { return func(o *StuffClientOptions) { o.Retries = r } } func WithTimeout(t int) StuffClientOption { return func(o *StuffClientOptions) { o.Timeout = t } } type StuffClient interface { DoStuff() error } type stuffClient struct { conn Connection timeout int retries int } type Connection struct{} func NewStuffClient(conn Connection, opts ...StuffClientOption) StuffClient { options := defaultStuffClientOptions for _, o := range opts { o(\u0026amp;options) } return \u0026amp;stuffClient{ conn: conn, timeout: options.Timeout, retries: options.Retries, } } func (c stuffClient) DoStuff() error { return nil } 但这也可以通过删除StuffClientOptions结构体进一步简化，并将选项直接应用在我们的StuffClient上。\nvar defaultStuffClient = stuffClient{ retries: 3, timeout: 2, } type StuffClientOption func(*stuffClient) func WithRetries(r int) StuffClientOption { return func(o *stuffClient) { o.retries = r } } func WithTimeout(t int) StuffClientOption { return func(o *stuffClient) { o.timeout = t } } type StuffClient interface { DoStuff() error } type stuffClient struct { conn Connection timeout int retries int } type Connection struct{} func NewStuffClient(conn Connection, opts ...StuffClientOption) StuffClient { client := defaultStuffClient for _, o := range opts { o(\u0026amp;client) } client.conn = conn return client } func (c stuffClient) DoStuff() error { return nil } 在我们的示例中，我们只是将配置直接应用于结构体中，如果中间有一个额外的结构体是没有意义的。但是，请注意，在许多情况下，您可能仍然想使用上一个示例中的config结构。例如，如果您的构造函数正在使用config选项执行某些操作时，但是并没有将它们存储到结构体中，或者被传递到其他地方，配置结构的变体是更通用的实现。\n转载自此处\n","date":"July 22, 2021","hero":"/posts/knowledge/2001-go/001-partten-1/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2001-go/001-partten-1/","summary":"#golang\n作为 Golang 开发者，遇到的许多问题之一就是尝试将函数的参数设置成可选项。这是一个十分常见的场景，您可以使用一些已经设置默认配置和开箱即用的对象，同时您也可以使用一些更为详细的配置。\n问题出发点 对于许多编程语言来说，这很容易。在 C 语言家族中，您可以提供具有同一个函数但是不同参数的多个版本；在 PHP 之类的语言中，您可以为参数提供默认值，并在调用该方法时将其忽略。但是在 Golang 中，上述的做法都不可以使用。那么您如何创建具有一些其他配置的函数，用户可以根据他的需求（但是仅在需要时）指定一些额外的配置。\n有很多的方法可以做到这一点，但是大多数方法都不是尽如人意，要么需要在服务端的代码中进行大量额外的检查和验证，要么通过传入他们不关心的其他参数来为客户端进行额外的工作。\n下面我将会介绍一些不同的选项，然后为其说明为什么每个选项都不理想，接着我们会逐步构建自己的方式来作为最终的干净解决方案：函数选项模式。\n让我们来看一个例子。比方说，这里有一个叫做StuffClient的服务，它能够胜任一些工作，同时还具有两个配置选项（超时和重试）。\ntype StuffClient interface { DoStuff() error } type stuffClient struct { conn Connection timeout int retries int } 这是个私有的结构体，因此我们应该为它提供某种构造函数：\nfunc NewStuffClient(conn Connection, timeout, retries int) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: timeout, retries: retries, } } 嗯，但是现在我们每次调用NewStuffClient函数时都要提供timeout和retries。因为在大多数情况下，我们只想使用默认值，我们无法使用不同参数数量带定义多个版本的NewStuffClient，否则我们会得到一个类似NewStuffClient redeclared in this block编译错误。\n一个可选方案是创建另一个具有不同名称的构造函数，例如：\nfunc NewStuffClient(conn Connection) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: DEFAULT_TIMEOUT, retries: DEFAULT_RETRIES, } } func NewStuffClientWithOptions(conn Connection, timeout, retries int) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: timeout, retries: retries, } } 但是这么做的话有点蹩脚。我们可以做得更好，如果我们传入了一个配置对象呢:","tags":null,"title":"Go 惯用模式：函数选项模式"},{"categories":null,"contents":" 博客后端使用Golang重构之后使用GitHub-DockerHub-Jenkins自动打包部署流程\n虽然说Golang打包生成的是二进制可执行文件，不需要像JAVA一样部署环境变量，但依然也是需要打包的流程。由于考虑到在不(hen)久(yuan)的将来可能做成简单的微服务程序，又要使用Docker部署，所以在这就直接使用Docker镜像的方式来部署运行。\n本地代码→GitHub 这一步是通过git commit-git push或是直接使用IDE将代码托管到GitHub上。 在这一步的同时需要编写Dockerfile文件，用来指定Docker镜像打包时的各种参数\n# Go程序编译之后会得到一个可执行的二进制文件，其实在最终的镜像中是不需要go编译器的，也就是说我们只需要一个运行最终二进制文件的容器即可。 # 作为别名为\u0026#34;builder\u0026#34;的编译镜像，下面会用到 FROM golang AS builder # 为镜像设置必要的环境变量 ENV GO111MODULE=on \\ CGO_ENABLED=0 \\ GOOS=linux \\ GOARCH=amd64 \\ GOPROXY=https://goproxy.cn # 设置工作目录：/build WORKDIR /build # 复制项目中的 go.mod 和 go.sum文件并下载依赖信息 COPY go.mod . COPY go.sum . RUN go mod download # 将代码复制到容器中 COPY 2021-03-04T18:02:29 . # 将代码编译成二进制可执行文件app RUN go build -o go-blog-app . ################### # 接下来创建一个小镜像 ################### FROM scratch # 设置程序运行时必要的环境变量，包括监听端口、数据库配置等等 ENV SERVER_PORT=8085 \\ DATASOURCE_DRIVERNAME=mysql \\ DATASOURCE_HOST=192.168.13.110 \\ DATASOURCE_PORT=3306 \\ DATASOURCE_DATABASE=blog \\ DATASOURCE_USERNAME=root \\ DATASOURCE_PASSWORD=5KvA82*Ziq \\ DATASOURCE_CHARSET=utf8mb4 # 从builder镜像中把/dist/app 拷贝到当前目录 COPY --from=builder /build/go-blog-app / # 声明服务端口 EXPOSE 8085 # 启动容器时运行的命令 ENTRYPOINT [\u0026#34;/go-blog-app\u0026#34;] GitHub→Docker Hub 这一步是将GitHub上的代码打包成Docker镜像并将镜像托管到Docker Hub上，我在这里使用的是使用Docker Hub来自动打包Docker镜像。也有另一种方式是GitHub通过设置好的Webhooks来通知Jenkins等CI/CD工具来拉取代码在自己的服务器上打包Docker镜像再上传到Docker Hub或是其他Docker镜像管理工具上，由于自己的这个项目代码更新比较慢，可以容忍提交代码之后有较长的时间来更新到线上环境中，所以就采用了Docker官方的打包功能。\n首先要有一个Docker Hub的账号 将GitHub账号关联到Docker Hub账号上 创建Docker仓库并且与GitHub仓库绑定 打开Docker Hub的仓库创建页面 添加仓库名称 选择GitHub作为代码仓库 选择要打包Docker镜像的GitHub仓库 添加Docker镜像打包规则 可以选择按git push到指定分支或者是git push一个git tag来触发build动作 可以指定Docker镜像的Tag 可以指定用于打包Docker镜像的Dockerfile文件 可以开关Docker镜像打包的缓存 创建好Docker仓库之后再去GitHub仓库的setting页面中就会发现多了一个Webhook的设置 每当GitHub仓库里触发了指定条件之后就会通过这个Webhook通知到Docker Hub触发对应的镜像打包动作，当然打包动作也可以手动触发 Docker Hub→服务器生产环境 这一步是将Docker Hub上已经打包好的Docker镜像部署到生产服务器上。\n在Docker Hub仓库中添加Webhook，首先需要有自己的CI/CD服务，我这里用的时搭在自己服务器上的Jenkins(搭建流程)。当然理论上应该也可以使用GitHub上一些CI/CD应用，我没有深入了解就不赘述了。 未完待续。。。 由于时间比较紧，Docker Hub→服务器生产环境这一步还没有实际操作，目前还是docker pull→docker run 不过基于已经线上运行很久的前端VUE项目的自动部署流程，理论上这一步应该是可行的 ","date":"March 3, 2021","hero":"/posts/deployment/3001-blog-cicd/head.svg","permalink":"https://ormissia.github.io/posts/deployment/3001-blog-cicd/","summary":"博客后端使用Golang重构之后使用GitHub-DockerHub-Jenkins自动打包部署流程\n虽然说Golang打包生成的是二进制可执行文件，不需要像JAVA一样部署环境变量，但依然也是需要打包的流程。由于考虑到在不(hen)久(yuan)的将来可能做成简单的微服务程序，又要使用Docker部署，所以在这就直接使用Docker镜像的方式来部署运行。\n本地代码→GitHub 这一步是通过git commit-git push或是直接使用IDE将代码托管到GitHub上。 在这一步的同时需要编写Dockerfile文件，用来指定Docker镜像打包时的各种参数\n# Go程序编译之后会得到一个可执行的二进制文件，其实在最终的镜像中是不需要go编译器的，也就是说我们只需要一个运行最终二进制文件的容器即可。 # 作为别名为\u0026#34;builder\u0026#34;的编译镜像，下面会用到 FROM golang AS builder # 为镜像设置必要的环境变量 ENV GO111MODULE=on \\ CGO_ENABLED=0 \\ GOOS=linux \\ GOARCH=amd64 \\ GOPROXY=https://goproxy.cn # 设置工作目录：/build WORKDIR /build # 复制项目中的 go.mod 和 go.sum文件并下载依赖信息 COPY go.mod . COPY go.sum . RUN go mod download # 将代码复制到容器中 COPY 2021-03-04T18:02:29 . # 将代码编译成二进制可执行文件app RUN go build -o go-blog-app . ################### # 接下来创建一个小镜像 ################### FROM scratch # 设置程序运行时必要的环境变量，包括监听端口、数据库配置等等 ENV SERVER_PORT=8085 \\ DATASOURCE_DRIVERNAME=mysql \\ DATASOURCE_HOST=192.","tags":null,"title":"我的博客后端Docker镜像打包自动部署流程"},{"categories":null,"contents":"notes 我的笔记本\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/readme/","summary":"notes 我的笔记本","tags":null,"title":""},{"categories":null,"contents":"client-go #k8s #kubernetes #clientgo #apiserver #go #golang\n基础使用 源码仓库 依赖引入 go get k8s.io/client-go@latest go get k8s.io/client-go@v0.20.4 client-go 客户端 架构 图片来源\n客户端组件 Reflector：反射器，定义在 type Reflector inside package cache 中，监视 Kubernetes API 的指定资源类型（种类）。完成此操作的函数是 ListAndWatch。监视可以用于内置资源，也可以用于自定义资源。当 Reflector 通过 watch API 接收到关于新资源实例存在的通知时，它使用相应的 listing API 获取新创建的对象并将其放入 watchHandler 函数内的 Delta Fifo 队列中。 Informer：在 base controller inside package cache 中定义的 Informer 从 Delta Fifo 队列中弹出对象。完成此操作的函数是 processLoop。这个基本控制器的工作是保存对象供以后检索，并调用我们的控制器将对象传递给它。 Indexer：索引器提供对象的索引功能。在 type Indexer inside package cache 中定义。一个典型的索引用例是基于对象标签创建索引。Indexer 可以维护基于多个索引函数的索引。索引器使用线程安全的数据存储来存储对象及其键。type Store inside package cache 中定义了一个名为 MetaNamespaceKeyFunc 的默认函数，它生成 \u0026lt;namespace\u0026gt;/\u0026lt;name\u0026gt; 的键作为该对象的组合。 自定义控制器组件 Informer reference：这是对知道如何使用自定义资源对象的 Informer 实例的引用。自定义控制器代码需要创建适当的 Informer。 Indexer reference：这是对知道如何使用自定义资源对象的 Indexer 实例的引用。自定义控制器代码需要创建它。将使用此引用来检索对象以供以后处理。 client-go 中的 base controller 提供了 NewIndexerInformer 函数来创建 Informer 和 Indexer。在代码中，可以直接调用此函数或使用工厂方法来创建Informer。\nResource Event Handlers：这些是回调函数，当 Informer 想要将对象传递给控制器时将调用这些回调函数。编写这些函数的典型模式是获取分派对象的键并将该键放入工作队列中以供进一步处理。 Work queue:：这是在控制器代码中创建的队列，用于将对象的传递与其处理分离。编写资源事件处理程序函数以提取已交付对象的键并将其添加到工作队列中。 Process Item：这是在代码中创建的函数，用于处理工作队列中的项目。可以有一个或多个其他函数进行实际处理。这些函数通常会使用 Indexer reference 或 Listing wrapper 来检索与键对应的对象。 组件 client-go 共提供了 4 种与 Kubernetes APIServer 交互的客户端。分别是 RESTClient、DiscoveryClient、ClientSet、DynamicClient。\nRESTClient：最基础的客户端，主要是对 HTTP 请求进行了封装，支持 Json 和 Protobuf 格式的数据。 DiscoveryClient：发现客户端，负责发现 APIServer 支持的资源组、资源版本和资源信息的。 ClientSet：负责操作 Kubernetes 内置的资源对象，例如：Pod、Service等。 DynamicClient：动态客户端，可以对任意的 Kubernetes 资源对象进行通用操作，包括 CRD。 graph TD A[DiscoveryClient] B[ClientSet] C[DynamicClient] D[RESTClient] E[net/http] F[Kubernetes APIServer] A --\u0026gt; D B --\u0026gt; D C --\u0026gt; D D --\u0026gt; E E --\u0026gt; F ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E4%B8%AD%E9%97%B4%E4%BB%B6/kubernetes/client-go/","summary":"client-go #k8s #kubernetes #clientgo #apiserver #go #golang\n基础使用 源码仓库 依赖引入 go get k8s.io/client-go@latest go get k8s.io/client-go@v0.20.4 client-go 客户端 架构 图片来源\n客户端组件 Reflector：反射器，定义在 type Reflector inside package cache 中，监视 Kubernetes API 的指定资源类型（种类）。完成此操作的函数是 ListAndWatch。监视可以用于内置资源，也可以用于自定义资源。当 Reflector 通过 watch API 接收到关于新资源实例存在的通知时，它使用相应的 listing API 获取新创建的对象并将其放入 watchHandler 函数内的 Delta Fifo 队列中。 Informer：在 base controller inside package cache 中定义的 Informer 从 Delta Fifo 队列中弹出对象。完成此操作的函数是 processLoop。这个基本控制器的工作是保存对象供以后检索，并调用我们的控制器将对象传递给它。 Indexer：索引器提供对象的索引功能。在 type Indexer inside package cache 中定义。一个典型的索引用例是基于对象标签创建索引。Indexer 可以维护基于多个索引函数的索引。索引器使用线程安全的数据存储来存储对象及其键。type Store inside package cache 中定义了一个名为 MetaNamespaceKeyFunc 的默认函数，它生成 \u0026lt;namespace\u0026gt;/\u0026lt;name\u0026gt; 的键作为该对象的组合。 自定义控制器组件 Informer reference：这是对知道如何使用自定义资源对象的 Informer 实例的引用。自定义控制器代码需要创建适当的 Informer。 Indexer reference：这是对知道如何使用自定义资源对象的 Indexer 实例的引用。自定义控制器代码需要创建它。将使用此引用来检索对象以供以后处理。 client-go 中的 base controller 提供了 NewIndexerInformer 函数来创建 Informer 和 Indexer。在代码中，可以直接调用此函数或使用工厂方法来创建Informer。","tags":null,"title":""},{"categories":null,"contents":"Kubernetes 组件 #k8s #kubernetes #容器 #云 #go #golang\n控制平面组件（Control Plane Components） 控制平面组件会为集群做出全局决策，比如资源的调度。 以及检测和响应集群事件，例如当不满足部署的 replicas 字段时， 要启动新的 pod）。\n控制平面组件可以在集群中的任何节点上运行。 然而，为了简单起见，设置脚本通常会在同一个计算机上启动所有控制平面组件， 并且不会在此计算机上运行用户容器。 请参阅使用 kubeadm 构建高可用性集群 中关于跨多机器控制平面设置的示例。\nkube-apiserver API 服务器是 Kubernetes 控制平面的组件， 该组件负责公开了 Kubernetes API，负责处理接受请求的工作。 API 服务器是 Kubernetes 控制平面的前端。\nKubernetes API 服务器的主要实现是 kube-apiserver。 kube-apiserver 设计上考虑了水平扩缩，也就是说，它可通过部署多个实例来进行扩缩。 你可以运行 kube-apiserver 的多个实例，并在这些实例之间平衡流量。\netcd 一致且高可用的键值存储，用作 Kubernetes 所有集群数据的后台数据库。\n如果你的 Kubernetes 集群使用 etcd 作为其后台数据库， 请确保你针对这些数据有一份 备份计划。\n你可以在官方文档中找到有关 etcd 的深入知识。\nkube-scheduler kube-scheduler 是控制平面的组件， 负责监视新创建的、未指定运行节点（node）的 Pods， 并选择节点来让 Pod 在上面运行。\n调度决策考虑的因素包括单个 Pod 及 Pods 集合的资源需求、软硬件及策略约束、 亲和性及反亲和性规范、数据位置、工作负载间的干扰及最后时限。\nkube-controller-manager kube-controller-manager 是控制平面的组件， 负责运行控制器进程。\n从逻辑上讲， 每个控制器都是一个单独的进程， 但是为了降低复杂性，它们都被编译到同一个可执行文件，并在同一个进程中运行。\n这些控制器包括：\n节点控制器（Node Controller）：负责在节点出现故障时进行通知和响应 任务控制器（Job Controller）：监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成 端点分片控制器（EndpointSlice controller）：填充端点分片（EndpointSlice）对象（以提供 Service 和 Pod 之间的链接）。 服务账号控制器（ServiceAccount controller）：为新的命名空间创建默认的服务账号（ServiceAccount）。 cloud-controller-manager 一个 Kubernetes 控制平面组件， 嵌入了特定于云平台的控制逻辑。 云控制器管理器（Cloud Controller Manager）允许你将你的集群连接到云提供商的 API 之上， 并将与该云平台交互的组件同与你的集群交互的组件分离开来。\ncloud-controller-manager 仅运行特定于云平台的控制器。 因此如果你在自己的环境中运行 Kubernetes，或者在本地计算机中运行学习环境， 所部署的集群不需要有云控制器管理器。\n与 kube-controller-manager 类似，cloud-controller-manager 将若干逻辑上独立的控制回路组合到同一个可执行文件中， 供你以同一进程的方式运行。 你可以对其执行水平扩容（运行不止一个副本）以提升性能或者增强容错能力。\n下面的控制器都包含对云平台驱动的依赖：\n节点控制器（Node Controller）：用于在节点终止响应后检查云提供商以确定节点是否已被删除 路由控制器（Route Controller）：用于在底层云基础架构中设置路由 服务控制器（Service Controller）：用于创建、更新和删除云提供商负载均衡器 Node 组件 节点组件会在每个节点上运行，负责维护运行的 Pod 并提供 Kubernetes 运行环境。\nkubelet kubelet 会在集群中每个节点（node）上运行。 它保证容器（containers）都运行在 Pod 中。\nkubelet 接收一组通过各类机制提供给它的 PodSpecs， 确保这些 PodSpecs 中描述的容器处于运行状态且健康。 kubelet 不会管理不是由 Kubernetes 创建的容器。\nkube-proxy kube-proxy 是集群中每个节点（node）上所运行的网络代理， 实现 Kubernetes 服务（Service） 概念的一部分。\nkube-proxy 维护节点上的一些网络规则， 这些网络规则会允许从集群内部或外部的网络会话与 Pod 进行网络通信。\n如果操作系统提供了可用的数据包过滤层，则 kube-proxy 会通过它来实现网络规则。 否则，kube-proxy 仅做流量转发。\n容器运行时（Container Runtime） 容器运行环境是负责运行容器的软件。\nKubernetes 支持许多容器运行环境，例如 containerd、 CRI-O 以及 Kubernetes CRI (容器运行环境接口) 的其他任何实现。\n插件（Addons） 插件使用 Kubernetes 资源（DaemonSet、 Deployment 等）实现集群功能。 因为这些插件提供集群级别的功能，插件中命名空间域的资源属于 kube-system 命名空间。\n下面描述众多插件中的几种。有关可用插件的完整列表，请参见 插件（Addons）。\nDNS 尽管其他插件都并非严格意义上的必需组件，但几乎所有 Kubernetes 集群都应该有集群 DNS， 因为很多示例都需要 DNS 服务。\n集群 DNS 是一个 DNS 服务器，和环境中的其他 DNS 服务器一起工作，它为 Kubernetes 服务提供 DNS 记录。\nKubernetes 启动的容器自动将此 DNS 服务器包含在其 DNS 搜索列表中。\nWeb 界面（仪表盘） Dashboard 是 Kubernetes 集群的通用的、基于 Web 的用户界面。 它使用户可以管理集群中运行的应用程序以及集群本身， 并进行故障排除。\n容器资源监控 容器资源监控 将关于容器的一些常见的时间序列度量值保存到一个集中的数据库中， 并提供浏览这些数据的界面。\n集群层面日志 集群层面日志机制负责将容器的日志数据保存到一个集中的日志存储中， 这种集中日志存储提供搜索和浏览接口。\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E4%B8%AD%E9%97%B4%E4%BB%B6/kubernetes/kubernetes-%E7%BB%84%E4%BB%B6/","summary":"Kubernetes 组件 #k8s #kubernetes #容器 #云 #go #golang\n控制平面组件（Control Plane Components） 控制平面组件会为集群做出全局决策，比如资源的调度。 以及检测和响应集群事件，例如当不满足部署的 replicas 字段时， 要启动新的 pod）。\n控制平面组件可以在集群中的任何节点上运行。 然而，为了简单起见，设置脚本通常会在同一个计算机上启动所有控制平面组件， 并且不会在此计算机上运行用户容器。 请参阅使用 kubeadm 构建高可用性集群 中关于跨多机器控制平面设置的示例。\nkube-apiserver API 服务器是 Kubernetes 控制平面的组件， 该组件负责公开了 Kubernetes API，负责处理接受请求的工作。 API 服务器是 Kubernetes 控制平面的前端。\nKubernetes API 服务器的主要实现是 kube-apiserver。 kube-apiserver 设计上考虑了水平扩缩，也就是说，它可通过部署多个实例来进行扩缩。 你可以运行 kube-apiserver 的多个实例，并在这些实例之间平衡流量。\netcd 一致且高可用的键值存储，用作 Kubernetes 所有集群数据的后台数据库。\n如果你的 Kubernetes 集群使用 etcd 作为其后台数据库， 请确保你针对这些数据有一份 备份计划。\n你可以在官方文档中找到有关 etcd 的深入知识。\nkube-scheduler kube-scheduler 是控制平面的组件， 负责监视新创建的、未指定运行节点（node）的 Pods， 并选择节点来让 Pod 在上面运行。\n调度决策考虑的因素包括单个 Pod 及 Pods 集合的资源需求、软硬件及策略约束、 亲和性及反亲和性规范、数据位置、工作负载间的干扰及最后时限。","tags":null,"title":""},{"categories":null,"contents":"MySQL #mysql #数据库 #db #b加树\n基础 #事务 只有 InnoDB 引擎才支持事务\nMySQL 默认的事务隔离级别是可重复读（REPEATABLE READ）\n#ACID 特性 原子性 (Atomicity)： 一致性 (Consistency)： 隔离性 (Isolation)： 持久性 (Durability)： 并发问题 脏读：当一个事务读取到另外一个事务修改但未提交的数据时，就可能发生脏读 不可重复读：“不可重复读”现象发生在当执行 SELECT 操作时没有获得读锁或者 SELECT 操作执行完后马上释放了读锁；另外一个事务对数据进行了更新， 读到了不同的结果 幻读：是\u0026rsquo;\u0026lsquo;不可重复读\u0026rsquo;\u0026lsquo;的一种特殊场景：当事务1两次执行\u0026rsquo;\u0026lsquo;SELECT \u0026hellip; WHERE\u0026rsquo;\u0026lsquo;检索一定范围内数据的操作中间，事务2在这个表中创建了 (如 INSERT 或 DELETE)了一行新数据，这条新数据正好满足事务1的“WHERE”子句。事务1执行了两遍同样的查询语句，第二遍比第一遍多出了一条数据，就是幻读 三者区别： 脏读：指读到了其他事务未提交的数据 不可重复读：读到了其他事务已提交的数据 (update)\n不可重复读与幻读都是读到其他事务已提交的数据, 但是它们针对点不同 不可重复读：update 幻读：delete, insert\n乐观锁与悲观锁 #悲观锁 ：在整个数据处理过程中，将数据处于锁定状态。读取数据时给加锁，其它事务无法修改这些数据。修改删除数据时也要加锁，其它事务无法读取这些数据 #乐观锁 ：相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。乐观锁，大多是基于数据版本（ Version ）记录机制实现。在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据 #隔离级别 事务隔离级别 脏读 不可重复读 幻读 读未提交 ✅ ✅ ✅ 读已提交 ❎ ✅ ✅ 可重复读 ❎ ❎ ✅ 串行化 ❎ ❎ ❎ 读未提交：该隔离级别因为可以读取到其他事务中未提交的数据，而未提交的数据可能会发生回滚，因此我们把该级别读取到的数据称之为脏数据，把这个问题称之为脏读。 读已提交：该隔离级别的事务能读取到已经提交事务的数据，因此它不会有脏读问题。但由于在事务的执行中可以读取到其他事务提交的结果，所以在不同时间的相同 SQL 查询中，可能会得到不同的结果，这种现象叫做不可重复读。 可重复读：可重复读，是 MySQL 的默认事务隔离级别，它能确保同一事务多次查询的结果一致。但也会有新的问题，比如此级别的事务正在执行时，另一个事务成功的插入了某条数据，但因为它每次查询的结果都是一样的，所以会导致查询不到这条数据，自己重复插入时又失败（因为唯一约束的原因）。明明在事务中查询不到这条信息，但自己就是插入不进去，这就叫幻读 （Phantom Read）。 序列化：序列化，事务最高隔离级别，它会强制事务排序，使之不会发生冲突，从而解决了脏读、不可重复读和幻读问题，但执行效率低。 #MVCC (多版本并发控制) 在 MySQL 中可重复读隔离级别就是通过 MVCC 来实现的乐观锁解决不可重复读问题。\n调优 建表优化 字段长度越小越好 时间选择时间类型 时间戳 datetime timestamp date IP 选择整型 select inet_aton('192.168.13.1'); select inet_ntoa(3232238849); 尽量避免使用 null：会使索引等变复杂 主键选择 代理主键（推荐） 自然主键 字符集选择 一定要选择 utf8mb4\n查询优化 show profile performance_chema 数据库引擎 MyISAM InnoDB 适当的数据冗余 拆分 垂直拆分 水平拆分 执行计划 索引优化 索引分类 主键索引 唯一索引 普通索引 全文索引 组合索引 名词 回表 覆盖索引：要查的字段在索引中存在，不需要回表的情况下为覆盖索引 最左匹配 索引下推：在最左匹配失效时使用索引下推 哈希索引 聚簇索引和非聚簇索引 InnoDB 聚集索引的叶子节点存储行记录，因此， InnoDB 必须要有，且只有一个聚集索引：\n如果表定义了主键，则 PK 就是聚集索引 如果表没有定义主键，则第一个非空唯一索引（not NULL unique）列是聚集索引； 否则，InnoDB 会创建一个隐藏的 row-id 作为聚集索引； 作者：技术灭霸\n链接：https://www.jianshu.com/p/d0d3de6832b9\n来源：简书\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n聚簇索引：不是单独的索引类型，而是一种数据存储方式，指的是数据行跟相邻的键值紧凑的存储在一起 非聚簇索引：数据文件跟索引文件分开存储 其它细节 当使用索引列进行查询的时候尽量不要使用表达式，把计算放到业务层而不是数据库层 select id from tab where id = 4 select id from tab where id + 1 = 5 尽量使用主键查询，而不是其他索引，因为主键查询不会触发回表 使用前缀索引 前缀索引：很长的字符串使用开始的部分字符串创建索引 使用索引扫描来排序 如果明确知道只有一条返回结果，limit 1 能提高效率 加了查到数据就直接返回了 单表索引不宜超过 5 个 但索引字段数不宜超过 5 个 索引监控 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E4%B8%AD%E9%97%B4%E4%BB%B6/mysql/mysql/","summary":"MySQL #mysql #数据库 #db #b加树\n基础 #事务 只有 InnoDB 引擎才支持事务\nMySQL 默认的事务隔离级别是可重复读（REPEATABLE READ）\n#ACID 特性 原子性 (Atomicity)： 一致性 (Consistency)： 隔离性 (Isolation)： 持久性 (Durability)： 并发问题 脏读：当一个事务读取到另外一个事务修改但未提交的数据时，就可能发生脏读 不可重复读：“不可重复读”现象发生在当执行 SELECT 操作时没有获得读锁或者 SELECT 操作执行完后马上释放了读锁；另外一个事务对数据进行了更新， 读到了不同的结果 幻读：是\u0026rsquo;\u0026lsquo;不可重复读\u0026rsquo;\u0026lsquo;的一种特殊场景：当事务1两次执行\u0026rsquo;\u0026lsquo;SELECT \u0026hellip; WHERE\u0026rsquo;\u0026lsquo;检索一定范围内数据的操作中间，事务2在这个表中创建了 (如 INSERT 或 DELETE)了一行新数据，这条新数据正好满足事务1的“WHERE”子句。事务1执行了两遍同样的查询语句，第二遍比第一遍多出了一条数据，就是幻读 三者区别： 脏读：指读到了其他事务未提交的数据 不可重复读：读到了其他事务已提交的数据 (update)\n不可重复读与幻读都是读到其他事务已提交的数据, 但是它们针对点不同 不可重复读：update 幻读：delete, insert\n乐观锁与悲观锁 #悲观锁 ：在整个数据处理过程中，将数据处于锁定状态。读取数据时给加锁，其它事务无法修改这些数据。修改删除数据时也要加锁，其它事务无法读取这些数据 #乐观锁 ：相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。乐观锁，大多是基于数据版本（ Version ）记录机制实现。在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据 #隔离级别 事务隔离级别 脏读 不可重复读 幻读 读未提交 ✅ ✅ ✅ 读已提交 ❎ ✅ ✅ 可重复读 ❎ ❎ ✅ 串行化 ❎ ❎ ❎ 读未提交：该隔离级别因为可以读取到其他事务中未提交的数据，而未提交的数据可能会发生回滚，因此我们把该级别读取到的数据称之为脏数据，把这个问题称之为脏读。 读已提交：该隔离级别的事务能读取到已经提交事务的数据，因此它不会有脏读问题。但由于在事务的执行中可以读取到其他事务提交的结果，所以在不同时间的相同 SQL 查询中，可能会得到不同的结果，这种现象叫做不可重复读。 可重复读：可重复读，是 MySQL 的默认事务隔离级别，它能确保同一事务多次查询的结果一致。但也会有新的问题，比如此级别的事务正在执行时，另一个事务成功的插入了某条数据，但因为它每次查询的结果都是一样的，所以会导致查询不到这条数据，自己重复插入时又失败（因为唯一约束的原因）。明明在事务中查询不到这条信息，但自己就是插入不进去，这就叫幻读 （Phantom Read）。 序列化：序列化，事务最高隔离级别，它会强制事务排序，使之不会发生冲突，从而解决了脏读、不可重复读和幻读问题，但执行效率低。 #MVCC (多版本并发控制) 在 MySQL 中可重复读隔离级别就是通过 MVCC 来实现的乐观锁解决不可重复读问题。","tags":null,"title":""},{"categories":null,"contents":"Redis #redis #中间件 #缓存 #db #内存缓存\n基础数据类型 string list hash set zset bitmap 高级特性 #慢查询 #pipeline 多个命令一次请求减少网络开销\n#事务 #Lua 原子操作\n#Stream 底层原理 持久化 RDB save: 阻塞主线程 bgsave: 不阻塞主线程 AOF 分布式锁 setnx set lock_name 1 ex 10 nx 普通流程 加锁：set lock_name uuid ex 10 nx 业务操作 释放锁：lua 脚本，先 get 判断是否属于自己，再 del 释放锁 红锁流程 客户端获取当前时间戳T1 客户端依次向这 5 台 redis 实例（非集群）发起加锁请求 如果\u0026gt;=3个（大多数）成功，当前时间戳T2 - T1 \u0026lt; 锁的过期时间则加锁成功 加锁成功，操作业务 加锁失败/释放锁，向5台redis发起释放锁请求 集群 一主多从 主从 哨兵 多主多从 虚拟一致性哈希 -\u0026gt; 虚拟槽分区\n常见问题及解决办法 缓存相关 #缓存一致性 成因：由于网络延迟等因素导致缓存中数据与DB中数据不一致 解决办法：#延时双删 #缓存穿透 成因：DB中不存在的数据被频繁请求 解决办法：1. 数据进行插入操作同时添加到 #布隆过滤器 ，2. 缓存空对象 #缓存击穿 成因：同一个缓存中不存在的 key ，在一段时间（一般是极短时间）内第一个请求查询完 DB 后还未写入缓存，导致这段时间内后续请求又直接打到 DB 解决办法：查询前加锁 #缓存雪崩 成因：大量缓存数据同时过期导致请求直接打到DB 解决办法：在一定范围内随机过期时间，比如一小时随机加减十以内分钟数 key相关 #热点key 解决办法： 使用 redis 命令：容易造成 redis 宕机 #TCP抓包 ： 无入侵性，成本高 elk-packetbeat 容易造成机器网络波动，如丢包 维护成本高 二级缓存 主从架构时，在从节点中扫描大 key 子 key #hash算法 #大key 大概标准： string 大于 10kb #数据倾斜 链接 [[计算机/项目/Go缓存垫片]] ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/redis/","summary":"Redis #redis #中间件 #缓存 #db #内存缓存\n基础数据类型 string list hash set zset bitmap 高级特性 #慢查询 #pipeline 多个命令一次请求减少网络开销\n#事务 #Lua 原子操作\n#Stream 底层原理 持久化 RDB save: 阻塞主线程 bgsave: 不阻塞主线程 AOF 分布式锁 setnx set lock_name 1 ex 10 nx 普通流程 加锁：set lock_name uuid ex 10 nx 业务操作 释放锁：lua 脚本，先 get 判断是否属于自己，再 del 释放锁 红锁流程 客户端获取当前时间戳T1 客户端依次向这 5 台 redis 实例（非集群）发起加锁请求 如果\u0026gt;=3个（大多数）成功，当前时间戳T2 - T1 \u0026lt; 锁的过期时间则加锁成功 加锁成功，操作业务 加锁失败/释放锁，向5台redis发起释放锁请求 集群 一主多从 主从 哨兵 多主多从 虚拟一致性哈希 -\u0026gt; 虚拟槽分区","tags":null,"title":""},{"categories":null,"contents":"FreeRTOS #操作系统 #freertos #嵌入式\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/freertos/","summary":"FreeRTOS #操作系统 #freertos #嵌入式","tags":null,"title":""},{"categories":null,"contents":"Linux #操作系统 #linux\n进程管理 查看进程 ps 查看某个时间点的进程信息。\n示例：查看自己的进程\nps -l 示例：查看系统所有进程\nps aux 示例：查看特定的进程\nps aux | grep threadx pstree 查看进程树。\n示例：查看所有进程树\npstree -A top 实时显示进程信息。\n示例：两秒钟刷新一次\ntop -d 2 netstat 查看占用端口的进程\n示例：查看特定端口的进程\nnetstat -anp | grep port 进程状态 状态 说明 R running or runnable (on run queue)正在执行或者可执行，此时进程位于执行队列中。 D uninterruptible sleep (usually I/O)不可中断阻塞，通常为 IO 阻塞。 S interruptible sleep (waiting for an event to complete) 可中断阻塞，此时进程正在等待某个事件完成。 Z zombie (terminated but not reaped by its parent)僵死，进程已经终止但是尚未被其父进程获取信息。 T stopped (either by a job control signal or because it is being traced) 结束，进程既可以被作业控制信号结束，也可能是正在被追踪。 #孤儿进程 一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。\n孤儿进程将被 init 进程（进程号为 1）所收养，并由 init 进程对它们完成状态收集工作。\n由于孤儿进程会被 init 进程收养，所以孤儿进程不会对系统造成危害。\n#僵尸进程 一个子进程的进程描述符在子进程退出时不会释放，只有当父进程通过 wait() 或 waitpid () 获取了子进程信息后才会释放。如果子进程退出，而父进程并没有调用 wait () 或 waitpid ()，那么子进程的进程描述符仍然保存在系统中，这种进程称之为僵尸进程。\n僵尸进程通过 ps 命令显示出来的状态为 Z（zombie）。\n系统所能使用的进程号是有限的，如果产生大量僵尸进程，将因为没有可用的进程号而导致系统不能产生新的进程。\n要消灭系统中大量的僵尸进程，只需要将其父进程杀死，此时僵尸进程就会变成孤儿进程，从而被 init 进程所收养，这样 init 进程就会释放所有的僵尸进程所占有的资源，从而结束僵尸进程。\n查看连接 netstat -natp ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/","summary":"Linux #操作系统 #linux\n进程管理 查看进程 ps 查看某个时间点的进程信息。\n示例：查看自己的进程\nps -l 示例：查看系统所有进程\nps aux 示例：查看特定的进程\nps aux | grep threadx pstree 查看进程树。\n示例：查看所有进程树\npstree -A top 实时显示进程信息。\n示例：两秒钟刷新一次\ntop -d 2 netstat 查看占用端口的进程\n示例：查看特定端口的进程\nnetstat -anp | grep port 进程状态 状态 说明 R running or runnable (on run queue)正在执行或者可执行，此时进程位于执行队列中。 D uninterruptible sleep (usually I/O)不可中断阻塞，通常为 IO 阻塞。 S interruptible sleep (waiting for an event to complete) 可中断阻塞，此时进程正在等待某个事件完成。 Z zombie (terminated but not reaped by its parent)僵死，进程已经终止但是尚未被其父进程获取信息。 T stopped (either by a job control signal or because it is being traced) 结束，进程既可以被作业控制信号结束，也可能是正在被追踪。 #孤儿进程 一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。","tags":null,"title":""},{"categories":null,"contents":"Ubuntu #linux #ubuntu #ssh\n开启 SSH 服务 检查是否有 ssh\nps -e | grep ssh 更新软件列表和软件\nsudo apt-get update sudo apt-get upgrade 安装 ssh\nsudo apt-get install ssh 启动 ssh\nsudo /etc/int.d/ssh start 再次检查是否有 ssh，当结果里看到 sshd 即为 ssh 服务端已启动\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/","summary":"Ubuntu #linux #ubuntu #ssh\n开启 SSH 服务 检查是否有 ssh\nps -e | grep ssh 更新软件列表和软件\nsudo apt-get update sudo apt-get upgrade 安装 ssh\nsudo apt-get install ssh 启动 ssh\nsudo /etc/int.d/ssh start 再次检查是否有 ssh，当结果里看到 sshd 即为 ssh 服务端已启动","tags":null,"title":""},{"categories":null,"contents":"操作系统零碎知识点 #操作系统\n#进程 、 #线程 、 #协程 的区别 进程：操作系统分配资源的单位，进程包含了一组资源，其中有进程的唯一 ID、虚拟地址空间、打开文件描述符（或句柄表）等，还有至少一个线程，也就是主线程 线程：CPU 调度的基本单位，在多线程模式下，进程打算开的文件描述符表、文件系统信息、虚拟地址空间、和命名空间是被进程内所有线程共享的，但是每个线程拥有自己的内核数据结构、内核栈和用户栈、以及信号处理器 协程： 异同：\n进程拥有自己独立的堆栈，堆栈均不共享 线程拥有独立的栈，共享堆 协程同线程一样共享堆但不共享栈 #CPU密集型 / #IO密集型 CPU 密集型任务一般更看重吞吐量，所以要尽量减少上下文切换，每次直接用完时间片就行了，所以对这种场景协程是非必要的。 IO 密集型任务可能更看重相应延迟，例如常见的 web 服务器 #乐观锁 / #悲观锁 悲观锁：访问资源的时候对资源加锁，未解锁之前，不允许其他访问者访问该资源 乐观锁：认为不会与其他访问冲突，因此默认不加锁，通常是通过对访问资源添加版本或是时间戳来控制数据的正确性 #零拷贝 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9B%B6%E7%A2%8E%E7%9F%A5%E8%AF%86%E7%82%B9/","summary":"操作系统零碎知识点 #操作系统\n#进程 、 #线程 、 #协程 的区别 进程：操作系统分配资源的单位，进程包含了一组资源，其中有进程的唯一 ID、虚拟地址空间、打开文件描述符（或句柄表）等，还有至少一个线程，也就是主线程 线程：CPU 调度的基本单位，在多线程模式下，进程打算开的文件描述符表、文件系统信息、虚拟地址空间、和命名空间是被进程内所有线程共享的，但是每个线程拥有自己的内核数据结构、内核栈和用户栈、以及信号处理器 协程： 异同：\n进程拥有自己独立的堆栈，堆栈均不共享 线程拥有独立的栈，共享堆 协程同线程一样共享堆但不共享栈 #CPU密集型 / #IO密集型 CPU 密集型任务一般更看重吞吐量，所以要尽量减少上下文切换，每次直接用完时间片就行了，所以对这种场景协程是非必要的。 IO 密集型任务可能更看重相应延迟，例如常见的 web 服务器 #乐观锁 / #悲观锁 悲观锁：访问资源的时候对资源加锁，未解锁之前，不允许其他访问者访问该资源 乐观锁：认为不会与其他访问冲突，因此默认不加锁，通常是通过对访问资源添加版本或是时间戳来控制数据的正确性 #零拷贝 ","tags":null,"title":""},{"categories":null,"contents":"动态规划 #算法 #动态规划\n基础思想：使用自然智慧写出递归代码，然后使用递归的依赖关系以及边界条件该出动态规划算法\n模型 自左向右的尝试模型 范围上的尝试模型 多样本位置全对应的尝试模型 寻找业务限制的尝试模型 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%AE%97%E6%B3%95/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/","summary":"动态规划 #算法 #动态规划\n基础思想：使用自然智慧写出递归代码，然后使用递归的依赖关系以及边界条件该出动态规划算法\n模型 自左向右的尝试模型 范围上的尝试模型 多样本位置全对应的尝试模型 寻找业务限制的尝试模型 ","tags":null,"title":""},{"categories":null,"contents":"单调栈结构 #算法 #栈 #单调栈\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%AE%97%E6%B3%95/%E5%8D%95%E8%B0%83%E6%A0%88%E7%BB%93%E6%9E%84/","summary":"单调栈结构 #算法 #栈 #单调栈","tags":null,"title":""},{"categories":null,"contents":"基础算法 #算法\n#排序 #选择排序 #冒泡排序 #插入排序 #归并排序 #快速排序 #堆排序 [[计算机/算法/数据结构#堆]]\n#桶排序 查找 #二分查找 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%AE%97%E6%B3%95/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/","summary":"基础算法 #算法\n#排序 #选择排序 #冒泡排序 #插入排序 #归并排序 #快速排序 #堆排序 [[计算机/算法/数据结构#堆]]\n#桶排序 查找 #二分查找 ","tags":null,"title":""},{"categories":null,"contents":"数据结构 #算法\n#位运算 #位图 #异或 #同或 题目 #链表 #单链表 逆序 实现 #队列 实现栈 #双链表 逆序 实现 #双端队列 题目 多个 #有序链表 合并 先把所有头结点放入小根堆\n#树 #二叉树 遍历 先序遍历 中序遍历 后序遍历 Morris 序遍历 #堆 #大根堆 #小根堆 #最小四叉堆 #搜索二叉树 每一棵子树，左树的值比我小，右树的值比我大（中序遍历升序）\n#平衡二叉树 左树和右树高度相差不超过1\nSB 树 #平衡搜索二叉树 #红黑树 题目 #b加树 [[计算机/中间件/MySQL]]\n图 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%AE%97%E6%B3%95/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","summary":"数据结构 #算法\n#位运算 #位图 #异或 #同或 题目 #链表 #单链表 逆序 实现 #队列 实现栈 #双链表 逆序 实现 #双端队列 题目 多个 #有序链表 合并 先把所有头结点放入小根堆\n#树 #二叉树 遍历 先序遍历 中序遍历 后序遍历 Morris 序遍历 #堆 #大根堆 #小根堆 #最小四叉堆 #搜索二叉树 每一棵子树，左树的值比我小，右树的值比我大（中序遍历升序）\n#平衡二叉树 左树和右树高度相差不超过1\nSB 树 #平衡搜索二叉树 #红黑树 题目 #b加树 [[计算机/中间件/MySQL]]\n图 ","tags":null,"title":""},{"categories":null,"contents":"资源限制技巧 #算法\n布隆过滤器用于集合的建立与查询，可以节省大量空间 一致性哈希解决数据服务器的负载管理问题 利用并查集结构做岛问题的并行计算 哈希函数可以把数据按照种类均匀分流 位图解决某一范围上数字的出现情况，并可以节省大量空间 利用分段统计思想，进一步节省大量空间 利用堆、外排序来做多个处理单元的结果合并 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%AE%97%E6%B3%95/%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6%E6%8A%80%E5%B7%A7/","summary":"资源限制技巧 #算法\n布隆过滤器用于集合的建立与查询，可以节省大量空间 一致性哈希解决数据服务器的负载管理问题 利用并查集结构做岛问题的并行计算 哈希函数可以把数据按照种类均匀分流 位图解决某一范围上数字的出现情况，并可以节省大量空间 利用分段统计思想，进一步节省大量空间 利用堆、外排序来做多个处理单元的结果合并 ","tags":null,"title":""},{"categories":null,"contents":"HTTP #网络 #http\n基础概念 请求和响应报文 客户端发送一个请求报文给服务器，服务器根据请求报文中的信息进行处理，并将处理结果放入响应报文中返回给客户端。\n请求报文结构：\n第一行是包含了请求方法、URL、协议版本； 接下来的多行都是请求首部 Header，每个首部都有一个首部名称，以及对应的值。 一个空行用来分隔首部和内容主体 Body 最后是请求的内容主体 GET http://www.example.com/ HTTP/1.1 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9 Accept-Encoding: gzip, deflate Accept-Language: zh-CN,zh;q=0.9,en;q=0.8 Cache-Control: max-age=0 Host: www.example.com If-Modified-Since: Thu, 17 Oct 2019 07:18:26 GMT If-None-Match: \u0026#34;3147526947+gzip\u0026#34; Proxy-Connection: keep-alive Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 xxx param1=1\u0026amp;param2=2 响应报文结构：\n第一行包含协议版本、状态码以及描述，最常见的是 200 OK 表示请求成功了 接下来多行也是首部内容 一个空行分隔首部和内容主体 最后是响应的内容主体 HTTP/1.1 200 OK Age: 529651 Cache-Control: max-age=604800 Connection: keep-alive Content-Encoding: gzip Content-Length: 648 Content-Type: text/html; charset=UTF-8 Date: Mon, 02 Nov 2020 17:53:39 GMT Etag: \u0026#34;3147526947+ident+gzip\u0026#34; Expires: Mon, 09 Nov 2020 17:53:39 GMT Keep-Alive: timeout=4 Last-Modified: Thu, 17 Oct 2019 07:18:26 GMT Proxy-Connection: keep-alive Server: ECS (sjc/16DF) Vary: Accept-Encoding X-Cache: HIT \u0026lt;!doctype html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Example Domain\u0026lt;/title\u0026gt; // 省略... \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; URL HTTP 使用 URL（ Uniform Resource Locator，统一资源定位符）来定位资源，它是 URI（Uniform Resource Identifier，统一资源标识符）的子集，URL 在 URI 的基础上增加了定位能力。URI 除了包含 URL，还包含 URN（Uniform Resource Name，统一资源名称），它只是用来定义一个资源的名称，并不具备定位该资源的能力。例如 urn:isbn: 0451450523 用来定义一个书籍名称，但是却没有表示怎么找到这本书。\nwikipedia：统一资源标志符 wikipedia: URL rfc2616：3.2.2 http URL What is the difference between a URI, a URL and a URN? HTTP 方法 客户端发送的 请求报文 第一行为请求行，包含了方法字段。\nGET 获取资源\n当前网络请求中，绝大部分使用的是 GET 方法。\nHEAD 获取报文首部\n和 GET 方法类似，但是不返回报文实体主体部分。\n主要用于确认 URL 的有效性以及资源更新的日期时间等。\nPOST 传输实体主体\nPOST 主要用来传输数据，而 GET 主要用来获取资源。\n更多 POST 与 GET 的比较请见第九章。\nPUT 上传文件\n由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法。\nPUT /new.html HTTP/1.1 Host: example.com Content-type: text/html Content-length: 16 \u0026lt;p\u0026gt;New File\u0026lt;/p\u0026gt; PATCH 对资源进行部分修改\nPUT 也可以用于修改资源，但是只能完全替代原始资源，PATCH 允许部分修改。\nPATCH /file.txt HTTP/1.1 Host: www.example.com Content-Type: application/example If-Match: \u0026#34;e0023aa4e\u0026#34; Content-Length: 100 [description of changes] DELETE 删除文件\n与 PUT 功能相反，并且同样不带验证机制。\nDELETE /file.html HTTP/1.1 OPTIONS 查询支持的方法\n查询指定的 URL 能够支持的方法。\n会返回 Allow: GET, POST, HEAD, OPTIONS 这样的内容。\nCONNECT 要求在与代理服务器通信时建立隧道\n使用 SSL（Secure Sockets Layer，安全套接层）和 TLS（Transport Layer Security，传输层安全）协议把通信内容加密后经网络隧道传输。\nCONNECT www.example.com:443 HTTP/1.1 TRACE 追踪路径\n服务器会将通信路径返回给客户端。\n发送请求时，在 Max-Forwards 首部字段中填入数值，每经过一个服务器就会减 1，当数值为 0 时就停止传输。\n通常不会使用 TRACE，并且它容易受到 XST 攻击（Cross-Site Tracing，跨站追踪）。\nrfc2616：9 Method Definitions HTTP 状态码 服务器返回的 响应报文 中第一行为状态行，包含了状态码以及原因短语，用来告知客户端请求的结果。\n状态码 类别 含义 1XX Informational（信息性状态码） 接收的请求正在处理 2XX Success（成功状态码） 请求正常处理完毕 3XX Redirection（重定向状态码） 需要进行附加操作以完成请求 4XX Client Error（客户端错误状态码） 服务器无法处理请求 5XX Server Error（服务器错误状态码） 服务器处理请求出错 1XX 信息 100 Continue ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。 2XX 成功 200 OK\n204 No Content ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。\n206 Partial Content ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。\n3XX 重定向 301 Moved Permanently ：永久性重定向\n302 Found ：临时性重定向\n303 See Other ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。\n注：虽然 HTTP 协议规定 301、302 状态下重定向时不允许把 POST 方法改成 GET 方法，但是大多数浏览器都会在 301、302 和 303 状态下的重定向把 POST 方法改成 GET 方法。\n304 Not Modified ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。\n307 Temporary Redirect ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。\n4XX 客户端错误 400 Bad Request ：请求报文中存在语法错误。\n401 Unauthorized ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。\n403 Forbidden ：请求被拒绝。\n404 Not Found\n5XX 服务器错误 500 Internal Server Error ：服务器正在执行请求时发生错误。\n503 Service Unavailable ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。\nHTTP 首部 有 4 种类型的首部字段：通用首部字段、请求首部字段、响应首部字段和实体首部字段。\n各种首部字段及其含义如下（不需要全记，仅供查阅）：\n通用首部字段 首部字段名 说明 Cache-Control 控制缓存的行为 Connection 控制不再转发给代理的首部字段、管理持久连接 Date 创建报文的日期时间 Pragma 报文指令 Trailer 报文末端的首部一览 Transfer-Encoding 指定报文主体的传输编码方式 Upgrade 升级为其他协议 Via 代理服务器的相关信息 Warning 错误通知 请求首部字段 首部字段名 说明 Accept 用户代理可处理的媒体类型 Accept-Charset 优先的字符集 Accept-Encoding 优先的内容编码 Accept-Language 优先的语言（自然语言） Authorization Web 认证信息 Expect 期待服务器的特定行为 From 用户的电子邮箱地址 Host 请求资源所在服务器 If-Match 比较实体标记（ETag） If-Modified-Since 比较资源的更新时间 If-None-Match 比较实体标记（与 If-Match 相反） If-Range 资源未更新时发送实体 Byte 的范围请求 If-Unmodified-Since 比较资源的更新时间（与 If-Modified-Since 相反） Max-Forwards 最大传输逐跳数 Proxy-Authorization 代理服务器要求客户端的认证信息 Range 实体的字节范围请求 Referer 对请求中 URI 的原始获取方 TE 传输编码的优先级 User-Agent HTTP 客户端程序的信息 响应首部字段 首部字段名 说明 Accept-Ranges 是否接受字节范围请求 Age 推算资源创建经过时间 ETag 资源的匹配信息 Location 令客户端重定向至指定 URI Proxy-Authenticate 代理服务器对客户端的认证信息 Retry-After 对再次发起请求的时机要求 Server HTTP 服务器的安装信息 Vary 代理服务器缓存的管理信息 WWW-Authenticate 服务器对客户端的认证信息 实体首部字段 首部字段名 说明 Allow 资源可支持的 HTTP 方法 Content-Encoding 实体主体适用的编码方式 Content-Language 实体主体的自然语言 Content-Length 实体主体的大小 Content-Location 替代对应资源的 URI Content-MD5 实体主体的报文摘要 Content-Range 实体主体的位置范围 Content-Type 实体主体的媒体类型 Expires 实体主体过期的日期时间 Last-Modified 资源的最后修改日期时间 具体应用 连接管理 #短连接 与 #长连接 当浏览器访问一个包含多张图片的 HTML 页面时，除了请求访问的 HTML 页面资源，还会请求图片资源。如果每进行一次 HTTP 通信就要新建一个 TCP 连接，那么开销会很大。\n长连接只需要建立一次 TCP 连接就能进行多次 HTTP 通信。\n从 HTTP/1.1 开始默认是长连接的，如果要断开连接，需要由客户端或者服务器端提出断开，使用 Connection : close； 在 HTTP/1.1 之前默认是短连接的，如果需要使用长连接，则使用 Connection : Keep-Alive。 #流水线 默认情况下，HTTP 请求是按顺序发出的，下一个请求只有在当前请求收到响应之后才会被发出。由于受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。\n流水线是在同一条长连接上连续发出请求，而不用等待响应返回，这样可以减少延迟。\n#Cookie HTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务。HTTP/1.1 引入 Cookie 来保存状态信息。\nCookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销（尤其是在移动环境下）。\nCookie 曾一度用于客户端数据的存储，因为当时并没有其它合适的存储办法而作为唯一的存储手段，但现在随着现代浏览器开始支持各种各样的存储方式，Cookie 渐渐被淘汰。新的浏览器 API 已经允许开发者直接将数据存储到本地，如使用 Web storage API（本地存储和会话存储）或 IndexedDB。\n用途 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 个性化设置（如用户自定义设置、主题等） 浏览器行为跟踪（如跟踪分析用户行为等） 创建过程 服务器发送的响应报文包含 Set-Cookie 首部字段，客户端得到响应报文后把 Cookie 内容保存到浏览器中。\nHTTP/1.0 200 OK Content-type: text/html Set-Cookie: yummy_cookie=choco Set-Cookie: tasty_cookie=strawberry [page content] 客户端之后对同一个服务器发送请求时，会从浏览器中取出 Cookie 信息并通过 Cookie 请求首部字段发送给服务器。\nGET /sample_page.html HTTP/1.1 Host: www.example.org Cookie: yummy_cookie=choco; tasty_cookie=strawberry 分类 会话期 Cookie：浏览器关闭之后它会被自动删除，也就是说它仅在会话期内有效。 持久性 Cookie：指定过期时间（Expires）或有效期（max-age）之后就成为了持久性的 Cookie。 Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; 作用域 Domain 标识指定了哪些主机可以接受 Cookie。如果不指定，默认为当前文档的主机（不包含子域名）。如果指定了 Domain，则一般包含子域名。例如，如果设置 Domain=mozilla. org，则 Cookie 也包含在子域名中（如 developer. mozilla. org）。\nPath 标识指定了主机下的哪些路径可以接受 Cookie（该 URL 路径必须存在于请求 URL 中）。以字符 %x2F (\u0026quot;/\u0026quot;) 作为路径分隔符，子路径也会被匹配。例如，设置 Path=/docs，则以下地址都会匹配：\n/docs /docs/Web/ /docs/Web/HTTP JavaScript 浏览器通过 document.cookie 属性可创建新的 Cookie，也可通过该属性访问非 HttpOnly 标记的 Cookie。\ndocument.cookie = \u0026#34;yummy_cookie=choco\u0026#34;; document.cookie = \u0026#34;tasty_cookie=strawberry\u0026#34;; console.log(document.cookie); HttpOnly 标记为 HttpOnly 的 Cookie 不能被 JavaScript 脚本调用。跨站脚本攻击 (XSS) 常常使用 JavaScript 的 document.cookie API 窃取用户的 Cookie 信息，因此使用 HttpOnly 标记可以在一定程度上避免 XSS 攻击。\nSet-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly Secure 标记为 Secure 的 Cookie 只能通过被 HTTPS 协议加密过的请求发送给服务端。但即便设置了 Secure 标记，敏感信息也不应该通过 Cookie 传输，因为 Cookie 有其固有的不安全性，Secure 标记也无法提供确实的安全保障。\n#Session 除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。\nSession 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。\n使用 Session 维护用户登录状态的过程如下：\n用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中； 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID； 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中； 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。 应该注意 Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。\n浏览器禁用 Cookie 此时无法使用 Cookie 来保存用户信息，只能使用 Session。除此之外，不能再将 Session ID 存放到 Cookie 中，而是使用 URL 重写技术，将 Session ID 作为 URL 的参数进行传递。\nCookie 与 Session 选择 Cookie 只能存储 ASCII 码字符串，而 Session 则可以存储任何类型的数据，因此在考虑数据复杂性时首选 Session； Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密； 对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有的用户信息都存储到 Session 中。 缓存 优点 缓解服务器压力； 降低客户端获取资源的延迟：缓存通常位于内存中，读取缓存的速度更快。并且缓存服务器在地理位置上也有可能比源服务器来得近，例如浏览器缓存。 实现方法 让代理服务器进行缓存； 让客户端浏览器进行缓存。 Cache-Control HTTP/1.1 通过 Cache-Control 首部字段来控制缓存。\n禁止进行缓存\nno-store 指令规定不能对请求或响应的任何一部分进行缓存。\nCache-Control: no-store 强制确认缓存\nno-cache 指令规定缓存服务器需要先向源服务器验证缓存资源的有效性，只有当缓存资源有效时才能使用该缓存对客户端的请求进行响应。\nCache-Control: no-cache 私有缓存和公共缓存\nprivate 指令规定了将资源作为私有缓存，只能被单独用户使用，一般存储在用户浏览器中。\nCache-Control: private public 指令规定了将资源作为公共缓存，可以被多个用户使用，一般存储在代理服务器中。\nCache-Control: public 缓存过期机制\nmax-age 指令出现在请求报文，并且缓存资源的缓存时间小于该指令指定的时间，那么就能接受该缓存。\nmax-age 指令出现在响应报文，表示缓存资源在缓存服务器中保存的时间。\nCache-Control: max-age=31536000 Expires 首部字段也可以用于告知缓存服务器该资源什么时候会过期。\nExpires: Wed, 04 Jul 2012 08:26:05 GMT 在 HTTP/1.1 中，会优先处理 max-age 指令； 在 HTTP/1.0 中，max-age 指令会被忽略掉。 缓存验证 需要先了解 ETag 首部字段的含义，它是资源的唯一标识。URL 不能唯一表示资源，例如 http://www.google.com/ 有中文和英文两个资源，只有 ETag 才能对这两个资源进行唯一标识。\nETag: \u0026#34;82e22293907ce725faf67773957acd12\u0026#34; 可以将缓存资源的 ETag 值放入 If-None-Match 首部，服务器收到该请求后，判断缓存资源的 ETag 值和资源的最新 ETag 值是否一致，如果一致则表示缓存资源有效，返回 304 Not Modified。\nIf-None-Match: \u0026#34;82e22293907ce725faf67773957acd12\u0026#34; Last-Modified 首部字段也可以用于缓存验证，它包含在源服务器发送的响应报文中，指示源服务器对资源的最后修改时间。但是它是一种弱校验器，因为只能精确到一秒，所以它通常作为 ETag 的备用方案。如果响应首部字段里含有这个信息，客户端可以在后续的请求中带上 If-Modified-Since 来验证缓存。服务器只在所请求的资源在给定的日期时间之后对内容进行过修改的情况下才会将资源返回，状态码为 200 OK。如果请求的资源从那时起未经修改，那么返回一个不带有实体主体的 304 Not Modified 响应报文。\nLast-Modified: Wed, 21 Oct 2015 07:28:00 GMT If-Modified-Since: Wed, 21 Oct 2015 07:28:00 GMT 通信数据转发 代理 代理服务器接受客户端的请求，并且转发给其它服务器。\n使用代理的主要目的是：\n缓存 负载均衡 网络访问控制 访问日志记录 代理服务器分为正向代理和反向代理两种：\n用户察觉得到正向代理的存在 而反向代理一般位于内部网络中，用户察觉不到 正向代理代理的是客户端，反向代理代理的是服务端 网关 与代理服务器不同的是，网关服务器会将 HTTP 转化为其它协议进行通信，从而请求其它非 HTTP 服务器的服务。\n隧道 使用 SSL 等加密手段，在客户端和服务器之间建立一条安全的通信线路。\n#HTTPS GET / POST 比较 作用 GET 用于获取资源，而 POST 用于传输实体主体。\n参数 GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中。不能因为 POST 参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些抓包工具（Fiddler）查看。\n因为 URL 只支持 ASCII 码，因此 GET 的参数中如果存在中文等字符就需要先进行编码。例如 中文 会转换为 %E4%B8%AD%E6%96%87，而空格会转换为 %20。POST 参数支持标准字符集。\nGET /test/demo_form.asp?name1=value1\u0026amp;name2=value2 HTTP/1.1 POST /test/demo_form.asp HTTP/1.1 Host: w3schools.com name1=value1\u0026amp;name2=value2 安全 安全的 HTTP 方法不会改变服务器状态，也就是说它只是可读的。\nGET 方法是安全的，而 POST 却不是，因为 POST 的目的是传送实体主体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。\n安全的方法除了 GET 之外还有：HEAD、OPTIONS。\n不安全的方法除了 POST 之外还有 PUT、DELETE。\n幂等性 幂等的 HTTP 方法，同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。换句话说就是，幂等方法不应该具有副作用（统计用途除外）。\n所有的安全方法也都是幂等的。\n在正确实现的条件下，GET，HEAD，PUT 和 DELETE 等方法都是幂等的，而 POST 方法不是。\nGET /pageX HTTP/1.1 是幂等的，连续调用多次，客户端接收到的结果都是一样的：\nGET /pageX HTTP/1.1 GET /pageX HTTP/1.1 GET /pageX HTTP/1.1 GET /pageX HTTP/1.1 POST /add_row HTTP/1.1 不是幂等的，如果调用多次，就会增加多行记录：\nPOST /add_row HTTP/1.1 -\u0026gt; Adds a 1nd row POST /add_row HTTP/1.1 -\u0026gt; Adds a 2nd row POST /add_row HTTP/1.1 -\u0026gt; Adds a 3rd row DELETE /idX/delete HTTP/1.1 是幂等的，即使不同的请求接收到的状态码不一样：\nDELETE /idX/delete HTTP/1.1 -\u0026gt; Returns 200 if idX exists DELETE /idX/delete HTTP/1.1 -\u0026gt; Returns 404 as it just got deleted DELETE /idX/delete HTTP/1.1 -\u0026gt; Returns 404 可缓存 如果要对响应进行缓存，需要满足以下条件：\n请求报文的 HTTP 方法本身是可缓存的，包括 GET 和 HEAD，但是 PUT 和 DELETE 不可缓存，POST 在多数情况下不可缓存的。 响应报文的状态码是可缓存的，包括：200, 203, 204, 206, 300, 301, 404, 405, 410, 414, and 501。 响应报文的 Cache-Control 首部字段没有指定不进行缓存。 XMLHttpRequest 为了阐述 POST 和 GET 的另一个区别，需要先了解 XMLHttpRequest：\nXMLHttpRequest 是一个 API，它为客户端提供了在客户端和服务器之间传输数据的功能。它提供了一个通过 URL 来获取数据的简单方式，并且不会使整个页面刷新。这使得网页只更新一部分页面而不会打扰到用户。XMLHttpRequest 在 AJAX 中被大量使用。\n在使用 XMLHttpRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data。但并不是所有浏览器会这么做，例如火狐就不会。 而 GET 方法 Header 和 Data 会一起发送。 HTTP 版本变化 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/http/","summary":"HTTP #网络 #http\n基础概念 请求和响应报文 客户端发送一个请求报文给服务器，服务器根据请求报文中的信息进行处理，并将处理结果放入响应报文中返回给客户端。\n请求报文结构：\n第一行是包含了请求方法、URL、协议版本； 接下来的多行都是请求首部 Header，每个首部都有一个首部名称，以及对应的值。 一个空行用来分隔首部和内容主体 Body 最后是请求的内容主体 GET http://www.example.com/ HTTP/1.1 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9 Accept-Encoding: gzip, deflate Accept-Language: zh-CN,zh;q=0.9,en;q=0.8 Cache-Control: max-age=0 Host: www.example.com If-Modified-Since: Thu, 17 Oct 2019 07:18:26 GMT If-None-Match: \u0026#34;3147526947+gzip\u0026#34; Proxy-Connection: keep-alive Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 xxx param1=1\u0026amp;param2=2 响应报文结构：\n第一行包含协议版本、状态码以及描述，最常见的是 200 OK 表示请求成功了 接下来多行也是首部内容 一个空行分隔首部和内容主体 最后是响应的内容主体 HTTP/1.1 200 OK Age: 529651 Cache-Control: max-age=604800 Connection: keep-alive Content-Encoding: gzip Content-Length: 648 Content-Type: text/html; charset=UTF-8 Date: Mon, 02 Nov 2020 17:53:39 GMT Etag: \u0026#34;3147526947+ident+gzip\u0026#34; Expires: Mon, 09 Nov 2020 17:53:39 GMT Keep-Alive: timeout=4 Last-Modified: Thu, 17 Oct 2019 07:18:26 GMT Proxy-Connection: keep-alive Server: ECS (sjc/16DF) Vary: Accept-Encoding X-Cache: HIT \u0026lt;!","tags":null,"title":""},{"categories":null,"contents":"TCP/UDP #网络 #tcp #udp\nTCP ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/tcp%E4%B8%8Eudp/","summary":"TCP/UDP #网络 #tcp #udp\nTCP ","tags":null,"title":""},{"categories":null,"contents":"网络IO演进历程 #epoll #linux #网络 #网络模型\n网络 IO 模型演进 阻塞 IO #BIO (Blocking IO) 非阻塞 IO #NIO (Nonblocking IO) IO 多路复用第一版 #select / #poll / #epoll 异步 IO #AIO (Async IO) BIO 阻塞 IO，顾名思义当用户发生了系统调用后，如果数据未从网卡到达内核态，内核态数据未准备好，此时会一直阻塞。直到数据就绪，然后从内核态拷贝到用户态再返回。\nBIO 缺点，能支持的并发连接数比较少： 一台服务器能分配的线程数是有限的 大量线程频繁切换上下文会影响性能 核心矛盾：一个 client 分配一个线程是因为处理客户端读写是阻塞式的，为避免该阻塞影响接受后续新的 client 的连接，所以将阻塞逻辑交由单独的线程处理。\nNIO 非阻塞 IO：见名知意，就是在第一阶段 (网卡-内核态) 数据未到达时不等待，然后直接返回。因此非阻塞 IO 需要不断的用户发起请求，轮询内核。\n优点：将 socket 设为非阻塞后，在读取时如果数据未就绪就直接返回。可以通过一个线程管理多个 client 连接。 缺点：需要不断轮询内核，数据是否已经就绪，会造成很多无效的，太频繁的系统调用 (system call) 而造成资源浪费。 select/poll/epoll select 和 poll 的区别 select 能处理的最大连接，默认是 1024 个，可以通过修改配置来改变，但终究是有限个；而 poll 理论上可以支持无限个 select 和 poll 在管理海量的连接时，会频繁的从用户态拷贝到内核态，比较消耗资源 epoll 对文件描述符的操作有两种模式： LT（level trigger）和 ET（edge trigger）。\nLT 模式：当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用 epoll_wait 时，会再次响应应用程序并通知此事件。 ET 模式：当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用 epoll_wait 时，不会再次响应应用程序并通知此事件。 简言之：边沿触发仅触发一次，水平触发会一直触发。\nepoll 高效的本质在于：\n减少了用户态和内核态的文件句柄拷贝 减少了对可读可写文件句柄的遍历 mmap 加速了内核与用户空间的信息传递，epoll 是通过内核与用户 mmap 同一块内存，避免了无谓的内存拷贝 IO性能不会随着监听的文件描述的数量增长而下降 使用红黑树存储fd，以及对应的回调函数，其插入，查找，删除的性能不错，相比于hash，不必预先分配很多的空间 - select poll epoll 操作方式 遍历 遍历 回调 底层实现 数组 链表 哈希表 IO 效率 每次调用都进行线性遍历，时间复杂度为 O (n) 每次调用都进行线性遍历，时间复杂度为 O (n) 事件通知方式，每当 fd 就绪，系统注册的回调函数就会被调用，将就绪 fd 放到 rdllist 里面。时间复杂度 O (1) 最大连接数 1024（x86）或 2048（x64） 无上限 无上限 fd 拷贝 每次调用 select，都需要把 fd 集合从用户态拷贝到内核态 每次调用 poll，都需要把 fd 集合从用户态拷贝到内核态 调用 epoll_ctl 时拷贝进内核并保存，之后每次 epoll_wait 不拷贝 AIO 异步 IO ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9Cio%E6%BC%94%E8%BF%9B%E5%8E%86%E7%A8%8B/","summary":"网络IO演进历程 #epoll #linux #网络 #网络模型\n网络 IO 模型演进 阻塞 IO #BIO (Blocking IO) 非阻塞 IO #NIO (Nonblocking IO) IO 多路复用第一版 #select / #poll / #epoll 异步 IO #AIO (Async IO) BIO 阻塞 IO，顾名思义当用户发生了系统调用后，如果数据未从网卡到达内核态，内核态数据未准备好，此时会一直阻塞。直到数据就绪，然后从内核态拷贝到用户态再返回。\nBIO 缺点，能支持的并发连接数比较少： 一台服务器能分配的线程数是有限的 大量线程频繁切换上下文会影响性能 核心矛盾：一个 client 分配一个线程是因为处理客户端读写是阻塞式的，为避免该阻塞影响接受后续新的 client 的连接，所以将阻塞逻辑交由单独的线程处理。\nNIO 非阻塞 IO：见名知意，就是在第一阶段 (网卡-内核态) 数据未到达时不等待，然后直接返回。因此非阻塞 IO 需要不断的用户发起请求，轮询内核。\n优点：将 socket 设为非阻塞后，在读取时如果数据未就绪就直接返回。可以通过一个线程管理多个 client 连接。 缺点：需要不断轮询内核，数据是否已经就绪，会造成很多无效的，太频繁的系统调用 (system call) 而造成资源浪费。 select/poll/epoll select 和 poll 的区别 select 能处理的最大连接，默认是 1024 个，可以通过修改配置来改变，但终究是有限个；而 poll 理论上可以支持无限个 select 和 poll 在管理海量的连接时，会频繁的从用户态拷贝到内核态，比较消耗资源 epoll 对文件描述符的操作有两种模式： LT（level trigger）和 ET（edge trigger）。","tags":null,"title":""},{"categories":null,"contents":"C++ #CPP #编程语言\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AF%AD%E8%A8%80/c++/c++-%E8%AF%AD%E6%B3%95/","summary":"C++ #CPP #编程语言","tags":null,"title":""},{"categories":null,"contents":"Go GMP 调度模型 #go #golang #gmp #scheduler #抢占式调度 #goroutine #协程 #gmp\n所谓 GMP，其中 G 是指 goroutine；M 是 Machine 的缩写，指的是工作线程；P 则是指处理器 Processor，代表了一组资源，M 要想执行 G 的代码，必须持有一个 P 才行。\n简单来说，GMP 就是 Task、Worker、Resource 的关系，G 和 P 都是 Go 语言实现的抽象程度更高的组件，对于工作线程而言，Machine 一词表明了它与具体的操作系统和平台密切相关，对具体平台的适配和特殊处理等大多在这一层实现。\n从 GM 到 GMP GM 模型调度的几个明显问题 用一个全局的 mutex 保护一个全局的 runq（就绪队列），造成对锁的竞争异常严重 G 每次执行都会被分发到随机的 M 上，造成在不同 M 之间频繁切换，破坏了程序的局部性 每个 M 都会关联一个内存分配缓存 mcache，造成大量内存开销，进一步使数据的局部性变差。实际上只有执行 Go 代码的 M 才真正需要 mcache，那些阻塞在系统调用中的 M 根本不需要，而实际执行 Go 代码的 M 可能仅占总数的 1% 在存在系统调用的情况下，工作线程经常被阻塞和解除阻塞，从而增加了很多开销 通过 runtime.GOMAXPROCS() 函数可以精准的控制 P 的个数\nGMP 的数据结构 G 源码 runtime.g\ntype g struct { // Stack parameters. // stack describes the actual stack memory: [stack.lo, stack.hi). // stackguard0 is the stack pointer compared in the Go stack growth prologue. // It is stack.lo+StackGuard normally, but can be StackPreempt to trigger a preemption. // stackguard1 is the stack pointer compared in the C stack growth prologue. // It is stack.lo+StackGuard on g0 and gsignal stacks. // It is ~0 on other goroutine stacks, to trigger a call to morestackc (and crash). stack stack // offset known to runtime/cgo stackguard0 uintptr // offset known to liblink stackguard1 uintptr // offset known to liblink _panic *_panic // innermost panic - offset known to liblink _defer *_defer // innermost defer m *m // current m; offset known to arm liblink sched gobuf syscallsp uintptr // if status==Gsyscall, syscallsp = sched.sp to use during gc syscallpc uintptr // if status==Gsyscall, syscallpc = sched.pc to use during gc stktopsp uintptr // expected sp at top of stack, to check in traceback // param is a generic pointer parameter field used to pass // values in particular contexts where other storage for the // parameter would be difficult to find. It is currently used // in three ways: // 1. When a channel operation wakes up a blocked goroutine, it sets param to // point to the sudog of the completed blocking operation. // 2. By gcAssistAlloc1 to signal back to its caller that the goroutine completed // the GC cycle. It is unsafe to do so in any other way, because the goroutine\u0026#39;s // stack may have moved in the meantime. // 3. By debugCallWrap to pass parameters to a new goroutine because allocating a // closure in the runtime is forbidden. param unsafe.Pointer atomicstatus atomic.Uint32 stackLock uint32 // sigprof/scang lock; TODO: fold in to atomicstatus goid uint64 schedlink guintptr waitsince int64 // approx time when the g become blocked waitreason waitReason // if status==Gwaiting preempt bool // preemption signal, duplicates stackguard0 = stackpreempt preemptStop bool // transition to _Gpreempted on preemption; otherwise, just deschedule preemptShrink bool // shrink stack at synchronous safe point // asyncSafePoint is set if g is stopped at an asynchronous // safe point. This means there are frames on the stack // without precise pointer information. asyncSafePoint bool paniconfault bool // panic (instead of crash) on unexpected fault address gcscandone bool // g has scanned stack; protected by _Gscan bit in status throwsplit bool // must not split stack // activeStackChans indicates that there are unlocked channels // pointing into this goroutine\u0026#39;s stack. If true, stack // copying needs to acquire channel locks to protect these // areas of the stack. activeStackChans bool // parkingOnChan indicates that the goroutine is about to // park on a chansend or chanrecv. Used to signal an unsafe point // for stack shrinking. parkingOnChan atomic.Bool raceignore int8 // ignore race detection events sysblocktraced bool // StartTrace has emitted EvGoInSyscall about this goroutine tracking bool // whether we\u0026#39;re tracking this G for sched latency statistics trackingSeq uint8 // used to decide whether to track this G trackingStamp int64 // timestamp of when the G last started being tracked runnableTime int64 // the amount of time spent runnable, cleared when running, only used when tracking sysexitticks int64 // cputicks when syscall has returned (for tracing) traceseq uint64 // trace event sequencer tracelastp puintptr // last P emitted an event for this goroutine lockedm muintptr sig uint32 writebuf []byte sigcode0 uintptr sigcode1 uintptr sigpc uintptr gopc uintptr // pc of go statement that created this goroutine ancestors *[]ancestorInfo // ancestor information goroutine(s) that created this goroutine (only used if debug.tracebackancestors) startpc uintptr // pc of goroutine function racectx uintptr waiting *sudog // sudog structures this g is waiting on (that have a valid elem ptr); in lock order cgoCtxt []uintptr // cgo traceback context labels unsafe.Pointer // profiler labels timer *timer // cached timer for time.Sleep selectDone atomic.Uint32 // are we participating in a select and did someone win the race? // goroutineProfiled indicates the status of this goroutine\u0026#39;s stack for the // current in-progress goroutine profile goroutineProfiled goroutineProfileStateHolder // Per-G GC state // gcAssistBytes is this G\u0026#39;s GC assist credit in terms of // bytes allocated. If this is positive, then the G has credit // to allocate gcAssistBytes bytes without assisting. If this // is negative, then the G must correct this by performing // scan work. We track this in bytes to make it fast to update // and check for debt in the malloc hot path. The assist ratio // determines how this corresponds to scan work debt. gcAssistBytes int64 } 部分字段用途 stack：描述了 goroutine 的栈空间 stackguard0： stackguard1：原理同 stackguard0 差不多，只不过是被 g0 和 gsignal 中的 C 代码使用 m：关联到正在执行当前 G 的工作线程 M sched：被调度器用来保存 goroutine 的执行上下文 atomicstatus：用来表示当前 G 的状态 goid：当前 goroutine 的全局唯一 ID schedlink：被调度器用于实现内部链表、队列，对应的 gunitptr 类型从逻辑上等价于 *g，而底层类型却是个 uintptr，这样是为了避免写障碍 preempt：为 true 时，调度器会在合适的时机触发一次抢占 lockedm：关联到与当前 G 绑定的 M，可参考 LockOSThread waiting：主要用于实现 channel 中的等待队列 timer：runtime 内部实现的计时器类型，主要用来支持 time.Sleep atomicstatus 字段的取值及其含义 const ( // G status // // Beyond indicating the general state of a G, the G status // acts like a lock on the goroutine\u0026#39;s stack (and hence its // ability to execute user code). // // If you add to this list, add to the list // of \u0026#34;okay during garbage collection\u0026#34; status // in mgcmark.go too. // // TODO(austin): The _Gscan bit could be much lighter-weight. // For example, we could choose not to run _Gscanrunnable // goroutines found in the run queue, rather than CAS-looping // until they become _Grunnable. And transitions like // _Gscanwaiting -\u0026gt; _Gscanrunnable are actually okay because // they don\u0026#39;t affect stack ownership. // _Gidle means this goroutine was just allocated and has not // yet been initialized. _Gidle = iota // 0 // _Grunnable means this goroutine is on a run queue. It is // not currently executing user code. The stack is not owned. _Grunnable // 1 // _Grunning means this goroutine may execute user code. The // stack is owned by this goroutine. It is not on a run queue. // It is assigned an M and a P (g.m and g.m.p are valid). _Grunning // 2 // _Gsyscall means this goroutine is executing a system call. // It is not executing user code. The stack is owned by this // goroutine. It is not on a run queue. It is assigned an M. _Gsyscall // 3 // _Gwaiting means this goroutine is blocked in the runtime. // It is not executing user code. It is not on a run queue, // but should be recorded somewhere (e.g., a channel wait // queue) so it can be ready()d when necessary. The stack is // not owned *except* that a channel operation may read or // write parts of the stack under the appropriate channel // lock. Otherwise, it is not safe to access the stack after a // goroutine enters _Gwaiting (e.g., it may get moved). _Gwaiting // 4 // _Gmoribund_unused is currently unused, but hardcoded in gdb // scripts. _Gmoribund_unused // 5 // _Gdead means this goroutine is currently unused. It may be // just exited, on a free list, or just being initialized. It // is not executing user code. It may or may not have a stack // allocated. The G and its stack (if any) are owned by the M // that is exiting the G or that obtained the G from the free // list. _Gdead // 6 // _Genqueue_unused is currently unused. _Genqueue_unused // 7 // _Gcopystack means this goroutine\u0026#39;s stack is being moved. It // is not executing user code and is not on a run queue. The // stack is owned by the goroutine that put it in _Gcopystack. _Gcopystack // 8 // _Gpreempted means this goroutine stopped itself for a // suspendG preemption. It is like _Gwaiting, but nothing is // yet responsible for ready()ing it. Some suspendG must CAS // the status to _Gwaiting to take responsibility for // ready()ing this G. _Gpreempted // 9 // _Gscan combined with one of the above states other than // _Grunning indicates that GC is scanning the stack. The // goroutine is not executing user code and the stack is owned // by the goroutine that set the _Gscan bit. // // _Gscanrunning is different: it is used to briefly block // state transitions while GC signals the G to scan its own // stack. This is otherwise like _Grunning. // // atomicstatus\u0026amp;~Gscan gives the state the goroutine will // return to when the scan completes. _Gscan = 0x1000 _Gscanrunnable = _Gscan + _Grunnable // 0x1001 _Gscanrunning = _Gscan + _Grunning // 0x1002 _Gscansyscall = _Gscan + _Gsyscall // 0x1003 _Gscanwaiting = _Gscan + _Gwaiting // 0x1004 _Gscanpreempted = _Gscan + _Gpreempted // 0x1009 ) G 几种暂停的方式：\ngosched：将当前的 G 暂停，保存堆栈状态，以 _Grunable 状态放入 Global 队列中，让当前 M 继续执行其他任务。无需对 G 执行唤醒操作，因为总会有 M 从 Global 队列取得并执行 G，抢占调度即使用该方式。 gopark：与 gosched 的最大区别在于 gopark 没有将 G 放回执行队列，而是位于某个等待队列中（如 channel 的 waitq，此时 G 状态为 _Gwaitting）, 因此 G 必须被手动唤醒（通过 goready），否则会丢失任务。应用层阻塞通常使用这种方式。 notesleep：既不让出 M，也不让 G 和 P 重新调度，直接让线程休眠直到被唤醒（notewakeup），该方式更快，通常用于 gcMark，stopm 这类自旋场景。 notesleepg：阻塞 G 和 M，放开 P，P 可以和其它 M 绑定继续执行，比如可能阻塞的系统调用会主动调用 entersyscallblock，则会触发 notesleepg。 goexit：立即终止 G 任务，不管其处于调用堆栈的哪个层次，在终止前，确保所有 defer 正确执行。 M 源码 runtime.m\ntype m struct { g0 *g // goroutine with scheduling stack morebuf gobuf // gobuf arg to morestack divmod uint32 // div/mod denominator for arm - known to liblink _ uint32 // align next field to 8 bytes // Fields not known to debuggers. procid uint64 // for debuggers, but offset not hard-coded gsignal *g // signal-handling g goSigStack gsignalStack // Go-allocated signal handling stack sigmask sigset // storage for saved signal mask tls [tlsSlots]uintptr // thread-local storage (for x86 extern register) mstartfn func() curg *g // current running goroutine caughtsig guintptr // goroutine running during fatal signal p puintptr // attached p for executing go code (nil if not executing go code) nextp puintptr oldp puintptr // the p that was attached before executing a syscall id int64 mallocing int32 throwing throwType preemptoff string // if != \u0026#34;\u0026#34;, keep curg running on this m locks int32 dying int32 profilehz int32 spinning bool // m is out of work and is actively looking for work blocked bool // m is blocked on a note newSigstack bool // minit on C thread called sigaltstack printlock int8 incgo bool // m is executing a cgo call isextra bool // m is an extra m freeWait atomic.Uint32 // Whether it is safe to free g0 and delete m (one of freeMRef, freeMStack, freeMWait) fastrand uint64 needextram bool traceback uint8 ncgocall uint64 // number of cgo calls in total ncgo int32 // number of cgo calls currently in progress cgoCallersUse atomic.Uint32 // if non-zero, cgoCallers in use temporarily cgoCallers *cgoCallers // cgo traceback if crashing in cgo call park note alllink *m // on allm schedlink muintptr lockedg guintptr createstack [32]uintptr // stack that created this thread. lockedExt uint32 // tracking for external LockOSThread lockedInt uint32 // tracking for internal lockOSThread nextwaitm muintptr // next m waiting for lock waitunlockf func(*g, unsafe.Pointer) bool waitlock unsafe.Pointer waittraceev byte waittraceskip int startingtrace bool syscalltick uint32 freelink *m // on sched.freem // these are here because they are too large to be on the stack // of low-level NOSPLIT functions. libcall libcall libcallpc uintptr // for cpu profiler libcallsp uintptr libcallg guintptr syscall libcall // stores syscall parameters on windows vdsoSP uintptr // SP for traceback while in VDSO call (0 if not in call) vdsoPC uintptr // PC for traceback while in VDSO call // preemptGen counts the number of completed preemption // signals. This is used to detect when a preemption is // requested, but fails. preemptGen atomic.Uint32 // Whether this is a pending preemption signal on this M. signalPending atomic.Uint32 dlogPerM mOS // Up to 10 locks held by this m, maintained by the lock ranking code. locksHeldLen int locksHeld [10]heldLockInfo } 部分字段用途 g0：并不是一个真正的 goroutine，他的栈是由操作系统分配的，初始大小比普通 goroutine 的栈要大，被用作调度器执行的栈 gsignal：本质上是用来处理信号的栈，因为一些 UNIX 系统支持位信号处理器配置独立的栈 curg ：指向 M 当前正在执行的 G p：GMP 中的 P，即关联当当前 M 上的处理器 nextp：用来将 P 传递给 M，调度器一般是在 M 阻塞时为 m.nextp 赋值，等到 M 开始运行后会尝试从 nextp 处获取 P 进行关联 oldp：用来暂存执行系统调用之前关联的 P id：M 的唯一 ID preemptoff：不为空时表示要关闭对 curg 的抢占，字符串内容给出了相关的原因 locks：记录了当前 M 持有的锁数量，不为 0 时能够阻止抢占发生 spinning：表示当前 M 正处于自旋状态 park：用来支持 M 的挂起与唤醒，可以很方便的实现每个 M 的单独挂起与唤醒 alllink：把所有的 M 连起来，构成 allm 链表 schedlink：被调度器用来实现链表，如空闲的 M 链表 lockedg：关联到与当前 M 绑定的 G，可参考 LockOSThread freelink：用来把已经退出运行的 M 连起来，构成 sched.freem 链表，方便下次分配时复用 P 源码 runtime.p\ntype p struct { id int32 status uint32 // one of pidle/prunning/... link puintptr schedtick uint32 // incremented on every scheduler call syscalltick uint32 // incremented on every system call sysmontick sysmontick // last tick observed by sysmon m muintptr // back-link to associated m (nil if idle) mcache *mcache pcache pageCache raceprocctx uintptr deferpool []*_defer // pool of available defer structs (see panic.go) deferpoolbuf [32]*_defer // Cache of goroutine ids, amortizes accesses to runtime·sched.goidgen. goidcache uint64 goidcacheend uint64 // Queue of runnable goroutines. Accessed without lock. runqhead uint32 runqtail uint32 runq [256]guintptr // runnext, if non-nil, is a runnable G that was ready\u0026#39;d by // the current G and should be run next instead of what\u0026#39;s in // runq if there\u0026#39;s time remaining in the running G\u0026#39;s time // slice. It will inherit the time left in the current time // slice. If a set of goroutines is locked in a // communicate-and-wait pattern, this schedules that set as a // unit and eliminates the (potentially large) scheduling // latency that otherwise arises from adding the ready\u0026#39;d // goroutines to the end of the run queue. // // Note that while other P\u0026#39;s may atomically CAS this to zero, // only the owner P can CAS it to a valid G. runnext guintptr // Available G\u0026#39;s (status == Gdead) gFree struct { gList n int32 } sudogcache []*sudog sudogbuf [128]*sudog // Cache of mspan objects from the heap. mspancache struct { // We need an explicit length here because this field is used // in allocation codepaths where write barriers are not allowed, // and eliminating the write barrier/keeping it eliminated from // slice updates is tricky, moreso than just managing the length // ourselves. len int buf [128]*mspan } tracebuf traceBufPtr // traceSweep indicates the sweep events should be traced. // This is used to defer the sweep start event until a span // has actually been swept. traceSweep bool // traceSwept and traceReclaimed track the number of bytes // swept and reclaimed by sweeping in the current sweep loop. traceSwept, traceReclaimed uintptr palloc persistentAlloc // per-P to avoid mutex // The when field of the first entry on the timer heap. // This is 0 if the timer heap is empty. timer0When atomic.Int64 // The earliest known nextwhen field of a timer with // timerModifiedEarlier status. Because the timer may have been // modified again, there need not be any timer with this value. // This is 0 if there are no timerModifiedEarlier timers. timerModifiedEarliest atomic.Int64 // Per-P GC state gcAssistTime int64 // Nanoseconds in assistAlloc gcFractionalMarkTime int64 // Nanoseconds in fractional mark worker (atomic) // limiterEvent tracks events for the GC CPU limiter. limiterEvent limiterEvent // gcMarkWorkerMode is the mode for the next mark worker to run in. // That is, this is used to communicate with the worker goroutine // selected for immediate execution by // gcController.findRunnableGCWorker. When scheduling other goroutines, // this field must be set to gcMarkWorkerNotWorker. gcMarkWorkerMode gcMarkWorkerMode // gcMarkWorkerStartTime is the nanotime() at which the most recent // mark worker started. gcMarkWorkerStartTime int64 // gcw is this P\u0026#39;s GC work buffer cache. The work buffer is // filled by write barriers, drained by mutator assists, and // disposed on certain GC state transitions. gcw gcWork // wbBuf is this P\u0026#39;s GC write barrier buffer. // // TODO: Consider caching this in the running G. wbBuf wbBuf runSafePointFn uint32 // if 1, run sched.safePointFn at next safe point // statsSeq is a counter indicating whether this P is currently // writing any stats. Its value is even when not, odd when it is. statsSeq atomic.Uint32 // Lock for timers. We normally access the timers while running // on this P, but the scheduler can also do it from a different P. timersLock mutex // Actions to take at some time. This is used to implement the // standard library\u0026#39;s time package. // Must hold timersLock to access. timers []*timer // Number of timers in P\u0026#39;s heap. numTimers atomic.Uint32 // Number of timerDeleted timers in P\u0026#39;s heap. deletedTimers atomic.Uint32 // Race context used while executing timer functions. timerRaceCtx uintptr // maxStackScanDelta accumulates the amount of stack space held by // live goroutines (i.e. those eligible for stack scanning). // Flushed to gcController.maxStackScan once maxStackScanSlack // or -maxStackScanSlack is reached. maxStackScanDelta int64 // gc-time statistics about current goroutines // Note that this differs from maxStackScan in that this // accumulates the actual stack observed to be used at GC time (hi - sp), // not an instantaneous measure of the total stack size that might need // to be scanned (hi - lo). scannedStackSize uint64 // stack size of goroutines scanned by this P scannedStacks uint64 // number of goroutines scanned by this P // preempt is set to indicate that this P should be enter the // scheduler ASAP (regardless of what G is running on it). preempt bool // pageTraceBuf is a buffer for writing out page allocation/free/scavenge traces. // // Used only if GOEXPERIMENT=pagetrace. pageTraceBuf pageTraceBuf // Padding is no longer needed. False sharing is now not a worry because p is large enough // that its size class is an integer multiple of the cache line size (for any of our architectures). } 部分字段用途 id：P 的唯一 ID，等于当前 P 在 allp 中的数组下标 staus： 表示 P 的状态 link：是一个没有写屏障的指针，别调度器用来构造链表 schedtick：记录了调度发生的次数，实际上在每一次发生 goroutine 切换且不继承时间片的情况下，该字段会加一 syscalltick：每发生一次系统调用就会加一 sysmontick：被监控线程用来存储上一次检查时的调度器时钟滴答，用以实现时间片算法 m：本质上是个指针，反向关联到当前 P 绑定的 M goidcache，goidcacheend：用来从全局 sched，goidgen 处申请 goid，分配空间，批量申请以减少全局范围的锁竞争 runqhead，runqtail，runq：当前 P 的就绪队列，用一个数组和一头一尾两个下标实现了一个环形队列 runnext：如果不为 nil，则指向一个被当前 G 准备好（就绪）的 G，接下来将会继承当前 G 的时间片开始运行。该字段的存在意义在于，假如有一组 goroutine 中有生产者和消费者，他们在一个 channel 上频繁地等待和唤醒，那么调度器就会把他们作为一个单元来调度。每次使用 runnext 比添加到本地 runq 尾部能大幅减少延迟 gFree：用来缓存已经退出运行的 G，方便再次分配时进行复用 preempt：在 Go1.14 版本引入，以支持新的异步抢占机制 status 字段的取值及其含义 const ( // P status // _Pidle means a P is not being used to run user code or the // scheduler. Typically, it\u0026#39;s on the idle P list and available // to the scheduler, but it may just be transitioning between // other states. // // The P is owned by the idle list or by whatever is // transitioning its state. Its run queue is empty. _Pidle = iota // _Prunning means a P is owned by an M and is being used to // run user code or the scheduler. Only the M that owns this P // is allowed to change the P\u0026#39;s status from _Prunning. The M // may transition the P to _Pidle (if it has no more work to // do), _Psyscall (when entering a syscall), or _Pgcstop (to // halt for the GC). The M may also hand ownership of the P // off directly to another M (e.g., to schedule a locked G). _Prunning // _Psyscall means a P is not running user code. It has // affinity to an M in a syscall but is not owned by it and // may be stolen by another M. This is similar to _Pidle but // uses lightweight transitions and maintains M affinity. // // Leaving _Psyscall must be done with a CAS, either to steal // or retake the P. Note that there\u0026#39;s an ABA hazard: even if // an M successfully CASes its original P back to _Prunning // after a syscall, it must understand the P may have been // used by another M in the interim. _Psyscall // _Pgcstop means a P is halted for STW and owned by the M // that stopped the world. The M that stopped the world // continues to use its P, even in _Pgcstop. Transitioning // from _Prunning to _Pgcstop causes an M to release its P and // park. // // The P retains its run queue and startTheWorld will restart // the scheduler on Ps with non-empty run queues. _Pgcstop // _Pdead means a P is no longer used (GOMAXPROCS shrank). We // reuse Ps if GOMAXPROCS increases. A dead P is mostly // stripped of its resources, though a few things remain // (e.g., trace buffers). _Pdead ) ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AF%AD%E8%A8%80/go/go-gmp-%E8%B0%83%E5%BA%A6%E6%A8%A1%E5%9E%8B/","summary":"Go GMP 调度模型 #go #golang #gmp #scheduler #抢占式调度 #goroutine #协程 #gmp\n所谓 GMP，其中 G 是指 goroutine；M 是 Machine 的缩写，指的是工作线程；P 则是指处理器 Processor，代表了一组资源，M 要想执行 G 的代码，必须持有一个 P 才行。\n简单来说，GMP 就是 Task、Worker、Resource 的关系，G 和 P 都是 Go 语言实现的抽象程度更高的组件，对于工作线程而言，Machine 一词表明了它与具体的操作系统和平台密切相关，对具体平台的适配和特殊处理等大多在这一层实现。\n从 GM 到 GMP GM 模型调度的几个明显问题 用一个全局的 mutex 保护一个全局的 runq（就绪队列），造成对锁的竞争异常严重 G 每次执行都会被分发到随机的 M 上，造成在不同 M 之间频繁切换，破坏了程序的局部性 每个 M 都会关联一个内存分配缓存 mcache，造成大量内存开销，进一步使数据的局部性变差。实际上只有执行 Go 代码的 M 才真正需要 mcache，那些阻塞在系统调用中的 M 根本不需要，而实际执行 Go 代码的 M 可能仅占总数的 1% 在存在系统调用的情况下，工作线程经常被阻塞和解除阻塞，从而增加了很多开销 通过 runtime.","tags":null,"title":""},{"categories":null,"contents":"Go netpoll 原生网络模型 #go #golang #tcp #网络 #网络模型 #netpoll #epoll\n一个简单的 TCP 服务器 func main() { l, err := net.Listen(\u0026#34;tcp4\u0026#34;, \u0026#34;:8000\u0026#34;) if err != nil { log.Fatal(err) } defer func() { _ = l.Close() }() log.Println(\u0026#34;server listen port: 8000\u0026#34;) var id int for { conn, err := l.Accept() if err != nil { log.Fatal(err) } id++ go func(id int, conn net.Conn) { defer func() { _ = conn.Close() }() var packet [0xFFF]byte for { n, err := conn.Read(packet[:]) if err != nil { return } _, _ = conn.Write(packet[:n]) } }(id, conn) } } ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AF%AD%E8%A8%80/go/go-netpoll-%E5%8E%9F%E7%94%9F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/","summary":"Go netpoll 原生网络模型 #go #golang #tcp #网络 #网络模型 #netpoll #epoll\n一个简单的 TCP 服务器 func main() { l, err := net.Listen(\u0026#34;tcp4\u0026#34;, \u0026#34;:8000\u0026#34;) if err != nil { log.Fatal(err) } defer func() { _ = l.Close() }() log.Println(\u0026#34;server listen port: 8000\u0026#34;) var id int for { conn, err := l.Accept() if err != nil { log.Fatal(err) } id++ go func(id int, conn net.Conn) { defer func() { _ = conn.Close() }() var packet [0xFFF]byte for { n, err := conn.","tags":null,"title":""},{"categories":null,"contents":"Go 原子操作 #go #golang #atomic #原子操作\n互斥锁跟原子操作的区别 在并发编程里，Go 语言 sync 包里的同步原语 Mutex 是我们经常用来保证并发安全的，但是他跟 atomic 包在使用目的和底层实现上都不一样：\n\u0026mdash;\u0026ndash; 互斥锁 原子操作 使用目的 保护一段逻辑 保护一个变量 底层实现 由操作系统的调度器实现 由底层硬件指令直接提供支持 相对性能 低 高 Mutex 由操作系统的调度器实现，而 atomic 包中的原子操作则由底层硬件指令直接提供支持，这些指令在执行的过程中是不允许中断的，因此原子操作可以在 lock-free 的情况下保证并发安全，并且它的性能也能做到随 CPU 个数的增多而线性扩展。\n对于一个变量更新的保护，原子操作通常会更有效率，并且更能利用计算机多核的优势。\n性能对比测试 互斥锁性能测试 使用 sync 包下面互斥锁的多线程加法操作\nfunc syncAdd(param int64) int64 { var wg sync.WaitGroup lock := sync.Mutex{} for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func() { for i := 0; i \u0026lt; 1000000; i++ { lock.Lock() param++ lock.Unlock() } wg.Done() }() } wg.Wait() return param } Benchmark 测试方法\nfunc BenchmarkSync(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { flag := int64(0) res := syncAdd(flag) if res != 10000000 { b.Errorf(\u0026#34;calculate result err: %d\\n\u0026#34;, res) } } } 测试结果：\n根据运行环境和硬件性能会有所不同，这里是在相同环境下的对比\n第一次 goos: darwin goarch: arm64 pkg: wire/atomic_test BenchmarkSync BenchmarkSync-8 2 862741542 ns/op PASS 第二次 goos: darwin goarch: arm64 pkg: wire/atomic_test BenchmarkSync BenchmarkSync-8 2 875432729 ns/op PASS 第三次 goos: darwin goarch: arm64 pkg: wire/atomic_test BenchmarkSync BenchmarkSync-8 2 836373292 ns/op PASS 三次取平均：(862741542 + 875432729 + 836373292) / 3 = 858182521 ns/op\n原子操作性能测试 使用 atomic 包下面原子操作的多线程加法操作\nfunc atomicAdd(param int64) int64 { var wg sync.WaitGroup for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func() { for i := 0; i \u0026lt; 1000000; i++ { atomic.AddInt64(\u0026amp;param, 1) } wg.Done() }() } wg.Wait() return param } Benchmark 测试方法\nfunc BenchmarkAtomic(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { flag := int64(0) res := atomicAdd(flag) if res != 10000000 { b.Errorf(\u0026#34;calculate result err: %d\\n\u0026#34;, res) } } } 测试结果：\n根据运行环境和硬件性能会有所不同，这里是在相同环境下的对比\n第一次 goos: darwin goarch: arm64 pkg: wire/atomic_test BenchmarkAtomic BenchmarkAtomic-8 4 359013958 ns/op PASS 第二次 goos: darwin goarch: arm64 pkg: wire/atomic_test BenchmarkAtomic BenchmarkAtomic-8 3 359734514 ns/op PASS 第三次 goos: darwin goarch: arm64 pkg: wire/atomic_test BenchmarkAtomic BenchmarkAtomic-8 4 359007542 ns/op PASS 三次取平均：(359013958 + 359734514 + 359007542) / 3 = 359252004 ns/op\n测试结果对比 根据测试结果数据使用互斥锁做累加每次循环耗时 858182521 ns，而使用原子操作做累加每次耗时 359252004 ns。\n这也印证了之前说过的：互斥锁适用于来保护一段逻辑，原子操作适用于于对一个变量的更新保护。\n原理浅析 参考： 互斥锁跟原子操作的区别-底层实现\n参考链接 Golang五种原子性操作的用法详解 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AF%AD%E8%A8%80/go/go-%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/","summary":"Go 原子操作 #go #golang #atomic #原子操作\n互斥锁跟原子操作的区别 在并发编程里，Go 语言 sync 包里的同步原语 Mutex 是我们经常用来保证并发安全的，但是他跟 atomic 包在使用目的和底层实现上都不一样：\n\u0026mdash;\u0026ndash; 互斥锁 原子操作 使用目的 保护一段逻辑 保护一个变量 底层实现 由操作系统的调度器实现 由底层硬件指令直接提供支持 相对性能 低 高 Mutex 由操作系统的调度器实现，而 atomic 包中的原子操作则由底层硬件指令直接提供支持，这些指令在执行的过程中是不允许中断的，因此原子操作可以在 lock-free 的情况下保证并发安全，并且它的性能也能做到随 CPU 个数的增多而线性扩展。\n对于一个变量更新的保护，原子操作通常会更有效率，并且更能利用计算机多核的优势。\n性能对比测试 互斥锁性能测试 使用 sync 包下面互斥锁的多线程加法操作\nfunc syncAdd(param int64) int64 { var wg sync.WaitGroup lock := sync.Mutex{} for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func() { for i := 0; i \u0026lt; 1000000; i++ { lock.","tags":null,"title":""},{"categories":null,"contents":"Go 同步原语与锁 #go #golang #锁 #互斥锁 #读写锁\n基本原语 #Mutex #RWMutex 扩展原语 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AF%AD%E8%A8%80/go/go-%E5%90%8C%E6%AD%A5%E5%8E%9F%E8%AF%AD%E4%B8%8E%E9%94%81/","summary":"Go 同步原语与锁 #go #golang #锁 #互斥锁 #读写锁\n基本原语 #Mutex #RWMutex 扩展原语 ","tags":null,"title":""},{"categories":null,"contents":"Go 开源项目 #go #golang #开源\nGo Kubernetes Gin Gorm gnet ants ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AF%AD%E8%A8%80/go/go-%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/","summary":"Go 开源项目 #go #golang #开源\nGo Kubernetes Gin Gorm gnet ants ","tags":null,"title":""},{"categories":null,"contents":"Go 汇编 #go #golang #汇编\n官方文档 链接\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AF%AD%E8%A8%80/go/go-%E6%B1%87%E7%BC%96/","summary":"Go 汇编 #go #golang #汇编\n官方文档 链接","tags":null,"title":""},{"categories":null,"contents":"Go 语法 #go #golang #语法 #编程语言\n设置代理 go env -w GOPROXY=https://goproxy.cn,direct init () 函数 init() 函数的执行顺序：\n对同一个 go 文件的 init() 调用顺序是从上到下的。 对同一个 package 中不同文件是按文件名字符串比较\u0026quot;从小到大\u0026quot;顺序调用各文件中的 init() 函数。 对于不同的 package，如果不相互依赖的话，按照 main 包中”先 import 的后调用”的顺序调用其包中的 init()，如果 package 存在依赖，则先调用最早被依赖的 package 中的 init()，最后调用 main 函数。 如果 init 函数中使用了 println() 或者 print() 你会发现在执行过程中这两个不会按照你想象中的顺序执行。这两个函数官方只推荐在测试环境中使用，对于正式环境不要使用。 基本类型 类型 长度 默认值 说明 bool 1 false byte 1 0 uint8 rune 4 0 Unicode Code Point, int32 int/uint 4/8 0 32 或 64 位 int8/uint8 1 0 -128 ~ 127, 0 ~ 255，byte是uint8 的别名 int16/uint16 2 0 -32768 ~ 32767, 0 ~ 65535 int32/uint32 4 0 -21亿~ 21亿, 0 ~ 42亿，rune是int32 的别名 int64/uint64 8 0 float32 4 0.0 float64 8 0.0 complex64 8 complex128 16 uintptr 4/8 array struct string \u0026quot;\u0026quot; slice nil map nil channel nil interface nil 接口 function nil 函数 字符串转义符 转义符 含义 \\r (回车符) 返回当前行行首 \\n （换行符）向下移动一个字符 \\t 制表符 ' 单引号 \u0026quot; 双引号 / 斜杠 #切片 切片定义 使用 make 声明 // make中后两个参数为len和cap，后者可以省略 s := make([]int, 0, 100) // len允许运行时期动态指定 func f() { _ = make([]int, l()) } func l() int { return 1 } 使用字面值声明 // 中括号中不应有数字，加上数字则声明的是数组 s := []int{0, 1, 2, 3, 4, 5} 从现有的数组中声明 s := [6]int{0, 1, 2, 3, 4, 5} ns1 := s[1:3:4] ns2 := s[1:3] ns3 := s[:3] ns4 := s[1:] ns5 := s[:] 切片的遍历 s := []int{0, 1, 2, 3, 4} for i, a := range s { fmt.Printf(\u0026#34;addr_i: %p\\taddr_a: %p\\n\u0026#34;, \u0026amp;s[i], \u0026amp;a) // 此处注意：如果需要修改slice中的值，修改a的值是不起作用的，需要使用索引修改原切片值 a++ s[i] += 10 } fmt.Println(s) 控制台打印：\naddr_i: 0x140000a8030 addr_a: 0x140000a4008 addr_i: 0x140000a8038 addr_a: 0x140000a4008 addr_i: 0x140000a8040 addr_a: 0x140000a4008 addr_i: 0x140000a8048 addr_a: 0x140000a4008 addr_i: 0x140000a8050 addr_a: 0x140000a4008 [10 11 12 13 14] 根据打印可以看出：上述代码中变量 a 的地址始终是相同的\n切片的传递 go 中函数参数传递方式都为值传递。而对于切片来说，切片的结构中传递的是一个具体数组的地址。如果函数中的切片发生扩容，那么扩容之后的操作对于函数外部是不可见的。\n如果需要将改动传递到函数外部，要么将修改后的切片作为值返回，要么参数定义时使用切片指针。\n源码 源码参考 go version go1.19.2 darwin/arm64\nsrc/runtime/slice.go 切片数据结构 type slice struct { array unsafe.Pointer len int cap int } 创建切片 func makeslice(et *_type, len, cap int) unsafe.Pointer { mem, overflow := math.MulUintptr(et.size, uintptr(cap)) if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 || len \u0026gt; cap { // NOTE: Produce a \u0026#39;len out of range\u0026#39; error instead of a // \u0026#39;cap out of range\u0026#39; error when someone does make([]T, bignumber). // \u0026#39;cap out of range\u0026#39; is true too, but since the cap is only being // supplied implicitly, saying len is clearer. // See golang.org/issue/4085. mem, overflow := math.MulUintptr(et.size, uintptr(len)) if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 { panicmakeslicelen() } panicmakeslicecap() } return mallocgc(mem, et, true) } // 64位 func makeslice64(et *_type, len64, cap64 int64) unsafe.Pointer { len := int(len64) if int64(len) != len64 { panicmakeslicelen() } cap := int(cap64) if int64(cap) != cap64 { panicmakeslicecap() } return makeslice(et, len, cap) } 切片扩容 // growslice handles slice growth during append.// It is passed the slice element type, the old slice, and the desired new minimum capacity, // and it returns a new slice with at least that capacity, with the old data// copied into it. // The new slice\u0026#39;s length is set to the old slice\u0026#39;s length, // NOT to the new requested capacity. // This is for codegen convenience. The old slice\u0026#39;s length is used immediately // to calculate where to write new values during an append.// TODO: When the old backend is gone, reconsider this decision. // The SSA backend might prefer the new length or to return only ptr/cap and save stack space.func growslice(et *_type, old slice, cap int) slice { if raceenabled { callerpc := getcallerpc() racereadrangepc(old.array, uintptr(old.len*int(et.size)), callerpc, abi.FuncPCABIInternal(growslice)) } if msanenabled { msanread(old.array, uintptr(old.len*int(et.size))) } if asanenabled { asanread(old.array, uintptr(old.len*int(et.size))) } if cap \u0026lt; old.cap { panic(errorString(\u0026#34;growslice: cap out of range\u0026#34;)) } if et.size == 0 { // append should not create a slice with nil pointer but non-zero len. // We assume that append doesn\u0026#39;t need to preserve old.array in this case. return slice{unsafe.Pointer(\u0026amp;zerobase), old.len, cap} } newcap := old.cap doublecap := newcap + newcap if cap \u0026gt; doublecap { newcap = cap } else { const threshold = 256 if old.cap \u0026lt; threshold { newcap = doublecap } else { // Check 0 \u0026lt; newcap to detect overflow // and prevent an infinite loop. for 0 \u0026lt; newcap \u0026amp;\u0026amp; newcap \u0026lt; cap { // Transition from growing 2x for small slices // to growing 1.25x for large slices. This formula // gives a smooth-ish transition between the two. newcap += (newcap + 3*threshold) / 4 } // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap \u0026lt;= 0 { newcap = cap } } } var overflow bool var lenmem, newlenmem, capmem uintptr // Specialize for common values of et.size. // For 1 we don\u0026#39;t need any division/multiplication. // For goarch.PtrSize, compiler will optimize division/multiplication into a shift by a constant. // For powers of 2, use a variable shift. switch { case et.size == 1: lenmem = uintptr(old.len) newlenmem = uintptr(cap) capmem = roundupsize(uintptr(newcap)) overflow = uintptr(newcap) \u0026gt; maxAlloc newcap = int(capmem) case et.size == goarch.PtrSize: lenmem = uintptr(old.len) * goarch.PtrSize newlenmem = uintptr(cap) * goarch.PtrSize capmem = roundupsize(uintptr(newcap) * goarch.PtrSize) overflow = uintptr(newcap) \u0026gt; maxAlloc/goarch.PtrSize newcap = int(capmem / goarch.PtrSize) case isPowerOfTwo(et.size): var shift uintptr if goarch.PtrSize == 8 { // Mask shift for better code generation. shift = uintptr(sys.Ctz64(uint64(et.size))) \u0026amp; 63 } else { shift = uintptr(sys.Ctz32(uint32(et.size))) \u0026amp; 31 } lenmem = uintptr(old.len) \u0026lt;\u0026lt; shift newlenmem = uintptr(cap) \u0026lt;\u0026lt; shift capmem = roundupsize(uintptr(newcap) \u0026lt;\u0026lt; shift) overflow = uintptr(newcap) \u0026gt; (maxAlloc \u0026gt;\u0026gt; shift) newcap = int(capmem \u0026gt;\u0026gt; shift) default: lenmem = uintptr(old.len) * et.size newlenmem = uintptr(cap) * et.size capmem, overflow = math.MulUintptr(et.size, uintptr(newcap)) capmem = roundupsize(capmem) newcap = int(capmem / et.size) } // The check of overflow in addition to capmem \u0026gt; maxAlloc is needed // to prevent an overflow which can be used to trigger a segfault // on 32bit architectures with this example program: // // type T [1\u0026lt;\u0026lt;27 + 1]int64 // // var d T // var s []T // // func main() { // s = append(s, d, d, d, d) // print(len(s), \u0026#34;\\n\u0026#34;) // } if overflow || capmem \u0026gt; maxAlloc { panic(errorString(\u0026#34;growslice: cap out of range\u0026#34;)) } var p unsafe.Pointer if et.ptrdata == 0 { p = mallocgc(capmem, nil, false) // The append() that calls growslice is going to overwrite from old.len to cap (which will be the new length). // Only clear the part that will not be overwritten. memclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem) } else { // Note: can\u0026#39;t use rawmem (which avoids zeroing of memory), because then GC can scan uninitialized memory. p = mallocgc(capmem, et, true) if lenmem \u0026gt; 0 \u0026amp;\u0026amp; writeBarrier.enabled { // Only shade the pointers in old.array since we know the destination slice p // only contains nil pointers because it has been cleared during alloc. bulkBarrierPreWriteSrcOnly(uintptr(p), uintptr(old.array), lenmem-et.size+et.ptrdata) } } memmove(p, old.array, lenmem) return slice{p, old.len, newcap} } map map 定义 m1 := make(map[string]int, 100) m2 := map[string]int{ \u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2, } map 的基本使用 aValue := m[\u0026#34;a\u0026#34;] // 第二个变量ok可用于判断当前key是否存在 bValue, ok := m[\u0026#34;b\u0026#34;] map 的遍历 for k, v := range m { fmt.Println(k,v) } 删除元素 delete(m, \u0026#34;a\u0026#34;) 源码 源码参考 go version go1.19.2 darwin/arm64\nsrc/runtime/map.go #hash冲突 #开放定址法 ：当要存储一对 kv ，发现 hash(key) 的下表已经被别的 key 占用时，就在这个数组中重新找空白没有被占用的位置存储这个 key。常见的有：线性探测法，线性补偿探测法， 随机探测法。 #拉链法 ：可以简单理解成数组中元素指向链表的头结点的一种结构。当 key 发生 hash 冲突时，在冲突位置的元素上形成一个链表。当查找时，发现 key 冲突，顺着链表一直往下找，直到链表的尾节点，找不到则返回空。 开放定址法和拉链法的优缺点：\n拉链法通常比线性探测法处理简单 线性探测查找是会被拉链法会更消耗时间 线性探测会更加容易导致扩容，而拉链不会 拉链存储了指针，所以空间上会比线性探测占用多一点 拉链是动态申请存储空间的，所以更适合链长不确定的 map 的结构 // A header for a Go map. type hmap struct { // Note: the format of the hmap is also encoded in cmd/compile/internal/reflectdata/reflect.go. // Make sure this stays in sync with the compiler\u0026#39;s definition. count int // # live cells == size of map. Must be first (used by len() builtin) flags uint8 B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) noverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details hash0 uint32 // hash seed buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0. oldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing nevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated) extra *mapextra // optional fields } // mapextra holds fields that are not present on all maps. type mapextra struct { // If both key and elem do not contain pointers and are inline, then we mark bucket // type as containing no pointers. This avoids scanning such maps. // However, bmap.overflow is a pointer. In order to keep overflow buckets // alive, we store pointers to all overflow buckets in hmap.extra.overflow and hmap.extra.oldoverflow. // overflow and oldoverflow are only used if key and elem do not contain pointers. // overflow contains overflow buckets for hmap.buckets. // oldoverflow contains overflow buckets for hmap.oldbuckets. // The indirection allows to store a pointer to the slice in hiter. overflow *[]*bmap oldoverflow *[]*bmap // nextOverflow holds a pointer to a free overflow bucket. nextOverflow *bmap } // A bucket for a Go map. type bmap struct { // tophash generally contains the top byte of the hash value // for each key in this bucket. If tophash[0] \u0026lt; minTopHash, // tophash[0] is a bucket evacuation state instead. tophash [bucketCnt]uint8 // Followed by bucketCnt keys and then bucketCnt elems. // NOTE: packing all the keys together and then all the elems together makes the // code a bit more complicated than alternating key/elem/key/elem/... but it allows // us to eliminate padding which would be needed for, e.g., map[int64]int8. // Followed by an overflow pointer. } map set 以及扩容 // Like mapaccess, but allocates a slot for the key if it is not present in the map. func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { if h == nil { panic(plainError(\u0026#34;assignment to entry in nil map\u0026#34;)) } if raceenabled { callerpc := getcallerpc() pc := abi.FuncPCABIInternal(mapassign) racewritepc(unsafe.Pointer(h), callerpc, pc) raceReadObjectPC(t.key, key, callerpc, pc) } if msanenabled { msanread(key, t.key.size) } if asanenabled { asanread(key, t.key.size) } if h.flags\u0026amp;hashWriting != 0 { fatal(\u0026#34;concurrent map writes\u0026#34;) } hash := t.hasher(key, uintptr(h.hash0)) // Set hashWriting after calling t.hasher, since t.hasher may panic, // in which case we have not actually done a write. h.flags ^= hashWriting if h.buckets == nil { h.buckets = newobject(t.bucket) // newarray(t.bucket, 1) } again: bucket := hash \u0026amp; bucketMask(h.B) if h.growing() { growWork(t, h, bucket) } b := (*bmap)(add(h.buckets, bucket*uintptr(t.bucketsize))) top := tophash(hash) var inserti *uint8 var insertk unsafe.Pointer var elem unsafe.Pointer bucketloop: for { for i := uintptr(0); i \u0026lt; bucketCnt; i++ { if b.tophash[i] != top { if isEmpty(b.tophash[i]) \u0026amp;\u0026amp; inserti == nil { inserti = \u0026amp;b.tophash[i] insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) } if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } if !t.key.equal(key, k) { continue } // already have a mapping for key. Update it. if t.needkeyupdate() { typedmemmove(t.key, k, key) } elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) goto done } ovf := b.overflow(t) if ovf == nil { break } b = ovf } // Did not find mapping for key. Allocate new cell \u0026amp; add entry. // If we hit the max load factor or we have too many overflow buckets, // and we\u0026#39;re not already in the middle of growing, start growing. if !h.growing() \u0026amp;\u0026amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again // Growing the table invalidates everything, so try again } if inserti == nil { // The current bucket and all the overflow buckets connected to it are full, allocate a new one. newb := h.newoverflow(t, b) inserti = \u0026amp;newb.tophash[0] insertk = add(unsafe.Pointer(newb), dataOffset) elem = add(insertk, bucketCnt*uintptr(t.keysize)) } // store new key/elem at insert position if t.indirectkey() { kmem := newobject(t.key) *(*unsafe.Pointer)(insertk) = kmem insertk = kmem } if t.indirectelem() { vmem := newobject(t.elem) *(*unsafe.Pointer)(elem) = vmem } typedmemmove(t.key, insertk, key) *inserti = top h.count++ done: if h.flags\u0026amp;hashWriting == 0 { fatal(\u0026#34;concurrent map writes\u0026#34;) } h.flags \u0026amp;^= hashWriting if t.indirectelem() { elem = *((*unsafe.Pointer)(elem)) } return elem } range #泛型 泛型示例 // Sum 使用泛型 func Sum[T int64 | float64](a, b T) T { return a+b } 自定义泛型类型 // CustomInt 泛型与接口声明类似 type CustomInt interface { int | int8 | int16 | int32 | int64 } // Sum T的类型为声明的CustomInt func Sum[T CustomInt](a, b T) T { return a+b } 成员类型支持 go 中所有基本类型\ntype CustomT interface { int | float32 | bool | chan int | map[int]int | [10]int | []int | struct{} | *http.Client } 泛型中的 ~ 符号都是与类型一起出现的，用来表示支持该类型的衍生类型\n// int8的衍生类型 type int8A int8 type int8B = int8 // CustomInt 不仅支持int8, 还支持int8的衍生类型int8A和int8B type CustomInt interface { ~int8 } 使用带泛型的函数 var a int = 10 var b int = 20 // 方法1，正常调用，编译器会自动推断出传入类型是int Sum(a, b) // 方法2，显式告诉函数传入的类型是int Sum[int](a, b) 内置的泛型类型 any 和 comparable any: 表示 go 里面所有的内置基本类型，等价于 interface{}\n// any is an alias for interface{} and is equivalent to interface{} in all ways. type any = interface{} comparable: 表示 go 里面所有内置的可比较类型：int、uint、float、bool、struct、指针等一切可以比较的类型\n// comparable is an interface that is implemented by all comparable types // (booleans, numbers, strings, pointers, channels, arrays of comparable types, // structs whose fields are all comparable types). // The comparable interface may only be used as a type parameter constraint, // not as the type of a variable. type comparable interface{ comparable } 泛型与结构体 type AgeT interface { int8 | int16 } type NameE interface { string } type User[T AgeT, E NameE] struct { age T name E } // GetAge 获取年龄 func (u *User[T, E]) GetAge() T { return u.age } // GetName 获取名字 func (u *User[T, E]) GetName() E { return u.name } // 声明要使用的泛型的类型 var u User[int8, string] // 赋值 u.age = 10 u.name = \u0026#34;ormissia\u0026#34; // 调用方法 age := u.GetAge() name := u.GetName() fmt.Println(age, name) // 10 ormissia 泛型与 switch 泛型和 switch 配合使用时无法通过编译，只能先将泛型赋值给 interface 才可以和 switch 配合使用\n// GetX 编译不通过 func GetX[T any]() T { var t T switch T { case int: t = 18 } return t } // Get 编译通过 func Get[T any]() T { var t T var ti interface{} = \u0026amp;t switch v := ti.(type) { case *int: *v = 18 } return t } 泛型的实际使用 缓存适配器中泛型的使用 [[计算机/项目/Go缓存垫片]] panic 与 recovery 调用 panic 后会立刻停止执行当前函数的剩余代码，并在当前 Goroutine 中递归执行调用方的 defer recover 可以中止 panic 造成的程序崩溃。它是一个只能在 defer 中发挥作用的函数，在其他作用域中调用不会发挥作用 channel switch/case 单个 case 语句中，可以出现多个结果选项 只有在 case 中明确添加 fallthrough 关键字，才会明确执行紧跟的下一个case ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AF%AD%E8%A8%80/go/go-%E8%AF%AD%E6%B3%95/","summary":"Go 语法 #go #golang #语法 #编程语言\n设置代理 go env -w GOPROXY=https://goproxy.cn,direct init () 函数 init() 函数的执行顺序：\n对同一个 go 文件的 init() 调用顺序是从上到下的。 对同一个 package 中不同文件是按文件名字符串比较\u0026quot;从小到大\u0026quot;顺序调用各文件中的 init() 函数。 对于不同的 package，如果不相互依赖的话，按照 main 包中”先 import 的后调用”的顺序调用其包中的 init()，如果 package 存在依赖，则先调用最早被依赖的 package 中的 init()，最后调用 main 函数。 如果 init 函数中使用了 println() 或者 print() 你会发现在执行过程中这两个不会按照你想象中的顺序执行。这两个函数官方只推荐在测试环境中使用，对于正式环境不要使用。 基本类型 类型 长度 默认值 说明 bool 1 false byte 1 0 uint8 rune 4 0 Unicode Code Point, int32 int/uint 4/8 0 32 或 64 位 int8/uint8 1 0 -128 ~ 127, 0 ~ 255，byte是uint8 的别名 int16/uint16 2 0 -32768 ~ 32767, 0 ~ 65535 int32/uint32 4 0 -21亿~ 21亿, 0 ~ 42亿，rune是int32 的别名 int64/uint64 8 0 float32 4 0.","tags":null,"title":""},{"categories":null,"contents":"Lua 语法 #lua #编程语言\n注释 单行注释 -- 单行注释 多行注释 --[[ 多行注释 多行注释 ]] 数据类型 Lua 是动态类型语言，变量不要类型定义，只需要为变量赋值\nLua 中有 8 个基本类型分别为：nil、boolean、number、string、userdata、function、thread 和 table。\n数据类型 描述 nil 值nil属于该类，表示一个无效值（在条件表达式中相当于false） boolean 包含两个值：false 和 true number 表示双精度类型的实浮点数 string 字符串由一对双引号或单引号来表示 function 由 C 或 Lua 编写的函数 userdata 表示任意存储在变量中的C数据结构 thread 表示执行的独立线路，用于执行协同程序 table Lua 中的表（table）其实是一个\u0026quot;关联数组\u0026quot;（associative arrays），数组的索引可以是数字、字符串或表类型。在 Lua 里，table 的创建是通过\u0026quot;构造表达式\u0026quot;来完成，最简单构造表达式是{}，用来创建一个空表。 可以使用 type 函数测试给定变量或者值的类型：\nprint(type(\u0026#34;Hello world\u0026#34;)) print(type(10.4 * 3)) print(type(print)) print(type(type)) print(type(true)) print(type(nil)) print(type(type(X))) --[[ 输出 string number function function boolean nil string ]] 变量 在默认情况下，变量总是认为是全局的，哪怕是语句块或是函数里，除非用 local 显式声明为局部变量\nLua 变量有三种类型：全局变量、局部变量、表中的域 变量的默认值均为 nil\na = 5 -- 全局变量 local b = 5 -- 局部变量 循环 while a=10 while( a \u0026lt; 20 ) do print(\u0026#34;a 的值为:\u0026#34;, a) a = a+1 end for 数值 for 循环 for i=10,1,-1 do print(i) end for 的三个表达式在循环开始前一次性求值，以后不再进行求值。比如上面的 f (x) 只会在循环开始前执行一次，其结果用在后面的循环中\nfunction f(x) print(\u0026#34;function\u0026#34;) return x*2 end for i=1,f(5) do print(i) end 泛型 for 循环 i 是数组索引值，v 是对应索引的数组元素值。ipairs 是 Lua 提供的一个迭代器函数，用来迭代数组，相当于 Go 里面的 range\n--打印数组a的所有值 a = {\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, \u0026#34;three\u0026#34;} for i, v in ipairs(a) do print(i, v) end repeat\u0026hellip; until 相当于某些语言里的 do...while\n--[ 变量定义 --] a = 10 --[ 执行循环 --] repeat print(\u0026#34;a的值为:\u0026#34;, a) a = a + 1 until( a \u0026gt; 15 ) 嵌套循环 j =2 for i=2,10 do for j=2,(i/j) , 2 do if(not(i%j)) then break end if(j \u0026gt; (i/j))then print(\u0026#34;i 的值为：\u0026#34;,i) end end end 循环控制语句 break：退出当前循环或语句，并开始脚本执行紧接着的语句\ngoto\nlocal a = 1 ::label:: print(\u0026#34;--- goto label ---\u0026#34;) a = a+1 if a \u0026lt; 3 then goto label -- a 小于 3 的时候跳转到标签 label end 无限循环 while( true ) do print(\u0026#34;循环将永远执行下去\u0026#34;) end 流程控制 if --[ 定义变量 --] a = 10; --[ 使用 if 语句 --] if( a \u0026lt; 20 ) then --[ if 条件为 true 时打印以下信息 --] print(\u0026#34;a 小于 20\u0026#34; ); end print(\u0026#34;a 的值为:\u0026#34;, a); if\u0026hellip; else --[ 定义变量 --] a = 100; --[ 检查条件 --] if( a \u0026lt; 20 ) then --[ if 条件为 true 时执行该语句块 --] print(\u0026#34;a 小于 20\u0026#34; ) else --[ if 条件为 false 时执行该语句块 --] print(\u0026#34;a 大于 20\u0026#34; ) end print(\u0026#34;a 的值为 :\u0026#34;, a) 函数 函数定义格式：\noptional_function_scope function function_name( argument1, argument2, argument3..., argumentn) function_body return result_params_comma_separated end optional_function_scope：该参数是可选的指定函数是全局函数还是局部函数，未设置该参数默认为全局函数，如果你需要设置函数为局部函数需要使用关键字 local function_name：指定函数名称 argument1, argument2, argument3..., argumentn：函数参数，多个参数以逗号隔开，函数也可以不带参数 function_body：函数体，函数中需要执行的代码语句块 result_params_comma_separated：函数返回值，Lua 语言函数可以返回多个值，每个值以逗号隔开 --[[ 函数返回两个值的最大值 --]] function max(num1, num2) if (num1 \u0026gt; num2) then result = num1; else result = num2; end return result; end -- 调用函数 print(\u0026#34;两值比较最大值为 \u0026#34;,max(10,4)) print(\u0026#34;两值比较最大值为 \u0026#34;,max(5,6)) 多返回值 function maximum (a) local mi = 1 -- 最大值索引 local m = a[mi] -- 最大值 for i,val in ipairs(a) do if val \u0026gt; m then mi = i m = val end end return m, mi end print(maximum({8,10,23,12,5})) 可变参数 Lua 函数可以接受可变数目的参数，在函数参数列表中使用三点 \u0026hellip; 表示函数有可变的参数。\nfunction average(...) result = 0 local arg={...} --\u0026gt; arg 为一个表，局部变量 for i,v in ipairs(arg) do result = result + v end print(\u0026#34;总共传入 \u0026#34; .. #arg .. \u0026#34; 个数\u0026#34;) return result/#arg end print(\u0026#34;平均值为\u0026#34;,average(10,5,3,4,5,6)) 运算符 算术运算符 操作符 描述 + 加 - 减 * 乘 / 除 % 取余 ^ 乘幂 - 负号 // 整除运算符(\u0026gt;=lua5.3) 关系运算符 操作符 描述 == 等于 ~= 不等于 \u0026gt; 大于 \u0026lt; 小于 \u0026gt;= 大于等于 \u0026lt;= 小于等于 逻辑运算符 操作符 描述 and 逻辑与 or 逻辑或 not 逻辑非 这里可以实现三目运算符的操作：print(a \u0026gt; 10 and \u0026quot;yes\u0026quot; or \u0026quot;no\u0026quot;)\n其他运算符 操作符 描述 .. 连接两个字符串 # 返回字符串或表的长度（#\u0026ldquo;Hello\u0026rdquo; 返回 5） 运算符优先级 由高到低的顺序：\n^ not - (unary) * / % + - .. \u0026lt; \u0026gt; \u0026lt;= \u0026gt;= ~= == and or 字符串 Lua 语言中字符串可以使用以下三种方式来表示：\n单引号间的一串字符 双引号间的一串字符 [[ 与 ]] 间的一串字符 数组 在 lua 中数组下标是从 1 开始的，有别于其他语言中从 0 开始\n一维数组 array = {\u0026#34;Lua\u0026#34;, \u0026#34;Tutorial\u0026#34;} for i= 0, 2 do print(array[i]) end 多维数组 -- 初始化数组 array = {} for i=1,3 do array[i] = {} for j=1,3 do array[i][j] = i*j end end -- 访问数组 for i=1,3 do for j=1,3 do print(array[i][j]) end end ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AF%AD%E8%A8%80/lua/lua-%E8%AF%AD%E6%B3%95/","summary":"Lua 语法 #lua #编程语言\n注释 单行注释 -- 单行注释 多行注释 --[[ 多行注释 多行注释 ]] 数据类型 Lua 是动态类型语言，变量不要类型定义，只需要为变量赋值\nLua 中有 8 个基本类型分别为：nil、boolean、number、string、userdata、function、thread 和 table。\n数据类型 描述 nil 值nil属于该类，表示一个无效值（在条件表达式中相当于false） boolean 包含两个值：false 和 true number 表示双精度类型的实浮点数 string 字符串由一对双引号或单引号来表示 function 由 C 或 Lua 编写的函数 userdata 表示任意存储在变量中的C数据结构 thread 表示执行的独立线路，用于执行协同程序 table Lua 中的表（table）其实是一个\u0026quot;关联数组\u0026quot;（associative arrays），数组的索引可以是数字、字符串或表类型。在 Lua 里，table 的创建是通过\u0026quot;构造表达式\u0026quot;来完成，最简单构造表达式是{}，用来创建一个空表。 可以使用 type 函数测试给定变量或者值的类型：\nprint(type(\u0026#34;Hello world\u0026#34;)) print(type(10.4 * 3)) print(type(print)) print(type(type)) print(type(true)) print(type(nil)) print(type(type(X))) --[[ 输出 string number function function boolean nil string ]] 变量 在默认情况下，变量总是认为是全局的，哪怕是语句块或是函数里，除非用 local 显式声明为局部变量","tags":null,"title":""},{"categories":null,"contents":"RUST #rust #编程语言\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AF%AD%E8%A8%80/rust/rust-%E8%AF%AD%E6%B3%95/","summary":"RUST #rust #编程语言","tags":null,"title":""},{"categories":null,"contents":"Go 缓存垫片 #go #缓存 #框架 #延时双删\n一个数据库与内存之间的缓存适配器，运用了控制反转的思想。引入之后无需重复为每种实体实现相同的缓存策略\n项目背景 大多数情况下我们在代码中添加 #Redis 作为缓存中间件之后都会多出很多代码来。每给一个实体添加缓存，都需要加一大堆代码。久而久之，代码库变得非常冗杂而且难看。\n举个栗子，一个带缓存的实体的查询逻辑的伪代码：\nfunc (e *TestS) Select() { e, ok := SelectFromRedis() if !ok { et, ok := SelectFromDB() if !ok { return } e = et go func() { SaveToCache(e) }() return } return } 假如一个服务中有多个需要维护到缓存中的实体，再加上删除，修改等其他逻辑，就会出现非常多的相似代码，导致维护十分麻烦，而且复用性极低。即使写成工具类，当有新服务加入时，也需要将代码拷来拷去，显得十分不专业。\n因此，写了这个缓存适配器框架，使用 #控制反转 的思想，代码中的实体只需实现指定接口，删除、修改、查询时只需要调用该库的对应方法即可，无需关心具体实现，框架会自动完成缓存相关逻辑。\n使用示例 缓存客户端实现CacheClintImpl接口 type CacheClintImpl interface { Del(key string) (int64, error) SetString(key, value string) error GetString(k string) (string, error) } 实现参考redis_storage.go\n初始化缓存客户端并将缓存客户端示例初始化到框架中 redis_ex.Init() cache_shim.InitCacheClient(\u0026amp;redis_ex.RDB) 需要做缓存的实体实现CacheTypeImpl接口 // CacheType 需要缓存的实体接口定义 type CacheType interface { CacheKey() string Expiration() int Delete() error Select() error Update() error } 需要做缓存的实体实现 CacheTypeImpl 接口 因为控制反转，这个时候不需要直接调用实体的 Select() 方法，直接调用 cache_shim 包中的 Select() 函数即可，框架将自动维护缓存中的数据。 _ = t1.Insert() t, err := cache_shim.Select[*db_ex.UserEx](t1) fmt.Printf(\u0026#34;t.type: %T\\tt: %v\\terr: %v\u0026#34;,t,t,err) 向数据库中插入数据之后，使用框架提供的查询方法查询 代码参考main.go 修改、删除同理\n链接 项目源码 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E9%A1%B9%E7%9B%AE/go%E7%BC%93%E5%AD%98%E5%9E%AB%E7%89%87/","summary":"Go 缓存垫片 #go #缓存 #框架 #延时双删\n一个数据库与内存之间的缓存适配器，运用了控制反转的思想。引入之后无需重复为每种实体实现相同的缓存策略\n项目背景 大多数情况下我们在代码中添加 #Redis 作为缓存中间件之后都会多出很多代码来。每给一个实体添加缓存，都需要加一大堆代码。久而久之，代码库变得非常冗杂而且难看。\n举个栗子，一个带缓存的实体的查询逻辑的伪代码：\nfunc (e *TestS) Select() { e, ok := SelectFromRedis() if !ok { et, ok := SelectFromDB() if !ok { return } e = et go func() { SaveToCache(e) }() return } return } 假如一个服务中有多个需要维护到缓存中的实体，再加上删除，修改等其他逻辑，就会出现非常多的相似代码，导致维护十分麻烦，而且复用性极低。即使写成工具类，当有新服务加入时，也需要将代码拷来拷去，显得十分不专业。\n因此，写了这个缓存适配器框架，使用 #控制反转 的思想，代码中的实体只需实现指定接口，删除、修改、查询时只需要调用该库的对应方法即可，无需关心具体实现，框架会自动完成缓存相关逻辑。\n使用示例 缓存客户端实现CacheClintImpl接口 type CacheClintImpl interface { Del(key string) (int64, error) SetString(key, value string) error GetString(k string) (string, error) } 实现参考redis_storage.go\n初始化缓存客户端并将缓存客户端示例初始化到框架中 redis_ex.","tags":null,"title":""},{"categories":null,"contents":"色彩搭配样例 #设计 #色彩搭配 #高级感\n高级感撞色样例 使用时颜色代码前加 #\nBE98AA 珊瑚粉红 3E3F4C 蓝莓 E1DAD9 灰白 4D3A59 烈淡紫 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AE%BE%E8%AE%A1/%E8%89%B2%E5%BD%A9%E6%90%AD%E9%85%8D/%E8%89%B2%E5%BD%A9%E6%90%AD%E9%85%8D%E6%A0%B7%E4%BE%8B/","summary":"色彩搭配样例 #设计 #色彩搭配 #高级感\n高级感撞色样例 使用时颜色代码前加 #\nBE98AA 珊瑚粉红 3E3F4C 蓝莓 E1DAD9 灰白 4D3A59 烈淡紫 ","tags":null,"title":""},{"categories":null,"contents":"DDIA #系统设计\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/ddia/","summary":"DDIA #系统设计","tags":null,"title":""},{"categories":null,"contents":"一滴水到海洋 #读书笔记 #散文\n这个世界上所有的事情似乎都可以有很多完全不同的观点，然而，实践了什么才重要，观点反而是次要的 （P 4） 生命力任何事都没有特别的意义，在平凡中找到真实的人，就会发现每一段每一刻都有尊贵的意义。（P 30） 亦不观恶而生嫌，亦不观善而勤措，亦不舍智而近愚，亦不抛迷而求悟（P 43） 一个人如果心中有明月，就知道月亮虽有阴晴圆缺，其实月的本身是没有变化的（P 46） 我们今天在忧心台湾社会的时候，很少思考到社会是一个整体，许多事情不会单独或偶然发生，就像一个番薯的腐败，是整个番薯的事情（P 166） ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E4%B8%80%E6%BB%B4%E6%B0%B4%E5%88%B0%E6%B5%B7%E6%B4%8B/","summary":"一滴水到海洋 #读书笔记 #散文\n这个世界上所有的事情似乎都可以有很多完全不同的观点，然而，实践了什么才重要，观点反而是次要的 （P 4） 生命力任何事都没有特别的意义，在平凡中找到真实的人，就会发现每一段每一刻都有尊贵的意义。（P 30） 亦不观恶而生嫌，亦不观善而勤措，亦不舍智而近愚，亦不抛迷而求悟（P 43） 一个人如果心中有明月，就知道月亮虽有阴晴圆缺，其实月的本身是没有变化的（P 46） 我们今天在忧心台湾社会的时候，很少思考到社会是一个整体，许多事情不会单独或偶然发生，就像一个番薯的腐败，是整个番薯的事情（P 166） ","tags":null,"title":""},{"categories":null,"contents":"八次危机 #读书笔记 #经济\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%85%AB%E6%AC%A1%E5%8D%B1%E6%9C%BA/","summary":"八次危机 #读书笔记 #经济","tags":null,"title":""},{"categories":null,"contents":"如何屠龙 #读书笔记\n\u0026ldquo;嘿，宝贝儿，想来我的城堡探索高塔吗？\u0026quot;（P 49） 在 12 世纪的热那亚，城中的大户人家都会在家宅旁边修建高耸而优雅的塔楼。\u0026hellip;\u0026hellip; 然后，这些家族在高塔顶端修建了投石机，这样他们就可以向其他高塔投掷大石块，把它们砸倒。（P 55） 也就是说，你和人打架在法律上有什么样的后果取决于双方谁的名声更好。（P 56） 理论上，有关犯罪和罪犯的消息传播的快慢取决于马的速度。（P 57） ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%A6%82%E4%BD%95%E5%B1%A0%E9%BE%99/","summary":"如何屠龙 #读书笔记\n\u0026ldquo;嘿，宝贝儿，想来我的城堡探索高塔吗？\u0026quot;（P 49） 在 12 世纪的热那亚，城中的大户人家都会在家宅旁边修建高耸而优雅的塔楼。\u0026hellip;\u0026hellip; 然后，这些家族在高塔顶端修建了投石机，这样他们就可以向其他高塔投掷大石块，把它们砸倒。（P 55） 也就是说，你和人打架在法律上有什么样的后果取决于双方谁的名声更好。（P 56） 理论上，有关犯罪和罪犯的消息传播的快慢取决于马的速度。（P 57） ","tags":null,"title":""},{"categories":null,"contents":"TCP-IP协议及其应用 #读书笔记 #计算机 #计算机综合\n元数据 [!abstract] TCP-IP协议及其应用\n书名： TCP-IP协议及其应用 作者： 林成浴 简介： 本书基于网络工程和应用需求，按照从低层到高层的逻辑顺序，有针对性地讲解TCP-IP的层次结构、工作原理和协议数据单元。全书共13章，内容包括TCP-IP基础、网络接口层、IP寻址与地址解析、IP协议、ICMP协议、IP路由、TCP与UDP协议、DNS与DHCP协议、应用层协议、SNMP协议、网络安全协议，以及IPv6协议。本书内容丰富，注重系统性和实践性，对于重点协议提供协议分析操作示范，引导读者直观地探索TCP-IP。编写过程中参考了最新的RFC文档，反映TCP-IP最新的一些发展动态。本书可作为计算机网络相关专业的教材，也可作为网络管理和维护人员的参考书以及各种培训班的教材。 出版时间 2013-07-01 00:00:00 ISBN： 9787115325228 分类： 计算机-计算机综合 出版社： 人民邮电出版社 PC地址：https://weread.qq.com/web/reader/c8a324507159a3c4c8a8016 高亮划线 1.3 TCP/IP协议簇 📌 TCP/IP协议一个个堆叠起来，就像一个栈，有时又称其为协议栈。\n⏱ 2024-01-04 11:30:24 ^22651844-8-1442-1474\n📌 ARP用于根据IP地址获取物理地址。RARP用于根据物理地址查找其IP地址\n⏱ 2024-01-04 11:33:09 ^22651844-8-2361-2398\n📌 TCP为主机提供可靠的面向连接的传输服务；UDP为应用层提供简单高效的无连接传输服务。\n⏱ 2024-01-04 11:34:08 ^22651844-8-2871-2914\n📌 TCP、UDP、ICMP、IGMP都要向IP传送数据，为区分要传送的数据来源于哪一种协议，在生成的IP首部中加入一个称为协议号的标识，其中协议号1标识为ICMP协议，6标识为TCP协议，17标识为UDP协议。\n⏱ 2024-01-04 11:36:05 ^22651844-8-4556-4660\n📌 一般TCP/IP网络给临时端口分配1024～5000之间的端口号，大于5000的端口号是为其他服务器预留的。\n⏱ 2024-01-04 11:47:00 ^22651844-8-7213-7267\n📌 将一个IP地址和一个端口号码合并起来，就成为插座（Socket）\n⏱ 2024-01-04 11:48:02 ^22651844-8-7641-7673\n1.4 协议分析 📌 在网络中，数据的收发是由网卡来完成的，网卡有以下4种接收模式。 · 广播：能够接收发送给自己的数据帧和网络中的广播信息。 · 多播：只能够接收多播数据。 · 直接：只能够接收发送给自己的数据帧。 · 混杂（Promiscuous Mode）：能够接收一切通过它的数据帧，而不管该数据是否是传给它的。 默认情况下，网卡处于广播模式\n⏱ 2024-01-04 14:43:35 ^22651844-9-1109-1413\n📌 如图1-21所示，从低到高分别是物理层、数据链路层、网络层、传输层和应用层，例中分别以Frame（帧）、Ethernet II（以太网）、Internet Protocol Version 4（IP）、Transmission Control Protocol（TCP）和Hypertext Transfer Protocol（HTTP）打头。物理层呈现的是整个帧（数据包），数据链路层、网络层、传输层所呈现的是该层数据单元的首部，而应用层呈现的是报文本身。 ￼ 图1-21 协议树\n⏱ 2024-01-04 16:17:24 ^22651844-9-11868-12325\n2.2 MAC寻址 📌 在一个局域网段内可以发送的MAC帧有以下3种。 · 单播（Unicast）帧：目的MAC地址是单站地址，用于一对一通信，该帧发送某一指定的站点。 · 广播（Broadcast）帧：目的MAC 地址为广播地址（全1），用于一对全体通信，该帧将发送给网段内所有站点。 · 多播（Multicast）帧：目的MAC地址为多播地址，用于一对多通信，该帧发送给指定的一部分站点。\n⏱ 2024-01-05 09:19:59 ^22651844-13-2430-2698\n📌 所有的网卡都至少应当能够识别单播帧和广播帧，即能够识别单播地址和广播地址。\n⏱ 2024-01-05 09:20:04 ^22651844-13-2727-2764\n📌 实际上MAC地址的有效性只限于局域网内。虽然不同设备MAC要求是唯一的，但由于每经过一个路由网段，数据包的源和目的MAC地址都要更改（当然源和目的IP地址不变），所以不同网段中存在相同的MAC地址也是可以的，只要同一网段内MAC地址不重复就行。\n⏱ 2024-01-05 09:55:43 ^22651844-13-3240-3362\n2.3 以太网帧分析 📌 最小的以太网帧长度为64字节。最大的以太网帧长度为1518字节。驱动程序要确保帧满足最小帧长度规范的要求，如果某个帧不能满足最小帧长度64字节的要求，那么驱动程序必须填充相应的数据字段。\n⏱ 2024-01-05 14:38:38 ^22651844-14-2252-2345\n📌 Ethernet II和IEEE 802.3/802.2 SNAP对要传输的数据包的长度都有一个限制，其最大值分别是1500和1492字节。链路层的这个特性称作最大传输单元（Maximum Transmission Unit, MTU）。\n⏱ 2024-01-05 14:39:08 ^22651844-14-2374-2493\n3.1 IP分类地址 📌 有些IP地址并不是用来标识主机的，而是具有特殊意义，如网络地址、广播地址、环回地址。\n⏱ 2024-01-10 18:15:05 ^22651844-19-4678-4720\n📌 IANA（Internet地址分配管理局）将A、B、C类地址中保留一部分作为专用地址（Private Address，又译为私有地址），具体由RFC 1918 “Address Allocation for Private Internets”规定。3类专用IP地址范围如下。 · A类：10.0.0.0～10.255.255.255。 · B类：172.16.0.0～172.32.255.255。 · C类：192.168.0.0～192.168.255.255。 这些地址是专门提供给那些没有连接到Internet的网络使用的。如果要直接连入Internet，应使用由InterNIC分配的合法IP地址，称为公用地址（Public Address）。使用专用地址的目的是避免与Internet上合法的IP地址冲突。\n⏱ 2024-01-10 18:17:24 ^22651844-19-6321-6793\n3.2 IP子网与超网 📌 A、B、C三类网络的子网掩码分别为255.0.0.0、255.255.0.0和255.255.255.0。\n⏱ 2024-01-10 18:19:00 ^22651844-20-896-949\n3.4 IP地址的配置管理 📌 配置IP地址一般有两种分配方式。一种是通过动态分配方式获取IP地址，计算机启动时自动向DHCP服务器申请IP地址，除了获取IP地址外，还能获得子网掩码等。另一种是分配静态地址，设置固定的IP地址。必须为不同的计算机设置不同的IP地址，同一网段的子网掩码必须相同。\n⏱ 2024-01-10 18:21:03 ^22651844-22-646-777\n3.5 地址解析 📌 IP地址与物理地址之间的映射称为地址解析，包括两个方面：从IP地址到物理地址的映射和从物理地址到IP地址的映射。\n⏱ 2024-01-10 18:22:25 ^22651844-23-644-700\n读书笔记 本书评论 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%BE%AE%E4%BF%A1%E8%AF%BB%E4%B9%A6/tcp-ip%E5%8D%8F%E8%AE%AE%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8/","summary":"TCP-IP协议及其应用 #读书笔记 #计算机 #计算机综合\n元数据 [!abstract] TCP-IP协议及其应用\n书名： TCP-IP协议及其应用 作者： 林成浴 简介： 本书基于网络工程和应用需求，按照从低层到高层的逻辑顺序，有针对性地讲解TCP-IP的层次结构、工作原理和协议数据单元。全书共13章，内容包括TCP-IP基础、网络接口层、IP寻址与地址解析、IP协议、ICMP协议、IP路由、TCP与UDP协议、DNS与DHCP协议、应用层协议、SNMP协议、网络安全协议，以及IPv6协议。本书内容丰富，注重系统性和实践性，对于重点协议提供协议分析操作示范，引导读者直观地探索TCP-IP。编写过程中参考了最新的RFC文档，反映TCP-IP最新的一些发展动态。本书可作为计算机网络相关专业的教材，也可作为网络管理和维护人员的参考书以及各种培训班的教材。 出版时间 2013-07-01 00:00:00 ISBN： 9787115325228 分类： 计算机-计算机综合 出版社： 人民邮电出版社 PC地址：https://weread.qq.com/web/reader/c8a324507159a3c4c8a8016 高亮划线 1.3 TCP/IP协议簇 📌 TCP/IP协议一个个堆叠起来，就像一个栈，有时又称其为协议栈。\n⏱ 2024-01-04 11:30:24 ^22651844-8-1442-1474\n📌 ARP用于根据IP地址获取物理地址。RARP用于根据物理地址查找其IP地址\n⏱ 2024-01-04 11:33:09 ^22651844-8-2361-2398\n📌 TCP为主机提供可靠的面向连接的传输服务；UDP为应用层提供简单高效的无连接传输服务。\n⏱ 2024-01-04 11:34:08 ^22651844-8-2871-2914\n📌 TCP、UDP、ICMP、IGMP都要向IP传送数据，为区分要传送的数据来源于哪一种协议，在生成的IP首部中加入一个称为协议号的标识，其中协议号1标识为ICMP协议，6标识为TCP协议，17标识为UDP协议。\n⏱ 2024-01-04 11:36:05 ^22651844-8-4556-4660\n📌 一般TCP/IP网络给临时端口分配1024～5000之间的端口号，大于5000的端口号是为其他服务器预留的。\n⏱ 2024-01-04 11:47:00 ^22651844-8-7213-7267\n📌 将一个IP地址和一个端口号码合并起来，就成为插座（Socket）\n⏱ 2024-01-04 11:48:02 ^22651844-8-7641-7673\n1.4 协议分析 📌 在网络中，数据的收发是由网卡来完成的，网卡有以下4种接收模式。 · 广播：能够接收发送给自己的数据帧和网络中的广播信息。 · 多播：只能够接收多播数据。 · 直接：只能够接收发送给自己的数据帧。 · 混杂（Promiscuous Mode）：能够接收一切通过它的数据帧，而不管该数据是否是传给它的。 默认情况下，网卡处于广播模式","tags":null,"title":""},{"categories":null,"contents":"商业化推荐系统服务应用实战（机械工业出版社“十四五”硬核产品） #读书笔记 #计算机 #计算机综合\n元数据 [!abstract] 商业化推荐系统服务应用实战（机械工业出版社“十四五”硬核产品）\n书名： 商业化推荐系统服务应用实战（机械工业出版社“十四五”硬核产品） 作者： 张乐 简介： 1. 内容经典：涵盖从推荐服务的商业创新模式到需求与解决方案管理、商业化版本发布、工作流支持以及绩效KPI体系设计和跨职能团队的沟通技术等内容 2. 实用性强：知识经验与实例相结合，从不同角度详细阐述说明了商业化推荐服务领域各部分的内容 出版时间 2022-04-01 00:00:00 ISBN： 9787111704201 分类： 计算机-计算机综合 出版社： 机械工业出版社 PC地址：https://weread.qq.com/web/reader/d5f32350813ab7519g0136fb 高亮划线 1.1 从推荐开始的商业创新 📌 商业化推荐服务本身就是“在合适的时间，合适的位置，为合适的客户提供合适的商品和服务”，因此商业模式的研究和商业化推荐服务在内部模式和结构上，就构成了一种天然的商业联系。\n⏱ 2024-01-10 18:56:06 ^3300037373-6-1153-1237\n📌 在没有分析清楚自有平台和业务的商业模式特点之前，简单模仿不同商业模式下的推荐服务，不仅不会带来预期的商业效果，可能还会适得其反。\n⏱ 2024-01-10 18:56:30 ^3300037373-6-1290-1354\n📌 按照企业发展阶段的经典模型，企业的生命周期可以分为初创期、发展期、成熟期和衰退期。\n⏱ 2024-01-10 18:56:47 ^3300037373-6-5993-6053\n2.1 需求的出发点和分析 📌 面对范围广泛的消费者市场，处于市场竞争地位的各类型经营企业，在各自业务领域中都存在类似的问题，即需要知道哪些消费者，在什么地方，愿意以什么样的代价，购买什么样的商品和服务。\n⏱ 2024-01-10 18:57:03 ^3300037373-10-1029-1115\n读书笔记 本书评论 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%BE%AE%E4%BF%A1%E8%AF%BB%E4%B9%A6/%E5%95%86%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98%E6%9C%BA%E6%A2%B0%E5%B7%A5%E4%B8%9A%E5%87%BA%E7%89%88%E7%A4%BE%E5%8D%81%E5%9B%9B%E4%BA%94%E7%A1%AC%E6%A0%B8%E4%BA%A7%E5%93%81/","summary":"商业化推荐系统服务应用实战（机械工业出版社“十四五”硬核产品） #读书笔记 #计算机 #计算机综合\n元数据 [!abstract] 商业化推荐系统服务应用实战（机械工业出版社“十四五”硬核产品）\n书名： 商业化推荐系统服务应用实战（机械工业出版社“十四五”硬核产品） 作者： 张乐 简介： 1. 内容经典：涵盖从推荐服务的商业创新模式到需求与解决方案管理、商业化版本发布、工作流支持以及绩效KPI体系设计和跨职能团队的沟通技术等内容 2. 实用性强：知识经验与实例相结合，从不同角度详细阐述说明了商业化推荐服务领域各部分的内容 出版时间 2022-04-01 00:00:00 ISBN： 9787111704201 分类： 计算机-计算机综合 出版社： 机械工业出版社 PC地址：https://weread.qq.com/web/reader/d5f32350813ab7519g0136fb 高亮划线 1.1 从推荐开始的商业创新 📌 商业化推荐服务本身就是“在合适的时间，合适的位置，为合适的客户提供合适的商品和服务”，因此商业模式的研究和商业化推荐服务在内部模式和结构上，就构成了一种天然的商业联系。\n⏱ 2024-01-10 18:56:06 ^3300037373-6-1153-1237\n📌 在没有分析清楚自有平台和业务的商业模式特点之前，简单模仿不同商业模式下的推荐服务，不仅不会带来预期的商业效果，可能还会适得其反。\n⏱ 2024-01-10 18:56:30 ^3300037373-6-1290-1354\n📌 按照企业发展阶段的经典模型，企业的生命周期可以分为初创期、发展期、成熟期和衰退期。\n⏱ 2024-01-10 18:56:47 ^3300037373-6-5993-6053\n2.1 需求的出发点和分析 📌 面对范围广泛的消费者市场，处于市场竞争地位的各类型经营企业，在各自业务领域中都存在类似的问题，即需要知道哪些消费者，在什么地方，愿意以什么样的代价，购买什么样的商品和服务。\n⏱ 2024-01-10 18:57:03 ^3300037373-10-1029-1115\n读书笔记 本书评论 ","tags":null,"title":""},{"categories":null,"contents":"好好谈恋爱：让他爱上你的15个秘诀 #读书笔记 #心理 #心理学应用\n元数据 [!abstract] 好好谈恋爱：让他爱上你的15个秘诀\n书名： 好好谈恋爱：让他爱上你的15个秘诀 作者： 文森 简介： 【编辑推荐】 ★精通五国语言的情感专家为你解决情感困惑 ★作者全球粉丝量超过80万人，视频全平台播放量超过1亿次，帮助数万名女性成功解决情感困惑。 ★一本书帮你实现幸福爱情 ★书中包含150多条心理学依据、11个独创情感理论和15节恋爱必修课 【内容简介】 如果你不懂如何驾驶却要开车，安全到达目的地会很困难；同样，如果不懂如何好好谈恋爱，拥有幸福的爱情将会成为很难实现的梦想。“谈恋爱”并不是人们生来就会的本事，就像骑自行车、说一门外语或是弹钢琴，都少不了后天的学习与练习。问题是，没有人教我们“谈恋爱”这门人生必修课。 如何才能吸引你喜欢的人，让他对你动心？如何让他为你认真付出感情？如何避免被玩弄感情，提前判断出一个人是否真正适合你？如何让一段感情经久不衰？ 文森老师作为国际知名情感专家，以风趣幽默的语言、生动形象的比喻和引人入胜的案例为你提供这些问题的答案以及让女性头疼的情感困惑的解答方案。在书中，作者精心提出了诸如“长期吸引力公式”“爱情博弈论”“择偶金字塔”“达·芬奇偏见”等等15个恋爱秘诀，帮助你快速成长为高价值女神，从而收获理想的爱情。 【作者简介】 文森是西班牙情感专家，西班牙两性心理协会认证导师。他多年来深入钻研两性关系、心理学、认知行为治疗（CBT）等课题。文森老师的恋爱课程学员遍布世界五大洲，全球粉丝量超过八十万人，视频全平台播放量超过一亿次。他教授的课程已成功帮助数万名女性解决了情感问题，获得幸福爱情，也教授了若干畅销情感课程，如《聊天女王》及《男人的真相》等。 出版时间 2022-08-01 00:00:00 ISBN： 9787521627275 分类： 心理-心理学应用 出版社： 中国法制出版社有限公司 PC地址：https://weread.qq.com/web/reader/198328e0813ab74d3g010fb9 高亮划线 PART 1 ATTRACTION SECRETS 吸引力的秘密 📌 “柯立芝效应”(Coolidge Effect)这一概念，￼用来形容雄性动物对于新出现的异性有较高的交配意愿，反而会对周遭已有过交配经验的异性进入“性不应期”，在这段时间内会短暂地失去与之交配的兴趣。￼\n⏱ 2024-01-01 09:35:23 ^3300036670-5-7130-7757\n📌 女人会采用狙击枪策略。\n⏱ 2024-01-01 09:38:43 ^3300036670-5-9909-10114\n📌 男人的性策略就是机关枪策略\n⏱ 2024-01-01 09:38:51 ^3300036670-5-10227-10240\n📌 男女之间性策略的不同，也致使在两性关系中，男人往往扮演追求者、女人往往扮演筛选者的角色。男人像机关枪一样“开火”，尽可能多地追求不同的女生，直到“打中”一个。女人则像狙击手，在一堆追求者中瞄准好再“开火”，筛选出最佳人选。\n⏱ 2024-01-01 09:39:22 ^3300036670-5-10614-10725\n第二章 爱情是一件公平的事 为了得到你想要的爱情，你得配得上它 Deserve The Relationship You Want 📌 为了得到你想要的，你得先配得上它。 这个世界还没有疯狂到去奖励一群不值得的人。\n⏱ 2024-01-01 09:48:53 ^3300036670-6-3324-3393\n📌 当男人接触魅力值高的女人时，他们会变得更有雄心和赚钱的欲望，￼也能展示出更多的冒险精神和创造力，￼更加倍努力地试图脱颖而出。\n⏱ 2024-01-01 14:43:25 ^3300036670-6-9130-10030\n📌 因此，你越优秀，可选择的范围就越广，对方选择你的概率也越高。这很现实，但合乎常理。\n⏱ 2024-01-04 19:15:24 ^3300036670-6-10616-10657\n📌 当走上自我提升之路后，你会发现生活开始越来越美好，无论在感情、工作还是其他方面都更顺利了。你越努力，就越优秀；越优秀，就越幸福。成为更好的自己，这是你的使命。\n⏱ 2024-01-04 23:37:06 ^3300036670-6-11075-11154\n📌 一棵树不会在它自认为“差不多”的时候便停止生长，它能长多高就会长多高，每棵树都会尽其所能地成为“最好的自己”，你当然也可以做到。只不过，树的生长是自然的，而你需要主动成长。\n⏱ 2024-01-04 23:37:43 ^3300036670-6-11345-11431\n📌 想要好好谈恋爱，想要得到优质的另一半，还是选择成为更好的自己吧。你若芬芳，蝴蝶自来。\n⏱ 2024-01-04 23:37:56 ^3300036670-6-11460-11502\n📌 学习新的知识只是升级自己的工具箱，你还是在一直“做自己”，而且让自己越来越好。请不要不小心掉入“做自己”的陷阱，别用“做自己就好”作为限制自我潜力的借口。\n⏱ 2024-01-04 23:52:45 ^3300036670-6-12382-12459\n📌 你要相信自己值得美好的爱情，但这并不代表获得美好的爱情轻而易举。男神不会从天而降。好的感情值得投入精力、努力经营。你可以拥有这样的爱情，但你是否愿意为了得到它而努力？\n⏱ 2024-01-04 23:52:56 ^3300036670-6-12530-12613\n📌 爱情是一件公平的事。为了得到你想要的爱情，你得配得上它。\n⏱ 2024-01-04 23:53:08 ^3300036670-6-12642-12670\n第三章 培养长期吸引力 让男人离不开你 Create Long-Lasting Attraction 📌 这也许就是男人比女人更爱观看成人电影的原因之一。￼毕竟，在美国成人娱乐网站的计费服务数据中，购买在线色情内容的用户98%是男人。\n⏱ 2024-01-05 13:33:20 ^3300036670-7-2858-3407\n📌 女人的性幻想多是由一段恋情触发的，而男人的性幻想大多是由视觉刺激唤起的。\n⏱ 2024-01-05 13:33:40 ^3300036670-7-3442-3636\n📌 女人更喜欢浪漫的故事情节，而男人则更喜欢生动且刺激的视觉场景。\n⏱ 2024-01-05 13:33:51 ^3300036670-7-3637-3668\n📌 虽然长期吸引力不能只依靠视觉魅力，但事实上，再幸福美好的爱情故事，也都是从视觉开始的。\n⏱ 2024-01-05 13:34:44 ^3300036670-7-4626-4669\n📌 为了使你的优点得到发扬，你需要先吸引他的眼球，让他看到你。\n⏱ 2024-01-05 13:34:57 ^3300036670-7-4765-4794\n📌 要征服一个男人的心，就不需要征服他的胃，而是先征服他的眼睛。\n⏱ 2024-01-05 13:35:08 ^3300036670-7-4850-4880\n📌 虽然吸引力从外表开始，但内外因素的重要性不相上下，这只是顺序的问题。\n⏱ 2024-01-05 13:36:24 ^3300036670-7-5697-5731\n📌 男人只会爱一个他尊重的女人，而底线是能够获得尊重的前提。\n⏱ 2024-01-05 13:43:05 ^3300036670-7-7513-7541\n📌 (3)自信 常常否定自己的价值、怀疑自己各方面的能力、过于缺乏安全感等一系列不够自信的表现都会大大降低一个人的魅力值。如果你觉得自己不值得被爱，那男人又怎么可能会爱你？\n⏱ 2024-01-05 13:44:19 ^3300036670-7-7770-7882\n📌 无论你认为自己行还是不行，你都是对的。所以，还不如认为自己行。只有真正相信自己的价值，在别人眼中，你的价值才更有说服力。你要先认可自己，别人才会认可你。\n⏱ 2024-01-05 13:44:30 ^3300036670-7-7934-8010\n📌 因为不会表达，让聊天以尴尬收场，因而错失良机，让对方失去了对你的兴趣；因为不会聊天，让关系趋于平淡无趣，失去激情；因为不懂表达自己的需求，而难以得到对方的满足；因为措辞不当，引发误会，导致矛盾升级，而搞砸两人原本还不错的关系。\n⏱ 2024-01-05 13:45:32 ^3300036670-7-8582-8695\n📌 毋庸置疑的是，高情商的沟通能力就像骑自行车，这是每个人都能学会的本事\n⏱ 2024-01-05 13:45:45 ^3300036670-7-8754-8788\n📌 男人不能是女人生活里的唯一依靠，否则一旦对方离开（哪怕只是忙而已），就会觉得自己失去了救命稻草，觉得自己一无所有。\n⏱ 2024-01-05 13:46:39 ^3300036670-7-9834-9891\n📌 不少女生把独立性误解为强势，而视温柔为弱势。但事实并非如此。温柔会让男人想要迎难而上，而强势只会让男人望而却步。独立不代表咄咄逼人，温柔不代表言听计从。温柔与独立，两者并不冲突。\n⏱ 2024-01-05 13:47:13 ^3300036670-7-9920-10009\n📌 女生在暧昧期的“不随便”在一定程度上暗示着恋爱期的潜在忠诚。\n⏱ 2024-01-07 21:02:15 ^3300036670-7-13201-13231\n📌 爱情就是这样，始于颜值，陷于才华，合于性格，久于忠诚。短期吸引力就好像转瞬即逝的烟花，美好且短暂。好好培养你的长期吸引力，才能做他世界中永远闪亮的那颗星。\n⏱ 2024-01-07 21:02:27 ^3300036670-7-13537-13614\n📌 只在某方面一枝独秀也无法产生长期吸引力，而在多方面堆积自己的魅力，才能在男人眼中脱颖而出。\n⏱ 2024-01-07 21:16:50 ^3300036670-7-14576-14621\n📌 男人当然也喜欢优秀的女生，只是男人眼里的优秀和女人眼里的优秀有所不同。\n⏱ 2024-01-07 21:17:53 ^3300036670-7-15725-15760\n📌 为什么很多女人会担心自己的学历或工作配不上她们喜欢的男人呢？答案很简单：因为这是女人在乎的择偶条件。\n⏱ 2024-01-07 21:19:31 ^3300036670-7-16451-16501\n📌 男人更看重女人的外表和性格。\n⏱ 2024-01-07 21:19:40 ^3300036670-7-16603-16617\n📌 有些事情是为了自己的生活而做，有些事情是为了吸引异性而做。\n⏱ 2024-01-07 21:20:34 ^3300036670-7-17778-17807\nPART 2 BE THE PRIZE 激发男人的征服欲 📌 正是神秘的朦胧不清为追求增添了迷人之处。——文森(Vincent)\n⏱ 2024-01-07 21:20:47 ^3300036670-8-548-581\n📌 实，世间万物皆有利弊，重点在于把控程度。不喝水，人类平均只能活几天，但饮水过多也可能致命。那么，在感情中，太过容易或者过于难以让人追到，都可能导致让你大失所望的结果。\n⏱ 2024-01-07 21:22:48 ^3300036670-8-1860-1943\n📌 需要努力才能得到的东西会更被珍惜。\n⏱ 2024-01-07 21:23:00 ^3300036670-8-2260-2277\n📌 那些从一开始就对你表现出很明显的兴趣，对你又殷勤又热情，想要讨你欢心的男生，他们对你则没有那么强烈的吸引力。为什么会这样\n⏱ 2024-01-07 21:24:26 ^3300036670-8-3008-3068\n📌 。同样，那个男生所创造的不确定性，使他占据了你的整个大脑。\n⏱ 2024-01-07 21:24:43 ^3300036670-8-3386-3415\n📌 幸福在于追逐幸福的过程，而不是幸福本身。\n⏱ 2024-01-07 21:27:23 ^3300036670-8-5723-5899\n📌 我们可以简单地说，女生太容易追到与太难追到，都不会给对方很大的动力，追到的难度刚刚好，才会让他更积极地争取。\n⏱ 2024-01-07 21:28:31 ^3300036670-8-6679-6733\n📌 英国作家奥斯卡·王尔德(Oscar Wilde)认为，浪漫的精髓就在于它的不确定性。\n⏱ 2024-01-07 21:28:56 ^3300036670-8-6855-6897\n📌 请在交往中增加一点不确定性，让他的多巴胺飙升\n⏱ 2024-01-07 21:29:08 ^3300036670-8-6915-6937\n📌 没必要在不恰当的时间玩欲擒故纵的游戏，扮演一座冷漠的“冰山”，这很有可能会搞砸你们发展的机会。\n⏱ 2024-01-07 21:31:58 ^3300036670-8-7594-7641\n📌 “让人努力得到”不是“让自己不可能被得到”。\n⏱ 2024-01-07 21:32:25 ^3300036670-8-7755-7777\n📌 有一些行为，在二人关系稳定时是加分项，而在暧昧期则会扣分。要清楚你们的关系正处于什么阶段，然后做出该阶段适当的行为。\n⏱ 2024-01-07 21:33:27 ^3300036670-8-8059-8117\n📌 生理机制决定了男人是追求者，女人是筛选者。因此，在“买卖关系”中成为需要说服买家的卖家，是每个男人应该承担的角色，而女人成为买家，也正是每个男人期待的。\n⏱ 2024-01-07 21:34:31 ^3300036670-8-8684-8760\n📌 作为两性中的筛选者，要想好好谈恋爱，女人不得不成为更为精明的买家。\n⏱ 2024-01-07 21:36:47 ^3300036670-8-8947-8980\n📌 研究证明，男人更偏爱在会面中展示出大方、温暖、积极响应性的女人。\n⏱ 2024-01-07 21:37:52 ^3300036670-8-9714-10073\n📌 一开始，可以展示你的可接近性。但在你们相识后，一旦他准备展开行动，你就要开始提高自己的挑战性了，这就是所谓的“难”。让他追求你、联系你、试图和你见面、努力推进关系。当他真正走进你的世界，对你袒露真心，当他的每一个行为都充满爱意，当你无须再质疑他是否是个负心汉的时刻，你又要降低自己的挑战性，让他在关系中体会到舒适。\n⏱ 2024-01-07 21:39:15 ^3300036670-8-10914-11071\n📌 你只需保持自己的魅力和高价值行为，用心经营你们的感情就好。\n⏱ 2024-01-07 21:39:42 ^3300036670-8-11509-11538\n第五章 让他努力成为男人想征服的“黄金女神” Effort Adds Value 📌 对于一个人来说，任何东西的真正价值，是为了要得到它所经历的艰难困苦。——亚当·斯密(Adam Smith)\n⏱ 2024-01-07 21:39:55 ^3300036670-9-494-547\n📌 娃娃机心理\n⏱ 2024-01-07 21:40:27 ^3300036670-9-879-884\n📌 抓娃娃的意义就在于其努力的过程、潜在的奖励、对自己能力的考验和结果的不确定性。\n⏱ 2024-01-07 21:40:44 ^3300036670-9-975-1014\n📌 开采黄金可不是件容易事，大型地下采矿作业属于资本密集型产业，需要极高的机械化程度和技术水平，投资量大、成本回收也慢\n⏱ 2024-01-07 21:44:50 ^3300036670-9-5285-5342\n📌 想让男人吃醋，一定要选择更间接的方法让他知道：你很抢手，就像很多人想要的黄金；你很受异性的青睐，但你对他们无动于衷。这才是重点。 比如，你可以和他说：“刚才在咖啡厅，旁边的人一直在看我，我离开的时候他还想要我的联系方式，真烦人！”或者“天哪，好可怕呀！今天打车的时候，司机竟然要了我的微信！”当他担心地问“那你给他了吗”的时候，你就要给他安全感：“当然没有，怎么可能！”\n⏱ 2024-01-07 21:56:07 ^3300036670-9-8562-8775\n第六章 爱情博弈论 别过早“伺候皇帝” Play The Game Of Love 📌 爱情是一场双赢的游戏。——伊娃·嘉宝(Eva Gabor)\n⏱ 2024-01-07 21:58:01 ^3300036670-10-496-525\n第七章 真爱没有直飞航班 掌握亲密关系的节奏 Don’t Rush Something You Want To Last Forever 📌 第一次约会就发生关系，最终拥有美好结局的情侣的确存在，但这就像有些人抽了一辈子的烟，照样也能活到90岁\n⏱ 2024-01-08 09:03:05 ^3300036670-11-2475-2526\n📌 想让爱情持久，就别从一开始急于一时，别让自己陷入“快餐爱情”，好的爱情值得慢慢品尝。 ^3300036670-11-3546-3588\n💭 喜欢是乍见之欢，爱是久处不厌。 - ⏱ 2024-01-08 09:12:29 📌 不着急发生亲密关系，是淘汰“渣男”和不认真追求者的最佳方式，没有之一。\n⏱ 2024-01-08 09:07:25 ^3300036670-11-3888-3923\n📌 毕竟继续投入对于只想玩玩的男人来说太不划算，还不如省下时间和精力去寻找一个更容易的目标。但是，对于寻求长期伴侣的男人来说，他不会介意适应你的节奏。\n⏱ 2024-01-08 09:08:32 ^3300036670-11-4072-4145\n📌 关系的节奏，要由女人说了算。大部分男人会试图尽快发生关系，就像喜剧演员比利·克里斯托(Billy Crystal)认为的那样，要发生性关系，女人需要一个理由，男人则只需要一个地方。\n⏱ 2024-01-08 09:08:45 ^3300036670-11-4228-4318\n📌 。因为，如果男人不主动一点升级亲密关系，试试牵手、拥抱、接吻，那你和我都不会存在了。人类一直能够延续下去的原因是全世界的父亲升级了和母亲的亲密关系，否则我无法写这本书，你也无法阅读它。\n⏱ 2024-01-08 09:08:55 ^3300036670-11-4338-4430\n📌 所有男人早晚都会尝试发生关系，除非他只想做你的闺密，区别在于节奏。男女发生关系的节奏就好比猎豹和乌龟，一个快，一个慢。猎豹可以表明自己的节奏，可是最终他必须适应乌龟的节奏\n⏱ 2024-01-08 09:09:05 ^3300036670-11-4459-4544\n📌 过快与对方亲密还有一个风险，那就是很容易把散发荷尔蒙的激情误解为真爱，因而在还没来得及判断对方是否合适的情况下，不知不觉地就已经开始展开了一段恋情。\n⏱ 2024-01-08 09:10:24 ^3300036670-11-5587-5661\n📌 一个男人靠不靠谱、合不合适，没有人能够仅凭片面之交就看得一清二楚。也许你能在一个月内判断出来，也许你需要三个多月才能看清，每个人的情况不一样，但无论如何，你想淘汰只想玩弄感情的人，避免与不合适的人开始一段没有未来且日后会后悔的关系。\n⏱ 2024-01-08 09:10:45 ^3300036670-11-5690-5806\n📌 越了解对方的为人、越清楚地判断双方合适的价值观、建立越深厚的情感纽带和足够的信任，就越能够更确定也更放心地走入亲密关系的下一步，发生关系自然就是情到深处的水到渠成，而这都归功于你留给自己足够的时间来确定他就是那个对的人。如果你依旧犹豫不定，只有两种原因：一是时机未到，二是他不值得。\n⏱ 2024-01-08 09:11:03 ^3300036670-11-5835-5976\n📌 你的身体并不是你的唯一的“价值”\n⏱ 2024-01-08 09:14:18 ^3300036670-11-6431-6447\n📌 很多女生担心如果和男人发生关系，就意味着将自己最重要的部分交付给了对方。她们过于严重地看待发生关系这件事，误认为自己的身体是她对男人唯一的吸引力，害怕男人在与自己发生关系后就不会再珍惜。亲密关系就好像是自己唯一的宝藏，一旦给了对方，自己就身无分文。\n⏱ 2024-01-08 09:14:27 ^3300036670-11-6477-6601\n📌 当亲密关系沦为感情中最重的砝码，一旦发生关系后，女生的不自信和不安全感就将暴露无遗，这会使她在男人眼里彻底失去魅力。不要因此否定自身的价值，女人的价值是全面的。\n⏱ 2024-01-08 09:15:02 ^3300036670-11-6653-6733\n📌 美国的一项调查发现，与谈恋爱不到一年的夫妻相比，婚前谈过一两年恋爱的夫妻离婚的可能性要低20%￼，而在一起三年再结婚的夫妻离婚的可能性更低。￼\n⏱ 2024-01-08 09:15:46 ^3300036670-11-7152-7709\n📌 想要好好谈恋爱，就要将爱情视为一段长途的火车旅行。你可以欣赏沿途的风景，也可以在每一站下车逛逛，体验旅途中的有趣和美好，然后再次出发，到达下一站。亲密关系就仿佛爱情之旅中的一站。在到达“亲密站”之前，总有一些必经的站点：相识站、相知站、升温站、信任站。历经每一站，彼此携手共同到达终点，才会使这段爱的旅程更有意义和价值。\n⏱ 2024-01-08 09:18:07 ^3300036670-11-8062-8222\n📌 美好的爱情是没有直飞航班的。因此，请乘坐爱情的长途列车，逐步发展你们的关系，享受旅途中的点滴美好，然后共同到达真爱的目的地。\n⏱ 2024-01-08 09:18:21 ^3300036670-11-8251-8313\nPART 3 BALANCE LOGIC \u0026amp; EMOTION 平衡理性与感性 📌 凡事都有一件事是不可能的：理性。——弗里德里希·尼采(Friedrich Nietzsche)\n⏱ 2024-01-08 09:18:31 ^3300036670-12-606-653\n📌 “感情”之所以被称为“感情”而不叫作“理情”，难道不就是因为它是一件感性之事吗？巴尔扎克认为爱情是理性的放纵。理性的爱情还算什么爱情？\n⏱ 2024-01-08 09:20:56 ^3300036670-12-1591-1658\n📌 弗洛伊德也将精神分为三个部分：自我（有意识的、理性的）、本我（人最为原始的、满足本能冲动的欲望）和超我（苛刻的良知、内在道德管制者）。本我创造需求，超我为行动增添道德规范，自我通过现实判断在两者中间权衡。\n⏱ 2024-01-08 09:22:27 ^3300036670-12-2552-2654\n📌 在生活和爱情中，我们也需要有意识地面对现实，参考感性的反馈以及理性的判断，最终做出最明智的决定。中国作家郁达夫说，没有情感的理智，是无光彩的金块，而无理智的情感，是无鞍镫的野马。我们不能只凭借理性选择伴侣，也不能完全依靠感性去爱。我们不是毫无感性的钢铁之躯，也不能成为情绪和冲动的奴隶。\n⏱ 2024-01-08 09:24:51 ^3300036670-12-3070-3213\n📌 理性地看，为了公正，法官应该总是保持同一标准，无论他的状态如何。但法官也是人，人类通常难以做到完全的理性。 当你饥饿、生气、孤独或疲倦时，小心！\n⏱ 2024-01-08 09:28:50 ^3300036670-12-5674-5788\n📌 我们的理性很容易受到影响。在感情中，很常见的例子就是“分手懊悔”。和男朋友吵架，在负面情绪的高峰时刻，一气之下提出分手。第二天冷静过后，便开始后悔，发现自己其实很爱他，生活里不能没有他，明明“分手”只是一时的气话，想让他更在乎自己才做出了冲动的决定。可是，他可能已经很伤心，不想再和好了。此刻女生心痛不已、悔不当初，只是因为短暂失控的情绪而失去了一个彼此相爱的伴侣。因为失去理性，伤害了对方，也伤害了自己，更伤害了一段本应美好的感情。\n⏱ 2024-01-08 09:29:22 ^3300036670-12-5821-6038\n📌 一个有助于提高自我意识的工具——HALT（意为“停止”）。其中每个字母代表不同的状态：Hungry（饥饿），Angry（生气），Lonely（孤独），Tired（疲劳）。HALT提醒我们，在做出行为决策前，先暂停一下，观察一下自己是否感到饥饿、生气、孤独或疲倦。因为在这四种状态下，人们很容易难以自控。\n⏱ 2024-01-08 09:33:52 ^3300036670-12-6259-6410\n📌 自我意识(Self-Awareness)是对自己身心状态以及自己与客观世界关系的认识，是情商的组成部分之一￼，也是在容易冲昏头脑的爱情中，依旧得以保持理智的重要切入点。如果拥有自我意识，你就可以客观地评估自己、管理自己的情绪，使自己的行为与价值观保持一致。\n⏱ 2024-01-08 09:52:55 ^3300036670-12-7159-7448\n📌 你是自己最好的朋友，所以真的要像对待最好的朋友一般对待自己，给自己提供最佳建议。在做出决定之前先问问自己：如果我的朋友遇到了同样的问题，我会真心地给她怎样的建议？\n⏱ 2024-01-08 12:22:08 ^3300036670-12-8470-8551\n📌 当我们犯错时，总有以下两种选择：1.甩锅。犯错后的羞愧与难堪，使自己对错误不予理睬、矢口否认或寻找借口推卸责任，因而无法从错误中学习，进入“死循环”也在所难免。2.认错。接纳自己的过错，并反思到底发生了什么、是如何发生的，然后改过自新，避免再次犯同样的错误。\n⏱ 2024-01-08 21:48:54 ^3300036670-12-10735-10922\n📌 如果你的理性思维很好，那你应该很乐于寻找问题，因为发现问题会让你更接近目标。\n⏱ 2024-01-08 21:59:44 ^3300036670-12-11014-11052\n📌 自我分析是重要的，可是如果知道问题出在哪里，却什么都不做，再全面的分析也只是白费功夫。知识固然重要，但是不学以致用，对于改变现状也是没有多大帮助的。\n⏱ 2024-01-08 22:01:40 ^3300036670-12-12754-12828\n第九章 喜欢与合适是两回事 开启你的主观价值雷达 Not Everything You Like Is Good For You 📌 闪光的并不都是金子。——威廉·莎士比亚(William Shakespeare)\n⏱ 2024-01-08 22:27:51 ^3300036670-13-542-582\n📌 有时候选择一个人不是因为特别喜欢对方，而是因为太急迫地想要脱离单身的状态，或者着急结婚\n⏱ 2024-01-08 22:29:06 ^3300036670-13-1840-1883\n📌 如果客观价值指的是一个人的条件（婚姻市场价值），那么主观价值就是一个人对你的投入（情感价值）。\n⏱ 2024-01-08 22:30:29 ^3300036670-13-3185-3232\n📌 相亲节目《非诚勿扰》中的一位女嘉宾说过一句非常经典的话：“宁愿坐在宝马车里哭，也不愿坐在自行车上笑。”这就是典型的“只看客观价值”的案例。\n⏱ 2024-01-08 22:35:11 ^3300036670-13-7773-7842\n第十章 做一位聪明的投资者 喜欢那些珍惜你的人，在那些在乎你的人身上投入感情 Invest In Someone Who Invests In You 📌 女人是占主导地位的性别，男人必须做各种各样的事情来证明他们值得女人的注意。——卡米尔·帕格里亚(Camille Paglia)\n⏱ 2024-01-08 22:36:52 ^3300036670-14-564-627\n📌 我认为本章的内容是全书最重要的：喜欢那些珍惜你的人，在那些在乎你的人身上投入感情。\n⏱ 2024-01-08 22:38:37 ^3300036670-14-2280-2321\n📌 有一个很简单的原则，可以有效解决上述问题，并帮你判断一个男人的认真与靠谱程度——如果他说他爱你，就要看他的实际行动；如果他说他不爱你，他说的就是实话。\n⏱ 2024-01-08 22:46:12 ^3300036670-14-4514-4589\n📌 英国生物学家查尔斯·达尔文(Charles Darwin)把这些对于生存没有任何作用，仅仅在求偶时用以炫耀魅力的特征叫作“性装饰”(Sexual Ornaments)。\n⏱ 2024-01-08 22:47:23 ^3300036670-14-5425-5509\n📌 真爱是一段长途列车之旅。你的第一站不是“亲密关系”，同样，他的第一站也不是“一辈子的承诺”。爱情从不是一蹴而就的事，亲密关系也好，投入感情也好，无论对于你或他，都需要一个过程。两个人加深了解和互动，关系逐渐发展，他若是喜欢你，自然会逐步增加对你的投入。因此，给彼此一些相处的时间，找机会展示自己的魅力和价值，让他发觉，你就是世界上最值得他“投资的项目”。\n⏱ 2024-01-08 22:50:49 ^3300036670-14-10513-10690\n📌 如果你已经这样做了，他依然还表现得像一个小气的花匠，那么，你早晚需要亮出你的底线。\n⏱ 2024-01-08 22:51:04 ^3300036670-14-10722-10763\n第十一章 让男人害怕失去你 舍得离开的力量 Embrace The Power Of Walking Away 📌 永远别去爱一个把你当一般人对待的人。——奥斯卡·王尔德(Oscar Wilde)\n⏱ 2024-01-08 22:51:31 ^3300036670-15-524-564\n📌 许多被家暴的女人无法离开伴侣的原因之一是担心如果自己试图离开，对方威胁的后果将更加严重。除此之外，也可能是自我价值感很低、对对方有经济依赖、对对方依然有强烈的感情、因为孩子而不想破坏家庭的完整、担心家人和朋友的评头论足、被对方心理操纵等原因导致的。\n⏱ 2024-01-08 22:52:31 ^3300036670-15-1355-1479\n📌 很多时候，哪怕对方原本可能适合你，但最终他逐渐养成了一些不良的恋爱习惯（如不懂得珍惜和感恩、拒绝沟通），若是不做点什么来改变现状，这种情况只会愈演愈烈，原来的真命天子可能会慢慢变成错误的人。\n⏱ 2024-01-08 22:53:30 ^3300036670-15-1964-2059\n📌 一定要让男人害怕失去你。有时候，只有你愿意离开，他才会求你不要离开。但请别误会，舍得离开不是为了操纵对方而选的套路，不是与他玩心理游戏，也不意味着你要轻易放弃一段感情，一旦遇到问题就要转身走人。舍得离开是一种健康的心态。这种心态源自你的自信和自爱。你很清楚，如果他对你不好、待你不够认真，也很少投入感情，甚至欺骗你或者不尊重你，你舍得且愿意离开他。你敢于远离不好的恋人，有勇气走出不良的关系。这也是高价值女神的终极表现。\n⏱ 2024-01-08 22:54:10 ^3300036670-15-2197-2465\n📌 底线是由语言加行动构成的。第一步（语言）：说清楚你的底线，表明自己不接受什么样的对待。第二步（行动）：如果对方不改正他的行为，持续越界，你就会离开他。\n⏱ 2024-01-08 22:55:54 ^3300036670-15-3941-4074\n📌 舍得离开，从不是假装分手让对方挽留。舍得离开，是一种愿意将自己从一段不好的感情中抽离的真实态度，是一种鼓励他表现得越来越好的正向“危险感”。\n⏱ 2024-01-08 22:56:27 ^3300036670-15-5035-5105\n📌 在这一章中，我始终在强调要有底线、要舍得离开有害的恋情，但请不要把离开挂在嘴上。舍得离开，但不要随便离开。当你有对他不满意之处时，首先要做的是好好沟通，用平和的语气表达你的底线和感受，让他理解你的期待和需求，让他知道要怎么做才能避免失去你。\n⏱ 2024-01-08 22:57:55 ^3300036670-15-6277-6397\n📌 社会学中有一个概念叫作“最小兴趣原则”(Principle of Least Interest)——在一段关系中，投入最少或兴趣最低的一方掌握着最大的权力。\n⏱ 2024-01-08 23:02:18 ^3300036670-15-7845-7923\n📌 划定自己的底线，并不是因为你比对方更不在乎这段关系，而是因为只有在关系中被尊重，你们才能有一个更好的未来。\n⏱ 2024-01-08 23:03:25 ^3300036670-15-9398-9451\n📌 一段有害的爱情，就像一片深不见底的沼泽地，陷得越深，越无法自救。\n⏱ 2024-01-08 23:03:49 ^3300036670-15-10067-10099\nPART 4 CHOOSE WISELY 选对人 📌 你的选择决定你的命运。——文森(Vincent)\n⏱ 2024-01-09 08:21:07 ^3300036670-16-556-580\n📌 正确的选择会让你们长生不老，错误的选择会让你们就此长眠。请作出明智的选择。\n⏱ 2024-01-09 12:53:16 ^3300036670-16-1023-1060\n📌 人生是你所有选择的总和。你的选择决定着你的命运，你的择偶决定着你未来的幸福。\n⏱ 2024-01-09 12:53:48 ^3300036670-16-1345-1383\n📌 因为女人本来就对配偶更挑剔一些，并且这是好事。\n⏱ 2024-01-09 12:54:12 ^3300036670-16-1618-1641\n📌 很多女生的问题是，自己没有什么择偶标准，只看缘分，只要有眼缘，对自己好就够了，而一旦有一个这样的人出现，却不知道为什么自己怎么都不喜欢他\n⏱ 2024-01-09 21:50:09 ^3300036670-16-5618-5686\n第十三章 小心达·芬奇偏见 掌握眼高手高的FLOW Beware Of The da Vinci Bias 📌 继续找，不要放弃。千万别屈就于自己不喜欢的事。用尽所有心力去找，你会找到的。当你找到时，你的心会告诉你的。——史蒂夫·乔布斯(Steve Jobs)\n⏱ 2024-01-09 21:57:38 ^3300036670-17-520-594\n📌 你的一生中会遇到很多这样的男生，他没有白马王子的优点，也不像“渣男”和自恋狂般罪不可恕。“凑合先生”往往比较靠谱，他想和你在一起，也愿意为你付出承诺，只是没能让你怦然心动\n⏱ 2024-01-09 21:58:12 ^3300036670-17-919-1004\n📌 如果你选择与一个男人在一起，不是因为你爱他，而只是因为家人的催促、年龄的焦虑与压力，因为“我虽然对他没有什么感觉，但最起码他对我很好”，因为怕找不到更合适的人等不正确的原因，很有可能这段关系的结果不会很乐观。\n⏱ 2024-01-09 21:58:50 ^3300036670-17-1160-1264\n📌 完美的男人不真实，真实的男人不完美。\n⏱ 2024-01-09 22:02:46 ^3300036670-17-6388-6406\n第十四章 尽快淘汰错误的人 戒“渣”的艺术 Get Rid Of Mr.Wrong Fast 📌 如果一段关系不能使你成为更好的人，那你就跟错人了。——文森(Vincent)\n⏱ 2024-01-09 22:06:24 ^3300036670-18-506-544\n第十五章 莫失良机，真命天子不会永远等着你 好好珍惜你的Mr.Right Don’t Miss Mr.Right Looking for Mr.Perfect 📌 人生三大遗憾：不会选择；不坚持选择；不断地选择。——谚语\n⏱ 2024-01-09 22:38:01 ^3300036670-19-572-600\n📌 还未认识的人也并不一定比自己已经遇到的人好。这种与FOMO相关的现象叫作FOBO(Fear of a Better Option)——害怕有更好的选择综合征。\n⏱ 2024-01-10 09:13:19 ^3300036670-19-3096-3363\n📌 当你已经找到一个很适合你的人，你们互相吸引、三观吻合，并且和他在一起你很幸福，就请好好珍惜他。虽然他不完美（请记得，你也不完美），你知道世界上总会有人比他成功，但他们可能不会像他一样体贴用心；总会有人比他帅气，但他们可能不像他一样忠诚靠谱；总会有人家庭条件更好，但不一定有他的家庭和睦幸福。如果只看单一条件，总会有人比他好，但把他所有的优点堆积起来，他就很有可能超越其他竞争者，成为你的最佳选择。\n⏱ 2024-01-10 09:13:57 ^3300036670-19-3787-3985\n📌 亚里士多德说，爱情是两个身体里居住着同一个灵魂。如果与合适的另一半携手，共同成长，彼此磨合，互相帮助与支持，互相了解与进步，一起努力让感情茁壮成长，你们将会感受到，你们貌似分享着同一个灵魂。于是你们成了彼此的灵魂伴侣。缘分让你们相遇，但更重要的是，你们创造了自己的美妙爱情。\n⏱ 2024-01-10 09:16:38 ^3300036670-19-8263-8400\n📌 马斯洛需求层次理论的第三级就属于情感需求——归属和爱的需求。人人都希望得到爱、希望自己有能力爱别人，也渴望接受别人对自己的爱。如果情感需求无法得到满足，人就容易不快乐。无论其他方面多么顺利，如果没有爱或归属感，人们就容易感到孤独、自卑、焦虑和抑郁等。\n⏱ 2024-01-10 09:17:10 ^3300036670-19-9172-9484\n读书笔记 第七章 真爱没有直飞航班 掌握亲密关系的节奏 Don’t Rush Something You Want To Last Forever 划线评论 📌 想让爱情持久，就别从一开始急于一时，别让自己陷入“快餐爱情”，好的爱情值得慢慢品尝。 ^439222474-7O3MCm3yW - 💭 喜欢是乍见之欢，爱是久处不厌。 - ⏱ 2024-01-08 09:13:31\n本书评论 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%BE%AE%E4%BF%A1%E8%AF%BB%E4%B9%A6/%E5%A5%BD%E5%A5%BD%E8%B0%88%E6%81%8B%E7%88%B1%E8%AE%A9%E4%BB%96%E7%88%B1%E4%B8%8A%E4%BD%A0%E7%9A%8415%E4%B8%AA%E7%A7%98%E8%AF%80/","summary":"好好谈恋爱：让他爱上你的15个秘诀 #读书笔记 #心理 #心理学应用\n元数据 [!abstract] 好好谈恋爱：让他爱上你的15个秘诀\n书名： 好好谈恋爱：让他爱上你的15个秘诀 作者： 文森 简介： 【编辑推荐】 ★精通五国语言的情感专家为你解决情感困惑 ★作者全球粉丝量超过80万人，视频全平台播放量超过1亿次，帮助数万名女性成功解决情感困惑。 ★一本书帮你实现幸福爱情 ★书中包含150多条心理学依据、11个独创情感理论和15节恋爱必修课 【内容简介】 如果你不懂如何驾驶却要开车，安全到达目的地会很困难；同样，如果不懂如何好好谈恋爱，拥有幸福的爱情将会成为很难实现的梦想。“谈恋爱”并不是人们生来就会的本事，就像骑自行车、说一门外语或是弹钢琴，都少不了后天的学习与练习。问题是，没有人教我们“谈恋爱”这门人生必修课。 如何才能吸引你喜欢的人，让他对你动心？如何让他为你认真付出感情？如何避免被玩弄感情，提前判断出一个人是否真正适合你？如何让一段感情经久不衰？ 文森老师作为国际知名情感专家，以风趣幽默的语言、生动形象的比喻和引人入胜的案例为你提供这些问题的答案以及让女性头疼的情感困惑的解答方案。在书中，作者精心提出了诸如“长期吸引力公式”“爱情博弈论”“择偶金字塔”“达·芬奇偏见”等等15个恋爱秘诀，帮助你快速成长为高价值女神，从而收获理想的爱情。 【作者简介】 文森是西班牙情感专家，西班牙两性心理协会认证导师。他多年来深入钻研两性关系、心理学、认知行为治疗（CBT）等课题。文森老师的恋爱课程学员遍布世界五大洲，全球粉丝量超过八十万人，视频全平台播放量超过一亿次。他教授的课程已成功帮助数万名女性解决了情感问题，获得幸福爱情，也教授了若干畅销情感课程，如《聊天女王》及《男人的真相》等。 出版时间 2022-08-01 00:00:00 ISBN： 9787521627275 分类： 心理-心理学应用 出版社： 中国法制出版社有限公司 PC地址：https://weread.qq.com/web/reader/198328e0813ab74d3g010fb9 高亮划线 PART 1 ATTRACTION SECRETS 吸引力的秘密 📌 “柯立芝效应”(Coolidge Effect)这一概念，￼用来形容雄性动物对于新出现的异性有较高的交配意愿，反而会对周遭已有过交配经验的异性进入“性不应期”，在这段时间内会短暂地失去与之交配的兴趣。￼\n⏱ 2024-01-01 09:35:23 ^3300036670-5-7130-7757\n📌 女人会采用狙击枪策略。\n⏱ 2024-01-01 09:38:43 ^3300036670-5-9909-10114\n📌 男人的性策略就是机关枪策略\n⏱ 2024-01-01 09:38:51 ^3300036670-5-10227-10240\n📌 男女之间性策略的不同，也致使在两性关系中，男人往往扮演追求者、女人往往扮演筛选者的角色。男人像机关枪一样“开火”，尽可能多地追求不同的女生，直到“打中”一个。女人则像狙击手，在一堆追求者中瞄准好再“开火”，筛选出最佳人选。\n⏱ 2024-01-01 09:39:22 ^3300036670-5-10614-10725\n第二章 爱情是一件公平的事 为了得到你想要的爱情，你得配得上它 Deserve The Relationship You Want 📌 为了得到你想要的，你得先配得上它。 这个世界还没有疯狂到去奖励一群不值得的人。","tags":null,"title":""},{"categories":null,"contents":"总会过去 总会到来 #读书笔记 #个人成长 #励志成长\n元数据 [!abstract] 总会过去 总会到来\n书名： 总会过去 总会到来 作者： 王潇 简介： 继《趁早》《按自己的意愿过一生》后，励志偶像“潇洒姐”第三部人生成长故事书，这一次，她真诚袒露自己创业路上的至暗时刻，育儿、婚姻中的摸索和体悟，剖析自己如何被“别人的声音”和“自己的欲念”绑架，又如何重新梳理自己的思路，坚定地摈弃那些“连自己都不相信”的事，在喧嚣中安静地杀出一条“血路”的。她用亲身经历告诉我们一定找到并坚定信念，相信相信的力量。 出版时间 2022-09-01 00:00:00 ISBN： 9787533969530 分类： 个人成长-励志成长 出版社： 浙江文艺出版社 PC地址：https://weread.qq.com/web/reader/89f32de0813ab7297g01839c 高亮划线 第一章 盛夏的伏笔 📌 不存在完全正确的选择。 选了什么，接下来就要把它变成正确的选择。\n⏱ 2024-01-10 09:38:16 ^3300030958-4-462-551\n风华绝代 📌 热爱不是用来思辨的，热爱在思辨到来前，早就产生了。\n⏱ 2024-01-10 09:40:03 ^3300030958-7-431-456\n📌 好工作和好的恋爱一样，足够迷恋其中优美灿烂的部分，才能忍受其他时刻的煎熬，因为这两面总会相伴而生。但如果无法在心中为之尖叫和燃烧，付出就失去了根基。后来我明白，在很多时尚爱好者梦寐以求的场合，我也没有能享受当下，我总是在解决问题。\n⏱ 2024-01-10 09:38:57 ^3300030958-7-570-685\n📌 真正的生活方式是当你脱掉演出服，完全由自己来支配思想、时间、身体和金钱的时候，你到底会怎样生活。\n⏱ 2024-01-10 09:39:39 ^3300030958-7-3869-3917\n📌 我虽然远远达不到热爱的程度，但在群星闪耀时，我感激过这份工作，它让我在某几个瞬间见识到那种全情奔赴的激动。\n⏱ 2024-01-10 09:40:50 ^3300030958-7-4746-4799\n都是运动员 📌 我发现这些瞬间之中，只有很小一部分是夺冠和冲线的高光时刻，里面更多的是在记录惊慌、困惑、悲伤和恐惧，还有那些在折磨和质疑中的呼吸和哭泣，在现场被放大了数倍，真实得令人心碎。\n⏱ 2024-01-10 09:41:15 ^3300030958-8-3711-3797\n📌 原来真正厉害的人，装备都隐退了，手中已无剑，本身就是剑锋。\n⏱ 2024-01-10 09:41:35 ^3300030958-8-5015-5044\n📌 人本身最美，运动最时尚，健康最奢侈。\n⏱ 2024-01-10 09:41:53 ^3300030958-8-5978-5996\n沙田马场 📌 “您应该用这个时代最大的效率，去做自己一直想做的事。”\n⏱ 2024-01-10 09:42:10 ^3300030958-9-431-487\n第二章 忒修斯之船 📌 人切不可从事自己都不相信的东西。\n⏱ 2024-01-10 09:42:29 ^3300030958-10-462-478\n死亡概率 📌 “命运是事后回顾的东西，不是事先知道的东西。”\n⏱ 2024-01-10 09:43:23 ^3300030958-14-431-483\n午夜修罗场 📌 “最重要的是活着。活着才能说话，才能讲出自己的故事。无论如何先活着。”\n⏱ 2024-01-10 09:44:02 ^3300030958-15-432-467\n📌 此时的痛苦是无人诉说的，可以放声大哭，因为大海会淹没所有，包括你认为的珍贵和希望。庞大的世界对这答案漠不关心，一切都是沧海一鳞。\n⏱ 2024-01-10 09:43:39 ^3300030958-15-621-685\n赌上明天 📌 包括曾有句鸡汤文说，感到艰难，就说明走的是上坡路。\n⏱ 2024-01-10 09:44:22 ^3300030958-18-1512-1537\n📌 已在谷底，便觉得没什么可失去的了，光脚的不怕穿鞋的，剩下的全都是赤子之心。\n⏱ 2024-01-10 09:44:46 ^3300030958-18-4027-4064\n灵魂委员会 📌 一个人能到达的程度，基本上受限于两点，第一是见没见过，第二是敢不敢。\n⏱ 2024-01-10 09:45:08 ^3300030958-19-1626-1660\n科学变红 📌 公子颜如玉，城北徐公，或者潘安之貌，应该大抵如此。\n⏱ 2024-01-10 09:45:25 ^3300030958-20-6754-6779\n万般皆好 📌 很明显，早期的遗愿清单看似是对美好世界的探寻，实则是对向往生活的缝合模仿。内心认定这些事似乎值得玩，因为很多厉害的人都去玩了；如果自己也玩过，届时人生必定丰富多彩。至于到底好不好玩，那肯定是试了才知道的，毕竟生命的要义只取决于体验者本人。\n⏱ 2024-01-10 09:45:47 ^3300030958-22-2047-2166\n出厂设定 📌 好的表达只需要朴素平实，不需要大词新词，说普通人听得懂的话，用简单的语言就能讲清复杂的道理。\n⏱ 2024-01-10 09:46:11 ^3300030958-28-3020-3066\n高手常温 📌 每个人原来都只是大时代背景下的小人物。几堂课加上几顿聚餐垫底，你就找到自己是谁了。就算你拼了命为创造美好的微观小环境而努力，宏观大环境才是你的根本土壤。\n⏱ 2024-01-10 09:50:49 ^3300030958-34-663-739\n📌 如果进展不确定，夜灯初上的时候，人就会陷入一种低郁的状态，压力和烦躁像棉絮一样飞散在空气里。\n⏱ 2024-01-10 09:46:28 ^3300030958-34-981-1027\n读书笔记 本书评论 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%BE%AE%E4%BF%A1%E8%AF%BB%E4%B9%A6/%E6%80%BB%E4%BC%9A%E8%BF%87%E5%8E%BB-%E6%80%BB%E4%BC%9A%E5%88%B0%E6%9D%A5/","summary":"总会过去 总会到来 #读书笔记 #个人成长 #励志成长\n元数据 [!abstract] 总会过去 总会到来\n书名： 总会过去 总会到来 作者： 王潇 简介： 继《趁早》《按自己的意愿过一生》后，励志偶像“潇洒姐”第三部人生成长故事书，这一次，她真诚袒露自己创业路上的至暗时刻，育儿、婚姻中的摸索和体悟，剖析自己如何被“别人的声音”和“自己的欲念”绑架，又如何重新梳理自己的思路，坚定地摈弃那些“连自己都不相信”的事，在喧嚣中安静地杀出一条“血路”的。她用亲身经历告诉我们一定找到并坚定信念，相信相信的力量。 出版时间 2022-09-01 00:00:00 ISBN： 9787533969530 分类： 个人成长-励志成长 出版社： 浙江文艺出版社 PC地址：https://weread.qq.com/web/reader/89f32de0813ab7297g01839c 高亮划线 第一章 盛夏的伏笔 📌 不存在完全正确的选择。 选了什么，接下来就要把它变成正确的选择。\n⏱ 2024-01-10 09:38:16 ^3300030958-4-462-551\n风华绝代 📌 热爱不是用来思辨的，热爱在思辨到来前，早就产生了。\n⏱ 2024-01-10 09:40:03 ^3300030958-7-431-456\n📌 好工作和好的恋爱一样，足够迷恋其中优美灿烂的部分，才能忍受其他时刻的煎熬，因为这两面总会相伴而生。但如果无法在心中为之尖叫和燃烧，付出就失去了根基。后来我明白，在很多时尚爱好者梦寐以求的场合，我也没有能享受当下，我总是在解决问题。\n⏱ 2024-01-10 09:38:57 ^3300030958-7-570-685\n📌 真正的生活方式是当你脱掉演出服，完全由自己来支配思想、时间、身体和金钱的时候，你到底会怎样生活。\n⏱ 2024-01-10 09:39:39 ^3300030958-7-3869-3917\n📌 我虽然远远达不到热爱的程度，但在群星闪耀时，我感激过这份工作，它让我在某几个瞬间见识到那种全情奔赴的激动。\n⏱ 2024-01-10 09:40:50 ^3300030958-7-4746-4799\n都是运动员 📌 我发现这些瞬间之中，只有很小一部分是夺冠和冲线的高光时刻，里面更多的是在记录惊慌、困惑、悲伤和恐惧，还有那些在折磨和质疑中的呼吸和哭泣，在现场被放大了数倍，真实得令人心碎。\n⏱ 2024-01-10 09:41:15 ^3300030958-8-3711-3797\n📌 原来真正厉害的人，装备都隐退了，手中已无剑，本身就是剑锋。","tags":null,"title":""},{"categories":null,"contents":"摄影与心理学 #读书笔记 #艺术 #摄影\n元数据 [!abstract] 摄影与心理学\n书名： 摄影与心理学 作者： 陈磊编著 简介： 对于摄影初学者最大的烦恼莫过于，看到美丽的景物，可是拍下来的照片却与自己想象的结果大相径庭。本书从视觉心理学的角度去分析摄影者进行创作的过程。本书共分为4章，第一章探讨了格式塔与摄影三原则，即照片表现的主题，怎样把注意力吸引到主体上，如何使画面简洁，第二章探讨了格式塔的视觉原理即闭合性、连续性、相似性、接近性以及共同命运性等，了解这一点对于构图非常有帮助。第三章讨论了讨对主体形象的把握，它对拍摄效果的影响更为实际有效。第四章则研究了摄影对于色彩的要求，什么是真实的色彩，哪些是我们需要的色彩。本书探讨了心理学对于摄影的影响，了解了我们头脑中映射的图像和现实图像之间的差距，我们如何去从现实中提炼出我们头脑中的理想影像，这对于摄影创作大有裨益。本书适合摄影爱好者和职业摄影师学习参考。 出版时间 2021-03-01 00:00:00 ISBN： 9787115530530 分类： 艺术-摄影 出版社： 人民邮电出版社 PC地址：https://weread.qq.com/web/reader/00f32bb072323bc100faac6 高亮划线 1.2 大脑中的“美图秀秀” 📌 眼中看到的和大脑中显现的图像是不一样的。人的眼睛观察到的是全面的景物，而大脑只呈现特定的、美化了的部分形象。\n⏱ 2024-01-08 19:13:59 ^36846529-8-1778-1832\n1.4 人脑黑箱 📌 自然界本不存在形象/背景关系，而是由大脑的选择组织起了这种关系。\n⏱ 2024-01-08 19:23:52 ^36846529-10-7431-7463\n1.6 主体突出——让主体与背景分离 📌 有经验的摄影师要有意识地运用构图的艺术手段——让主体与背景区分出来，并突出主体，弱化背景。\n⏱ 2024-01-10 09:22:48 ^36846529-12-610-655\n📌 在摄影技术上，让主体与背景分离，手段有很多。常用的有以下几种：\n对准主体对焦，让主体更清晰； 使用大光圈虚化背景； 让主体在更重要的位置； 利用明暗对比，比如主体明亮，背景阴暗； 利用色彩对比，让主体与背景颜色有所区别； 还可以使用摄影后期手段，来区分主体与背景。 ⏱ 2024-01-10 09:23:07 ^36846529-12-657-879\n📌 科学的脚步太快，抛下了感情和心灵。\n⏱ 2024-01-10 09:24:02 ^36846529-12-4185-4202\n2.1 再探格式塔 📌 如果画面中的局部凌乱无关联，则会使整体含义丧失。\n⏱ 2024-01-10 12:13:55 ^36846529-17-4242-4266\n2.4 相似性 📌 心理学的趣味就在这里，看着舒服，符合规则但缺少创意；看着奇怪，破坏规则，反而引人注意\n⏱ 2024-01-10 12:24:01 ^36846529-20-4961-5003\n2.5 接近性 📌 两个或多个视觉元素越接近，它们被看成一组、一种图形或一个整体的可能性就越大。\n⏱ 2024-01-10 12:24:38 ^36846529-21-878-916\n📌 因此，如果主体是复数或是分成几个部分，则最好让它们更接近，更趋于成为一个整体。\n⏱ 2024-01-10 12:24:50 ^36846529-21-1100-1139\n📌 同样是一家人，人物充满画面，没有什么环境背景，导致我们会仔细观察每个人的面貌特征，人物的个体性突显，家庭的整体性相应地下降了\n⏱ 2024-01-10 12:26:08 ^36846529-21-4318-4380\n📌 虽然一家人之间站得稍微分散开，但画面留有很大的空间，其中还包含了小岛作为陪衬景物，于是家庭的整体性被大大加强了\n⏱ 2024-01-10 12:26:21 ^36846529-21-4883-4938\n2.6 共同命运性 📌 当代的科学知识，尤其是那些前沿知识，需要有大量的、多层级的知识储备才能理解。就像想要登上金字塔尖，必须经过每一层台阶。\n⏱ 2024-01-10 12:32:44 ^36846529-22-4462-4521\n2.7 心物同型论 📌 外形形制一致的景物在大脑中会形成同型刺激，从而会触发同样的感受，或引发同样的想法。\n⏱ 2024-01-10 12:34:37 ^36846529-23-581-622\n3.1 摄影的形状 📌 人在观察明暗交界处时会感到亮处更亮、暗处更暗。而且这只是一种主观上的边缘对比效应，在现实中并不存在，所以称为虚幻的。\n⏱ 2024-01-10 15:33:54 ^36846529-25-3962-4020\n📌 设计的三要素是画面、图形与背景空间。 画面：边框所包围的空间； 图形：画面中的形状； 背景空间：形状以外的画面空间。\n⏱ 2024-01-10 15:34:45 ^36846529-25-4891-5093\n3.2 现形术——发现最美的形状 📌 在日常拍摄中，最需要敏锐地发现以下两种最基本的形状：圆形和方形。\n⏱ 2024-01-10 21:58:39 ^36846529-26-551-583\n3.3 移形术——找到最佳的位置 📌 画面：边框所包容的空间，也就是取景框里的空间； 图形：画面里的形状，主要是主体的外部形状； 背景：图形以外的画面空间，主体周边的画面空间。\n⏱ 2024-01-10 22:07:51 ^36846529-27-501-673\n3.5 多形变术——构建最丰富的画面 📌 组合的规则不仅加强了构图的纯形式效果，而且加强了构图的象征意义。 ——《艺术与视知觉》\n⏱ 2024-01-10 22:46:24 ^36846529-29-4747-4831\n📌 越走近我们自己的时代，就越难以分辨什么是持久的成就，什么是短暂的时尚。 ——《艺术的事》\n⏱ 2024-01-10 22:47:34 ^36846529-29-7613-7698\n4.1 摄影怎样还原真实的色彩 📌 我们依旧怀念田园乡村，因为我们偏好不变；我们抱怨城市生活，因为我们害怕改变\n⏱ 2024-01-10 22:52:33 ^36846529-31-14051-14088\n4.2 自然的神奇色 📌 自然风光摄影家最喜欢的是日出，不仅仅是为了拍摄日出，还为观察日出，欣赏日出，进而为日出所震撼、折服。普通人欣赏日出，大多为了太阳跃出地平线的震撼一刻，而摄影人会从星耀的凌晨开始，欣赏天边不断变化的色彩。等待的过程最美\n⏱ 2024-01-10 22:55:34 ^36846529-32-917-1025\n结束语 📌 越喜欢摄影，越觉得它的丰富。它不但带人走遍千山万水，看尽人世沧桑；它还会引领人深入观察、了解与思考，从而让人有所领悟。无论是过程还是结果，这份满足感是最大的回报。\n⏱ 2024-01-10 22:58:14 ^36846529-33-772-853\n读书笔记 本书评论 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%BE%AE%E4%BF%A1%E8%AF%BB%E4%B9%A6/%E6%91%84%E5%BD%B1%E4%B8%8E%E5%BF%83%E7%90%86%E5%AD%A6/","summary":"摄影与心理学 #读书笔记 #艺术 #摄影\n元数据 [!abstract] 摄影与心理学\n书名： 摄影与心理学 作者： 陈磊编著 简介： 对于摄影初学者最大的烦恼莫过于，看到美丽的景物，可是拍下来的照片却与自己想象的结果大相径庭。本书从视觉心理学的角度去分析摄影者进行创作的过程。本书共分为4章，第一章探讨了格式塔与摄影三原则，即照片表现的主题，怎样把注意力吸引到主体上，如何使画面简洁，第二章探讨了格式塔的视觉原理即闭合性、连续性、相似性、接近性以及共同命运性等，了解这一点对于构图非常有帮助。第三章讨论了讨对主体形象的把握，它对拍摄效果的影响更为实际有效。第四章则研究了摄影对于色彩的要求，什么是真实的色彩，哪些是我们需要的色彩。本书探讨了心理学对于摄影的影响，了解了我们头脑中映射的图像和现实图像之间的差距，我们如何去从现实中提炼出我们头脑中的理想影像，这对于摄影创作大有裨益。本书适合摄影爱好者和职业摄影师学习参考。 出版时间 2021-03-01 00:00:00 ISBN： 9787115530530 分类： 艺术-摄影 出版社： 人民邮电出版社 PC地址：https://weread.qq.com/web/reader/00f32bb072323bc100faac6 高亮划线 1.2 大脑中的“美图秀秀” 📌 眼中看到的和大脑中显现的图像是不一样的。人的眼睛观察到的是全面的景物，而大脑只呈现特定的、美化了的部分形象。\n⏱ 2024-01-08 19:13:59 ^36846529-8-1778-1832\n1.4 人脑黑箱 📌 自然界本不存在形象/背景关系，而是由大脑的选择组织起了这种关系。\n⏱ 2024-01-08 19:23:52 ^36846529-10-7431-7463\n1.6 主体突出——让主体与背景分离 📌 有经验的摄影师要有意识地运用构图的艺术手段——让主体与背景区分出来，并突出主体，弱化背景。\n⏱ 2024-01-10 09:22:48 ^36846529-12-610-655\n📌 在摄影技术上，让主体与背景分离，手段有很多。常用的有以下几种：\n对准主体对焦，让主体更清晰； 使用大光圈虚化背景； 让主体在更重要的位置； 利用明暗对比，比如主体明亮，背景阴暗； 利用色彩对比，让主体与背景颜色有所区别； 还可以使用摄影后期手段，来区分主体与背景。 ⏱ 2024-01-10 09:23:07 ^36846529-12-657-879\n📌 科学的脚步太快，抛下了感情和心灵。\n⏱ 2024-01-10 09:24:02 ^36846529-12-4185-4202\n2.1 再探格式塔 📌 如果画面中的局部凌乱无关联，则会使整体含义丧失。","tags":null,"title":""},{"categories":null,"contents":"摄影入门：教你轻松拍大片 #读书笔记 #艺术 #摄影\n元数据 [!abstract] 摄影入门：教你轻松拍大片\n书名： 摄影入门：教你轻松拍大片 作者： 张晨曦 简介： 本书是一部面向大众的摄影教程，从摄影的基本概念出发，系统、全面地讲述了摄影的基础知识和技艺，包括购置和使用相机、曝光控制、动感的表现、景深控制、摄影构图、摄影用光、色彩、影调、质感、手机摄影、相机与镜头、辅助器材、风光摄影、花卉摄影、人像摄影等，对近几年流行的新技术和新方法进行了论述，如景深合成、曝光合成、向右曝光、堆栈技术、星野摄影等。本书知识架构层次清晰，逐层展开，讲解简练、细致、到位，插图精美，图文并茂，全书重点和关键词都用彩字突显，一目了然。 本书可作为初级入门摄影爱好者的自学参考书，也可作为高等院校摄影课以及各种摄影培训的教材。 出版时间 2018-03-01 00:00:00 ISBN： 9787302489092 分类： 艺术-摄影 出版社： 清华大学出版社 PC地址：https://weread.qq.com/web/reader/ba8325b07161e59bba81d1d 高亮划线 第9章 色彩、影调、质感 📌 色彩的三要素如下： （1）色别（色相）。指出具体是哪种颜色。 （2）明度。色彩的明暗、深浅程度。 （3）饱和度（纯度）。颜色的纯度和鲜艳程度。 它们是鉴别和评价色彩的主要依据。\n⏱ 2024-01-06 08:40:22 ^23192987-70-1411-1711\n读书笔记 本书评论 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%BE%AE%E4%BF%A1%E8%AF%BB%E4%B9%A6/%E6%91%84%E5%BD%B1%E5%85%A5%E9%97%A8%E6%95%99%E4%BD%A0%E8%BD%BB%E6%9D%BE%E6%8B%8D%E5%A4%A7%E7%89%87/","summary":"摄影入门：教你轻松拍大片 #读书笔记 #艺术 #摄影\n元数据 [!abstract] 摄影入门：教你轻松拍大片\n书名： 摄影入门：教你轻松拍大片 作者： 张晨曦 简介： 本书是一部面向大众的摄影教程，从摄影的基本概念出发，系统、全面地讲述了摄影的基础知识和技艺，包括购置和使用相机、曝光控制、动感的表现、景深控制、摄影构图、摄影用光、色彩、影调、质感、手机摄影、相机与镜头、辅助器材、风光摄影、花卉摄影、人像摄影等，对近几年流行的新技术和新方法进行了论述，如景深合成、曝光合成、向右曝光、堆栈技术、星野摄影等。本书知识架构层次清晰，逐层展开，讲解简练、细致、到位，插图精美，图文并茂，全书重点和关键词都用彩字突显，一目了然。 本书可作为初级入门摄影爱好者的自学参考书，也可作为高等院校摄影课以及各种摄影培训的教材。 出版时间 2018-03-01 00:00:00 ISBN： 9787302489092 分类： 艺术-摄影 出版社： 清华大学出版社 PC地址：https://weread.qq.com/web/reader/ba8325b07161e59bba81d1d 高亮划线 第9章 色彩、影调、质感 📌 色彩的三要素如下： （1）色别（色相）。指出具体是哪种颜色。 （2）明度。色彩的明暗、深浅程度。 （3）饱和度（纯度）。颜色的纯度和鲜艳程度。 它们是鉴别和评价色彩的主要依据。\n⏱ 2024-01-06 08:40:22 ^23192987-70-1411-1711\n读书笔记 本书评论 ","tags":null,"title":""},{"categories":null,"contents":"星期六晚我们去散步吧 #读书笔记 #文学 #现代诗歌\n元数据 [!abstract] 星期六晚我们去散步吧\n书名： 星期六晚我们去散步吧 作者： 隔花人 简介： 世间万物都有它自己的生命和生存的意义，花有花的语言，风有风的方向，种子有种子的选择，每个与你相遇的人都有他出现的理由。作者以童真的视角，将大多数人忽略的美好一一落笔成诗。 ·这本诗集很轻，三言两语自成宇宙， 这本诗集很重，千山万水装满心事。 每个人都是诗人，每个诗人都是孩子。 ·全书共收录作者136首诗集，作者以童真的视角，直接、清晰、简单、灵动的写下当下年轻人的内心问题、人生困惑以及生活中那些被大多数人忽略的美好。配以简单、黑白且有寓意的漫画，引起当下年轻人的喜欢和思考。 出版时间 2023-03-01 00:00:00 ISBN： 9787221176165 分类： 文学-现代诗歌 出版社： 贵州人民出版社 PC地址：https://weread.qq.com/web/reader/d59326c0813ab7bbdg017221 高亮划线 自我 📌 自我 灯在墙上的投影 也是一盏灯 如果它不打开自己 便看不清自己 ￼\n⏱ 2024-01-04 19:12:07 ^3300054377-153-339-685\n无聊的大多数 📌 无聊的大多数 重复的日子 是在日历上签到 每一天都力透纸背 每一天都在等待报废\n⏱ 2024-01-04 18:38:56 ^3300054377-160-339-495\n温水 📌 温水 嚼了很久口香糖 才发现没味道 日子过得没滋没味 也是过了很久才发现的 ￼\n⏱ 2024-01-04 19:12:51 ^3300054377-161-339-690\n路灯 📌 路灯 它弯着腰 想要抚摸我的头 我一言不发 用光洗了个澡 ￼\n⏱ 2024-01-04 19:13:36 ^3300054377-167-339-681\n纸 📌 纸 如果写得不好 就是在浪费彼此的一生\n⏱ 2024-01-04 19:13:45 ^3300054377-168-339-417\n雨刷 📌 雨刷 下雨的时候 我才能和你挥手 因为阳光会把我的胆怯 照得一览无余 ￼\n⏱ 2024-01-04 19:14:03 ^3300054377-171-339-687\n感冒药 📌 感冒药 想你 一天三次 每次十秒 谨遵医嘱 只对你感冒 ￼\n⏱ 2024-01-04 19:14:23 ^3300054377-176-339-709\n日记本 📌 日记本 秘密并不知道 自己的秘密在第几页 主人公也常常忘了 哪个缩写是主角\n⏱ 2024-01-04 19:14:33 ^3300054377-177-339-493\n红绿灯 📌 红绿灯 路人以为 绿灯和红灯永远不可能相遇 相爱的人却说 黄灯时他们融为一体\n⏱ 2024-01-05 09:10:36 ^3300054377-183-339-494\n错位 📌 错位 椅子也快忘记 自己的主人 是堆满的脏衣服 还是堆满脏衣服的人\n⏱ 2024-01-05 09:10:58 ^3300054377-187-339-489\n沙滩的清洁人员 📌 沙滩的清洁人员 海水来来去去 为了清理人类的脚印\n⏱ 2024-01-05 09:11:31 ^3300054377-193-339-422\n喜放 📌 喜放 当花学会照镜子 世界就又盛开了 一朵花\n⏱ 2024-01-05 09:11:46 ^3300054377-195-339-449\n黑屏 📌 黑屏 我们以为看见了星星 其实是灰尘蒙了眼睛\n⏱ 2024-01-05 09:12:01 ^3300054377-197-339-420\n伤心后遗症 📌 伤心后遗症 城市规划师的感情 被画了一个叉 就在市中心 造了一个十字路口 供许多人分道扬镳\n⏱ 2024-01-05 09:12:36 ^3300054377-200-339-530\n独角戏 📌 独角戏 梦里的我向自己求救 醒醒吧 别做梦了\n⏱ 2024-01-05 09:13:07 ^3300054377-205-339-449\n作息规律 📌 作息规律 我没有早上 也没有晚上 我只在中午出门买饭时 和世界见一面\n⏱ 2024-01-05 09:14:32 ^3300054377-219-339-490\n一个人 📌 一个人 我一个人吃饭 读书、坐车、看病 没有人认识我 真好 我刚到这座新城市就学会了隐身的魔法\n⏱ 2024-01-05 09:15:04 ^3300054377-224-339-532\n失眠 📌 失眠 我什么都不想想 就这样想着 想到了天亮\n⏱ 2024-01-05 09:15:34 ^3300054377-229-339-646\n失手 📌 失手 想住进你眼里 一见钟情 却成为你影子 离不开你\n⏱ 2024-01-05 09:16:19 ^3300054377-246-339-482\n有空吗 📌 有空吗 你不来 世界是空的 你来 我是有空的\n⏱ 2024-01-05 09:17:10 ^3300054377-256-339-478\n心事 📌 心事 心门打开 把话搬出来说 一上称 轻了五斤多\n⏱ 2024-01-05 09:17:21 ^3300054377-257-339-677\n后来 📌 后来 黑与白是一种比较级 你关上灯 光才照进来 你不爱了 才学会了爱\n⏱ 2024-01-05 09:18:12 ^3300054377-282-339-519\n生存 📌 生存 爱是零食 不是粮食 你什么时候来 我都不会饿死\n⏱ 2024-01-05 09:18:21 ^3300054377-284-339-482\n读书笔记 本书评论 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%BE%AE%E4%BF%A1%E8%AF%BB%E4%B9%A6/%E6%98%9F%E6%9C%9F%E5%85%AD%E6%99%9A%E6%88%91%E4%BB%AC%E5%8E%BB%E6%95%A3%E6%AD%A5%E5%90%A7/","summary":"星期六晚我们去散步吧 #读书笔记 #文学 #现代诗歌\n元数据 [!abstract] 星期六晚我们去散步吧\n书名： 星期六晚我们去散步吧 作者： 隔花人 简介： 世间万物都有它自己的生命和生存的意义，花有花的语言，风有风的方向，种子有种子的选择，每个与你相遇的人都有他出现的理由。作者以童真的视角，将大多数人忽略的美好一一落笔成诗。 ·这本诗集很轻，三言两语自成宇宙， 这本诗集很重，千山万水装满心事。 每个人都是诗人，每个诗人都是孩子。 ·全书共收录作者136首诗集，作者以童真的视角，直接、清晰、简单、灵动的写下当下年轻人的内心问题、人生困惑以及生活中那些被大多数人忽略的美好。配以简单、黑白且有寓意的漫画，引起当下年轻人的喜欢和思考。 出版时间 2023-03-01 00:00:00 ISBN： 9787221176165 分类： 文学-现代诗歌 出版社： 贵州人民出版社 PC地址：https://weread.qq.com/web/reader/d59326c0813ab7bbdg017221 高亮划线 自我 📌 自我 灯在墙上的投影 也是一盏灯 如果它不打开自己 便看不清自己 ￼\n⏱ 2024-01-04 19:12:07 ^3300054377-153-339-685\n无聊的大多数 📌 无聊的大多数 重复的日子 是在日历上签到 每一天都力透纸背 每一天都在等待报废\n⏱ 2024-01-04 18:38:56 ^3300054377-160-339-495\n温水 📌 温水 嚼了很久口香糖 才发现没味道 日子过得没滋没味 也是过了很久才发现的 ￼\n⏱ 2024-01-04 19:12:51 ^3300054377-161-339-690\n路灯 📌 路灯 它弯着腰 想要抚摸我的头 我一言不发 用光洗了个澡 ￼","tags":null,"title":""},{"categories":null,"contents":"瓦尔登湖 #读书笔记 #文学 #散文杂著\n元数据 [!abstract] 瓦尔登湖\n书名： 瓦尔登湖 作者： 亨利·戴维·梭罗 简介： 《瓦尔登湖》是美国作家梭罗独居瓦尔登湖畔的记录，描绘了他两年多时间里的所见、所闻和所思。 1845年3月，梭罗来到瓦尔登湖，动手搭建一座十英尺宽、十五英尺长的小木屋；7月4日，也就是美国的独立纪念日，终于如愿以偿地开始了那段在后世成为传奇的独居生活。两年后，他带着在湖边生活时完成的书稿，永远地离开了那座亲手所建的木屋。之后七年间七易其稿，直到1854年8月9日才正式出版。 出版时间 2013-07-01 00:00:00 ISBN： 9787201082134 分类： 文学-散文杂著 出版社： 天津人民出版社 PC地址：https://weread.qq.com/web/reader/0af32e00813ab77f7g0103c3 高亮划线 生计 📌 人只有想起自己的无知才能有长进，但他如此忙于使用已有的知识，又如何能想得起来呢？\n⏱ 2024-01-08 18:46:57 ^3300044710-4-5187-5227\n📌 人性最美好的品质就像水果表皮的白霜，只有通过最谨慎的处理才能得到保留。然而我们无论对待自己，还是对待他人，都不曾如此温柔。\n⏱ 2024-01-08 18:47:42 ^3300044710-4-5265-5326\n📌 大多数人生活在无言的绝望中。所谓的委曲求全其实是积重难返的绝望。你们从绝望的城市走进绝望的乡村，只能以水貂皮和麝鼠皮做成的华贵服装来自我安慰。就连各种所谓的游戏和娱乐，也隐藏着一种反复出现然而谁也没有察觉的绝望。这些游戏和娱乐并不愉快，因为它们是在工作之后才出现的。但智慧的特征之一就是不去做绝望的事。\n⏱ 2024-01-08 18:52:26 ^3300044710-4-7317-7468\n📌 没有哪种思考或做事的方式，无论它是多么的古老，值得我们盲目地去跟从。\n⏱ 2024-01-08 18:54:36 ^3300044710-4-7772-7806\n📌 身处文明社会的我们其实应该到蛮荒的边疆去生活，才能更好地了解什么是生活的必需品，\n⏱ 2024-01-08 18:57:13 ^3300044710-4-11548-11588\n读书笔记 本书评论 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%BE%AE%E4%BF%A1%E8%AF%BB%E4%B9%A6/%E7%93%A6%E5%B0%94%E7%99%BB%E6%B9%96/","summary":"瓦尔登湖 #读书笔记 #文学 #散文杂著\n元数据 [!abstract] 瓦尔登湖\n书名： 瓦尔登湖 作者： 亨利·戴维·梭罗 简介： 《瓦尔登湖》是美国作家梭罗独居瓦尔登湖畔的记录，描绘了他两年多时间里的所见、所闻和所思。 1845年3月，梭罗来到瓦尔登湖，动手搭建一座十英尺宽、十五英尺长的小木屋；7月4日，也就是美国的独立纪念日，终于如愿以偿地开始了那段在后世成为传奇的独居生活。两年后，他带着在湖边生活时完成的书稿，永远地离开了那座亲手所建的木屋。之后七年间七易其稿，直到1854年8月9日才正式出版。 出版时间 2013-07-01 00:00:00 ISBN： 9787201082134 分类： 文学-散文杂著 出版社： 天津人民出版社 PC地址：https://weread.qq.com/web/reader/0af32e00813ab77f7g0103c3 高亮划线 生计 📌 人只有想起自己的无知才能有长进，但他如此忙于使用已有的知识，又如何能想得起来呢？\n⏱ 2024-01-08 18:46:57 ^3300044710-4-5187-5227\n📌 人性最美好的品质就像水果表皮的白霜，只有通过最谨慎的处理才能得到保留。然而我们无论对待自己，还是对待他人，都不曾如此温柔。\n⏱ 2024-01-08 18:47:42 ^3300044710-4-5265-5326\n📌 大多数人生活在无言的绝望中。所谓的委曲求全其实是积重难返的绝望。你们从绝望的城市走进绝望的乡村，只能以水貂皮和麝鼠皮做成的华贵服装来自我安慰。就连各种所谓的游戏和娱乐，也隐藏着一种反复出现然而谁也没有察觉的绝望。这些游戏和娱乐并不愉快，因为它们是在工作之后才出现的。但智慧的特征之一就是不去做绝望的事。\n⏱ 2024-01-08 18:52:26 ^3300044710-4-7317-7468\n📌 没有哪种思考或做事的方式，无论它是多么的古老，值得我们盲目地去跟从。\n⏱ 2024-01-08 18:54:36 ^3300044710-4-7772-7806\n📌 身处文明社会的我们其实应该到蛮荒的边疆去生活，才能更好地了解什么是生活的必需品，\n⏱ 2024-01-08 18:57:13 ^3300044710-4-11548-11588\n读书笔记 本书评论 ","tags":null,"title":""},{"categories":null,"contents":"色彩 #读书笔记 #艺术 #绘画\n元数据 [!abstract] 色彩\n书名： 色彩 作者： 王海燕 杜建伟 简介： 《色彩》教材侧重于写生色彩，从色彩基础理论到色彩写生的观察方法和具体的表现技法全面展开。本书共分为6章：第1章主要介绍色彩基础理论，包括色彩的产生、绘画色彩的分类、绘画色彩基础、色彩的心理与联想；第2章介绍色彩的对比与和谐；第3章介绍色彩写生的表现方式，色彩的透视规律，色彩写生构图，色彩写生的观察与表现，写生色彩变化的一般规律以及色彩的临摹与默写；第4章介绍色彩静物写生的具体方法；第5章介绍色彩风景写生，包括色彩风景速写，色彩风景写生步骤，天空、山水、建筑等的画法，并针对学生容易出现的问题如色彩调配、写生中常见的问题等方面一一列举了解决的方法；第6章是优秀作品欣赏，包括国外大师的色彩风景、静物写生，还有国内当代有代表性画家的色彩写生作品，以供读者开阔眼界并作为临摹的范本。《色彩》面向美术学和设计专业的大学本科生学习而编写，适合本科、高职高专等院校美术相关专业的学生学习参考，也适合热爱色彩写生的美术爱好者进行自学参考。 出版时间 2018-09-01 00:00:00 ISBN： 9787122321909 分类： 艺术-绘画 出版社： 化学工业出版社 PC地址：https://weread.qq.com/web/reader/1a932420718998231a9fbf9 高亮划线 第1章 色彩基础理论 📌 有彩色系是由光的波长和振幅决定的，波长决定色相，振幅决定色调。有彩色系的颜色都具有三个基本特征：色相、纯度、明度。\n⏱ 2024-01-10 12:09:11 ^25794595-5-1379-1436\n📌 色彩的明度可用黑白度来表示，越接近白色，明度越高；越接近黑色，明度越低。黑与白作为颜料，可以调节物体色的反射率，使物体色提高明度或降低明度。\n⏱ 2024-01-10 12:10:29 ^25794595-5-1955-2025\n📌 无彩色系的颜色只有一种基本性质——明度。\n⏱ 2024-01-10 21:57:06 ^25794595-5-2054-2074\n📌 从表现方式上，色彩主要分为写生色彩、装饰色彩、主观色彩、意象色彩4大类型\n⏱ 2024-01-10 21:57:21 ^25794595-5-2131-2167\n读书笔记 本书评论 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%BE%AE%E4%BF%A1%E8%AF%BB%E4%B9%A6/%E8%89%B2%E5%BD%A9/","summary":"色彩 #读书笔记 #艺术 #绘画\n元数据 [!abstract] 色彩\n书名： 色彩 作者： 王海燕 杜建伟 简介： 《色彩》教材侧重于写生色彩，从色彩基础理论到色彩写生的观察方法和具体的表现技法全面展开。本书共分为6章：第1章主要介绍色彩基础理论，包括色彩的产生、绘画色彩的分类、绘画色彩基础、色彩的心理与联想；第2章介绍色彩的对比与和谐；第3章介绍色彩写生的表现方式，色彩的透视规律，色彩写生构图，色彩写生的观察与表现，写生色彩变化的一般规律以及色彩的临摹与默写；第4章介绍色彩静物写生的具体方法；第5章介绍色彩风景写生，包括色彩风景速写，色彩风景写生步骤，天空、山水、建筑等的画法，并针对学生容易出现的问题如色彩调配、写生中常见的问题等方面一一列举了解决的方法；第6章是优秀作品欣赏，包括国外大师的色彩风景、静物写生，还有国内当代有代表性画家的色彩写生作品，以供读者开阔眼界并作为临摹的范本。《色彩》面向美术学和设计专业的大学本科生学习而编写，适合本科、高职高专等院校美术相关专业的学生学习参考，也适合热爱色彩写生的美术爱好者进行自学参考。 出版时间 2018-09-01 00:00:00 ISBN： 9787122321909 分类： 艺术-绘画 出版社： 化学工业出版社 PC地址：https://weread.qq.com/web/reader/1a932420718998231a9fbf9 高亮划线 第1章 色彩基础理论 📌 有彩色系是由光的波长和振幅决定的，波长决定色相，振幅决定色调。有彩色系的颜色都具有三个基本特征：色相、纯度、明度。\n⏱ 2024-01-10 12:09:11 ^25794595-5-1379-1436\n📌 色彩的明度可用黑白度来表示，越接近白色，明度越高；越接近黑色，明度越低。黑与白作为颜料，可以调节物体色的反射率，使物体色提高明度或降低明度。\n⏱ 2024-01-10 12:10:29 ^25794595-5-1955-2025\n📌 无彩色系的颜色只有一种基本性质——明度。\n⏱ 2024-01-10 21:57:06 ^25794595-5-2054-2074\n📌 从表现方式上，色彩主要分为写生色彩、装饰色彩、主观色彩、意象色彩4大类型\n⏱ 2024-01-10 21:57:21 ^25794595-5-2131-2167\n读书笔记 本书评论 ","tags":null,"title":""},{"categories":null,"contents":"霍乱时期的爱情 #读书笔记 #文学 #外国文学\n元数据 [!abstract] 霍乱时期的爱情\n书名： 霍乱时期的爱情 作者： [哥]加西亚•马尔克斯 简介： 多年以后，当胡维纳尔乌尔比诺医生翻看霍乱时期的记录，发现父亲所采用的方法，仁爱多于科学。他的勤奋，他的牺牲精神，尤其是他个人的胆识，这一切都让他无愧于这座城市从灾难中死而复生后给予他的那些荣耀，他的名字理所应当和那些不计其数的战争英雄列在一起，因为比起这场战斗，那些战争可能要不光彩得多。《霍乱时期的爱情》，一本讲述战争、时疫、分别与重逢的暖心杰作，献给此时此刻的我们。 出版时间 2020-03-01 00:00:00 ISBN： 9787544297059 分类： 文学-外国文学 出版社： 南海出版公司 PC地址：https://weread.qq.com/web/reader/99632b00719376c6996d2d2 高亮划线 4 📌 她辩解说，爱情，首先是一种本能，“要么生下来就会，要么永远都不会”。\n⏱ 2024-01-10 18:23:09 ^26441414-17-29324-29358\n📌 两个几乎完全互不了解的人，没有任何血缘关系，性格不同，文化不同，甚至性别都不相同，却突然间不得不承诺生活在一起，睡在同一张床上，分享彼此也许注定有所分歧的命运，这一切本身就是完全违背科学的。\n⏱ 2024-01-10 18:24:02 ^26441414-17-38541-38636\n📌 婚姻的问题在于，它终结于每晚做爱之后，却在第二天早餐之前又必须重新建立起来。\n⏱ 2024-01-10 18:23:45 ^26441414-17-38640-38678\n📌 有时，他们从疯狂的节日庆典回到家，在门后伺机而动的怀旧之情也会一下子将他们扑倒在地，于是就会有一次美妙的爆发，一切又回到往昔，五分钟后，他们就又像蜜月中连门襟都无暇扣上的恋人们一样了。\n⏱ 2024-01-10 18:24:32 ^26441414-17-39088-39180\n📌 她用一种更为简单的方式为它下了定义：“社交生活的关键在于学会控制恐惧，夫妻生活的关键在于学会控制厌恶。”\n⏱ 2024-01-10 18:25:25 ^26441414-17-40339-40391\n5 📌 可以不忠，但不可背信弃义\n⏱ 2024-01-10 18:26:55 ^26441414-18-38624-38636\n6 📌 一个世纪前，人们毁掉了我和这个可怜男人的生活，因为我们太年轻；现在，他们又想在我们身上故伎重施，因为我们太老了。\n⏱ 2024-01-10 18:27:29 ^26441414-19-39220-39276\n读书笔记 本书评论 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%BE%AE%E4%BF%A1%E8%AF%BB%E4%B9%A6/%E9%9C%8D%E4%B9%B1%E6%97%B6%E6%9C%9F%E7%9A%84%E7%88%B1%E6%83%85/","summary":"霍乱时期的爱情 #读书笔记 #文学 #外国文学\n元数据 [!abstract] 霍乱时期的爱情\n书名： 霍乱时期的爱情 作者： [哥]加西亚•马尔克斯 简介： 多年以后，当胡维纳尔乌尔比诺医生翻看霍乱时期的记录，发现父亲所采用的方法，仁爱多于科学。他的勤奋，他的牺牲精神，尤其是他个人的胆识，这一切都让他无愧于这座城市从灾难中死而复生后给予他的那些荣耀，他的名字理所应当和那些不计其数的战争英雄列在一起，因为比起这场战斗，那些战争可能要不光彩得多。《霍乱时期的爱情》，一本讲述战争、时疫、分别与重逢的暖心杰作，献给此时此刻的我们。 出版时间 2020-03-01 00:00:00 ISBN： 9787544297059 分类： 文学-外国文学 出版社： 南海出版公司 PC地址：https://weread.qq.com/web/reader/99632b00719376c6996d2d2 高亮划线 4 📌 她辩解说，爱情，首先是一种本能，“要么生下来就会，要么永远都不会”。\n⏱ 2024-01-10 18:23:09 ^26441414-17-29324-29358\n📌 两个几乎完全互不了解的人，没有任何血缘关系，性格不同，文化不同，甚至性别都不相同，却突然间不得不承诺生活在一起，睡在同一张床上，分享彼此也许注定有所分歧的命运，这一切本身就是完全违背科学的。\n⏱ 2024-01-10 18:24:02 ^26441414-17-38541-38636\n📌 婚姻的问题在于，它终结于每晚做爱之后，却在第二天早餐之前又必须重新建立起来。\n⏱ 2024-01-10 18:23:45 ^26441414-17-38640-38678\n📌 有时，他们从疯狂的节日庆典回到家，在门后伺机而动的怀旧之情也会一下子将他们扑倒在地，于是就会有一次美妙的爆发，一切又回到往昔，五分钟后，他们就又像蜜月中连门襟都无暇扣上的恋人们一样了。\n⏱ 2024-01-10 18:24:32 ^26441414-17-39088-39180\n📌 她用一种更为简单的方式为它下了定义：“社交生活的关键在于学会控制恐惧，夫妻生活的关键在于学会控制厌恶。”\n⏱ 2024-01-10 18:25:25 ^26441414-17-40339-40391\n5 📌 可以不忠，但不可背信弃义\n⏱ 2024-01-10 18:26:55 ^26441414-18-38624-38636\n6 📌 一个世纪前，人们毁掉了我和这个可怜男人的生活，因为我们太年轻；现在，他们又想在我们身上故伎重施，因为我们太老了。\n⏱ 2024-01-10 18:27:29 ^26441414-19-39220-39276\n读书笔记 本书评论 ","tags":null,"title":""},{"categories":null,"contents":"香水（同名电影原著） #读书笔记 #文学 #外国文学\n元数据 [!abstract] 香水（同名电影原著）\n书名： 香水（同名电影原著） 作者： 帕·聚斯金德 简介： 豆瓣8.5分高分电影《香水》原著。格雷诺耶出生在巴黎最臭的鱼市上。他天生没有体味，而嗅觉却异常灵敏。长大后他成了巴黎一香水大师的学徒，从而也渐渐产生了用香水征服世界的野心。一天，他发现一少女的气味令人着迷，无意中杀死了该少女，并嗅光了她的体香。之后，他先后杀死了26个少女，萃取了她们的体昧，并蒸馏出神奇的香水。当他的罪行败露，被押赴刑场时，他释放了一瓶奇特的香水…… 出版时间 2016-10-01 00:00:00 ISBN： 9787532745449 分类： 文学-外国文学 出版社： 上海译文出版社 PC地址：https://weread.qq.com/web/reader/4e5324a0716b071b4e588ff 高亮划线 11 📌 人的不幸来源于他不肯安分守己地呆在自己应呆的房间里。\n⏱ 2024-01-10 09:48:29 ^23791387-69-4007-4033\n📌 目光所及，到处都是一派狂热病似的忙碌景象。男男女女都在读书。教士们蹲在咖啡馆里。若是警察进行干预，抓了这些高级坏蛋中的一个并把他投入监狱，那么出版商们就大声疾呼，递上申请书，上流社会的先生们和女士们就施加他们的影响，直至警察在几周之后又把这个高级坏蛋释放，或是把他流放到外国，而他在那儿又可以不受阻碍地撰写论战性的小册子。\n⏱ 2024-01-10 09:48:48 ^23791387-69-4538-4699\n📌 购买桥上的房子是个错误，而购买坐落在桥西侧的房子，更是个双重的错误。如今他经常望着奔流而去的河水。他觉得，他自己、他的房子以及他在几十年中赚得的财产，仿佛像河水一样流去。\n⏱ 2024-01-10 09:49:10 ^23791387-69-5707-5792\n读书笔记 本书评论 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%BE%AE%E4%BF%A1%E8%AF%BB%E4%B9%A6/%E9%A6%99%E6%B0%B4%E5%90%8C%E5%90%8D%E7%94%B5%E5%BD%B1%E5%8E%9F%E8%91%97/","summary":"香水（同名电影原著） #读书笔记 #文学 #外国文学\n元数据 [!abstract] 香水（同名电影原著）\n书名： 香水（同名电影原著） 作者： 帕·聚斯金德 简介： 豆瓣8.5分高分电影《香水》原著。格雷诺耶出生在巴黎最臭的鱼市上。他天生没有体味，而嗅觉却异常灵敏。长大后他成了巴黎一香水大师的学徒，从而也渐渐产生了用香水征服世界的野心。一天，他发现一少女的气味令人着迷，无意中杀死了该少女，并嗅光了她的体香。之后，他先后杀死了26个少女，萃取了她们的体昧，并蒸馏出神奇的香水。当他的罪行败露，被押赴刑场时，他释放了一瓶奇特的香水…… 出版时间 2016-10-01 00:00:00 ISBN： 9787532745449 分类： 文学-外国文学 出版社： 上海译文出版社 PC地址：https://weread.qq.com/web/reader/4e5324a0716b071b4e588ff 高亮划线 11 📌 人的不幸来源于他不肯安分守己地呆在自己应呆的房间里。\n⏱ 2024-01-10 09:48:29 ^23791387-69-4007-4033\n📌 目光所及，到处都是一派狂热病似的忙碌景象。男男女女都在读书。教士们蹲在咖啡馆里。若是警察进行干预，抓了这些高级坏蛋中的一个并把他投入监狱，那么出版商们就大声疾呼，递上申请书，上流社会的先生们和女士们就施加他们的影响，直至警察在几周之后又把这个高级坏蛋释放，或是把他流放到外国，而他在那儿又可以不受阻碍地撰写论战性的小册子。\n⏱ 2024-01-10 09:48:48 ^23791387-69-4538-4699\n📌 购买桥上的房子是个错误，而购买坐落在桥西侧的房子，更是个双重的错误。如今他经常望着奔流而去的河水。他觉得，他自己、他的房子以及他在几十年中赚得的财产，仿佛像河水一样流去。\n⏱ 2024-01-10 09:49:10 ^23791387-69-5707-5792\n读书笔记 本书评论 ","tags":null,"title":""},{"categories":null,"contents":"高性能MySQL（第4版） #读书笔记 #计算机 #数据库\n元数据 [!abstract] 高性能MySQL（第4版）\n书名： 高性能MySQL（第4版） 作者： Silvia Botros Jeremy Tinley 简介： 《高性能 MySQL》一直是 MySQL 领域的经典之作，影响了一代又一代的 DBA 和技术人员，从第3 版出版到第 4 版出版过去了近十年，MySQL 也从 5.5 版本更新到了 8.0 版本。第 4 版中增加了大量对 MySQL 5.7 和 8.0 版本新特性的介绍，删除了一些在新版本中已经废弃或者不再常用的功能，还增加了对云数据库的介绍，减少了在官方文档中已有的基础使用和配置相关的内容。这些年，MySQL 经过在大量大规模互联网场景中的应用验证，使得本书在继续关注高性能之外，还用了较多的篇幅来介绍如何实现 MySQL 的大规模可扩展应用和合规性问题，这是相比第 3 版最大的不同，也是本书封面上所写的“经过大规模运维验证的策略”的体现。本书适合数据库管理员（DBA）阅读，也适合系统运维和开发人员参考学习。不管你是数据库新手还是专家，相信都能从本书中有所收获。 出版时间 2022-09-01 00:00:00 ISBN： 9787121442575 分类： 计算机-数据库 出版社： 电子工业出版社 PC地址：https://weread.qq.com/web/reader/00a32b70813ab746fg018ec7 高亮划线 第6章 schema设计与管理 📌 DATETIME和TIMESAMP列可以存储相同类型的数据：时间和日期，精确到秒。然而TIMESTAMP只使用DATETIME一半的存储空间，还会根据时区变化，而且具有特殊的自动更新能力。另一方面，TIMESTAMP允许的时间范围要小得多，有时候它的特殊能力会成为障碍。\n⏱ 2024-01-02 14:32:36 ^3300035678-16-2521-2656\n📌 MySQL可以为整数类型指定宽度，例如，INT(11)，这对大多数应用毫无意义：它不会限制值的合法范围，只是规定了MySQL的一些交互工具（例如，MySQL命令行客户端）用来显示字符的个数。对于存储和计算来说，INT(1)和INT(20)是相同的。\n⏱ 2024-01-02 14:36:30 ^3300035678-16-3741-3865\n📌 在一些大容量的场景，可以考虑使用BIGINT代替DECIMAL，将需要存储的货币单位根据小数的位数乘以相应的倍数即可。假设要存储财务数据并精确到万分之一分，则可以把所有金额乘以一百万，然后将结果存储在BIGINT里，这样可以同时避免浮点存储计算不精确和DECIMAL精确计算代价高的问题。\n⏱ 2024-01-02 14:39:40 ^3300035678-16-4511-4655\n📌 CHAR适合存储非常短的字符串，或者适用于所有值的长度都几乎相同的情况\n⏱ 2024-01-02 14:43:07 ^3300035678-16-6006-6041\n📌 MySQL不能将BLOB和TEXT数据类型的完整字符串放入索引，也不能使用索引进行排序。\n⏱ 2024-01-02 14:48:25 ^3300035678-16-8643-8687\n📌 对于完全“随机”的字符串要非常小心，如MD5()、SHA1()或UUID()生成的字符串。这些函数生成的新值会任意分布在很大的空间内，这会减慢INSERT和某些类型的SELECT查询的速度：\n⏱ 2024-01-08 11:50:13 ^3300035678-16-23460-23660\n📌 如果存储通用唯一标识符(UUID)值，则应该删除破折号，或者更好的做法是，使用UNHEX()函数将UUID值转换为16字节的数字，并将其存储在一个BINARY(16)列中。可以使用HEX()函数以十六进制格式检索值。\n⏱ 2024-01-08 11:50:57 ^3300035678-16-24001-24109\n📌 MySQL提供了INET_ATON()和INET_NTOA()函数来在这两种表示形式之间进行转换。使用的空间从VARCHAR(15)的约16字节缩减到无符号32位整数的4字节。如果你担心数据库的可读性，不想继续使用函数查看行数据，请记住MySQL有视图，可以使用视图来简化数据查看的复杂性。\n⏱ 2024-01-08 11:53:01 ^3300035678-16-25001-25146\n📌 即使需要在表中存储事实上的“空值”，也可能不需要使用NULL。也许可以使用0、特殊值或空字符串作为代替。\n⏱ 2024-01-08 12:00:23 ^3300035678-16-27090-27142\n第7章 创建高性能的索引 📌 在MySQL中，索引是在存储引擎层而不是服务器层实现的\n⏱ 2024-01-09 17:08:36 ^3300035678-17-2261-2288\n📌 InnoDB则使用的是B+tree\n⏱ 2024-01-09 17:09:32 ^3300035678-17-3003-3020\n📌 自适应哈希索引。InnoDB存储引擎有一个被称为自适应哈希索引的特性。当InnoDB发现某些索引值被非常频繁地被访问时，它会在原有的B-tree索引之上，在内存中再构建一个哈希索引。\n⏱ 2024-01-09 17:12:21 ^3300035678-17-4702-4793\n📌 B-tree索引通常可以支持“只访问索引的查询”，即查询只需要访问索引，而无须访问数据行。后面我们将单独讨论这种“覆盖索引”的优化。\n⏱ 2024-01-09 17:13:22 ^3300035678-17-5844-5910\n📌 ●索引大大减少了服务器需要扫描的数据量。 ●索引可以帮助服务器避免排序和临时表。 ●索引可以将随机I/O变为顺序I/O。\n⏱ 2024-01-09 17:28:43 ^3300035678-17-7486-7602\n📌 “三星系统”(three-star system)评价体系，用以判断一个索引是不是适合某个查询语句：索引将相关的记录放到一起则获得“一星”；如果索引中的数据顺序和查找中的排列顺序一致则获得“二星”；如果索引中的列包含了查询中需要的全部列则获得“三星”。\n⏱ 2024-01-09 17:30:21 ^3300035678-17-7897-8023\n📌 有时候为了提升索引的性能，同时也节省索引空间，可以只对字段的前一部分字符进行索引，这样做的缺点是，会降低索引的选择性。索引的选择性是指，不重复的索引值（也称为基数，cardinality）和数据表的记录总数(＃T)的比值，范围从1/＃T到1之间。索引的选择性越高则查询效率越高\n⏱ 2024-01-09 17:31:46 ^3300035678-17-8636-8774\n📌 对于BLOB、TEXT或者很长的VARCHAR类型的列，必须使用前缀索引，因为MySQL并不支持对这些列的完整内容进行索引。\n⏱ 2024-01-09 17:32:25 ^3300035678-17-8892-8954\n📌 查询显示，当前缀长度到达7的时候，再增加前缀长度，选择性提升的幅度已经很小了。\n⏱ 2024-01-09 17:34:34 ^3300035678-17-11189-11228\n📌 MySQL无法使用前缀索引做ORDER BY和GROUP BY操作，也无法使用前缀索引做覆盖扫描。\n⏱ 2024-01-09 17:35:32 ^3300035678-17-12081-12130\n📌 使用UNION改写查询，往往是最好的办法。 ^3300035678-17-14062-14083\n💭 And条件使用联合索引，or条件建议使用union - ⏱ 2024-01-09 17:41:33 📌 如果在EXPLAIN中看到有索引合并，那么就应该好好检查一下查询语句的写法和表的结构，看是不是已经是最优的。\n⏱ 2024-01-09 17:48:52 ^3300035678-17-14112-14166\n读书笔记 第7章 创建高性能的索引 划线评论 📌 使用UNION改写查询，往往是最好的办法。 ^439222474-7O5Qdd6db - 💭 And条件使用联合索引，or条件建议使用union - ⏱ 2024-01-09 17:41:44\n本书评论 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%BE%AE%E4%BF%A1%E8%AF%BB%E4%B9%A6/%E9%AB%98%E6%80%A7%E8%83%BDmysql%E7%AC%AC4%E7%89%88/","summary":"高性能MySQL（第4版） #读书笔记 #计算机 #数据库\n元数据 [!abstract] 高性能MySQL（第4版）\n书名： 高性能MySQL（第4版） 作者： Silvia Botros Jeremy Tinley 简介： 《高性能 MySQL》一直是 MySQL 领域的经典之作，影响了一代又一代的 DBA 和技术人员，从第3 版出版到第 4 版出版过去了近十年，MySQL 也从 5.5 版本更新到了 8.0 版本。第 4 版中增加了大量对 MySQL 5.7 和 8.0 版本新特性的介绍，删除了一些在新版本中已经废弃或者不再常用的功能，还增加了对云数据库的介绍，减少了在官方文档中已有的基础使用和配置相关的内容。这些年，MySQL 经过在大量大规模互联网场景中的应用验证，使得本书在继续关注高性能之外，还用了较多的篇幅来介绍如何实现 MySQL 的大规模可扩展应用和合规性问题，这是相比第 3 版最大的不同，也是本书封面上所写的“经过大规模运维验证的策略”的体现。本书适合数据库管理员（DBA）阅读，也适合系统运维和开发人员参考学习。不管你是数据库新手还是专家，相信都能从本书中有所收获。 出版时间 2022-09-01 00:00:00 ISBN： 9787121442575 分类： 计算机-数据库 出版社： 电子工业出版社 PC地址：https://weread.qq.com/web/reader/00a32b70813ab746fg018ec7 高亮划线 第6章 schema设计与管理 📌 DATETIME和TIMESAMP列可以存储相同类型的数据：时间和日期，精确到秒。然而TIMESTAMP只使用DATETIME一半的存储空间，还会根据时区变化，而且具有特殊的自动更新能力。另一方面，TIMESTAMP允许的时间范围要小得多，有时候它的特殊能力会成为障碍。\n⏱ 2024-01-02 14:32:36 ^3300035678-16-2521-2656\n📌 MySQL可以为整数类型指定宽度，例如，INT(11)，这对大多数应用毫无意义：它不会限制值的合法范围，只是规定了MySQL的一些交互工具（例如，MySQL命令行客户端）用来显示字符的个数。对于存储和计算来说，INT(1)和INT(20)是相同的。\n⏱ 2024-01-02 14:36:30 ^3300035678-16-3741-3865\n📌 在一些大容量的场景，可以考虑使用BIGINT代替DECIMAL，将需要存储的货币单位根据小数的位数乘以相应的倍数即可。假设要存储财务数据并精确到万分之一分，则可以把所有金额乘以一百万，然后将结果存储在BIGINT里，这样可以同时避免浮点存储计算不精确和DECIMAL精确计算代价高的问题。\n⏱ 2024-01-02 14:39:40 ^3300035678-16-4511-4655","tags":null,"title":""},{"categories":null,"contents":"杂七杂八 #读书笔记\n经学家看见《易》，道学家看见淫，才子看见缠绵，高官家看见排满，流言家看见宫闱秘事 见天地，见众生，见自己 别嫌弃教你妈妈用手机，她曾经教你用筷子 你终会明白，前途比爱情重要，你还会明白，爱情比前途更难得，但最后你会明白，对的人会站在你的前途里 想要瓦解一个民族，只要抽掉男人的脊梁和血性，拿走女人的廉耻和善良，社会风气坏了，几代人也难以修复 如果个体的困顿和集体无关，那集体的荣辱又与个体有什么关系呢 智者不入爱河，建设美丽祖国 正应了那句古话，人死王八活。摇身一变，成正经人了。池边一蹲充了龙王，抹点锅底灰楞充灶王爷，乍一看还真看不出个子午寅卯来。可盐从哪咸醋打哪酸，脸一抹拉这日子就想重新过了，是两撇的都明白，那不可能 虽然说强扭的瓜不甜，但有的时候我并不在乎它甜不甜。我只想把它扭下来，扭下来我就高兴了 所谓有趣的灵魂，实际上就是这个人的信息密度和知识层面，都远高于你。并愿俯下身去听你说那毫无营养的废话和你交流，提出一些你没有听过的观点，颠覆了你短浅的想象力及三观 此去经年，应是良辰好景虚设。便纵有千种风情，更与何人说 没事，只不过一切恢复原状罢了，我本来就是一无所有的 在人海里相遇的人，终究要还给人海 我感到难过不是因为你欺骗了我，而是因为我再也不能相信你了 我以为爱情可以填满人生的遗憾，然而制造更多遗憾的却偏偏是爱情 太阳不是突然下山的，而所有的离开都是蓄谋已久 世上存在着不能流泪的悲伤，这种悲伤无法向人解释，即使解释人家也不会理解，它永远一成不变，如无风夜晚的雪花，静静沉在心底 我注意过，即使是那些声称\u0026quot;一切都是命中注定的，而我们无力改变\u0026quot;的人，在过马路时都会左右看 乞丐不会嫉妒百万富翁，但是他肯定会嫉妒收入更高的乞丐 情不知所起，一往而深 欲买桂花同载酒，终不似，少年游 聊美国不聊福利高科技，聊越南不聊人权收入低。聊日本着重聊军国主义，聊国际就谈巴铁好兄弟。北欧各国挨冻缺天然气，美国遍地是罪犯和枪击。日韩西瓜和牛肉吃不起，加拿大明显美国的小弟。若要拿出事实讲些道理，定是阁下生活不太如意 新的资产阶级发展壮大了起来，底层还在幻想他们自己消灭自己 人的欲望，就如同高山滚石一般，一旦开始，就再也停不下来了 小时候家的北边有一个铁匠叫苏大哥，虽然有一些矛盾，但有忙也会帮，看到苏大哥在修自行车，我就笑了，苏大哥也笑着说，笑什么笑，将来你比我还能修 看到苏大哥修自行车，我笑了，苏大哥说: 你笑牛魔酬宾，你爸给你留的自行车比我的还容易坏，你将来修得更狠 君子生非异也，善假于物也 尊重历史发展规律，客观事实不会改变，自然环境恶劣动物就会停止繁殖 西晋在永嘉之乱中，整个社会上弥漫着废晋弃晋的气氛，有人想自立山头，有人想南下避难，有人依附胡人，唯独没有一个人想拯救大晋 因为害怕失望，索性就不再抱有期望 每次坦诚去对待别人后不出意外又被上了一课 并不是所有人都拥有自救的能力，长年累月形成的自卑，敏感，焦虑，不是说顿悟一下就能自信起来的，这需要一个极其漫长的过程并且不能中断，一但中断那种感觉就像是被人拉了一把后又眼睁睁看着自己摔下去 曾经有一段低谷期，我每天至少读一小时，有时一天三到四小时。我一直相信阅读会让我的生活变得更好，让我越来越强大。然而后来我发现，我似乎读书是为了逃避社交和生活，所以我通过阅读麻痹自己，生活依旧没有越变越好，问题仍然存在 人和人刚分开的时候，其实是没有痛感的，那时候更多的是错愕，那份痛苦会随着时间的推移，在每个回忆袭来的瞬间跑出来吞噬你，完完全全地吞噬，一条街道、一首歌、一种气味，都足以成为凌迟你的凶器 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/","summary":"杂七杂八 #读书笔记\n经学家看见《易》，道学家看见淫，才子看见缠绵，高官家看见排满，流言家看见宫闱秘事 见天地，见众生，见自己 别嫌弃教你妈妈用手机，她曾经教你用筷子 你终会明白，前途比爱情重要，你还会明白，爱情比前途更难得，但最后你会明白，对的人会站在你的前途里 想要瓦解一个民族，只要抽掉男人的脊梁和血性，拿走女人的廉耻和善良，社会风气坏了，几代人也难以修复 如果个体的困顿和集体无关，那集体的荣辱又与个体有什么关系呢 智者不入爱河，建设美丽祖国 正应了那句古话，人死王八活。摇身一变，成正经人了。池边一蹲充了龙王，抹点锅底灰楞充灶王爷，乍一看还真看不出个子午寅卯来。可盐从哪咸醋打哪酸，脸一抹拉这日子就想重新过了，是两撇的都明白，那不可能 虽然说强扭的瓜不甜，但有的时候我并不在乎它甜不甜。我只想把它扭下来，扭下来我就高兴了 所谓有趣的灵魂，实际上就是这个人的信息密度和知识层面，都远高于你。并愿俯下身去听你说那毫无营养的废话和你交流，提出一些你没有听过的观点，颠覆了你短浅的想象力及三观 此去经年，应是良辰好景虚设。便纵有千种风情，更与何人说 没事，只不过一切恢复原状罢了，我本来就是一无所有的 在人海里相遇的人，终究要还给人海 我感到难过不是因为你欺骗了我，而是因为我再也不能相信你了 我以为爱情可以填满人生的遗憾，然而制造更多遗憾的却偏偏是爱情 太阳不是突然下山的，而所有的离开都是蓄谋已久 世上存在着不能流泪的悲伤，这种悲伤无法向人解释，即使解释人家也不会理解，它永远一成不变，如无风夜晚的雪花，静静沉在心底 我注意过，即使是那些声称\u0026quot;一切都是命中注定的，而我们无力改变\u0026quot;的人，在过马路时都会左右看 乞丐不会嫉妒百万富翁，但是他肯定会嫉妒收入更高的乞丐 情不知所起，一往而深 欲买桂花同载酒，终不似，少年游 聊美国不聊福利高科技，聊越南不聊人权收入低。聊日本着重聊军国主义，聊国际就谈巴铁好兄弟。北欧各国挨冻缺天然气，美国遍地是罪犯和枪击。日韩西瓜和牛肉吃不起，加拿大明显美国的小弟。若要拿出事实讲些道理，定是阁下生活不太如意 新的资产阶级发展壮大了起来，底层还在幻想他们自己消灭自己 人的欲望，就如同高山滚石一般，一旦开始，就再也停不下来了 小时候家的北边有一个铁匠叫苏大哥，虽然有一些矛盾，但有忙也会帮，看到苏大哥在修自行车，我就笑了，苏大哥也笑着说，笑什么笑，将来你比我还能修 看到苏大哥修自行车，我笑了，苏大哥说: 你笑牛魔酬宾，你爸给你留的自行车比我的还容易坏，你将来修得更狠 君子生非异也，善假于物也 尊重历史发展规律，客观事实不会改变，自然环境恶劣动物就会停止繁殖 西晋在永嘉之乱中，整个社会上弥漫着废晋弃晋的气氛，有人想自立山头，有人想南下避难，有人依附胡人，唯独没有一个人想拯救大晋 因为害怕失望，索性就不再抱有期望 每次坦诚去对待别人后不出意外又被上了一课 并不是所有人都拥有自救的能力，长年累月形成的自卑，敏感，焦虑，不是说顿悟一下就能自信起来的，这需要一个极其漫长的过程并且不能中断，一但中断那种感觉就像是被人拉了一把后又眼睁睁看着自己摔下去 曾经有一段低谷期，我每天至少读一小时，有时一天三到四小时。我一直相信阅读会让我的生活变得更好，让我越来越强大。然而后来我发现，我似乎读书是为了逃避社交和生活，所以我通过阅读麻痹自己，生活依旧没有越变越好，问题仍然存在 人和人刚分开的时候，其实是没有痛感的，那时候更多的是错愕，那份痛苦会随着时间的推移，在每个回忆袭来的瞬间跑出来吞噬你，完完全全地吞噬，一条街道、一首歌、一种气味，都足以成为凌迟你的凶器 ","tags":null,"title":""},{"categories":null,"contents":"火的精神分析 #读书笔记\n当我们谈论某客体，我们就会以为自己是客观的。但是，在我我们最初的选择中，与其说我们指定客体，不如说客体指定着我们，并且我们相信：我们对于世界的基本思想往往是一些有关我们的精神青春的机密。（P 44） ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%81%AB%E7%9A%84%E7%B2%BE%E7%A5%9E%E5%88%86%E6%9E%90/","summary":"火的精神分析 #读书笔记\n当我们谈论某客体，我们就会以为自己是客观的。但是，在我我们最初的选择中，与其说我们指定客体，不如说客体指定着我们，并且我们相信：我们对于世界的基本思想往往是一些有关我们的精神青春的机密。（P 44） ","tags":null,"title":""},{"categories":null,"contents":"眩晕 #读书笔记\n在这样的冲动过后，一股模糊的焦虑感开始涌上心头，我感到一阵恶心和眩晕。我尝试捕捉的画面失去了轮廓，我的思想在我还未能确切地把握之前就瓦解了。当我不得不依靠着墙壁甚至躲到门道里，虽然有时担心会陷入瘫痪或脑疾发作，我却想不出任何其他抵御的方法，除了一直行走到深夜，直到筋疲力尽为止。（P 30） ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%9C%A9%E6%99%95/","summary":"眩晕 #读书笔记\n在这样的冲动过后，一股模糊的焦虑感开始涌上心头，我感到一阵恶心和眩晕。我尝试捕捉的画面失去了轮廓，我的思想在我还未能确切地把握之前就瓦解了。当我不得不依靠着墙壁甚至躲到门道里，虽然有时担心会陷入瘫痪或脑疾发作，我却想不出任何其他抵御的方法，除了一直行走到深夜，直到筋疲力尽为止。（P 30） ","tags":null,"title":""},{"categories":null,"contents":"羽蛇 #读书笔记\n人必须重生。斩断生活的毒须，驱走堕落的巨蛇，那曾被毁坏的脆弱的生活必须获得新的存在（P 48） \u0026hellip; 在精美而发着音乐声的寂静里，独自面对自己展开的灵魂（P 48） ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/my_notes/notes/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%BE%BD%E8%9B%87/","summary":"羽蛇 #读书笔记\n人必须重生。斩断生活的毒须，驱走堕落的巨蛇，那曾被毁坏的脆弱的生活必须获得新的存在（P 48） \u0026hellip; 在精美而发着音乐声的寂静里，独自面对自己展开的灵魂（P 48） ","tags":null,"title":""}]