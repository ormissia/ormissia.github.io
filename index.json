[{"categories":null,"contents":"基础类型内存宽度以及表示范围 bool\n1Byte true/false uint8\n1Byte 0-255 uint16\n2Byte 0-65535 uint32\n4Byte 0-4294967295 uint64\n8Byte 0-18446744073709551615 int8\n1Byte -128-127 int16\n2Byte -32768-32767 int32\n4Byte -2147483648-2147483647 int64\n6Byte -9223372036854775808-9223372036854775807 byte\n1Byte 类似 uint8 rune\n4Byte 类似 int32 uint\n4Byte / 8Byte 32 或 64 位 int\n4Byte / 8Byte 与 uint 一样大小 float32\n4Byte float64\n8Byte string\n1Byte （英文） / 2Byte-4Byte（中文，取决于字符编码类型）     切片拼接 slice1 := []int{0, 1, 2, 3} slice2 := []int{3, 4, 5} slice1 = append(slice1, slice2...) fmt.Println(slice1) //[0 1 2 3 3 4 5]     bit Byte bit：计算机记忆的最小单位，一个bit可以代表0或1\nByte：一个Byte由8bits所组成\n1Byte=8Bits\n1KB=1024Bytes\n    ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/go/basic/basic/","summary":"基础类型内存宽度以及表示范围 bool\n1Byte true/false uint8\n1Byte 0-255 uint16\n2Byte 0-65535 uint32\n4Byte 0-4294967295 uint64\n8Byte 0-18446744073709551615 int8\n1Byte -128-127 int16\n2Byte -32768-32767 int32\n4Byte -2147483648-2147483647 int64\n6Byte -9223372036854775808-9223372036854775807 byte\n1Byte 类似 uint8 rune\n4Byte 类似 int32 uint\n4Byte / 8Byte 32 或 64 位 int\n4Byte / 8Byte 与 uint 一样大小 float32\n4Byte float64\n8Byte string\n1Byte （英文） / 2Byte-4Byte（中文，取决于字符编码类型）     切片拼接 slice1 := []int{0, 1, 2, 3} slice2 := []int{3, 4, 5} slice1 = append(slice1, slice2.","tags":null,"title":"Basic"},{"categories":null,"contents":"时间转换 字符串转时间\ntime.Parse() 时间转字符串\ntime.Format() 时间转时间戳\nTime.Unix() 时间戳转时间\ntime.Unix()     计时 朴素方法\nstartTime := time.Now() //do something \ttime.Sleep(time.Second) duration := time.Since(startTime) fmt.Printf(\u0026#34;经过时间：%v\\n\u0026#34;, duration) //经过时间：1.005046959s   简洁方法\n// TimeCost 耗时统计函数 func TimeCost(start time.Time) { duration := time.Since(start) fmt.Printf(\u0026#34;经过时间：%v\\n\u0026#34;, duration) } defer TimeCost(time.Now()) //do something \ttime.Sleep(time.Second) //经过时间：1.005054375s   优雅方法\n// TimeCost 耗时统计函数 func TimeCost() func() { start := time.Now() return func() { duration := time.Since(start) fmt.Printf(\u0026#34;经过时间：%v\\n\u0026#34;, duration) } } defer TimeCost()() //do something \ttime.Sleep(time.Second) //经过时间：1.005033916s     时间的加减法 // Add 时间相加 \tnow := time.Now() // ParseDuration parses a duration string. \t// A duration string is a possibly signed sequence of decimal numbers, \t// each with optional fraction and a unit suffix, \t// such as \u0026#34;300ms\u0026#34;, \u0026#34;-1.5h\u0026#34; or \u0026#34;2h45m\u0026#34;. \t// Valid time units are \u0026#34;ns\u0026#34;, \u0026#34;us\u0026#34; (or \u0026#34;µs\u0026#34;), \u0026#34;ms\u0026#34;, \u0026#34;s\u0026#34;, \u0026#34;m\u0026#34;, \u0026#34;h\u0026#34;. \t// 10分钟前 \tm, _ := time.ParseDuration(\u0026#34;-1m\u0026#34;) m1 := now.Add(m) fmt.Println(m1) // 8个小时前 \th, _ := time.ParseDuration(\u0026#34;-1h\u0026#34;) h1 := now.Add(8 * h) fmt.Println(h1) // 一天前 \td, _ := time.ParseDuration(\u0026#34;-24h\u0026#34;) d1 := now.Add(d) fmt.Println(d1) // 10分钟后 \tmm, _ := time.ParseDuration(\u0026#34;1m\u0026#34;) mm1 := now.Add(mm) fmt.Println(mm1) // 8小时后 \thh, _ := time.ParseDuration(\u0026#34;1h\u0026#34;) hh1 := now.Add(hh) fmt.Println(hh1) // 一天后 \tdd, _ := time.ParseDuration(\u0026#34;24h\u0026#34;) dd1 := now.Add(dd) fmt.Println(dd1) // Sub 计算两个时间差 \tsubM := now.Sub(m1) fmt.Println(subM.Minutes(), \u0026#34;分钟\u0026#34;) sumH := now.Sub(h1) fmt.Println(sumH.Hours(), \u0026#34;小时\u0026#34;) sumD := now.Sub(d1) fmt.Printf(\u0026#34;%v 天\\n\u0026#34;, sumD.Hours()/24)     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/go/advance/time/","summary":"时间转换 字符串转时间\ntime.Parse() 时间转字符串\ntime.Format() 时间转时间戳\nTime.Unix() 时间戳转时间\ntime.Unix()     计时 朴素方法\nstartTime := time.Now() //do something \ttime.Sleep(time.Second) duration := time.Since(startTime) fmt.Printf(\u0026#34;经过时间：%v\\n\u0026#34;, duration) //经过时间：1.005046959s   简洁方法\n// TimeCost 耗时统计函数 func TimeCost(start time.Time) { duration := time.Since(start) fmt.Printf(\u0026#34;经过时间：%v\\n\u0026#34;, duration) } defer TimeCost(time.Now()) //do something \ttime.Sleep(time.Second) //经过时间：1.005054375s   优雅方法\n// TimeCost 耗时统计函数 func TimeCost() func() { start := time.Now() return func() { duration := time.Since(start) fmt.","tags":null,"title":"time"},{"categories":null,"contents":"go get 下载指定版本 go get github.com/ormissia/go-opv@v0.0.2     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/go/advance/gomod/","summary":"go get 下载指定版本 go get github.com/ormissia/go-opv@v0.0.2     ","tags":null,"title":"go mod"},{"categories":null,"contents":"go chan close 在go的chan中，chan被关闭后，消费者会继续读取channel中的消息。直到消息被全部读取之后使用i, ok := \u0026lt;-ch得到的ok才会变为false\n下面是测试代码以及运行时控制台打印结果：\nfunc main() { ch := make(chan int, 3) go producer(ch) for { i, ok := \u0026lt;-ch fmt.Printf(\u0026#34;consume msg: %d\\tok: %v\\n\u0026#34;, i, ok) time.Sleep(time.Second * 3) } } func producer(ch chan int) { for i := 0; i \u0026lt; 10; i++ { ch \u0026lt;- i fmt.Printf(\u0026#34;produce msg: %d\\n\u0026#34;, i) time.Sleep(time.Second) } close(ch) fmt.Println(\u0026#34;chan closed\u0026#34;) } 输出结果\nproduce msg: 0 consume msg: 0\tok: true produce msg: 1 produce msg: 2 consume msg: 1\tok: true produce msg: 3 produce msg: 4 consume msg: 2\tok: true produce msg: 5 consume msg: 3\tok: true produce msg: 6 consume msg: 4\tok: true produce msg: 7 consume msg: 5\tok: true produce msg: 8 consume msg: 6\tok: true produce msg: 9 chan closed consume msg: 7\tok: true consume msg: 8\tok: true consume msg: 9\tok: true consume msg: 0\tok: false consume msg: 0\tok: false     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/go/advance/chan/","summary":"go chan close 在go的chan中，chan被关闭后，消费者会继续读取channel中的消息。直到消息被全部读取之后使用i, ok := \u0026lt;-ch得到的ok才会变为false\n下面是测试代码以及运行时控制台打印结果：\nfunc main() { ch := make(chan int, 3) go producer(ch) for { i, ok := \u0026lt;-ch fmt.Printf(\u0026#34;consume msg: %d\\tok: %v\\n\u0026#34;, i, ok) time.Sleep(time.Second * 3) } } func producer(ch chan int) { for i := 0; i \u0026lt; 10; i++ { ch \u0026lt;- i fmt.Printf(\u0026#34;produce msg: %d\\n\u0026#34;, i) time.Sleep(time.Second) } close(ch) fmt.Println(\u0026#34;chan closed\u0026#34;) } 输出结果\nproduce msg: 0 consume msg: 0\tok: true produce msg: 1 produce msg: 2 consume msg: 1\tok: true produce msg: 3 produce msg: 4 consume msg: 2\tok: true produce msg: 5 consume msg: 3\tok: true produce msg: 6 consume msg: 4\tok: true produce msg: 7 consume msg: 5\tok: true produce msg: 8 consume msg: 6\tok: true produce msg: 9 chan closed consume msg: 7\tok: true consume msg: 8\tok: true consume msg: 9\tok: true consume msg: 0\tok: false consume msg: 0\tok: false     ","tags":null,"title":"go chan"},{"categories":null,"contents":"异或  异或运算法则：无进位相加 异或运算性质：  0 ^ N = N N ^ N = 0 满足交换律和结合律    a := 0b1100 b := 0b1001 fmt.Printf(\u0026#34;%b\u0026#34;,a^b) //101 简单应用：不申请额外内存交换两个变量的值\na := 0b1100 b := 0b1001 a = a ^ b b = a ^ b //b = (a ^ b) ^ b = a a = a ^ b //a = (a ^ b) ^ a = b fmt.Printf(\u0026#34;a:%b,b:%b\u0026#34;, a, b) //a:1001,b:1100     堆  堆的实质是一棵完全二叉树\n 堆可分为两种类型：\n 大根堆：所有子树的根节点均为最大值 小根堆：所有子树的根节点均为最小值  一般情况下堆可以用一个有序数组来存储\n[0\u0026hellip;i\u0026hellip;n] i节点的左孩子index为2*i+1，右孩子为2i+2，父节点为(i-1)/2\n也有一种特例是从1开始(位运算比加减法快)\n[01\u0026hellip;i\u0026hellip;n] i节点的左孩子index为2*i即i\u0026lt;\u0026lt;1，右孩子为2i+1即i\u0026lt;\u0026lt;1|1，父节点为i/2\n 堆的基本操作：  上浮 下沉   堆的插入弹出  插入  在最后插入节点 依次上浮   弹出  弹出根节点 将最后一个节点放入根节点 将根节点下沉     堆排序  依次弹出根节点        ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/go/algorithm/basic/","summary":"异或  异或运算法则：无进位相加 异或运算性质：  0 ^ N = N N ^ N = 0 满足交换律和结合律    a := 0b1100 b := 0b1001 fmt.Printf(\u0026#34;%b\u0026#34;,a^b) //101 简单应用：不申请额外内存交换两个变量的值\na := 0b1100 b := 0b1001 a = a ^ b b = a ^ b //b = (a ^ b) ^ b = a a = a ^ b //a = (a ^ b) ^ a = b fmt.Printf(\u0026#34;a:%b,b:%b\u0026#34;, a, b) //a:1001,b:1100     堆  堆的实质是一棵完全二叉树","tags":null,"title":"Basic"},{"categories":null,"contents":"Strings test\nString str = \u0026#34;123\u0026#34;;     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/java/basic/basic_type/","summary":"Strings test\nString str = \u0026#34;123\u0026#34;;     ","tags":null,"title":"Basic Types"},{"categories":null,"contents":"函数 函数参数为val类型，且可以给出默认值\ndef test(a: Int, b: Int = 1, c: Int = 2): Unit = { println(s\u0026quot;$a $b $c\u0026quot;) } test(1, 2) //1 2 2 test(1, c = 4) //1 1 4     匿名函数 函数是带有参数的表达式。\n(x: Int) =\u0026gt; x + 1     方法 方法的表现和行为和函数非常类似，但是它们之间有一些关键的差别。\n方法由def关键字定义。def后面跟着一个名字、参数列表、返回类型和方法体。\ndef addThenMultiply(x: Int, y: Int)(multiplier: Int): Int = (x + y) * multiplier println(addThenMultiply(1, 2)(3)) // 9     字符串拼接 val a = 1 val b = 2 val c = s\u0026quot;$a+$b=${a + b}\u0026quot;     对象 约等于static单例对象\nobject TestObj { def main(args: Array[String]): Unit = { val a = 1 val b = 2 val c = s\u0026quot;$a+$b=${a + b}\u0026quot; println(c) } }     类 可以使用class关键字定义一个类，后面跟着它的名字和构造参数。\n 类里裸露的代码是默认构造中的 类名构造器中的参数就是类的成员属性，默认是val类型，且是private 只有在类名构造器中的参数可以设置成var，其他方法函数中的参数都是val类型的，且不允许设置成var类型  class Greeter(prefix: String, var suffix: String) { var name = \u0026quot;name\u0026quot; def greet(name: String): Unit = println(prefix + name + suffix) }     循环 scala中嵌套for循环可以写到一起，循环上可以加守卫（条件）。 循环结果可以通过yield收集到一个集合中\n// val value = for (i \u0026lt;- 1 to 9; j \u0026lt;- 1 to i) yield { val value = for (i \u0026lt;- 1 to 9; j \u0026lt;- 1 to 10 if (j \u0026lt;= i)) yield { i * j } for (i \u0026lt;- value) { println(i) }     偏应用函数 类似于重新封装一下函数\ndef log(date: Date, logType: String, msg: String): Unit = { println(s\u0026quot;$date\\t$logType\\t$msg\u0026quot;) } val info = log(_, \u0026quot;info\u0026quot;, _) info(new Date, \u0026quot;this is a info msg\u0026quot;) //Thu Jul 22 23:14:04 CST 2021\tinfo\tthis is a info msg     可变长度参数以及foreach def foreachTest(a: Int*): Unit = { //for (i \u0026lt;- a) { // print(i) //} //a.foreach((x: Int) =\u0026gt; { // print(x) //}) //a.foreach(print(_)) a.foreach(print) } foreachTest(1, 2, 3, 4, 5) //12345     高阶函数 函数作为参数\ndef computer(a: Int, b: Int, f: (Int, Int) =\u0026gt; Int): Unit = { val res = f(a, b) println(res) } computer(1, 2, (x: Int, y: Int) =\u0026gt; {x + y}) //3 computer(1, 2, _ + _) //3   函数作为返回值\ndef factory(i: String): (Int, Int) =\u0026gt; Int = { def plus(x: Int, y: Int): Int = { x + y } if (i.equals(\u0026quot;+\u0026quot;)) { plus } else { _ * _ } } val plus = factory(\u0026quot;+\u0026quot;) computer(1,2,plus) //3     柯里化 多个参数列表\ndef testFunc(a:Int*)(b:Int*)(c:String*): Unit ={ a.foreach(print) b.foreach(print) c.foreach(print) } testFunc(1,2,3)(2,3,4)(\u0026quot;3\u0026quot;,\u0026quot;4\u0026quot;,\u0026quot;5\u0026quot;) //123234345     数组 数组 scala中泛型是[]，数组用()\nval约等于final，不可变描述的是val指定的引用（字面值、地址）\nval arr1 = Array[Int](1, 2, 3) arr1(1) = 99 println(arr1(1)) //99   遍历\n for (elem \u0026lt;- arr1) {} //foreach需要函数接收元素 arr1.foreach(println)     链表 scala中collections中有两个包：immutable,mutable，默认是不可变的immutable\nval list1 = List(1, 2, 3, 4) //++ += ++: :++ val list2 = new ListBuffer[Int] list2.+=(1) list2.+=(2) list2.+=(3)   val list1 = List(1, 2, 3, 4) val list2 = list1.map(_ * 2) list2.foreach(print) //2468     Set Set\n不可变的\nval set1 = Set(1, 2, 3, 4, 1, 2) //1 2 3 4   可变的\nval set2 = mutable.Set(1, 2, 3, 4, 1, 2) set2.add(1) set2.add(5) //1 2 3 4 5     Map Map\nval map1 = Map((\u0026quot;a\u0026quot;, 1), \u0026quot;b\u0026quot; -\u0026gt; 2, (\u0026quot;c\u0026quot;, 3), (\u0026quot;a\u0026quot;, 4)) map1.foreach(print) //(a,4)(b,2)(c,3) println(map1.get(\u0026quot;a\u0026quot;)) //Some(4) println(map1.get(\u0026quot;d\u0026quot;)) //None println(map1.getOrElse(\u0026quot;a\u0026quot;, \u0026quot;test\u0026quot;)) //4 println(map1.getOrElse(\u0026quot;d\u0026quot;, \u0026quot;test\u0026quot;)) //test val keys = map1.keys keys.foreach(println)   遍历\nfor (m \u0026lt;- map1) { print(s\u0026quot;$m\u0026quot;) } for (k \u0026lt;- keys) { print(s\u0026quot;($k,${map1(k)})\u0026quot;) }   可变的\nval map2 = mutable.Map((\u0026quot;a\u0026quot;, 1), \u0026quot;b\u0026quot; -\u0026gt; 2, (\u0026quot;c\u0026quot;, 3), (\u0026quot;a\u0026quot;, 4)) map2.put(\u0026quot;a\u0026quot;, 5)     案例类     模式匹配     特质     偏函数     隐式转换     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/scala/basic/basic_type/","summary":"函数 函数参数为val类型，且可以给出默认值\ndef test(a: Int, b: Int = 1, c: Int = 2): Unit = { println(s\u0026quot;$a $b $c\u0026quot;) } test(1, 2) //1 2 2 test(1, c = 4) //1 1 4     匿名函数 函数是带有参数的表达式。\n(x: Int) =\u0026gt; x + 1     方法 方法的表现和行为和函数非常类似，但是它们之间有一些关键的差别。\n方法由def关键字定义。def后面跟着一个名字、参数列表、返回类型和方法体。\ndef addThenMultiply(x: Int, y: Int)(multiplier: Int): Int = (x + y) * multiplier println(addThenMultiply(1, 2)(3)) // 9     字符串拼接 val a = 1 val b = 2 val c = s\u0026quot;$a+$b=${a + b}\u0026quot;     对象 约等于static单例对象","tags":null,"title":"Basic Types"},{"categories":null,"contents":"函数 在 python 中，类型属于对象，变量是没有类型的：\na=[1,2,3] a=\u0026#34;ormissia\u0026#34; 以上代码中，[1,2,3]是List类型，\u0026quot;ormissia\u0026quot;是String类型，而变量a是没有类型，他仅仅是一个对象的引用（一个指针），可以是指向List类型对象，也可以是指向String类型对象。\n可更改(mutable)与不可更改(immutable)对象 在python中，strings，tuples和numbers是不可更改的对象，而list，dict等则是可以修改的对象。\n  不可变类型：变量赋值a=5后再赋值a=10，这里实际是新生成一个int值对象10，再让a指向它，而5被丢弃，不是改变a的值，相当于新生成了a。\n  可变类型：变量赋值la = [1,2,3,4]后再赋值la[2] = 5则是将list la的第三个元素值更改，本身la没有动，只是其内部的一部分值被修改了。\n  python函数的参数传递：   不可变类型：类似C++的值传递，如整数、字符串、元组。如fun(a)，传递的只是a的值，没有影响a对象本身。如果在fun(a)内部修改a的值，则是新生成一个a的对象。\n  可变类型：类似C++的引用传递，如列表，字典。如fun(la)，则是将la真正的传过去，修改后fun外部的la也会受影响\n  python中一切都是对象，严格意义我们不能说值传递还是引用传递，我们应该说传不可变对象和传可变对象。\n    ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/python/basic/basic/","summary":"函数 在 python 中，类型属于对象，变量是没有类型的：\na=[1,2,3] a=\u0026#34;ormissia\u0026#34; 以上代码中，[1,2,3]是List类型，\u0026quot;ormissia\u0026quot;是String类型，而变量a是没有类型，他仅仅是一个对象的引用（一个指针），可以是指向List类型对象，也可以是指向String类型对象。\n可更改(mutable)与不可更改(immutable)对象 在python中，strings，tuples和numbers是不可更改的对象，而list，dict等则是可以修改的对象。\n  不可变类型：变量赋值a=5后再赋值a=10，这里实际是新生成一个int值对象10，再让a指向它，而5被丢弃，不是改变a的值，相当于新生成了a。\n  可变类型：变量赋值la = [1,2,3,4]后再赋值la[2] = 5则是将list la的第三个元素值更改，本身la没有动，只是其内部的一部分值被修改了。\n  python函数的参数传递：   不可变类型：类似C++的值传递，如整数、字符串、元组。如fun(a)，传递的只是a的值，没有影响a对象本身。如果在fun(a)内部修改a的值，则是新生成一个a的对象。\n  可变类型：类似C++的引用传递，如列表，字典。如fun(la)，则是将la真正的传过去，修改后fun外部的la也会受影响\n  python中一切都是对象，严格意义我们不能说值传递还是引用传递，我们应该说传不可变对象和传可变对象。\n    ","tags":null,"title":"Basic"},{"categories":null,"contents":"函数     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/js/basic/basic/","summary":"函数     ","tags":null,"title":"Basic"},{"categories":null,"contents":"按年月日分组聚合 group by date_format(field_name, format); 根据format字符串格式化date值。下列修饰符可以被用在format字符串中：\n%M 月名字(January……December) %W 星期名字(Sunday……Saturday) %D 有英语前缀的月份的日期(1st, 2nd, 3rd, 等等。） %Y 年, 数字, 4 位 %y 年, 数字, 2 位 %a 缩写的星期名字(Sun……Sat) %d 月份中的天数, 数字(00……31) %e 月份中的天数, 数字(0……31) %m 月, 数字(01……12) %c 月, 数字(1……12) %b 缩写的月份名字(Jan……Dec) %j 一年中的天数(001……366) %H 小时(00……23) %k 小时(0……23) %h 小时(01……12) %I 小时(01……12) %l 小时(1……12) %i 分钟, 数字(00……59) %r 时间,12 小时(hh:mm:ss [AP]M) %T 时间,24 小时(hh:mm:ss) %S 秒(00……59) %s 秒(00……59) %p AM或PM %w 一个星期中的天数(0=Sunday ……6=Saturday ） %U 星期(0……52), 这里星期天是星期的第一天 %u 星期(0……52), 这里星期一是星期的第一天 %% 一个文字“%”     count统计不重复个数 select count(distinct (field_name)) from table_name     sum结果为null时置为0 SQL中使用sum统计总数时:sum(col_name)，如果某列不符合sum的条件（比如某列中含有NULL元素，或者不是数值类型，或者没有符合where条件的行），那么会返回NULL 有的时候不希望sum的结果为NULL，可以做如下的处理：\nSELECT COALESCE(sum(col_name), 0) FROM Table 此外还有ISNULL(SQL Server)，NVL(Oracle)以及IFNULL(MySQL)的用法，起到同样的效果\n    ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/sql/dml/dml/","summary":"按年月日分组聚合 group by date_format(field_name, format); 根据format字符串格式化date值。下列修饰符可以被用在format字符串中：\n%M 月名字(January……December) %W 星期名字(Sunday……Saturday) %D 有英语前缀的月份的日期(1st, 2nd, 3rd, 等等。） %Y 年, 数字, 4 位 %y 年, 数字, 2 位 %a 缩写的星期名字(Sun……Sat) %d 月份中的天数, 数字(00……31) %e 月份中的天数, 数字(0……31) %m 月, 数字(01……12) %c 月, 数字(1……12) %b 缩写的月份名字(Jan……Dec) %j 一年中的天数(001……366) %H 小时(00……23) %k 小时(0……23) %h 小时(01……12) %I 小时(01……12) %l 小时(1……12) %i 分钟, 数字(00……59) %r 时间,12 小时(hh:mm:ss [AP]M) %T 时间,24 小时(hh:mm:ss) %S 秒(00……59) %s 秒(00……59) %p AM或PM %w 一个星期中的天数(0=Sunday ……6=Saturday ） %U 星期(0……52), 这里星期天是星期的第一天 %u 星期(0……52), 这里星期一是星期的第一天 %% 一个文字“%”     count统计不重复个数 select count(distinct (field_name)) from table_name     sum结果为null时置为0 SQL中使用sum统计总数时:sum(col_name)，如果某列不符合sum的条件（比如某列中含有NULL元素，或者不是数值类型，或者没有符合where条件的行），那么会返回NULL 有的时候不希望sum的结果为NULL，可以做如下的处理：","tags":null,"title":"SQL DML"},{"categories":null,"contents":"快捷键 回到命令行开头\u0026ndash;Home\nCtrl+a 回到命令行的尾部\u0026ndash;End\nCtrl+e   删除光标前边的所有字符\nCtrl+u 删除光标后边的所有字符\nCtrl+k 删除光标前的一个单词\nCtrl+w   输入曾经的命令下的某个单词或字母，按照单词的匹配history\nCtrl+r     cat 在cat输出时候显示行数\ncat -n maim.go     wc 统计文件行、单词、字符数量 格式：\nusage: wc [-clmw] [file ...] 统计main.go的行、单词、字符数量\nwc main.go 选项：\n-l 统计行数 -c 统计字符数 -w 统计单词数 -L 统计最长的行的字符数     nc 简单的文件传输工具\n接收方\nnc -l [port] \u0026gt; filename 发送方\nnc [ip] [port] \u0026lt; filename     gzip 解压*.gz的压缩文件\n与*.tar.gz文件不同，*.gz文件需要用gzip来解压\ngzip -d filename     hostnamectl 修改hostname，重启也生效\nhostnamectl set-hostname CentOS 查看hostname\nhostname     echo -n：不换行 -e：支持扩展属性\n# 红色显示OK echo -e \u0026#34;\\033[31mOK\\033[0m\u0026#34; # 绿色显示OK echo -e \u0026#34;\\033[32mOK\\033[0m\u0026#34;     tr 删除多余重复字符串\n# 删除多余的空格 echo \u0026#34;a b c\u0026#34; | tr -s \u0026#34; \u0026#34; # 输出：a b c # 删除多余的a echo \u0026#34;aaaaacccdetaaadfa c\u0026#34; | tr -s \u0026#34;a\u0026#34; # 输出：acccdetadfa c     cut # 以冒号为分隔，过滤第一列 cut -d: -f1 /etc/passwd # 输出当前系统下所有用户名     date 查看系统时间\ndate # Tue Oct 12 13:36:24 CST 2021     tzselect 查看时区\nls -l /etc/localtime # lrwxrwxrwx. 1 root root 33 Oct 12 11:32 /etc/localtime -\u0026gt; /usr/share/zoneinfo/Asia/Shanghai   获取TZ时区\ntzselect 输出：\nPlease identify a location so that time zone rules can be set correctly. Please select a continent, ocean, \u0026#34;coord\u0026#34;, or \u0026#34;TZ\u0026#34;. 1) Africa 2) Americas 3) Antarctica 4) Asia 5) Atlantic Ocean 6) Australia 7) Europe 8) Indian Ocean 9) Pacific Ocean 10) coord - I want to use geographical coordinates. 11) TZ - I want to specify the time zone using the Posix TZ format. #?  # 选择数字，依次选择地区、国家、城市，即可得到对应时区 # Asia/Shanghai   修改系统时区（所有用户生效）\nrm -f /etc/localtime ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/linux/shell/basic/","summary":"快捷键 回到命令行开头\u0026ndash;Home\nCtrl+a 回到命令行的尾部\u0026ndash;End\nCtrl+e   删除光标前边的所有字符\nCtrl+u 删除光标后边的所有字符\nCtrl+k 删除光标前的一个单词\nCtrl+w   输入曾经的命令下的某个单词或字母，按照单词的匹配history\nCtrl+r     cat 在cat输出时候显示行数\ncat -n maim.go     wc 统计文件行、单词、字符数量 格式：\nusage: wc [-clmw] [file ...] 统计main.go的行、单词、字符数量\nwc main.go 选项：\n-l 统计行数 -c 统计字符数 -w 统计单词数 -L 统计最长的行的字符数     nc 简单的文件传输工具\n接收方\nnc -l [port] \u0026gt; filename 发送方\nnc [ip] [port] \u0026lt; filename     gzip 解压*.","tags":null,"title":"Basic"},{"categories":null,"contents":"xargs xargs是给命令传递参数的一个过滤器，可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据，一般是和管道一起使用。 格式:\nsomecommand | xargs [-item] [command] 选项：\n-a file 从文件中读入作为 stdin -e flag ，注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。 -p 当每次执行一个argument的时候询问一次用户。 -n num 后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的。 -t 表示先打印命令，然后再执行。 -i 或者是-I，这得看linux支持了，将xargs的每项名称，一般是一行一行赋值给 {}，可以用 {} 代替。 -r no-run-if-empty 当xargs的输入为空的时候则停止xargs，不用再去执行了。 -s num 命令行的最大字符数，指的是 xargs 后面那个命令的最大命令行字符数。 -L num 从标准输入一次读取 num 行送给 command 命令。 -l 同 -L。 -d delim 分隔符，默认的xargs分隔符是回车，argument的分隔符是空格，这里修改的是xargs的分隔符。 -x exit的意思，主要是配合-s使用。。     top Linux top命令VIRT,RES,SHR,DATA的含义:\n VIRT:virtual memory usage虚拟内存  进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据等 假如进程申请100m的内存，但实际只使用了10m，那么它会增长100m，而不是实际的使用量   RES:resident memory usage常驻内存  进程当前使用的内存大小，但不包括swap out 包含其他进程的共享 如果申请100m的内存，实际使用10m，它只增长10m，与VIRT相反 关于库占用内存的情况，它只统计加载的库文件所占内存大小   SHR:shared memory共享内存  除了自身进程的共享内存，也包括其他进程的共享内存 虽然进程只使用了几个共享库的函数，但它包含了整个共享库的大小 计算某个进程所占的物理内存大小公式：RES – SHR swap out后，它将会降下来    top运行中可以通过top的内部命令对进程的显示方式进行控制。内部命令如下：\ns – 改变画面更新频率\nl – 关闭或开启第一部分第一行 top 信息的表示\nt – 关闭或开启第一部分第二行 Tasks 和第三行 Cpus 信息的表示\nm – 关闭或开启第一部分第四行 Mem 和 第五行 Swap 信息的表示\nN – 以 PID 的大小的顺序排列表示进程列表\nP – 以 CPU 占用率大小的顺序排列进程列表\nM – 以内存占用率大小的顺序排列进程列表\nh – 显示帮助\nn – 设置在进程列表所显示进程的数量\nq – 退出 top\n序号 列名 含义\na PID 进程id\nb PPID 父进程id\nc RUSER Real user name\nd UID 进程所有者的用户id\ne USER 进程所有者的用户名\nf GROUP 进程所有者的组名\ng TTY 启动进程的终端名。不是从终端启动的进程则显示为 ?\nh PR 优先级\ni NI nice值。负值表示高优先级，正值表示低优先级\nj P 最后使用的CPU，仅在多CPU环境下有意义\nk %CPU 上次更新到现在的CPU时间占用百分比\nl TIME 进程使用的CPU时间总计，单位秒\nm TIME+ 进程使用的CPU时间总计，单位1/100秒\nn %MEM 进程使用的物理内存百分比\no VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES\np SWAP 进程使用的虚拟内存中，被换出的大小，单位kb。\nq RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA\nr CODE 可执行代码占用的物理内存大小，单位kb\ns DATA 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb\nt SHR 共享内存大小，单位kb\nu nFLT 页面错误次数\nv nDRT 最后一次写入到现在，被修改过的页面数。\nw S 进程状态。（D=不可中断的睡眠状态，R=运行，S=睡眠，T=跟踪/停止，Z=僵尸进程）\nx COMMAND 命令名/命令行\ny WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名\nz Flags 任务标志，参考 sched.h\n默认情况下仅显示比较重要的 PID、USER、PR、NI、VIRT、RES、SHR、S、%CPU、%MEM、TIME+、COMMAND 列。可以通过下面的快捷键来更改显示内容。\n通过f键可以选择显示的内容。按f键之后会显示列的列表，按a-z即可显示或隐藏对应的列，最后按回车键确定。 按o键可以改变列的显示顺序。按小写的a-z可以将相应的列向右移动，而大写的A-Z可以将相应的列向左移动。最后按回车键确定。 按大写的F或O键，然后按a-z可以将进程按照相应的列进行排序。而大写的R键可以将当前的排序倒转。\n    ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/linux/shell/advance/","summary":"xargs xargs是给命令传递参数的一个过滤器，可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据，一般是和管道一起使用。 格式:\nsomecommand | xargs [-item] [command] 选项：\n-a file 从文件中读入作为 stdin -e flag ，注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。 -p 当每次执行一个argument的时候询问一次用户。 -n num 后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的。 -t 表示先打印命令，然后再执行。 -i 或者是-I，这得看linux支持了，将xargs的每项名称，一般是一行一行赋值给 {}，可以用 {} 代替。 -r no-run-if-empty 当xargs的输入为空的时候则停止xargs，不用再去执行了。 -s num 命令行的最大字符数，指的是 xargs 后面那个命令的最大命令行字符数。 -L num 从标准输入一次读取 num 行送给 command 命令。 -l 同 -L。 -d delim 分隔符，默认的xargs分隔符是回车，argument的分隔符是空格，这里修改的是xargs的分隔符。 -x exit的意思，主要是配合-s使用。。     top Linux top命令VIRT,RES,SHR,DATA的含义:\n VIRT:virtual memory usage虚拟内存  进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据等 假如进程申请100m的内存，但实际只使用了10m，那么它会增长100m，而不是实际的使用量   RES:resident memory usage常驻内存  进程当前使用的内存大小，但不包括swap out 包含其他进程的共享 如果申请100m的内存，实际使用10m，它只增长10m，与VIRT相反 关于库占用内存的情况，它只统计加载的库文件所占内存大小   SHR:shared memory共享内存  除了自身进程的共享内存，也包括其他进程的共享内存 虽然进程只使用了几个共享库的函数，但它包含了整个共享库的大小 计算某个进程所占的物理内存大小公式：RES – SHR swap out后，它将会降下来    top运行中可以通过top的内部命令对进程的显示方式进行控制。内部命令如下：","tags":null,"title":"Advance"},{"categories":null,"contents":"命令 显示行号\n:set number   在vi中执行shell命令\n:!ls-l   将shell命令的结果插入到当前行的下一行\n:r !date //读取系统时间并插入到当前行的下一行   将起始行号和结束行号指定的范围中的内容输入到shell命令command处理，并将处理结果替换起始行号和结束行号指定的范围中的内容\n:62,72 !sort //将62行到72行的内容进行排序 当前光标所在行，除可以指定行号外，也可以用.表示\n:. !tr [a-z] [A-Z] //将当前行的小写转为大写   将起始行号和结束行号所指定的范围的内容作为命令command的输入，不会改变当前编辑的文件的内容\n:62,72 w !sort //将62行到72行的内容进行排序，但排序的结果并不会直接输出到当前编辑的文件中，而是显示在vim敲命令的区域   将某一行作为shell命令执行\n:62 w !shell //将会把第62行的内容作为shell命令来执行并显示结果，而且不会改变当前编辑的文件的内容     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/linux/shell/vi/","summary":"命令 显示行号\n:set number   在vi中执行shell命令\n:!ls-l   将shell命令的结果插入到当前行的下一行\n:r !date //读取系统时间并插入到当前行的下一行   将起始行号和结束行号指定的范围中的内容输入到shell命令command处理，并将处理结果替换起始行号和结束行号指定的范围中的内容\n:62,72 !sort //将62行到72行的内容进行排序 当前光标所在行，除可以指定行号外，也可以用.表示\n:. !tr [a-z] [A-Z] //将当前行的小写转为大写   将起始行号和结束行号所指定的范围的内容作为命令command的输入，不会改变当前编辑的文件的内容\n:62,72 w !sort //将62行到72行的内容进行排序，但排序的结果并不会直接输出到当前编辑的文件中，而是显示在vim敲命令的区域   将某一行作为shell命令执行\n:62 w !shell //将会把第62行的内容作为shell命令来执行并显示结果，而且不会改变当前编辑的文件的内容     ","tags":null,"title":"vi"},{"categories":null,"contents":"脚本执行方式  需要可执行权限  相对路径执行 绝对路径执行   不需要可执行权限  sh 脚本文件名 source 脚本文件名 // 不会启动子进程，通过pstree查看进程树        定义变量  定义变量：变量名=变量值 取消变量：unset 变量名 注意事项：  =两边不能有空格 不能使用关键字做变量名，如：ls、cd等 如果变量名已存在，则会覆盖之前的变量值 变量名称由字母、数字、下划线组成，不能以数字开头        变量类型  环境变量：变量名通常大写，由操作系统维护 位置变量：shell内置变量，存储脚本执行时的参数  使用$n表示，n为数字序列号：$1、$2、\u0026hellip;、${10}、${11}、\u0026hellip;   预定义变量：shell内置变量，可以直接调用但是不能赋值或修改'  $0：存储所在的进程或脚本名 $$：当前进程的PID号 $?：命令执行后的返回状态，0-正常，其他-异常 $#：已加载的位置变量的个数 $*：所有位置变量的值   自定义变量：用户自主设置      多种引号的区别  双引号：允许扩展，以$引用其他变量 单引号：禁用扩展，将$视为普通字符 反引号：将命令执行的输出作为变量值，$()与反引号等效      变量的作用范围  局部变量：新定义的变量默认只在当前Shell中有效，无法在子Shell环境中使用 全局变量：在当前Shell以及子Shell中均有效（export a=1：定义全局变量a）      read标准输入取值 read从键盘读入变量值完成赋值\n 格式：read [参数] [变量名] 参数：  -p：提示信息 -t：指定超时秒数 -s：设置是否在终端显示输入的内容        变量作用范围  局部变量  新定义的变量默认只在当前Shell环境中有效，无法在子Shell环境中使用   全局变量  全局变量在当前Shell及子Shell中均有效，定义格式：export a=1        数学运算 整数运算\n使用$[]或$(())表达式\n格式：$[整数1 运算符 整数2]\n  小数运算\nBash内建机制仅支持整数运算，不支持小数运算 可以通过计算器软件bc实现小数计算\n如果没有该软件需要使用yum安装 bc支持交互式和非交互式两种方式计算，scale=n可以约束小数位\nbc也支持比较操作： \u0026gt;,\u0026gt;=,\u0026lt;,\u0026lt;=,==,!= 表达式成立返回1，否则返回0\n    字符串 字符串比较\n中括号与字符串之间和运算符与字符串之间均有有个空格\n是否为空：[ -z 字符串 ]\n等于：[ 字符串1 == 字符串2 ]\n不等于：[ 字符串1 ！= 字符串2 ]\n    整数值比较 [ 整数值1 操作符 整数值2 ]\n-eq 等于（equal） -ne 不等于（not equal） -ge 大于等于（greater or equal） -le 小于等于（less or equal） -gt 大于（greater than） -lt 小于（less than）\n    文件状态测试 [ 操作符 文件或目录 ]\n-e 判断对象是否存在（exit） -d 判断对象是否为目录（directory） -f 判断对象是否为一般文件（file） -r 判断对象是否有可读权限（read） -w 判断对象是否有可写权限（write） -x 判断对象是否有可执行权限（excute）\n    组合多个命令 ;：顺序执行 ||：前面执行失败继续执行 \u0026amp;\u0026amp;：前面执行成功继续执行    数组 存储多个数据的集合\ntest=(1 2 3) echo ${test[0]}     函数 语法格式\nfunction 函数名{ #命令序列 } 函数名(){ #命令序列 }   调用\n函数名 参数1 参数2 ... 传递的值作为函数的位置参数\n    中断与退出 continue：结束单次循环 break：跳出循环体 exit：退出脚本    子串截取 ${变量:起始位置:长度}\nab=123456 # 统计ab长度 echo ${#ab} # 输出：6 echo ${ab:2:5} # 输出：3456     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/linux/shell/script/","summary":"脚本执行方式  需要可执行权限  相对路径执行 绝对路径执行   不需要可执行权限  sh 脚本文件名 source 脚本文件名 // 不会启动子进程，通过pstree查看进程树        定义变量  定义变量：变量名=变量值 取消变量：unset 变量名 注意事项：  =两边不能有空格 不能使用关键字做变量名，如：ls、cd等 如果变量名已存在，则会覆盖之前的变量值 变量名称由字母、数字、下划线组成，不能以数字开头        变量类型  环境变量：变量名通常大写，由操作系统维护 位置变量：shell内置变量，存储脚本执行时的参数  使用$n表示，n为数字序列号：$1、$2、\u0026hellip;、${10}、${11}、\u0026hellip;   预定义变量：shell内置变量，可以直接调用但是不能赋值或修改'  $0：存储所在的进程或脚本名 $$：当前进程的PID号 $?：命令执行后的返回状态，0-正常，其他-异常 $#：已加载的位置变量的个数 $*：所有位置变量的值   自定义变量：用户自主设置      多种引号的区别  双引号：允许扩展，以$引用其他变量 单引号：禁用扩展，将$视为普通字符 反引号：将命令执行的输出作为变量值，$()与反引号等效      变量的作用范围  局部变量：新定义的变量默认只在当前Shell中有效，无法在子Shell环境中使用 全局变量：在当前Shell以及子Shell中均有效（export a=1：定义全局变量a）      read标准输入取值 read从键盘读入变量值完成赋值","tags":null,"title":"Script"},{"categories":null,"contents":"内存 一般来说内存占用大小有如下规律：VSS \u0026gt;= RSS \u0026gt;= PSS \u0026gt;= USS\n VSS - Virtual Set Size 虚拟耗用内存（包含共享库占用的内存） RSS - Resident Set Size 实际使用物理内存（包含共享库占用的内存） PSS - Proportional Set Size 实际使用的物理内存（比例分配共享库占用的内存） USS - Unique Set Size 进程独自占用的物理内存（不包含共享库占用的内存）    RSS / VSZ\n RSS是Resident Set Size（常驻内存大小）的缩写，用于表示进程使用了多少内存（RAM中的物理内存）， RSS不包含已经被换出的内存。RSS包含了它所链接的动态库并且被加载到物理内存中的内存。RSS还包含栈内存和堆内存。 VSZ是Virtual Memory Size（虚拟内存大小）的缩写。它包含了进程所能访问的所有内存，包含了被换出的内存， 被分配但是还没有被使用的内存，以及动态库中的内存。  假设进程A的二进制文件是500K，并且链接了一个2500K的动态库，堆和栈共使用了200K，其中100K在内存中（剩下的被换出或者不再被使用）， 一共加载了动态库中的1000K内容以及二进制文件中的400K内容至内存中，那么：\nRSS: 400K + 1000K + 100K = 1500K VSZ: 500K + 2500K + 200K = 3200K 由于部分内存是共享的，被多个进程使用，所以如果将所有进程的RSS值加起来可能会大于系统的内存总量。\n申请过的内存如果程序没有实际使用，则可能不显示在RSS里。比如说一个程序，预先申请了一大批内存， 过了一段时间才使用，你会发现RSS会增长而VSZ保持不变。\n还有一个概念是PSS，它是proportional set size（proportional是成比例的意思）的缩写。 这是一种新的度量方式。它将动态库所使用的内存按比例划分。比如我们前面例子中的动态库如果是被两个进程使用，那么：\nPSS: 400K + (1000K/2) + 100K = 400K + 500K + 100K = 1000K 一个进程中的多个线程共享同样的地址空间。所以一个进程中的多个线程的RSS，VSZ，PSS是完全相同的。linux下可以使用ps或者top命令查看这些信息。\n英文原文\n    ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/linux/system/system/","summary":"内存 一般来说内存占用大小有如下规律：VSS \u0026gt;= RSS \u0026gt;= PSS \u0026gt;= USS\n VSS - Virtual Set Size 虚拟耗用内存（包含共享库占用的内存） RSS - Resident Set Size 实际使用物理内存（包含共享库占用的内存） PSS - Proportional Set Size 实际使用的物理内存（比例分配共享库占用的内存） USS - Unique Set Size 进程独自占用的物理内存（不包含共享库占用的内存）    RSS / VSZ\n RSS是Resident Set Size（常驻内存大小）的缩写，用于表示进程使用了多少内存（RAM中的物理内存）， RSS不包含已经被换出的内存。RSS包含了它所链接的动态库并且被加载到物理内存中的内存。RSS还包含栈内存和堆内存。 VSZ是Virtual Memory Size（虚拟内存大小）的缩写。它包含了进程所能访问的所有内存，包含了被换出的内存， 被分配但是还没有被使用的内存，以及动态库中的内存。  假设进程A的二进制文件是500K，并且链接了一个2500K的动态库，堆和栈共使用了200K，其中100K在内存中（剩下的被换出或者不再被使用）， 一共加载了动态库中的1000K内容以及二进制文件中的400K内容至内存中，那么：\nRSS: 400K + 1000K + 100K = 1500K VSZ: 500K + 2500K + 200K = 3200K 由于部分内存是共享的，被多个进程使用，所以如果将所有进程的RSS值加起来可能会大于系统的内存总量。\n申请过的内存如果程序没有实际使用，则可能不显示在RSS里。比如说一个程序，预先申请了一大批内存， 过了一段时间才使用，你会发现RSS会增长而VSZ保持不变。","tags":null,"title":"Memory"},{"categories":null,"contents":"shell 在hbase的shell中scan时指定列\nscan \u0026#39;table_name\u0026#39;,{STARTROW=\u0026gt;\u0026#39;start_row\u0026#39;,ENDROW=\u0026gt;\u0026#39;end_row\u0026#39;,LIMIT=\u0026gt;100,COLUMNS=\u0026gt;[\u0026#39;info:type\u0026#39;]} COLUMNS=\u0026gt;['info:type']中参数为数组，可以指定列簇名和列名\n    ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/hbase/shell/basic/","summary":"shell 在hbase的shell中scan时指定列\nscan \u0026#39;table_name\u0026#39;,{STARTROW=\u0026gt;\u0026#39;start_row\u0026#39;,ENDROW=\u0026gt;\u0026#39;end_row\u0026#39;,LIMIT=\u0026gt;100,COLUMNS=\u0026gt;[\u0026#39;info:type\u0026#39;]} COLUMNS=\u0026gt;['info:type']中参数为数组，可以指定列簇名和列名\n    ","tags":null,"title":"Basic"},{"categories":null,"contents":"shell 查询消费者组\nkafka-consumer-groups.sh --bootstrap-server bigdata7:9092 --list kafka-consumer-groups.sh --bootstrap-server bigdata7:9092 --describe --group group_name 删除消费者组\nkafka-consumer-groups.sh --bootstrap-server bigdata7:9092 --delete --group group_name 查看topic消息数量\nkafka-run-class.sh kafka.tools.GetOffsetShell --bootstrap-server bigdata7:9092 --topic topic_name --time -1     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/kafka/shell/basic/","summary":"shell 查询消费者组\nkafka-consumer-groups.sh --bootstrap-server bigdata7:9092 --list kafka-consumer-groups.sh --bootstrap-server bigdata7:9092 --describe --group group_name 删除消费者组\nkafka-consumer-groups.sh --bootstrap-server bigdata7:9092 --delete --group group_name 查看topic消息数量\nkafka-run-class.sh kafka.tools.GetOffsetShell --bootstrap-server bigdata7:9092 --topic topic_name --time -1     ","tags":null,"title":"Basic"},{"categories":null,"contents":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.toml\n``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nBúsqueda de archivos adicionales Para buscar campos adicionales definidos en el front matter, debes añadirlo en 2 lugares.\nEditar layouts/_default/index.JSON Esto expone los valores en /index.json: por ejemplo, para agregar categories ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEditar las opciones de fuse.js para buscar static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.","tags":null,"title":"Resultados de Búsqueda"},{"categories":null,"contents":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.toml\n``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nBúsqueda de archivos adicionales Para buscar campos adicionales definidos en el front matter, debes añadirlo en 2 lugares.\nEditar layouts/_default/index.JSON Esto expone los valores en /index.json: por ejemplo, para agregar categories ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEditar las opciones de fuse.js para buscar static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.","tags":null,"title":"Resultados de Búsqueda"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"অনুসন্ধানের ফলাফল"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"অনুসন্ধানের ফলাফল"},{"categories":null,"contents":" #golang\n  前面几次着重讨论了在分布式系统中出现错误之后该如何处理。虽然长篇累牍谈了很多，但所谈到的情况还是过于乐观，现实则会更加复杂。我们可以根据墨菲定律做一个非常悲观的假定：即所有可能出错的事情最终一定会出错。\n 作为开发者，我们的核心任务是构建可靠的系统，即使系统面临各种出错的可能，也需要完成预定的工作（确保满足用户期望）。\n所以，首先我们要充分认识目前所面临的挑战。\n 比如：故障可能来自网络问题，以及时钟与时序问题等等\u0026hellip;\u0026hellip;\n在有一段工作经历中，我们的线上系统使用的是公有云，其中用到了不同地区的实例。两地区之间使用的是一条百兆带宽的专线。某个星期天的下午，领导通知我们有个服务出问题了，我查了程序日志之后，看到有许多访问上游服务网络超时的日志，即网络问题。随机运维查看之后告诉我们，上面提到的那条百兆专线被跑满了。至此，服务出问题的罪魁祸首已经找到——网络原因。当然，带宽被占满是由于业务增长还是某些服务出现bug抑或是恶意攻击，这就是另一个话题了。\n所以，在我看来，所谓网络的不可靠性并不一定特指网络本身出了什么问题。\n 故障与部分失效 我们所开发的单点程序，通常会以一种确定的方式运行：要么工作，要么出错。单台节点上的软件通常不应该出现模棱两可的现象。而在分布式系统中，可能会出现系统的一部分正常工作，但其他部分出现难以预测的故障，我们称之为\u0026quot;部分失效\u0026quot;。\n问题的难点就在于这种部分失效是不确定的：如果涉及多个节点和网络，几乎肯定会碰到有时网络正常，有时则莫名地失败。\n正是由于这种不确定性和部分失效大大提高了分布式系统的复杂性。\n不可靠的网络 我们目前关注的主要是分布式无共享系统，即通过网络连接多个节点。所以网络是跨节点通信的唯一途径，并且每台机器都有自己的内存和磁盘，一台机器不能直接访问另一台机器的内存或磁盘除非通过网络向对方发出请求。\n 诚然，无共享并不是构建集群系统的唯一方式，但却是当下构建互联网服务的主流方式。主要因为：硬件成本低廉，可以采用跨区域多数据中心来实现高可靠性，同时也可以给不同地域的用户提供更高的访问效率。\n 在我们的网络中一个节点发送数据到另一个节点，但是网络并不能保证他什么时候到达，甚至于，不能保证何时到达。\n发送请求等待响应的过程中，有很多错误可能出现：\n 请求已经丢失（比如有人拔了网线，当然在系统上云之后这种物理层面的小问题，基本可以由底层的虚拟化系统来避免和保障） 请求可能在某个队列中等待，无法马上发送或响应（比如网络发送方或接收方已经超负荷，正如文章开头所提到的例子） 远程接收节点可能已经失效（比如依赖的上游服务崩溃，不过目前基于kubernetes的系统可以在一定程度上保障服务的稳定性） 远程节点可能暂时无法响应（比如正在运行长时间的垃圾回收。可以对服务进行内存的调优，可以在基于kubernetes的系统限制内存大小同时增加实例数等等） 远程接收节点已经完成了请求处理，但回复却在网络中丢失（比如交换机配置错误） 远程接收节点已经完成了请求处理，但回复却被延迟处理（比如网络或发送者的机器超出负荷）  处理类似的问题通常可以采用超市机制：在等待一段时间之后，如果仍然没有收到回复则选择放弃，并认为响应不会到达。\n检测故障 许多系统都有自动检测节点失效这种的功能，比如\n 在ES中节点超过1分钟无响应则踢出集群，而后数据分片在正常的节点上进行重建。 在kubernetes中节点失效后，集群也会自动将失效节点的任务自动负载到其他节点之上。  超时与无限期的延迟 如果超时是故障检测唯一可行的方法，那么超时应该设置多长呢？很不幸，这并没有一个标准的答案。在上面提到的ES的例子是采用了一分钟的时间，延迟1分钟是为了防止偶尔的网络延迟等，因为将某个节点踢出集群后数据分片在集群中重新分配是需要消耗资源的。\n设置较长超时则意味着更长时间的等待，才能宣告节点失效（在这期间，用户只能等待或者看到错误信息）。而较短的超时设置可以帮助更快地检测故障，但可能会出现误判，例如实际上节点只是出现短暂的性能波动（由于节点或者网络上的高负载峰值）。\n参考链接 《数据密集型应用系统设计》\n","date":"May 3, 2022","hero":"/posts/booknotes/6001-ddia/003-ddia/head.svg","permalink":"https://ormissia.github.io/posts/booknotes/6001-ddia/003-ddia/","summary":"#golang\n  前面几次着重讨论了在分布式系统中出现错误之后该如何处理。虽然长篇累牍谈了很多，但所谈到的情况还是过于乐观，现实则会更加复杂。我们可以根据墨菲定律做一个非常悲观的假定：即所有可能出错的事情最终一定会出错。\n 作为开发者，我们的核心任务是构建可靠的系统，即使系统面临各种出错的可能，也需要完成预定的工作（确保满足用户期望）。\n所以，首先我们要充分认识目前所面临的挑战。\n 比如：故障可能来自网络问题，以及时钟与时序问题等等\u0026hellip;\u0026hellip;\n在有一段工作经历中，我们的线上系统使用的是公有云，其中用到了不同地区的实例。两地区之间使用的是一条百兆带宽的专线。某个星期天的下午，领导通知我们有个服务出问题了，我查了程序日志之后，看到有许多访问上游服务网络超时的日志，即网络问题。随机运维查看之后告诉我们，上面提到的那条百兆专线被跑满了。至此，服务出问题的罪魁祸首已经找到——网络原因。当然，带宽被占满是由于业务增长还是某些服务出现bug抑或是恶意攻击，这就是另一个话题了。\n所以，在我看来，所谓网络的不可靠性并不一定特指网络本身出了什么问题。\n 故障与部分失效 我们所开发的单点程序，通常会以一种确定的方式运行：要么工作，要么出错。单台节点上的软件通常不应该出现模棱两可的现象。而在分布式系统中，可能会出现系统的一部分正常工作，但其他部分出现难以预测的故障，我们称之为\u0026quot;部分失效\u0026quot;。\n问题的难点就在于这种部分失效是不确定的：如果涉及多个节点和网络，几乎肯定会碰到有时网络正常，有时则莫名地失败。\n正是由于这种不确定性和部分失效大大提高了分布式系统的复杂性。\n不可靠的网络 我们目前关注的主要是分布式无共享系统，即通过网络连接多个节点。所以网络是跨节点通信的唯一途径，并且每台机器都有自己的内存和磁盘，一台机器不能直接访问另一台机器的内存或磁盘除非通过网络向对方发出请求。\n 诚然，无共享并不是构建集群系统的唯一方式，但却是当下构建互联网服务的主流方式。主要因为：硬件成本低廉，可以采用跨区域多数据中心来实现高可靠性，同时也可以给不同地域的用户提供更高的访问效率。\n 在我们的网络中一个节点发送数据到另一个节点，但是网络并不能保证他什么时候到达，甚至于，不能保证何时到达。\n发送请求等待响应的过程中，有很多错误可能出现：\n 请求已经丢失（比如有人拔了网线，当然在系统上云之后这种物理层面的小问题，基本可以由底层的虚拟化系统来避免和保障） 请求可能在某个队列中等待，无法马上发送或响应（比如网络发送方或接收方已经超负荷，正如文章开头所提到的例子） 远程接收节点可能已经失效（比如依赖的上游服务崩溃，不过目前基于kubernetes的系统可以在一定程度上保障服务的稳定性） 远程节点可能暂时无法响应（比如正在运行长时间的垃圾回收。可以对服务进行内存的调优，可以在基于kubernetes的系统限制内存大小同时增加实例数等等） 远程接收节点已经完成了请求处理，但回复却在网络中丢失（比如交换机配置错误） 远程接收节点已经完成了请求处理，但回复却被延迟处理（比如网络或发送者的机器超出负荷）  处理类似的问题通常可以采用超市机制：在等待一段时间之后，如果仍然没有收到回复则选择放弃，并认为响应不会到达。\n检测故障 许多系统都有自动检测节点失效这种的功能，比如\n 在ES中节点超过1分钟无响应则踢出集群，而后数据分片在正常的节点上进行重建。 在kubernetes中节点失效后，集群也会自动将失效节点的任务自动负载到其他节点之上。  超时与无限期的延迟 如果超时是故障检测唯一可行的方法，那么超时应该设置多长呢？很不幸，这并没有一个标准的答案。在上面提到的ES的例子是采用了一分钟的时间，延迟1分钟是为了防止偶尔的网络延迟等，因为将某个节点踢出集群后数据分片在集群中重新分配是需要消耗资源的。\n设置较长超时则意味着更长时间的等待，才能宣告节点失效（在这期间，用户只能等待或者看到错误信息）。而较短的超时设置可以帮助更快地检测故障，但可能会出现误判，例如实际上节点只是出现短暂的性能波动（由于节点或者网络上的高负载峰值）。\n参考链接 《数据密集型应用系统设计》","tags":null,"title":"数据密集型应用系统设计(DDIA)读书笔记"},{"categories":null,"contents":" #golang\n  上一次我们主要从书中学习了主从架构消息同步相关的内容，而书中后面提到了多主节点复制（如多数据中心等）和无主节点复制（书中提到的Riak、Dynamo等并不了解，我认为最近比较火的一些区块链技术也是一些无主节点复制）。这两种模式在实际中（至少在我的认知范围内中小体量的公司基本不会维护一些多数据中心的场景）并不常见，这里不再过多讨论。\n 在一个单独的主从复制架构中，主节点和所有从节点都需要保存全量的数据。在项目初期，如果对未来的数据增量没有一个相对准确的判断，在业务发展一段时间之后应用就会遇到性能瓶颈，同时也有可能面临扩容困难等一系列问题。因此，分片的机制应运而生。\n数据分区与数据复制  分区通常与复制相结合，即每一个分区的复制都是一个完整的主从架构的复制，而每个分区都会在多个节点上拥有相同的（不考虑微观上的延迟）副本，这意味着某条记录属于特定分区，而同样的内容会被保存到不同节点上以提高系统的容错性，这样即使某一个节点失效也不会影响整个集群的运行。\n 键-值数据的分区 面对海量的数据如何决定哪一条记录该放在哪个分区上呢？分区的主要目标就是将数据和查询负载均匀地分布在所有节点上。\n而如果分区不均匀，就会出现某些分区节点比其他分区承担了更多的任务，即为数据倾斜。数据倾斜会导致分区效率严重下降以至于丧失了既定的目标。\n避免热点最简单的办法是将数据随机分配到所有节点上。这种方法可以比较均匀地分布数据，但也有一个致命的缺点：如此写入到集群中的数据是无法通过特定key来读取的，因为没有办法知道数据保存在哪个节点上，所以不得不查询所有节点。\n简单的改进方法可以通过key来分配分区，比如a-z的单词根据首字母分配到26个节点上。\n基于关键字区间分区 假如上述根据单纯根据首字母字来分区时没有26个节点，那就需要将某些临近的字母放到同一个分区中，比如ab放到第一个分区，cd放到第二个分区\u0026hellip;\u0026hellip;依次类推，26个字母需要13个节点即可放完。\n但是基于关键字区间的分区也存在缺点，某些访问模式会导致热点。假如使用时间戳作为关键字，每一天的数据写入到一个分区中时，就会使这个分区成为热点。而其他分区始终处于空闲状态。\n为了避免上述问题，可以在时间戳以外加入其他内容，比如数据类型等\n基于关键字哈希值分区 对于上述数据倾斜与热点问题，许多分布式系统采用了基于关键字哈希函数的方式来分区。\n一个好的哈希函数可以处理数据倾斜并使其均匀分布，这样从整体来看可以使数据均匀的分布到所有分区上。\n负载倾斜与热点 如上所述，基于哈希的分区方法可以减轻热点，但依然无法完全避免。一个极端情况是所有读写都是针对同一个key进行的，则最终的请求都会被路由到同一个分区中。比如某个明星又离婚了等等\u0026hellip;\n 而最让人困扰的是，数据倾斜的问题不光会出现在这些基础设施（指分布式存储，一些消息中间件等）中，也会出现在我们的应用层中。比如，为了防止数据乱序（有时候乱序的数据会给下游处理带来压力，比如Flink处理乱序数据产生的延迟问题。再者相同key发往不同分区时也会使Flink处理数据时产生大量的Shuffle带来的网络IO压力）从而采用哈希等方法将数据写入kafka的partition中。\n即使采用了哈希分区的方法，如果出现某个热点key产生大量数据，就会造成数据倾斜。严重时将导致Kafka集群中某几个节点（主分片和所有副本所在的节点）磁盘被写满，进而导致整个集群不可用引发生产故障。\n针对这个特特定的场景，由于同一key的数据可以在较长一段时间后忍受分区发生改变，因此可以在几个小时以后改变一次分区选择规则。诚然，这个办法并不能推广到所有数据倾斜问题的解决中。\n 分区与二级索引 上面讨论的分区方案都依赖于键值的数据模型（其实我个人认为，多数数据存储莫不如此，即便是回到MySQL也是通过主键查询，要么回表，再要么全表扫描）。键值模型相对简单，即都是通过关键字来访问记录。但是涉及到二级索引，情况就会变得复杂。\n考虑到其复杂性，部分存储并不支持二级索引，如HBase作为一个面向列的存储，为了兼顾大数据量写入和OLAP场景的应用，并不支持二级索引。但是二级索引则是ES等一些全文搜索引擎的根本值所在。\n而二级索引也是需要存储到不同分区中的，目前主要有两种方法来支持二级索引进行分区：\n 基于文档的分区 基于此条的分区  基于文档分区的二级索引 基于文档的分区是将所有二级索引在每个分区中都存了一个词条，而每个分区中的二级索引只记录自己分区的数据。\n如果需要通过二级索引查询数据，就需要每一个分区的二级索引，再做统一处理。因此会导致读延迟显著放大。\n基于此条的二级索引分区 基于词条的二级索引分区即与数据分区类似，二级索引的词条被放入所有分区，每个词条只存在于某一个分区（不考虑副本）。\n这种方法对比前者，好处就是读取更为高效，不需要遍历所有分区的二级索引。相反这种方案写入性能相对较低，因为一个文档里面可能涉及到多个二级索引，而二级索引的分区又可能完全不同甚至不在同一节点上，由此势必引入显著的写放大。\n而正因如此，实践中对全局二级索引的更新往往都是异步的。\n参考链接 《数据密集型应用系统设计》\n","date":"May 1, 2022","hero":"/posts/booknotes/6001-ddia/002-ddia/head.svg","permalink":"https://ormissia.github.io/posts/booknotes/6001-ddia/002-ddia/","summary":"#golang\n  上一次我们主要从书中学习了主从架构消息同步相关的内容，而书中后面提到了多主节点复制（如多数据中心等）和无主节点复制（书中提到的Riak、Dynamo等并不了解，我认为最近比较火的一些区块链技术也是一些无主节点复制）。这两种模式在实际中（至少在我的认知范围内中小体量的公司基本不会维护一些多数据中心的场景）并不常见，这里不再过多讨论。\n 在一个单独的主从复制架构中，主节点和所有从节点都需要保存全量的数据。在项目初期，如果对未来的数据增量没有一个相对准确的判断，在业务发展一段时间之后应用就会遇到性能瓶颈，同时也有可能面临扩容困难等一系列问题。因此，分片的机制应运而生。\n数据分区与数据复制  分区通常与复制相结合，即每一个分区的复制都是一个完整的主从架构的复制，而每个分区都会在多个节点上拥有相同的（不考虑微观上的延迟）副本，这意味着某条记录属于特定分区，而同样的内容会被保存到不同节点上以提高系统的容错性，这样即使某一个节点失效也不会影响整个集群的运行。\n 键-值数据的分区 面对海量的数据如何决定哪一条记录该放在哪个分区上呢？分区的主要目标就是将数据和查询负载均匀地分布在所有节点上。\n而如果分区不均匀，就会出现某些分区节点比其他分区承担了更多的任务，即为数据倾斜。数据倾斜会导致分区效率严重下降以至于丧失了既定的目标。\n避免热点最简单的办法是将数据随机分配到所有节点上。这种方法可以比较均匀地分布数据，但也有一个致命的缺点：如此写入到集群中的数据是无法通过特定key来读取的，因为没有办法知道数据保存在哪个节点上，所以不得不查询所有节点。\n简单的改进方法可以通过key来分配分区，比如a-z的单词根据首字母分配到26个节点上。\n基于关键字区间分区 假如上述根据单纯根据首字母字来分区时没有26个节点，那就需要将某些临近的字母放到同一个分区中，比如ab放到第一个分区，cd放到第二个分区\u0026hellip;\u0026hellip;依次类推，26个字母需要13个节点即可放完。\n但是基于关键字区间的分区也存在缺点，某些访问模式会导致热点。假如使用时间戳作为关键字，每一天的数据写入到一个分区中时，就会使这个分区成为热点。而其他分区始终处于空闲状态。\n为了避免上述问题，可以在时间戳以外加入其他内容，比如数据类型等\n基于关键字哈希值分区 对于上述数据倾斜与热点问题，许多分布式系统采用了基于关键字哈希函数的方式来分区。\n一个好的哈希函数可以处理数据倾斜并使其均匀分布，这样从整体来看可以使数据均匀的分布到所有分区上。\n负载倾斜与热点 如上所述，基于哈希的分区方法可以减轻热点，但依然无法完全避免。一个极端情况是所有读写都是针对同一个key进行的，则最终的请求都会被路由到同一个分区中。比如某个明星又离婚了等等\u0026hellip;\n 而最让人困扰的是，数据倾斜的问题不光会出现在这些基础设施（指分布式存储，一些消息中间件等）中，也会出现在我们的应用层中。比如，为了防止数据乱序（有时候乱序的数据会给下游处理带来压力，比如Flink处理乱序数据产生的延迟问题。再者相同key发往不同分区时也会使Flink处理数据时产生大量的Shuffle带来的网络IO压力）从而采用哈希等方法将数据写入kafka的partition中。\n即使采用了哈希分区的方法，如果出现某个热点key产生大量数据，就会造成数据倾斜。严重时将导致Kafka集群中某几个节点（主分片和所有副本所在的节点）磁盘被写满，进而导致整个集群不可用引发生产故障。\n针对这个特特定的场景，由于同一key的数据可以在较长一段时间后忍受分区发生改变，因此可以在几个小时以后改变一次分区选择规则。诚然，这个办法并不能推广到所有数据倾斜问题的解决中。\n 分区与二级索引 上面讨论的分区方案都依赖于键值的数据模型（其实我个人认为，多数数据存储莫不如此，即便是回到MySQL也是通过主键查询，要么回表，再要么全表扫描）。键值模型相对简单，即都是通过关键字来访问记录。但是涉及到二级索引，情况就会变得复杂。\n考虑到其复杂性，部分存储并不支持二级索引，如HBase作为一个面向列的存储，为了兼顾大数据量写入和OLAP场景的应用，并不支持二级索引。但是二级索引则是ES等一些全文搜索引擎的根本值所在。\n而二级索引也是需要存储到不同分区中的，目前主要有两种方法来支持二级索引进行分区：\n 基于文档的分区 基于此条的分区  基于文档分区的二级索引 基于文档的分区是将所有二级索引在每个分区中都存了一个词条，而每个分区中的二级索引只记录自己分区的数据。\n如果需要通过二级索引查询数据，就需要每一个分区的二级索引，再做统一处理。因此会导致读延迟显著放大。\n基于此条的二级索引分区 基于词条的二级索引分区即与数据分区类似，二级索引的词条被放入所有分区，每个词条只存在于某一个分区（不考虑副本）。\n这种方法对比前者，好处就是读取更为高效，不需要遍历所有分区的二级索引。相反这种方案写入性能相对较低，因为一个文档里面可能涉及到多个二级索引，而二级索引的分区又可能完全不同甚至不在同一节点上，由此势必引入显著的写放大。\n而正因如此，实践中对全局二级索引的更新往往都是异步的。\n参考链接 《数据密集型应用系统设计》","tags":null,"title":"数据密集型应用系统设计(DDIA)读书笔记"},{"categories":null,"contents":" #golang\n  通常在生产中存储结构化数据最常用的是MySQL，而MySQL底层存储用的数据结构是B+树。当并发量达到一定程度之后通常会将单点的MySQL拆分成主从架构（在这之前可以加入内存型缓存如Redis等，属于不同层级的解决办法，不在此文讨论范畴）。\n 问题产生 在主从架构中主要问题之一有复制滞后。\n这里以MySQL集群为例，主从复制要求所有写请求都经由主节点，而从节点只接收只读的查询请求（这一点在ES/Kafka的多副本分片中也有类似体现，主分片写入，从分片只支持读取）。对于读操作密集的负载（如web），这是一个不错的选择。\n在这种扩展体系下，只需增加更多的从节点，就可以提高读请求的吞吐量。但是，这种方法在实际生产中只能用于异步复制，如果试图同步所有的从副本（即强一致性），则单个副本的写入失败将使数据在整个集群中写入失败。并且节点越多，发生故障的概率越高，所以以完全同步来设计系统在现实中反而非常不可靠。\n 在Kafka集群中为了提高消息吞吐量时与副本同步相关的设置通常会将acks设置为1或者0（1/0的区别在于leader是否落盘），partition的leader收到数据后即代表集群收到消息\n 说回到MySQL的主从集群，从上文中得到的结论，如果采用异步复制的话，很不幸如果一个应用正好从一个异步的从节点中读取数据，而该副本落后于主节点，这时应用读到的是过期的消息，表现在用户面前就会产生薛定谔的数据，即在同一时刻查询会出现两种截然不同的数据。\n不过这个不一致的状态只是暂时的，经过一段时间之后，从节点的数据会更新到与主节点保持一致，即最终一致性。\n解决办法  由于网络等原因导致的不一致性，不仅仅是存在于理论中，其是个实实在在的现实问题。下面分析复制滞后可能出现的问题，并找出相应的解决思路。\n 读自己的写 举个栗子：\n当用户提交一些数据，然后刷新页面查看刚刚修改的内容时，例如用户信息，或者是对于一些帖子的评论等。提交新数据必须发送到主节点，但是当用户取数据时，数据可能来自从节点。\n当集群是异步复制时就会出现问题，用户在数据写入到主节点而尚未达到从节点时刷新页面，看到的是数据修改之前的状态。这将给用户带来困惑。延伸到一些库存类型的应用，其实并不会导致超卖。如果用户看到是旧状态，误认为操作失败重新走了一遍流程，这时写入请求依然是访问到主节点，而主节点的数据是最新的，会返回失败。而这将进一步给用户带来困扰。\n对于这种情况，我们需要\u0026quot;写后读一致性\u0026quot;，该机制保证用户重新加载页面，总是能看到自己最新更新的数据。但对于其他用户看这条信息没有任何保证\n方案一 总是从主节点读取用户可能会修改的信息，否则在从节点读取。即，从用户访问自己的信息时候从主节点读取，访问其他人的信息时候在从节点读取。\n方案二 在客户端记住最近更新的时间戳，并附带在请求中。如果查到的数据不够新，则从其他副本中重新查询，或者直接从主节点中查询。\n方案三 如果副本分布在多个数据中心（地理位置上的多个机房）等，就必须把请求路由到主节点所在的数据中心。至少目前还没有接触过这种项目，没有很深的理解，不过多讨论这种情况。\n 此外，依然存在一些其他问题需要考虑，如用户在多个设备上登录，这样一个设备就无法知道其他设备上进行了什么操作，如果采用方案二的话，依然会出现不一致。\n 单调读  在上述第二个例子中，出现了用户数据向后回滚的情况。\n 假设用户从不同副本进行了多次读取，用户刷新了一个网页，该请求可能会被随机路由到某一个从节点。用户2345先后在两个从节点上执行了两次完全相同的查询（先是少量滞后的从节点，然后是滞后很大的从节点），则很有可能出现以下情况。\n第一个查询返回了最近用户1234所添加的评论，但第二个查询结果代表了更早时间点的状态。如果第一个查询没有返回任何内容，用户2345并不知道用户1234最近的评论，情况还好。但当用户2345看到了用户1234的评论之后，紧接着评论又消失了，就会感到十分困惑。\n 阿b(bilibili)的评论系统在使用中出现过类型的现象，但不清楚是否是由于审核等一些其他因素造成的。总之是在一个新视频发布后去刷新评论，第一次看到有人评论了，再次刷新评论又消失了。\n 单调读一致性可以确保不会发生这种异常。这是一个比强一致性弱，但比最终一致性强的保证。即保证用户依次进行多次读取，绝不会看到回滚的现象。\n实现单调读的一种方式是，确保每个用户总是从固定的同一副本执行读操作（不同的用户当然可以从不同的副本读取）。例如，使用用户ID的哈希来决定去哪个副本读取消息，但如果该副本失效，系统必须要有能力将查询重新路由到其他有效的副本上。\n前缀一致读 第三个由于复制滞后导致反常的例子。\n比如A和B之间以下的对话：\nA： 请问B，你能听到吗？ B： 你好A，我能听到 这两句话之间存在因果关系，即B听到了A的问题，然后再去回答。\n现在如果有第三人在通过从节点上收听上述对话。假设B发的消息先同步了，观察者看到的对话就变成了这样：\nB： 你好A，我能听到 A： 请问B，你能听到吗？ 这逻辑就变得混乱了。\n防止这种异常需要引入另一种保证：前缀一致读。该保证是说，对于一系列按照某个顺序发生的写请求，那么读取这些内容时必须要按照当时写入的顺序\n小结 上面讨论的是在保证最终一致性异步复制的情况下发生的。当系统决不能忍受这些问题时，那就必须采用强一致性，但随之而来的就是写入性能低下，故障率高，一个节点故障引发整个集群不可用等各种问题。都需要在应用开始进行得失的平衡。\n再举个栗子：\n 在kafka这种对写入性能要求极高的应用中，如果发送的消息不是特别重要，有要求极高吞吐量的时候，比如日志收集等，则可以设置为Leader收到消息即代表成功 而在ES中，则必须要求数据分片的所有副本都写入成功才返回成功，采用了强一致性。而ES采用了健康检查，超过1分钟不活跃的节点就剔除集群等机制，从而保证了数据可以实时地写入。  延伸 结合到实际工作中的项目分析，也存在类似问题。\n下面举两个类似的栗子：\n例一 在某基础信息管理平台中需要一个模糊搜索的功能，各方面平衡之后采用在应用内存中使用前缀树的方式做缓存。由于应用是多实例的，这时数据的增删改就会在多实例之间存在一个短暂的不一致。\n例二 在某数据处理应用中，由于每一条数据中需要有多个（一到十几不等）条目访问缓存。开始的时候将缓存放在Redis里，而应用访问Redis的时间大概需要十几到几十毫秒的时间，这样每一条数据的处理时间就在几十毫秒到几百毫秒之间。而使用多线程处理，则会造成消息的严重乱序。\n测试下来，程序每秒只能处理不超过20条数据，大大影响了效率。而后将缓存改到内存中，省掉了访问Redis的时间，再结合Kafka的一些优化策略，极大的提高了应用吞吐量。测试后每秒大概可以处理几千条数据。缓存放到程序内存中之后，也同样会出现缓存不一致的问题。\n下面是这两个应用中采用的一个缓存架构图：\n在这个架构中，如果某个实例接收Redis消息慢了，就会出现不同实例间的数据不一致\n参考链接 《数据密集型应用系统设计》\n","date":"April 30, 2022","hero":"/posts/booknotes/6001-ddia/001-ddia/head.svg","permalink":"https://ormissia.github.io/posts/booknotes/6001-ddia/001-ddia/","summary":"#golang\n  通常在生产中存储结构化数据最常用的是MySQL，而MySQL底层存储用的数据结构是B+树。当并发量达到一定程度之后通常会将单点的MySQL拆分成主从架构（在这之前可以加入内存型缓存如Redis等，属于不同层级的解决办法，不在此文讨论范畴）。\n 问题产生 在主从架构中主要问题之一有复制滞后。\n这里以MySQL集群为例，主从复制要求所有写请求都经由主节点，而从节点只接收只读的查询请求（这一点在ES/Kafka的多副本分片中也有类似体现，主分片写入，从分片只支持读取）。对于读操作密集的负载（如web），这是一个不错的选择。\n在这种扩展体系下，只需增加更多的从节点，就可以提高读请求的吞吐量。但是，这种方法在实际生产中只能用于异步复制，如果试图同步所有的从副本（即强一致性），则单个副本的写入失败将使数据在整个集群中写入失败。并且节点越多，发生故障的概率越高，所以以完全同步来设计系统在现实中反而非常不可靠。\n 在Kafka集群中为了提高消息吞吐量时与副本同步相关的设置通常会将acks设置为1或者0（1/0的区别在于leader是否落盘），partition的leader收到数据后即代表集群收到消息\n 说回到MySQL的主从集群，从上文中得到的结论，如果采用异步复制的话，很不幸如果一个应用正好从一个异步的从节点中读取数据，而该副本落后于主节点，这时应用读到的是过期的消息，表现在用户面前就会产生薛定谔的数据，即在同一时刻查询会出现两种截然不同的数据。\n不过这个不一致的状态只是暂时的，经过一段时间之后，从节点的数据会更新到与主节点保持一致，即最终一致性。\n解决办法  由于网络等原因导致的不一致性，不仅仅是存在于理论中，其是个实实在在的现实问题。下面分析复制滞后可能出现的问题，并找出相应的解决思路。\n 读自己的写 举个栗子：\n当用户提交一些数据，然后刷新页面查看刚刚修改的内容时，例如用户信息，或者是对于一些帖子的评论等。提交新数据必须发送到主节点，但是当用户取数据时，数据可能来自从节点。\n当集群是异步复制时就会出现问题，用户在数据写入到主节点而尚未达到从节点时刷新页面，看到的是数据修改之前的状态。这将给用户带来困惑。延伸到一些库存类型的应用，其实并不会导致超卖。如果用户看到是旧状态，误认为操作失败重新走了一遍流程，这时写入请求依然是访问到主节点，而主节点的数据是最新的，会返回失败。而这将进一步给用户带来困扰。\n对于这种情况，我们需要\u0026quot;写后读一致性\u0026quot;，该机制保证用户重新加载页面，总是能看到自己最新更新的数据。但对于其他用户看这条信息没有任何保证\n方案一 总是从主节点读取用户可能会修改的信息，否则在从节点读取。即，从用户访问自己的信息时候从主节点读取，访问其他人的信息时候在从节点读取。\n方案二 在客户端记住最近更新的时间戳，并附带在请求中。如果查到的数据不够新，则从其他副本中重新查询，或者直接从主节点中查询。\n方案三 如果副本分布在多个数据中心（地理位置上的多个机房）等，就必须把请求路由到主节点所在的数据中心。至少目前还没有接触过这种项目，没有很深的理解，不过多讨论这种情况。\n 此外，依然存在一些其他问题需要考虑，如用户在多个设备上登录，这样一个设备就无法知道其他设备上进行了什么操作，如果采用方案二的话，依然会出现不一致。\n 单调读  在上述第二个例子中，出现了用户数据向后回滚的情况。\n 假设用户从不同副本进行了多次读取，用户刷新了一个网页，该请求可能会被随机路由到某一个从节点。用户2345先后在两个从节点上执行了两次完全相同的查询（先是少量滞后的从节点，然后是滞后很大的从节点），则很有可能出现以下情况。\n第一个查询返回了最近用户1234所添加的评论，但第二个查询结果代表了更早时间点的状态。如果第一个查询没有返回任何内容，用户2345并不知道用户1234最近的评论，情况还好。但当用户2345看到了用户1234的评论之后，紧接着评论又消失了，就会感到十分困惑。\n 阿b(bilibili)的评论系统在使用中出现过类型的现象，但不清楚是否是由于审核等一些其他因素造成的。总之是在一个新视频发布后去刷新评论，第一次看到有人评论了，再次刷新评论又消失了。\n 单调读一致性可以确保不会发生这种异常。这是一个比强一致性弱，但比最终一致性强的保证。即保证用户依次进行多次读取，绝不会看到回滚的现象。\n实现单调读的一种方式是，确保每个用户总是从固定的同一副本执行读操作（不同的用户当然可以从不同的副本读取）。例如，使用用户ID的哈希来决定去哪个副本读取消息，但如果该副本失效，系统必须要有能力将查询重新路由到其他有效的副本上。\n前缀一致读 第三个由于复制滞后导致反常的例子。\n比如A和B之间以下的对话：\nA： 请问B，你能听到吗？ B： 你好A，我能听到 这两句话之间存在因果关系，即B听到了A的问题，然后再去回答。\n现在如果有第三人在通过从节点上收听上述对话。假设B发的消息先同步了，观察者看到的对话就变成了这样：\nB： 你好A，我能听到 A： 请问B，你能听到吗？ 这逻辑就变得混乱了。\n防止这种异常需要引入另一种保证：前缀一致读。该保证是说，对于一系列按照某个顺序发生的写请求，那么读取这些内容时必须要按照当时写入的顺序\n小结 上面讨论的是在保证最终一致性异步复制的情况下发生的。当系统决不能忍受这些问题时，那就必须采用强一致性，但随之而来的就是写入性能低下，故障率高，一个节点故障引发整个集群不可用等各种问题。都需要在应用开始进行得失的平衡。\n再举个栗子：\n 在kafka这种对写入性能要求极高的应用中，如果发送的消息不是特别重要，有要求极高吞吐量的时候，比如日志收集等，则可以设置为Leader收到消息即代表成功 而在ES中，则必须要求数据分片的所有副本都写入成功才返回成功，采用了强一致性。而ES采用了健康检查，超过1分钟不活跃的节点就剔除集群等机制，从而保证了数据可以实时地写入。  延伸 结合到实际工作中的项目分析，也存在类似问题。\n下面举两个类似的栗子：\n例一 在某基础信息管理平台中需要一个模糊搜索的功能，各方面平衡之后采用在应用内存中使用前缀树的方式做缓存。由于应用是多实例的，这时数据的增删改就会在多实例之间存在一个短暂的不一致。","tags":null,"title":"数据密集型应用系统设计(DDIA)读书笔记"},{"categories":null,"contents":" #http-code\n http协议（超文本传输协议）  是客户端和服务器端两者通信共同遵循的一些规则。主要内容是定义了客户端如何向服务器请求资源，服务器如何响应客户端请求。\n 请求中的POST与GET方法的区别\n get是从服务器上获取数据，post是向服务器传送数据。 在客户端，Get方式在通过URL提交数据，数据在URL中可以看到；POST方式，数据放置在HTML HEADER内提交。 对于get方式，服务器端用Request.QueryString获取变量的值，对于post方式，服务器端用Request.Form获取提交的数据。 GET方式提交的数据最多只能有1024字节，而POST则没有此限制。 安全性问题。正如在（1）中提到，使用 GET 的时候，参数会显示在地址栏上，而 Post 不会。所以，如果这些数据是中文数据而且是非敏感数据，那么使用 GET；如果用户输入的数据不是中文字符而且包含敏感数据，那么还是使用 post为好。  HTTP 1.0 HTTP 1.0规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接\n当一个网页文件中包含了很多图像的地址的时候，那就需要很多次的HTTP请求和响应，每次请求和响应都需要一个单独的连接，每次连接只是传输一个文档和图像，上一次和下一次请求完全分离。即使图像文件都很小，但是客户端和服务器端每次建立和关闭连接却是一个相对比较费时的过程，并且会严重影响客户机和服务器的性能。当一个网页文件中包含JS文件，CSS文件等内容时，也会出现类似上述的情况。\nHTTP 1.1 为了克服HTTP 1.0的这个缺陷，HTTP 1.1支持持久连接（HTTP/1.1的默认模式使用带流水线的持久连接），在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。一个包含有许多图像的网页文件的多个请求和应答可以在一个连接中传输，但每个单独的网页文件的请求和应答仍然需要使用各自的连接。\nHTTP 1.1还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容，这样也显著地减少了整个下载过程所需要的时间。\n在HTTP 1.1，request和response头中都有可能出现一个connection的头，此header的含义是当client和server通信时对于长链接如何进行处理。\n在HTTP 1.1中，client和server都是默认对方支持长链接的， 如果client使用HTTP 1.1协议，但又不希望使用长链接，则需要在header中指明connection的值为close；如果server方也不想支持长链接，则在response中也需要明确说明connection的值为close。不论request还是response的header中包含了值为close的connection，都表明当前正在使用的tcp链接在当天请求处理完毕后会被断掉。以后client再进行新的请求时就必须创建新的tcp链接了。\nHTTP 1.1在继承了HTTP 1.0优点的基础上，也克服了HTTP 1.0的性能问题。\nHTTP 1.1通过增加更多的请求头和响应头来改进和扩充HTTP 1.0的功能。如，HTTP 1.0不支持Host请求头字段，浏览器无法使用主机头名来明确表示要访问服务器上的哪个WEB站点，这样就无法使用WEB服务器在同一个IP地址和端口号上配置多个虚拟WEB站点。在HTTP 1.1中增加Host请求头字段后，WEB浏览器可以使用主机头名来明确表示要访问服务器上的哪个WEB站点，这才实现了在一台WEB服务器上可以在同一个IP地址和端口号上使用不同的主机名来创建多个虚拟WEB站点。HTTP 1.1的持续连接，也需要增加新的请求头来帮助实现，例如，Connection请求头的值为Keep-Alive时，客户端通知服务器返回本次请求结果后保持连接；Connection请求头的值为close时，客户端通知服务器返回本次请求结果后关闭连接。HTTP 1.1还提供了与身份认证、状态管理和Cache缓存等机制相关的请求头和响应头。HTTP 1.0不支持文件断点续传，RANGE:bytes是HTTP 1.1新增内容，HTTP 1.0每次传送文件都是从文件头开始，即0字节处开始。RANGE:bytes=XXXX表示要求服务器从文件XXXX字节处开始传送，这就是我们平时所说的断点续传。\nHTTP 1.1和HTTP 1.0协议的区别  缓存处理 带宽优化及网络连接的使用 错误通知的管理 消息在网络中的发送 互联网地址的维护 安全性及完整性  HTTP 1.x和HTTP 2协议的区别  二进制分帧：HTTP 2采用二进制格式传输数据，而非HTTP 1.x的文本格式 头部压缩：头部表在HTTP 2的连接存续期内始终存在，由客户端和服务器共同渐进地更新。请求一发送了所有的头部字段，第二个请求则只需要发送差异数据，这样可以减少冗余数据，降低开销 多路复用：直白的说就是所有的请求都是通过一个TCP连接并发完成。HTTP 1.x虽然通过pipeline也能并发请求，但是多个请求之间的响应会被阻塞的，所以pipeline至今也没有被普及应用，而HTTP 2做到了真正的并发请求。同时，流还支持优先级和流量控制。 服务器推送：服务端能够更快的把资源推送给客户端。例如服务端可以主动把JS和CSS文件推送给客户端，而不需要客户端解析HTML再发送这些请求。当客户端需要的时候，它已经在客户端了。   HTTP 2主要是HTTP 1.x在底层传输机制上的完全重构，HTTP 2是基本兼容HTTP 1.x的语义。Content-Type仍然是Content-Type，只不过它不再是文本传输了。\n HTTP和HTTPS协议的区别  HTTP的URL以http://开头，而HTTPS的URL以https://开头 HTTP是不安全的，而HTTPS是安全的 HTTP标准端口是80，而HTTPS的标准端口是443 在OSI网络模型中，HTTP工作于应用层，而HTTPS的安全传输机制工作在传输层 HTTP无法加密，而HTTPS对传输的数据进行加密 HTTP无需证书，而HTTPS需要CA机构颁发的SSL证书  常用的请求方式  GET:请求获取Request-URI所标识的资源 POST:在Request-URI所标识的资源后附加新的数据 HEAD:请求获取由Request-URI所标识的资源的响应消息报头 PUT:请求服务器存储一个资源，并用Request-URI作为其标识 DELETE:请求服务器删除Request-URI所标识的资源 TRACE:请求服务器回送收到的请求信息，主要用于测试或诊断 CONNECT:保留将来使用 OPTIONS:请求查询服务器的性能，或者查询与资源相关的选项和需求  GET方法：在浏览器的地址栏中输入网址的方式访问网页时，浏览器采用GET方法向服务器获取资源，POST方法要求被请求服务器接受附在请求后面的数据，常用于提交表单。GET是用于获取数据的，POST一般用于将数据发给服务器之用。\nHTTP响应状态码  1XX:信息性状态码 2XX:成功状态码 3XX:重定向状态码 4XX:客户端错误状态码 5XX:服务端错误状态码  常见的状态码 2XX  200:表示从客户端发出的请求在服务端正常被处理且返回 204:表示服务器接收的请求已成功处理，但在返回的响应报文中不含实体的主体部分。比如，当从浏览器发出请求处理后，返回204响应，那么浏览器显示的页面不发生更新 206:该状态码表示客户端进行了范围请求，而服务器成功执行了这部分的GET请求  3XX  301:永久性重定向。该状态码表示请求的资源已经被分配了新的URI，以后应使用资源现在所指的URI。 当指定的资源路径的最后忘记添加斜杠\u0026quot;/\u0026quot;，就会产生301状态码 302:临时性重定向。该状态码表示请求的资源已被分配了新的URI，希望用户(本次)能使用新的URI访问 303:该状态码表示由于请求对应的资源存在另外一个URI，应使用GET方法定向获取请求的资源。 303状态码和302状态码有着相同的功能，但303状态码明确表明客户端应当采用GET方法获取资源。 当301，302，303响应状态码返回时，几乎所有的浏览器都会把POST改成GET，并删除请求报文的主体，之后请求会自动再次发送。 301，302标准是禁止将POST方法改变成GET方法的，但实际上使用时大家都会这么做。 304:该状态码表示客户端发送附带条件的请求时，服务器端允许请求访问资源，但未满足条件的情况。304状态码返回时，不包含任何响应的主体部分。304虽然被划分在3XX类别中，但是和重定向没有关系 307:临时重定向。该状态码与302 Found有着相同的含义。307会遵照浏览器标准，不会从POST变成GET  4XX  400:该状态码表示请求报文中存在语法错误。当错误发生时，需要修改请求的内容后再次放松请求 401:该状态码表示发送的请求需要有通过HTTP认证的认证信息，另外若之前已进行过1此请求，则表示用户认证失败 403:该状态码表明对请求资源的访问被服务器拒绝了 404:该状态码表明服务器上无法找到请求的资源  5XX  500:该状态码表明服务器端在执行请求时发生了错误 503:该状态码表明服务器暂时处于超负载或正在进行停机维护，现在无法处理请求  参考连接  综合阐述http1.0/1.1/2和https 说说 HTTP1.0/1.1/2.0 的区别  ","date":"March 31, 2022","hero":"/posts/knowledge/2004-network/002-http_statuscode/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2004-network/002-http_statuscode/","summary":"#http-code\n http协议（超文本传输协议）  是客户端和服务器端两者通信共同遵循的一些规则。主要内容是定义了客户端如何向服务器请求资源，服务器如何响应客户端请求。\n 请求中的POST与GET方法的区别\n get是从服务器上获取数据，post是向服务器传送数据。 在客户端，Get方式在通过URL提交数据，数据在URL中可以看到；POST方式，数据放置在HTML HEADER内提交。 对于get方式，服务器端用Request.QueryString获取变量的值，对于post方式，服务器端用Request.Form获取提交的数据。 GET方式提交的数据最多只能有1024字节，而POST则没有此限制。 安全性问题。正如在（1）中提到，使用 GET 的时候，参数会显示在地址栏上，而 Post 不会。所以，如果这些数据是中文数据而且是非敏感数据，那么使用 GET；如果用户输入的数据不是中文字符而且包含敏感数据，那么还是使用 post为好。  HTTP 1.0 HTTP 1.0规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接\n当一个网页文件中包含了很多图像的地址的时候，那就需要很多次的HTTP请求和响应，每次请求和响应都需要一个单独的连接，每次连接只是传输一个文档和图像，上一次和下一次请求完全分离。即使图像文件都很小，但是客户端和服务器端每次建立和关闭连接却是一个相对比较费时的过程，并且会严重影响客户机和服务器的性能。当一个网页文件中包含JS文件，CSS文件等内容时，也会出现类似上述的情况。\nHTTP 1.1 为了克服HTTP 1.0的这个缺陷，HTTP 1.1支持持久连接（HTTP/1.1的默认模式使用带流水线的持久连接），在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。一个包含有许多图像的网页文件的多个请求和应答可以在一个连接中传输，但每个单独的网页文件的请求和应答仍然需要使用各自的连接。\nHTTP 1.1还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容，这样也显著地减少了整个下载过程所需要的时间。\n在HTTP 1.1，request和response头中都有可能出现一个connection的头，此header的含义是当client和server通信时对于长链接如何进行处理。\n在HTTP 1.1中，client和server都是默认对方支持长链接的， 如果client使用HTTP 1.1协议，但又不希望使用长链接，则需要在header中指明connection的值为close；如果server方也不想支持长链接，则在response中也需要明确说明connection的值为close。不论request还是response的header中包含了值为close的connection，都表明当前正在使用的tcp链接在当天请求处理完毕后会被断掉。以后client再进行新的请求时就必须创建新的tcp链接了。\nHTTP 1.1在继承了HTTP 1.0优点的基础上，也克服了HTTP 1.0的性能问题。\nHTTP 1.1通过增加更多的请求头和响应头来改进和扩充HTTP 1.0的功能。如，HTTP 1.0不支持Host请求头字段，浏览器无法使用主机头名来明确表示要访问服务器上的哪个WEB站点，这样就无法使用WEB服务器在同一个IP地址和端口号上配置多个虚拟WEB站点。在HTTP 1.1中增加Host请求头字段后，WEB浏览器可以使用主机头名来明确表示要访问服务器上的哪个WEB站点，这才实现了在一台WEB服务器上可以在同一个IP地址和端口号上使用不同的主机名来创建多个虚拟WEB站点。HTTP 1.1的持续连接，也需要增加新的请求头来帮助实现，例如，Connection请求头的值为Keep-Alive时，客户端通知服务器返回本次请求结果后保持连接；Connection请求头的值为close时，客户端通知服务器返回本次请求结果后关闭连接。HTTP 1.1还提供了与身份认证、状态管理和Cache缓存等机制相关的请求头和响应头。HTTP 1.0不支持文件断点续传，RANGE:bytes是HTTP 1.1新增内容，HTTP 1.0每次传送文件都是从文件头开始，即0字节处开始。RANGE:bytes=XXXX表示要求服务器从文件XXXX字节处开始传送，这就是我们平时所说的断点续传。\nHTTP 1.1和HTTP 1.0协议的区别  缓存处理 带宽优化及网络连接的使用 错误通知的管理 消息在网络中的发送 互联网地址的维护 安全性及完整性  HTTP 1.x和HTTP 2协议的区别  二进制分帧：HTTP 2采用二进制格式传输数据，而非HTTP 1.","tags":null,"title":"HTTP笔记"},{"categories":null,"contents":" #golang #atomic\n 互斥锁跟原子操作的区别 在并发编程里，Go语言sync包里的同步原语Mutex是我们经常用来保证并发安全的，那么他跟atomic包在使用目的和底层实现上都不一样：\n使用目的 互斥锁是用来保护一段逻辑，原子操作用于对一个变量的更新保护。\n底层实现 Mutex由操作系统的调度器实现，而atomic包中的原子操作则由底层硬件指令直接提供支持，这些指令在执行的过程中是不允许中断的，因此原子操作可以在lock-free的情况下保证并发安全，并且它的性能也能做到随CPU个数的增多而线性扩展。\n对于一个变量更新的保护，原子操作通常会更有效率，并且更能利用计算机多核的优势。\n性能测试对比 互斥锁性能测试  使用sync包下面互斥锁的多线程加法操作\n func syncAdd(param int64) int64 { var wg sync.WaitGroup lock := sync.Mutex{} for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func() { for i := 0; i \u0026lt; 1000000; i++ { lock.Lock() param++ lock.Unlock() } wg.Done() }() } wg.Wait() return param } Benchmark测试方法\nfunc BenchmarkSync(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { flag := int64(0) res := syncAdd(flag) if res != 10000000 { b.Errorf(\u0026#34;calculate result err: %d\\n\u0026#34;, res) } } } 测试结果：\n 根据运行环境和硬件性能会有所不同，这里是在相同环境下的对比\n  第一次  goos: darwin goarch: arm64 pkg: wire/atomic_test BenchmarkSync BenchmarkSync-8 2\t862741542 ns/op PASS  第二次  goos: darwin goarch: arm64 pkg: wire/atomic_test BenchmarkSync BenchmarkSync-8 2\t875432729 ns/op PASS  第三次  goos: darwin goarch: arm64 pkg: wire/atomic_test BenchmarkSync BenchmarkSync-8 2\t836373292 ns/op PASS 三次取平均：(862741542 + 875432729 + 836373292) / 3 = 858182521 ns/op\n原子操作性能测试  使用atomic包下面原子操作的多线程加法操作\n func atomicAdd(param int64) int64 { var wg sync.WaitGroup for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func() { for i := 0; i \u0026lt; 1000000; i++ { atomic.AddInt64(\u0026amp;param, 1) } wg.Done() }() } wg.Wait() return param } Benchmark测试方法\nfunc BenchmarkAtomic(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { flag := int64(0) res := atomicAdd(flag) if res != 10000000 { b.Errorf(\u0026#34;calculate result err: %d\\n\u0026#34;, res) } } } 测试结果：\n 根据运行环境和硬件性能会有所不同，这里是在相同环境下的对比\n  第一次  goos: darwin goarch: arm64 pkg: wire/atomic_test BenchmarkAtomic BenchmarkAtomic-8 4\t359013958 ns/op PASS  第二次  goos: darwin goarch: arm64 pkg: wire/atomic_test BenchmarkAtomic BenchmarkAtomic-8 3\t359734514 ns/op PASS  第三次  goos: darwin goarch: arm64 pkg: wire/atomic_test BenchmarkAtomic BenchmarkAtomic-8 4\t359007542 ns/op PASS  三次取平均：(359013958 + 359734514 + 359007542) / 3 = 359252004 ns/op\n 测试结果对比 根据测试结果数据使用互斥锁做累加每次循环耗时858182521 ns，而使用原子操作做累加每次耗时359252004 ns。\n这也印证了之前说过的：互斥锁适用于来保护一段逻辑，原子操作适用于于对一个变量的更新保护。\n原理浅析 参考： 互斥锁跟原子操作的区别-底层实现\n参考链接  Golang五种原子性操作的用法详解  ","date":"March 30, 2022","hero":"/posts/knowledge/2001-go/006-atomic/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2001-go/006-atomic/","summary":"#golang #atomic\n 互斥锁跟原子操作的区别 在并发编程里，Go语言sync包里的同步原语Mutex是我们经常用来保证并发安全的，那么他跟atomic包在使用目的和底层实现上都不一样：\n使用目的 互斥锁是用来保护一段逻辑，原子操作用于对一个变量的更新保护。\n底层实现 Mutex由操作系统的调度器实现，而atomic包中的原子操作则由底层硬件指令直接提供支持，这些指令在执行的过程中是不允许中断的，因此原子操作可以在lock-free的情况下保证并发安全，并且它的性能也能做到随CPU个数的增多而线性扩展。\n对于一个变量更新的保护，原子操作通常会更有效率，并且更能利用计算机多核的优势。\n性能测试对比 互斥锁性能测试  使用sync包下面互斥锁的多线程加法操作\n func syncAdd(param int64) int64 { var wg sync.WaitGroup lock := sync.Mutex{} for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func() { for i := 0; i \u0026lt; 1000000; i++ { lock.Lock() param++ lock.Unlock() } wg.Done() }() } wg.Wait() return param } Benchmark测试方法\nfunc BenchmarkSync(b *testing.B) { for i := 0; i \u0026lt; b.","tags":null,"title":"Golang中的原子操作"},{"categories":null,"contents":"#redis #cache #db\n缓存一致性 形成原因 数据增删修操作造成的缓存内容与持久层内容的不一致\n解决办法  先更新缓存后更新数据库：更新缓存后程序异常终止或持久化失败导致数据未持久化 先更新数据库后更新缓存：更新数据库后程序异常终止或更新缓存失败导致缓存数据与数据库不一致。解决办法：先更新缓存，后将数据修改操作写入持久化队列，比如Kafka，让下游服务执行持久化操作  缓存穿透  针对多个key\n 形成原因 缓存穿透是指查询一个不存在的数据，由于缓存是不命中时，去存储层（如MySQL）查找数据。如果从存储层查不到数据没有写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，导致缓存穿透。流量一旦大了之后，容易导致DB宕机，进而影响整个业务。利用不存在的key频繁攻击应用，这就是漏洞。\n解决办法  使用布隆过滤器，如果从DB中没有查到则添加到布隆过滤器中。但由于布隆过滤器中存储的内容是不能修改的，需要注意使用场景。如果当前查询不存在的key以后会出现再实际数据中，使用布隆过滤器会导致改条数据无法查询到。 缓存不存在的key，如果从DB中没有查询到该数据，则将对应的key写入缓存中，并加一个合适的过期时间。value内容写一个不存在的标记，当程序读到该内容后，即知道这条key不存在对应的内容直接返回，不会将流量打入存储层。  缓存雪崩  多个key相同的过期时间\n 形成原因 缓存雪崩是指多个key在相同时间过期，导致缓存在某一时刻同时失效。请求全部转发到DB，DB瞬时压力过高宕机导致服务不可用。\n解决办法  使用队列，将需要缓存的数据发往一个统一的队列中，依次写缓存。 随机过期时间，比如一个key需要缓存一小时，则在一小时的基础上随机±5分钟，这样可以一定程度上解决一批key集中过期的问题  缓存击穿  针对一个key\n 形成原因 某个设置了过期时间的key，在过期后某一时间有大量并发请求进来。而在第一个请求进来，从DB中查完还没来得及写入缓存中时后面的并发请求也进来了，就会造成同一个key并发访问DB，瞬间打垮存储层。\n一般突然出现的热点key容易造成这种问题。\n解决办法  使用分布式互斥锁，当一个key在缓存中没有查询到时，先去抢这个key的锁，抢到则去存储层进行查询，没有抢到则去缓存中查询，根据实际情况如果一次没有查找到可以循环查找几次（毕竟查数据库需要耗时）。  其他 数据的缓存策略，有时也需要根据实际业务来设定。比如一些热点key设置为永不过期，但永不过期也会给缓存的存储带来压力，而给key设置过期时间，又会带来以上几种问题。抑或是缓存设置永不过期，使用异步线程定期删除一些没有访问的key。\n写代码的时候需要一个指导思想，但同时亦不可死搬教条。\n","date":"March 11, 2022","hero":"/posts/knowledge/2009-redis/001-cache/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2009-redis/001-cache/","summary":"#redis #cache #db\n缓存一致性 形成原因 数据增删修操作造成的缓存内容与持久层内容的不一致\n解决办法  先更新缓存后更新数据库：更新缓存后程序异常终止或持久化失败导致数据未持久化 先更新数据库后更新缓存：更新数据库后程序异常终止或更新缓存失败导致缓存数据与数据库不一致。解决办法：先更新缓存，后将数据修改操作写入持久化队列，比如Kafka，让下游服务执行持久化操作  缓存穿透  针对多个key\n 形成原因 缓存穿透是指查询一个不存在的数据，由于缓存是不命中时，去存储层（如MySQL）查找数据。如果从存储层查不到数据没有写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，导致缓存穿透。流量一旦大了之后，容易导致DB宕机，进而影响整个业务。利用不存在的key频繁攻击应用，这就是漏洞。\n解决办法  使用布隆过滤器，如果从DB中没有查到则添加到布隆过滤器中。但由于布隆过滤器中存储的内容是不能修改的，需要注意使用场景。如果当前查询不存在的key以后会出现再实际数据中，使用布隆过滤器会导致改条数据无法查询到。 缓存不存在的key，如果从DB中没有查询到该数据，则将对应的key写入缓存中，并加一个合适的过期时间。value内容写一个不存在的标记，当程序读到该内容后，即知道这条key不存在对应的内容直接返回，不会将流量打入存储层。  缓存雪崩  多个key相同的过期时间\n 形成原因 缓存雪崩是指多个key在相同时间过期，导致缓存在某一时刻同时失效。请求全部转发到DB，DB瞬时压力过高宕机导致服务不可用。\n解决办法  使用队列，将需要缓存的数据发往一个统一的队列中，依次写缓存。 随机过期时间，比如一个key需要缓存一小时，则在一小时的基础上随机±5分钟，这样可以一定程度上解决一批key集中过期的问题  缓存击穿  针对一个key\n 形成原因 某个设置了过期时间的key，在过期后某一时间有大量并发请求进来。而在第一个请求进来，从DB中查完还没来得及写入缓存中时后面的并发请求也进来了，就会造成同一个key并发访问DB，瞬间打垮存储层。\n一般突然出现的热点key容易造成这种问题。\n解决办法  使用分布式互斥锁，当一个key在缓存中没有查询到时，先去抢这个key的锁，抢到则去存储层进行查询，没有抢到则去缓存中查询，根据实际情况如果一次没有查找到可以循环查找几次（毕竟查数据库需要耗时）。  其他 数据的缓存策略，有时也需要根据实际业务来设定。比如一些热点key设置为永不过期，但永不过期也会给缓存的存储带来压力，而给key设置过期时间，又会带来以上几种问题。抑或是缓存设置永不过期，使用异步线程定期删除一些没有访问的key。\n写代码的时候需要一个指导思想，但同时亦不可死搬教条。","tags":null,"title":"Redis缓存相关问题"},{"categories":null,"contents":" #oauth\n  PKCE全称是Proof Key for Code Exchange，在2015年发布，它是OAuth 2.0核心的一个扩展协议，所以可以和现有的授权模式结合使用，比如Authorization Code+PKCE， 这也是最佳实践，PKCE最初是为移动设备应用和本地应用创建的， 主要是为了减少公共客户端的授权码拦截攻击。 在最新的OAuth 2.1规范中，推荐所有客户端都使用PKCE，而不仅仅是公共客户端，并且移除了Implicit隐式和Password模式，那之前使用这两种模式的客户端怎么办? 是的，现在都可以尝试使用Authorization Code+PKCE的授权模式。那PKCE为什么有这种魔力呢? 实际上它的原理是客户端提供一个自创建的证明给授权服务器，授权服务器通过它来验证客户端，把访问令牌(access_token)颁发给真实的客户端而不是伪造的。\n 客户端类型 上面说到了PKCE主要是为了减少公共客户端的授权码拦截攻击，那就有必要介绍下两种客户端类型了。\n OAuth 2.0核心规范定义了两种客户端类型， confidential 机密的， 和 public 公开的， 区分这两种类型的方法是， 判断这个客户端是否有能力维护自己的机密性凭据 client_secret。\n  confidential\n对于一个普通的web站点来说，虽然用户可以访问到前端页面，但是数据都来自服务器的后端api服务，前端只是获取授权码code，通过code换取access_token这一步是在后端的api完成的，由于是内部的服务器，客户端有能力维护密码或者密钥信息，这种是机密的的客户端。 public\n客户端本身没有能力保存密钥信息，比如桌面软件，手机App，单页面程序(SPA)，因为这些应用是发布出去的，实际上也就没有安全可言，恶意攻击者可以通过反编译等手段查看到客户端的密钥，这种是公开的客户端。  在OAuth 2.0授权码模式（Authorization Code）中，客户端通过授权码code向授权服务器获取访问令牌(access_token)时，同时还需要在请求中携带客户端密钥(client_secret)，授权服务器对其进行验证，保证access_token颁发给了合法的客户端，对于公开的客户端来说，本身就有密钥泄露的风险，所以就不能使用常规OAuth 2.0的授权码模式，于是就针对这种不能使用client_secret的场景，衍生出了Implicit隐式模式，这种模式从一开始就是不安全的。在经过一段时间之后，PKCE扩展协议推出，就是为了解决公开客户端的授权安全问题。\n授权码拦截攻击 上面是OAuth 2.0授权码模式的完整流程，授权码拦截攻击就是图中的C步骤发生的，也就是授权服务器返回给客户端授权码的时候，这么多步骤中为什么C步骤是不安全的呢?在OAuth 2.0核心规范中，要求授权服务器的anthorize endpoint和token endpoint必须使用TLS（安全传输层协议）保护，但是授权服务器携带授权码code返回到客户端的回调地址时，有可能不受TLS的保护，恶意程序就可以在这个过程中拦截授权码code，拿到code之后，接下来就是通过code向授权服务器换取访问令牌access_token，对于机密的客户端来说，请求access_token时需要携带客户端的密钥client_secret，而密钥保存在后端服务器上，所以恶意程序通过拦截拿到授权码code也没有用，而对于公开的客户端（手机App，桌面应用）来说，本身没有能力保护client_secret，因为可以通过反编译等手段，拿到客户端client_secret，也就可以通过授权码code换取access_token，到这一步，恶意应用就可以拿着token请求资源服务器了。\nstate参数，在OAuth 2.0核心协议中，通过code换取token步骤中，推荐使用state参数，把请求和响应关联起来，可以防止跨站点请求伪造-CSRF攻击，但是state并不能防止上面的授权码拦截攻击，因为请求和响应并没有被伪造，而是响应的授权码被恶意程序拦截。\nPKCE 协议流程 PKCE协议本身是对OAuth 2.0的扩展，它和之前的授权码流程大体上是一致的。区别在于，在向授权服务器的authorize endpoint请求时，需要额外的code_challenge和code_challenge_method参数，向token endpoint请求时，需要额外的code_verifier参数，最后授权服务器会对这三个参数进行对比验证，通过后颁发令牌。\n原理分析 上面我们说了授权码拦截攻击，它是指在整个授权流程中，只需要拦截到从授权服务器回调给客户端的授权码code，就可以去授权服务器申请令牌了，因为客户端是公开的，就算有密钥client_secret也是形同虚设，恶意程序拿到访问令牌后，就可以光明正大的请求资源服务器了。\nPKCE是怎么做的呢?既然固定的client_secret是不安全的，那就每次请求生成一个随机的密钥（code_verifier），第一次请求到授权服务器的authorize endpoint时，携带code_challenge和code_challenge_method，也就是code_verifier转换后的值和转换方法，然后授权服务器需要把这两个参数缓存起来，第二次请求到token endpoint时，携带生成的随机密钥的原始值(code_verifier)，然后授权服务器使用下面的方法进行验证:\n plain\ncode_challenge = code_verifier sha256\ncode_challenge = BASE64URL-ENCODE(SHA256(ASCII(code_verifier)))  通过后才颁发令牌，那向授权服务器authorize endpoint和token endpoint发起的这两次请求，该如何关联起来呢?通过授权码code即可，所以就算恶意程序拦截到了授权码code，但是没有code_verifier，也是不能获取访问令牌的，当然PKCE也可以用在机密（confidential）的客户端，那就是client_secret+code_verifier双重密钥了。\n参考连接  oauth文档  ","date":"February 10, 2022","hero":"/posts/knowledge/2004-network/001-oauth/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2004-network/001-oauth/","summary":"#oauth\n  PKCE全称是Proof Key for Code Exchange，在2015年发布，它是OAuth 2.0核心的一个扩展协议，所以可以和现有的授权模式结合使用，比如Authorization Code+PKCE， 这也是最佳实践，PKCE最初是为移动设备应用和本地应用创建的， 主要是为了减少公共客户端的授权码拦截攻击。 在最新的OAuth 2.1规范中，推荐所有客户端都使用PKCE，而不仅仅是公共客户端，并且移除了Implicit隐式和Password模式，那之前使用这两种模式的客户端怎么办? 是的，现在都可以尝试使用Authorization Code+PKCE的授权模式。那PKCE为什么有这种魔力呢? 实际上它的原理是客户端提供一个自创建的证明给授权服务器，授权服务器通过它来验证客户端，把访问令牌(access_token)颁发给真实的客户端而不是伪造的。\n 客户端类型 上面说到了PKCE主要是为了减少公共客户端的授权码拦截攻击，那就有必要介绍下两种客户端类型了。\n OAuth 2.0核心规范定义了两种客户端类型， confidential 机密的， 和 public 公开的， 区分这两种类型的方法是， 判断这个客户端是否有能力维护自己的机密性凭据 client_secret。\n  confidential\n对于一个普通的web站点来说，虽然用户可以访问到前端页面，但是数据都来自服务器的后端api服务，前端只是获取授权码code，通过code换取access_token这一步是在后端的api完成的，由于是内部的服务器，客户端有能力维护密码或者密钥信息，这种是机密的的客户端。 public\n客户端本身没有能力保存密钥信息，比如桌面软件，手机App，单页面程序(SPA)，因为这些应用是发布出去的，实际上也就没有安全可言，恶意攻击者可以通过反编译等手段查看到客户端的密钥，这种是公开的客户端。  在OAuth 2.0授权码模式（Authorization Code）中，客户端通过授权码code向授权服务器获取访问令牌(access_token)时，同时还需要在请求中携带客户端密钥(client_secret)，授权服务器对其进行验证，保证access_token颁发给了合法的客户端，对于公开的客户端来说，本身就有密钥泄露的风险，所以就不能使用常规OAuth 2.0的授权码模式，于是就针对这种不能使用client_secret的场景，衍生出了Implicit隐式模式，这种模式从一开始就是不安全的。在经过一段时间之后，PKCE扩展协议推出，就是为了解决公开客户端的授权安全问题。\n授权码拦截攻击 上面是OAuth 2.0授权码模式的完整流程，授权码拦截攻击就是图中的C步骤发生的，也就是授权服务器返回给客户端授权码的时候，这么多步骤中为什么C步骤是不安全的呢?在OAuth 2.0核心规范中，要求授权服务器的anthorize endpoint和token endpoint必须使用TLS（安全传输层协议）保护，但是授权服务器携带授权码code返回到客户端的回调地址时，有可能不受TLS的保护，恶意程序就可以在这个过程中拦截授权码code，拿到code之后，接下来就是通过code向授权服务器换取访问令牌access_token，对于机密的客户端来说，请求access_token时需要携带客户端的密钥client_secret，而密钥保存在后端服务器上，所以恶意程序通过拦截拿到授权码code也没有用，而对于公开的客户端（手机App，桌面应用）来说，本身没有能力保护client_secret，因为可以通过反编译等手段，拿到客户端client_secret，也就可以通过授权码code换取access_token，到这一步，恶意应用就可以拿着token请求资源服务器了。\nstate参数，在OAuth 2.0核心协议中，通过code换取token步骤中，推荐使用state参数，把请求和响应关联起来，可以防止跨站点请求伪造-CSRF攻击，但是state并不能防止上面的授权码拦截攻击，因为请求和响应并没有被伪造，而是响应的授权码被恶意程序拦截。\nPKCE 协议流程 PKCE协议本身是对OAuth 2.0的扩展，它和之前的授权码流程大体上是一致的。区别在于，在向授权服务器的authorize endpoint请求时，需要额外的code_challenge和code_challenge_method参数，向token endpoint请求时，需要额外的code_verifier参数，最后授权服务器会对这三个参数进行对比验证，通过后颁发令牌。\n原理分析 上面我们说了授权码拦截攻击，它是指在整个授权流程中，只需要拦截到从授权服务器回调给客户端的授权码code，就可以去授权服务器申请令牌了，因为客户端是公开的，就算有密钥client_secret也是形同虚设，恶意程序拿到访问令牌后，就可以光明正大的请求资源服务器了。\nPKCE是怎么做的呢?既然固定的client_secret是不安全的，那就每次请求生成一个随机的密钥（code_verifier），第一次请求到授权服务器的authorize endpoint时，携带code_challenge和code_challenge_method，也就是code_verifier转换后的值和转换方法，然后授权服务器需要把这两个参数缓存起来，第二次请求到token endpoint时，携带生成的随机密钥的原始值(code_verifier)，然后授权服务器使用下面的方法进行验证:\n plain\ncode_challenge = code_verifier sha256\ncode_challenge = BASE64URL-ENCODE(SHA256(ASCII(code_verifier)))  通过后才颁发令牌，那向授权服务器authorize endpoint和token endpoint发起的这两次请求，该如何关联起来呢?","tags":null,"title":"OAuth 2.0扩展协议PKCE"},{"categories":null,"contents":" 与MySQL类似，Redis安装完也不能直接使用，默认的配置文件有几处需要修改\n 使用yum安装的Redis默认配置文件路径：/etc/redis.conf\n允许访问地址 # bind 127.0.0.1 将只限本地访问的配置注释掉\n修改保护模式 protected-mode no 将保护模式修改为no\n启用守护进程 daemonize yes 将守护进程设置为yes\n","date":"January 13, 2022","hero":"/posts/deployment/3008-linux-redis/head.svg","permalink":"https://ormissia.github.io/posts/deployment/3008-linux-redis/","summary":"与MySQL类似，Redis安装完也不能直接使用，默认的配置文件有几处需要修改\n 使用yum安装的Redis默认配置文件路径：/etc/redis.conf\n允许访问地址 # bind 127.0.0.1 将只限本地访问的配置注释掉\n修改保护模式 protected-mode no 将保护模式修改为no\n启用守护进程 daemonize yes 将守护进程设置为yes","tags":null,"title":"Redis默认配置文件修改"},{"categories":null,"contents":" #IO #bio #nio #多路复用\n  作为\n 网络IO演进模型  阻塞IO BIO(Blocking IO) 非阻塞IO NIO(Nonblocking IO) IO多路复用第一版 select/poll/epoll 异步IO AIO(Async IO)  BIO  阻塞 IO，顾名思义当用户发生了系统调用后，如果数据未从网卡到达内核态，内核态数据未准备好，此时会一直阻塞。直到数据就绪，然后从内核态拷贝到用户态再返回。\n  BIO缺点，能支持的并发连接数比较少：  一台服务器能分配的线程数是有限的 大量线程频繁切换上下文会影响性能     核心矛盾：一个client分配一个线程是因为处理客户端读写是阻塞式的，为避免该阻塞影响接受后续新的client的连接，所以将阻塞逻辑交由单独的线程处理。\n NIO  非阻塞 IO：见名知意，就是在第一阶段(网卡-内核态)数据未到达时不等待，然后直接返回。因此非阻塞 IO 需要不断的用户发起请求，轮询内核。\n  优点  将socket设为非阻塞后，在读取时如果数据未就绪就直接返回。可以通过一个线程管理多个client连接。   缺点  需要不断轮询内核，数据是否已经就绪，会造成很多无效的，太频繁的系统调用(system call)而造成资源浪费。    select/poll/epoll  select 和 poll 的区别  select 能处理的最大连接，默认是 1024 个，可以通过修改配置来改变，但终究是有限个；而 poll 理论上可以支持无限个 select 和 poll 在管理海量的连接时，会频繁的从用户态拷贝到内核态，比较消耗资源    epoll对文件描述符的操作有两种模式： LT（level trigger）和 ET（edge trigger）。\n LT模式：当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用 epoll_wait 时，会再次响应应用程序并通知此事件。 ET模式：当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用 epoll_wait 时，不会再次响应应用程序并通知此事件。   简言之：边沿触发仅触发一次，水平触发会一直触发。\n epoll高效的本质在于：\n 减少了用户态和内核态的文件句柄拷贝 减少了对可读可写文件句柄的遍历 mmap 加速了内核与用户空间的信息传递，epoll是通过内核与用户mmap同一块内存，避免了无谓的内存拷贝 IO性能不会随着监听的文件描述的数量增长而下降 使用红黑树存储fd，以及对应的回调函数，其插入，查找，删除的性能不错，相比于hash，不必预先分配很多的空间     - select poll epoll     操作方式 遍历 遍历 回调   底层实现 数组 链表 哈希表   IO效率 每次调用都进行线性遍历，时间复杂度为O(n) 每次调用都进行线性遍历，时间复杂度为O(n) 事件通知方式，每当fd就绪，系统注册的回调函数就会被调用，将就绪fd放到rdllist里面。时间复杂度O(1)   最大连接数 1024（x86）或 2048（x64） 无上限 无上限   fd拷贝 每次调用select，都需要把fd集合从用户态拷贝到内核态 每次调用poll，都需要把fd集合从用户态拷贝到内核态 调用epoll_ctl时拷贝进内核并保存，之后每次epoll_wait不拷贝    AIO 参考连接  Chapter 6. I/O Multiplexing: The select and poll Functions epoll(7) — Linux manual page The C10K problem  ","date":"January 1, 2022","hero":"/posts/knowledge/2005-operating-system/001-io-network/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2005-operating-system/001-io-network/","summary":"#IO #bio #nio #多路复用\n  作为\n 网络IO演进模型  阻塞IO BIO(Blocking IO) 非阻塞IO NIO(Nonblocking IO) IO多路复用第一版 select/poll/epoll 异步IO AIO(Async IO)  BIO  阻塞 IO，顾名思义当用户发生了系统调用后，如果数据未从网卡到达内核态，内核态数据未准备好，此时会一直阻塞。直到数据就绪，然后从内核态拷贝到用户态再返回。\n  BIO缺点，能支持的并发连接数比较少：  一台服务器能分配的线程数是有限的 大量线程频繁切换上下文会影响性能     核心矛盾：一个client分配一个线程是因为处理客户端读写是阻塞式的，为避免该阻塞影响接受后续新的client的连接，所以将阻塞逻辑交由单独的线程处理。\n NIO  非阻塞 IO：见名知意，就是在第一阶段(网卡-内核态)数据未到达时不等待，然后直接返回。因此非阻塞 IO 需要不断的用户发起请求，轮询内核。\n  优点  将socket设为非阻塞后，在读取时如果数据未就绪就直接返回。可以通过一个线程管理多个client连接。   缺点  需要不断轮询内核，数据是否已经就绪，会造成很多无效的，太频繁的系统调用(system call)而造成资源浪费。    select/poll/epoll  select 和 poll 的区别  select 能处理的最大连接，默认是 1024 个，可以通过修改配置来改变，但终究是有限个；而 poll 理论上可以支持无限个 select 和 poll 在管理海量的连接时，会频繁的从用户态拷贝到内核态，比较消耗资源    epoll对文件描述符的操作有两种模式： LT（level trigger）和 ET（edge trigger）。","tags":null,"title":"网络IO演进历程"},{"categories":null,"contents":" #javascript #js #react\n 初始化React项目 npm install -g react npm install -g react-dom npm install -g react-scripts npm install -g create-react-app create-react-app hello-react cd hello-react npm start 更新package.json npm install -g npm-check-updates ncu # 或者npm-check-updates ncu -u to upgrade package.json npm install ","date":"December 23, 2021","hero":"/posts/knowledge/2011-react-note/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2011-react-note/","summary":" #javascript #js #react\n 初始化React项目 npm install -g react npm install -g react-dom npm install -g react-scripts npm install -g create-react-app create-react-app hello-react cd hello-react npm start 更新package.json npm install -g npm-check-updates ncu # 或者npm-check-updates ncu -u to upgrade package.json npm install ","tags":null,"title":"React学习笔记"},{"categories":null,"contents":" #mysql #macos\n  一般MySQL 8.x安装完在select语句中使用group by时会报错，需要在my.cnf中配置设置sql_model参数。在Linux中，这个文件通常位于/etc目录下，而在Mac上，却不在这里。\n 在Mac本地安装的测试用的MySQL数据库，安装完成之后需要进行如下设置\n设置sql_model  关闭ONLY_FULL_GROUP_BY模式\n 在sql命令行中查询sql_mode配置\nselect @@sql_mode; mysql\u0026gt; select @@sql_mode; +-----------------------------------------------------------------------------------------------------------------------+ | @@sql_mode | +-----------------------------------------------------------------------------------------------------------------------+ | ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION | +-----------------------------------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) 去掉第一项后得到：\nSTRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION 使用mysql --help命令获取my.cnf配置文件所在位置\n# ... Default options are read from the following files in the given order: /etc/my.cnf /etc/mysql/my.cnf /opt/homebrew/etc/my.cnf ~/.my.cnf The following groups are read: mysql client # ... 我安装的MySQL在/opt/homebrew/etc/my.cnf目录下，添加一行：\nsql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION 重启MySQL，问题解决\nmysql.server restart 设置开机启动 cp /opt/homebrew/Cellar/mysql/8.0.27/homebrew.mxcl.mysql.plist ~/Library/LaunchAgents launchctl load -w ~/Library/LaunchAgents/homebrew.mxcl.mysql.plist ","date":"December 20, 2021","hero":"/posts/problems/5006-mysql-brew-conf/head.svg","permalink":"https://ormissia.github.io/posts/problems/5006-mysql-brew-conf/","summary":"#mysql #macos\n  一般MySQL 8.x安装完在select语句中使用group by时会报错，需要在my.cnf中配置设置sql_model参数。在Linux中，这个文件通常位于/etc目录下，而在Mac上，却不在这里。\n 在Mac本地安装的测试用的MySQL数据库，安装完成之后需要进行如下设置\n设置sql_model  关闭ONLY_FULL_GROUP_BY模式\n 在sql命令行中查询sql_mode配置\nselect @@sql_mode; mysql\u0026gt; select @@sql_mode; +-----------------------------------------------------------------------------------------------------------------------+ | @@sql_mode | +-----------------------------------------------------------------------------------------------------------------------+ | ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION | +-----------------------------------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) 去掉第一项后得到：\nSTRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION 使用mysql --help命令获取my.cnf配置文件所在位置\n# ... Default options are read from the following files in the given order: /etc/my.cnf /etc/mysql/my.cnf /opt/homebrew/etc/my.cnf ~/.my.cnf The following groups are read: mysql client # ... 我安装的MySQL在/opt/homebrew/etc/my.cnf目录下，添加一行：\nsql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION 重启MySQL，问题解决\nmysql.server restart 设置开机启动 cp /opt/homebrew/Cellar/mysql/8.","tags":null,"title":"修改Mac上brew安装的MySQL配置"},{"categories":null,"contents":" #kubernetes #k8s\n  为系统守护进程预留计算资源 开启服务拓扑 Master节点的高可用 Service 的 DNS  ","date":"November 4, 2021","hero":"/posts/knowledge/2007-kubernetes/001-link-index/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2007-kubernetes/001-link-index/","summary":" #kubernetes #k8s\n  为系统守护进程预留计算资源 开启服务拓扑 Master节点的高可用 Service 的 DNS  ","tags":null,"title":"Kubernetes文档索引"},{"categories":null,"contents":" #docker\n 问题现象 国内某些网络环境下，会出现docker pull无法拉取镜像的情况\n解决办法  修改Docker镜像源\n 新建或修改\nvi /etc/docker/daemon.json { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;http://hub-mirror.c.163.com\u0026#34; ] } 最后重启Docker\nsystemctl restart docker.service ","date":"November 4, 2021","hero":"/posts/problems/5005-docker-image-source/head.svg","permalink":"https://ormissia.github.io/posts/problems/5005-docker-image-source/","summary":" #docker\n 问题现象 国内某些网络环境下，会出现docker pull无法拉取镜像的情况\n解决办法  修改Docker镜像源\n 新建或修改\nvi /etc/docker/daemon.json { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;http://hub-mirror.c.163.com\u0026#34; ] } 最后重启Docker\nsystemctl restart docker.service ","tags":null,"title":"修改Docker镜像源"},{"categories":null,"contents":" #kubernetes #k8s\n  连接一些多实例的服务（比如Kafka、ES）时，通常是在client端做负载均衡。\n假如这种集群又恰好跑在k8s中，如果是普通业务类型的服务，通常是创建一个Service来做为一个代理去访问不同实例，从而达到负载均衡的目的。\n但是诸如如：Kafka、ES类型的服务，还用Service来做负载均衡，显然就不那么合理了（诚然，Kafka、ES这种东西多半是不会跑在k8s上的，这里只是作为一个引子，不在本文讨论的范畴）。\n 实验环境  多实例服务whoami在kube-test-1的命名空间下 多实例服务whoami以StatefulSet方式部署，设置为3个实例，会自动创建whoami-0、whoami-1以及whoami-2三个Pod 给StatefulSet创建Headless类型的Service 模拟客户端使用Nginx镜像，部署在kube-test-2的命名空间下（使用curl命令模拟）  本实验创建资源使用的k8s dashboard，创建的资源默认放在选中的明明空间下，因此yml文件中未指定namespace。\nServer cluster  服务端模拟相关资源在kube-test-1下创建\n StatefulSet 使用traefik/whoami镜像来模拟服务端\n这里使用StatefulSet的方式创建服务端。spec.replicas设为3，此时会自动创建whoami-0、whoami-1以及whoami-2三个Pod。\napiVersion: apps/v1 kind: StatefulSet metadata: name: whoami labels: app: whoami spec: replicas: 3 selector: matchLabels: app: whoami serviceName: whoami template: metadata: name: whoami labels: app: whoami spec: containers: - name: whoami image: traefik/whoami ports: - containerPort: 80 注意这里的spec.serviceName必须与下面的Service名字相同，否则调用时候pod的subdomain只能使用IP\n$ k get pod -n kube-test-1 -o wide | grep whoami whoami-0 1/1 Running 0 29m 10.244.1.220 node2 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; whoami-1 1/1 Running 0 29m 10.244.0.52 node1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; whoami-2 1/1 Running 0 29m 10.244.1.221 node2 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; Headless 使用Headless的方式向外暴露Pod，不允许使用Service的负载均衡\napiVersion: v1 kind: Service metadata: name: whoami spec: clusterIP: None ports: - port: 80 selector: app: whoami $ k get service -n kube-test-1 -o wide | grep whoami whoami ClusterIP None \u0026lt;none\u0026gt; 80/TCP 10s app=whoami Client  客户端模拟相关资源在kube-test-2下创建\n apiVersion: apps/v1 kind: Deployment metadata: name: nginx labels: app: nginx spec: selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx nginx用来模拟客户端，调用镜像自带的curl命令\n进入nginx容器\n$ k exec -it nginx-6799fc88d8-cgvtp -n kube-test-2 /bin/bash 使用curl命令分别调用几个服务端\n$ curl whoami-0.whoami.kube-test-1.svc.cluster.local Hostname: whoami-0 IP: 127.0.0.1 IP: 10.244.1.220 RemoteAddr: 10.244.0.53:39400 GET / HTTP/1.1 Host: whoami-0.whoami.kube-test-1.svc.cluster.local User-Agent: curl/7.64.0 Accept: */* $ curl whoami-1.whoami.kube-test-1.svc.cluster.local Hostname: whoami-1 IP: 127.0.0.1 IP: 10.244.0.52 RemoteAddr: 10.244.0.53:40354 GET / HTTP/1.1 Host: whoami-1.whoami.kube-test-1.svc.cluster.local User-Agent: curl/7.64.0 Accept: */* $ curl whoami-2.whoami.kube-test-1.svc.cluster.local Hostname: whoami-2 IP: 127.0.0.1 IP: 10.244.1.221 RemoteAddr: 10.244.0.53:38370 GET / HTTP/1.1 Host: whoami-2.whoami.kube-test-1.svc.cluster.local User-Agent: curl/7.64.0 Accept: */* 可以看到分别访问到三个不同的服务端pod了。\n总结 访问的url格式为：\npod-ip-address.deployment-name.my-namespace.svc.cluster-domain.example 参考链接  k8s 文档：A/AAAA 记录  ","date":"November 1, 2021","hero":"/posts/knowledge/2007-kubernetes/002-handless-statefullset/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2007-kubernetes/002-handless-statefullset/","summary":"#kubernetes #k8s\n  连接一些多实例的服务（比如Kafka、ES）时，通常是在client端做负载均衡。\n假如这种集群又恰好跑在k8s中，如果是普通业务类型的服务，通常是创建一个Service来做为一个代理去访问不同实例，从而达到负载均衡的目的。\n但是诸如如：Kafka、ES类型的服务，还用Service来做负载均衡，显然就不那么合理了（诚然，Kafka、ES这种东西多半是不会跑在k8s上的，这里只是作为一个引子，不在本文讨论的范畴）。\n 实验环境  多实例服务whoami在kube-test-1的命名空间下 多实例服务whoami以StatefulSet方式部署，设置为3个实例，会自动创建whoami-0、whoami-1以及whoami-2三个Pod 给StatefulSet创建Headless类型的Service 模拟客户端使用Nginx镜像，部署在kube-test-2的命名空间下（使用curl命令模拟）  本实验创建资源使用的k8s dashboard，创建的资源默认放在选中的明明空间下，因此yml文件中未指定namespace。\nServer cluster  服务端模拟相关资源在kube-test-1下创建\n StatefulSet 使用traefik/whoami镜像来模拟服务端\n这里使用StatefulSet的方式创建服务端。spec.replicas设为3，此时会自动创建whoami-0、whoami-1以及whoami-2三个Pod。\napiVersion: apps/v1 kind: StatefulSet metadata: name: whoami labels: app: whoami spec: replicas: 3 selector: matchLabels: app: whoami serviceName: whoami template: metadata: name: whoami labels: app: whoami spec: containers: - name: whoami image: traefik/whoami ports: - containerPort: 80 注意这里的spec.serviceName必须与下面的Service名字相同，否则调用时候pod的subdomain只能使用IP\n$ k get pod -n kube-test-1 -o wide | grep whoami whoami-0 1/1 Running 0 29m 10.","tags":null,"title":"k8s中通过Headless连接StatefulSet"},{"categories":null,"contents":" #kubernetes #k8s #token #dashboard\n 问题现象 kubernetes的dashboard登录token过期时间太短，不操作没一会就需要重新登录\n解决办法 修改kubernetes-dashboard的deployment，加入一条arg参数：\n- '--token-ttl=10800' ","date":"November 1, 2021","hero":"/posts/problems/5004-kubernetes-dashboard-token/head.svg","permalink":"https://ormissia.github.io/posts/problems/5004-kubernetes-dashboard-token/","summary":" #kubernetes #k8s #token #dashboard\n 问题现象 kubernetes的dashboard登录token过期时间太短，不操作没一会就需要重新登录\n解决办法 修改kubernetes-dashboard的deployment，加入一条arg参数：\n- '--token-ttl=10800' ","tags":null,"title":"k8s dashboard token过期时间太短"},{"categories":null,"contents":" #elasticsearch #elastic #db #search-engine #lucene\n 搜索类型  搜索引擎：百度、搜狗、谷歌、必应 垂直领域：各大电商平台、OA系统、站内搜索 商业智能：数据分析、数据挖掘、用户画像 GitHub：千亿+行代码秒查 日志系统：ELK  ES特点  搜索、聚合分析、大数据存储 分布式、高性能、高可用、可伸缩、易维护 支持文本搜索、结构化数据、非结构化数据、地理位置搜索等  ES单机部署 同一节点启动不同服务 ./bin/elasticsearch -E path.data=data1 -E path.logs=log1 -E node.name=node1 -E cluster.name=ormissia_test ./bin/elasticsearch -E path.data=data2 -E path.logs=log2 -E node.name=node2 -E cluster.name=ormissia_test http://localhost:9200/ http://localhost:9201/ 不同节点启动同一服务 open ./elasticsearch_node1/bin/elasticsearch open ./elasticsearch_node2/bin/elasticsearch open ./elasticsearch_node3/bin/elasticsearch open ./elasticsearch_node4/bin/elasticsearch open ./elasticsearch_node5/bin/elasticsearch open ./kibana-7.15.1-darwin-x86_64/bin/kibana elasticsearch-head插件 GitHub Repository\ngit clone git://github.com/mobz/elasticsearch-head.git cd elasticsearch-head npm install npm run start 默认端口：9100\n 如果集群无法连接，需要修改ES配置文件\n http.cors.enabled: true http.cors.allow-origin: \u0026#34;*\u0026#34;  elasticsearch-head也可以以Chrome插件的方式安装\n 集群健康值检查 健康值状态  Grenn：所有Primary和Replica均为active，集群健康 Yellow：至少有一个Replica不可用，但是所有Primary均为active，数据仍然是可以保证完整性的 Red：至少有一个Primary为不可用状态，数据不完整，集群不可用   Replica是不可以写的\n 健康值检查  _cat/health  GET _cat/health?v epoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent 1634624559 06:22:39 elasticsearch green 5 5 24 12 0 0 0 0 - 100.0% 格林尼治时间 集群名称 集群状态 节点数 数据节点 分片 Primary 准备执行任务数 最大任务等待时间 当前活动分片百分比 _cluster/health  GET _cluster/health { \u0026#34;cluster_name\u0026#34; : \u0026#34;elasticsearch\u0026#34;, \u0026#34;status\u0026#34; : \u0026#34;green\u0026#34;, \u0026#34;timed_out\u0026#34; : false, \u0026#34;number_of_nodes\u0026#34; : 5, \u0026#34;number_of_data_nodes\u0026#34; : 5, \u0026#34;active_primary_shards\u0026#34; : 12, \u0026#34;active_shards\u0026#34; : 24, \u0026#34;relocating_shards\u0026#34; : 0, \u0026#34;initializing_shards\u0026#34; : 0, \u0026#34;unassigned_shards\u0026#34; : 0, \u0026#34;delayed_unassigned_shards\u0026#34; : 0, \u0026#34;number_of_pending_tasks\u0026#34; : 0, \u0026#34;number_of_in_flight_fetch\u0026#34; : 0, \u0026#34;task_max_waiting_in_queue_millis\u0026#34; : 0, \u0026#34;active_shards_percent_as_number\u0026#34; : 100.0 } 注释\n# \u0026#34;relocating_shards\u0026#34; : 0, 迁移中 # \u0026#34;initializing_shards\u0026#34; : 0, 初始化中 # \u0026#34;unassigned_shards\u0026#34; : 0, 未分配的 搜索引擎 搜索引擎类别  全文搜索引擎：自然语言处理（NLP）、爬虫、网页处理、大数据处理，如谷歌、百度、搜狗、必应等 垂直搜索引擎：有明确目的的搜索行为，如各大电商网站、OA系统、站内搜索、视频网站等  搜索引擎要求  查询速度快  高效的压缩算法 快速的编码和解码速度   结果准确  BM25评分算法（7.0之后） TF-IDF   检验结果丰富  召回率    Lucene  以MySQL为例的数据库组成结构\n MySQL索引面临大数据检索的问题：\n 索引失效 精准度差 大数据量下索引性能变低  Lucene使用倒排索引解决了上述问题\n倒排索引核心算法  倒排索引表的压缩算法  FOR: Frame Of Reference RBM: RoaringBitMap   词项索引的检索原理  FST: Finit state Transducers    FOR RBM FST FSA：有限状态接收机 FST：有限状态转换机\nFST最重要的功能是实现key到value的映射，相当于HashMap。\nFST的查询比HashMap要慢一点，但FST的内存消耗要比HashMap少很多。\nFST在Lucene中被大量使用，如：倒排索引的存储，同义词词典的存储，搜索关键词建议等\nNode 节点\nAcr 出度 freezeTail 尾部冻结\n通用最小化算法：BitMap\nES简单的CRUD  示例使用Kibana的Dev Tools操作\n 创建索引 创建test索引\nPUT /test 查询索引 查询test索引\nGET /test 添加一条文档 创建索引为1的一条文档\nPUT /test/_doc/1 { \u0026quot;name\u0026quot;: \u0026quot;xiaoming\u0026quot;, \u0026quot;age\u0026quot;: 123, \u0026quot;tag\u0026quot;: [ \u0026quot;pople\u0026quot;, \u0026quot;student\u0026quot; ] } 查询文档 根据索引查询文档\nGET /test/_doc/1 修改文档 根据索引修改文档\nPOST /test/_update/1 { \u0026quot;doc\u0026quot;: { \u0026quot;age\u0026quot;: 222 } } Mapping  定义ES索引中字段类型等信息的映射，映射是定义文档及其包含的字段的存储和索引方式的过程，换句话来说，Mapping相当于传统关系型数据库中的DDL建表语句。\n在Mapping里也包含了一些属性，比如字段名称、类型、字段使用的分词器、是否评分、是否创建索引等属性，并且在ES中一个字段可以有多个类型。\n Mapping类型：\n Dynamic mapping：动态映射 Explicit mapping：显式映射  查看Mapping GET /index/_mapping 数据类型  基础类型  数字类型：long、integer、short、byte、double、float、half_float、scaled_float、unsigned_long Keywords：  Keywords适用于索引结构化的字段，可以用于过滤、排序、聚合。keyword类型的字段只能通过精确值（exact value）搜索到。id应该用keyword constant_keyword：始终包含相同值的关键字字段 wildcard：可针对类似grep的通配符查询优化日志行和类似的关键字值   Dates（时间类型）：包括Date和 Date nanoseconds Alias：为现有字段定义别名 Binary：二进制 Range：区间类型，integer_range、float_range、long_range、double_range、date_range text：当一个字段是要被全文搜索的，比如Email内容、产品描述，这些字段应该使用text类型。设置text类型以后，字段内容会被分析，在生成倒排索引以前，字符串会被分析器分成一个一个词项。text类型的字段不用于排序，很少用于聚合。（解释一下为啥不会为text创建正排索引：大量堆空间，尤其是在加载高基数text字段时。字段数据一旦加载到堆中，就在该段的生命周期内保持在那里。同样，加载字段数据是一个昂贵的过程，可能导致用户遇到延迟问题。这就是默认情况下禁用字段数据的原因）   对象关系类型  Object：用于单个JSON对象 Nested：用于JSON对象数组 flattened：允许将整个JSON对象索引为单个字段。   结构化类型  Geopoint：纬度/经度积分 Geoshape：用于多边形等复杂形状 Point：笛卡尔坐标点 Shape：笛卡尔任意几何图形   特殊类型  IP：用于IPv4和IPv6地址 Completion：提供自动完成建议 // TODO Token count：计算字符串中令牌的数量 \u0026hellip;   Array（数组）：在ES中，数组不需要专用的字段数据类型。默认情况下，任何字段都可以包含零个或多个值，但是，数组中的所有值都必须具有相同的数据类型。 版本新增  Date nanoseconds \u0026hellip;     除了支持的映射参数之外，无法更改现有字段的映射或字段类型。更改现有字段可能会使已编入索引的数据无效。\n Dynamic mapping字段对应关系    内容 类型     整数 long   浮点数 float   true/false boolean   日期 date   数组 取决于数组中的第一个有效值   对象 object   字符串 如果不是数字和日期类型，那会被映射为text和keyword两个类型      除了上述字段类型之外，其他类型都必须显式映射，也就是必须手工指定，因为其他类型ES无法自动识别。\n Explicit mapping显式映射 PUT /my-index-000001 { \u0026quot;mappings\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;age\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot; }, \u0026quot;email\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;name\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot; } } } }  再次注明：除了支持的映射参数之外，无法更改现有字段的映射或字段类型。更改现有字段可能会使已编入索引的数据无效。\n 参数  index：是否对创建对当前字段创建倒排索引，默认true，如果不创建索引，该字段不会通过索引被搜索到,但是仍然会在source元数据中展示 analyzer：指定分析器，Character filter、Tokenizer、Token filters boost：对当前字段相关度的评分权重，默认1 coerce：是否允许强制类型转换 true “1”=\u0026gt; 1 false “1”=\u0026lt; 1 doc_values：为了提升排序和聚合效率，默认true，如果确定不需要对字段进行排序或聚合，也不需要通过脚本访问字段值，则可以禁用doc值以节省磁盘空间（不支持text和annotated_text） dynamic：控制是否可以动态添加新字段  true：新检测到的字段将添加到映射中。（默认） false：新检测到的字段将被忽略。这些字段将不会被索引，因此将无法搜索，但仍会出现在_source返回的匹配项中。这些字段不会添加到映射中，必须显式添加新字段。 strict：如果检测到新字段，则会引发异常并拒绝文档。必须将新字段显式添加到映射中   eager_global_ordinals：用于聚合的字段上，优化聚合性能。 Frozen indices：冻结索引，有些索引使用率很高，会被保存在内存中，有些使用率特别低，宁愿在使用的时候重新创建，在使用完毕后丢弃数据，Frozen indices的数据命中频率小，不适用于高搜索负载，数据不会被保存在内存中，堆空间占用比普通索引少得多，Frozen indices是只读的，请求可能是秒级或者分钟级。eager_global_ordinals不适用于Frozen indices enable：是否创建倒排索引，可以对字段操作，也可以对索引操作，如果不创建索引，仍然可以检索并在_source元数据中展示，谨慎使用，该状态无法修改。 fielddata：查询时内存数据结构，在首次用当前字段聚合、排序或者在脚本中使用时，需要字段为fielddata数据结构，并且创建倒排索引保存到堆中。 fields：给field创建多字段，用于不同目的（全文检索或者聚合分析排序） format：格式化  \u0026quot;date\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;, \u0026quot;format\u0026quot;: \u0026quot;yyyy-MM-dd\u0026quot; }  norms：是否禁用评分（在filter和聚合字段上应该禁用）。 null_value：为null值设置默认值 search_analyzer：设置单独的查询时分析器 store：设置字段是否仅查询 \u0026hellip;  Query DSL(Domain Specific Language) 查询上下文  使用query关键字进行检索，倾向于相关度搜索，需要计算相关度评分。\n 相关度评分_score 相关度评分用于对搜索结果排序，评分越高则认为其结果和搜索的预期值相关度越高，即越符合搜索预期值。在7.x之前相关度评分默认使用TF/IDF算法计算而来，7.x之后默认为BM25。\n相关度评分为搜索结果的排序依据，默认情况下评分越高，则结果越靠前。\n元数据_source 禁用_source\nGET product/_search { \u0026quot;_source\u0026quot;: false, \u0026quot;query\u0026quot;: { \u0026quot;match_all\u0026quot;: {} } }  好处：节省存储开销 坏处：  不支持update、update_by_query和reindex API。 不支持高亮。 不支持reindex、更改mapping分析器和版本升级。 通过查看索引时使用的原始文档来调试查询或聚合的功能。 将来有可能自动修复索引损坏。    总结：如果只是为了节省磁盘，可以压缩索引比禁用_source更好。\n数据源过滤器\n Including：结果中返回哪些field Excluding：结果中不要返回哪些field，不返回的field不代表不能通过该字段进行检索，因为元数据不存在不代表索引不存在  在mapping中定义过滤：支持通配符，但是这种方式不推荐，因为mapping不可变\nGET product/_search { \u0026quot;_source\u0026quot;: [\u0026quot;owner.name\u0026quot;,\u0026quot;owner.sex\u0026quot;], \u0026quot;query\u0026quot;: { \u0026quot;match_all\u0026quot;: {} } } 常用过滤规则\n  \u0026quot;_source\u0026quot;: \u0026quot;false\u0026quot;,   \u0026quot;_source\u0026quot;: \u0026quot;obj.*\u0026quot;,   \u0026quot;_source\u0026quot;: [ \u0026quot;obj1.\\*\u0026quot;, \u0026quot;obj2.\\*\u0026quot; ],   \u0026quot;_source\u0026quot;: { \u0026quot;includes\u0026quot;: [ \u0026quot;obj1.\\*\u0026quot;, \u0026quot;obj2.\\*\u0026quot; ], \u0026quot;excludes\u0026quot;: [ \u0026quot;*.description\u0026quot; ] }   Query String  查询所有：GET /product/_search 带参数：GET /product/_search?q=name:productname 分页：GET /product/_search?from=0\u0026amp;size=2\u0026amp;sort=price:asc 精准匹配：GET /product/_search?q=date:2021-10-21 _all搜索（相当于在所有有索引的字段中检索）：GET /product/_search?q=2021-06-01  全文检索-Fulltext query GET index/_search { \u0026quot;query\u0026quot;: { *** } } 示例\nGET product/_search { \u0026quot;query\u0026quot;: { \u0026quot;match\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;huahua blue cat\u0026quot; } } }  match：匹配包含某个term的子句 match_all：匹配所有结果的子句 multi_match：多字段条件 match_phrase：短语查询，分词结果必须在被检索字段的分词中都包含，而且顺序必须相同，而且默认必须都是连续的  精准查询-Term query term：匹配和搜索词项完全相等的结果\n term和match_phrase区别:  match_phrase会将检索关键词分词,match_phrase的分词结果必须在被检索字段的分词中都包含，而且顺序必须相同，而且默认必须都是连续的 term搜索不会将搜索词分词   term和keyword区别  term是对于搜索词不分词, keyword是字段类型,是对于source data中的字段值不分词    # term GET product/_search { \u0026quot;query\u0026quot;: { \u0026quot;term\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;xiaomi phone\u0026quot; } } } #term和match_phrase区别 GET product/_search { \u0026quot;query\u0026quot;: { \u0026quot;match_phrase\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;blue cat\u0026quot; } } } #term和keyword的区别 GET product/_search { \u0026quot;query\u0026quot;: { \u0026quot;term\u0026quot;: { \u0026quot;name.keyword\u0026quot;: \u0026quot;blue cat\u0026quot; } } } terms：匹配和搜索词项列表中任意项匹配的结果（数据中的tags字段只要有任意一项就可以查到）\nGET product/_search { \u0026quot;query\u0026quot;: { \u0026quot;terms\u0026quot;: { \u0026quot;tags\u0026quot;: [ \u0026quot;aaaaaa\u0026quot;, \u0026quot;cat\u0026quot; ], \u0026quot;boost\u0026quot;: 1.0 } } } range：范围查找\nGET /_search { \u0026quot;query\u0026quot;: { \u0026quot;range\u0026quot;: { \u0026quot;price\u0026quot;: { \u0026quot;gte\u0026quot;: 1000, \u0026quot;lte\u0026quot;: 20000 } } } } GET product/_search { \u0026quot;query\u0026quot;: { \u0026quot;range\u0026quot;: { \u0026quot;date\u0026quot;: { \u0026quot;time_zone\u0026quot;: \u0026quot;+08:00\u0026quot;, \u0026quot;gte\u0026quot;: \u0026quot;2021-10-21\u0026quot;, \u0026quot;lt\u0026quot;: \u0026quot;2021-10-21\u0026quot; } } } } GET product/_search { \u0026quot;query\u0026quot;: { \u0026quot;range\u0026quot;: { \u0026quot;date\u0026quot;: { \u0026quot;gte\u0026quot;: \u0026quot;now-1d/d\u0026quot;, \u0026quot;lt\u0026quot;: \u0026quot;now/d\u0026quot; } } } } 过滤器-Filter  query和filter的主要区别在：filter是结果导向的而query是过程导向。query倾向于“当前文档和查询的语句的相关度”而filter倾向于“当前文档和查询的条件是不是相符”。即在查询过程中，query是要对查询的每个结果计算相关性得分的，而filter不会。另外filter有相应的缓存机制，可以提高查询效率。\n GET product/_search { \u0026quot;query\u0026quot;: { \u0026quot;constant_score\u0026quot;: { \u0026quot;filter\u0026quot;: { \u0026quot;term\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;phone\u0026quot; } }, \u0026quot;boost\u0026quot;: 1.2 } } } 组合查询-Bool query  可以组合多个查询条件，bool查询也是采用more_matches_is_better的机制，因此满足must和should子句的文档将会合并起来计算分值\n  must：必须满足子句（查询）必须出现在匹配的文档中，并将有助于得分。 filter：过滤器，不计算相关度分数，cache子句（查询）必须出现在匹配的文档中。但是不像must查询的分数将被忽略。Filter子句在filter上下文中执行，这意味着计分被忽略，并且子句被考虑用于缓存。 should：可能满足，or子句（查询）应出现在匹配的文档中。 must_not：必须不满足，不计算相关度分数，not子句（查询）不得出现在匹配的文档中。子句在过滤器上下文中执行，这意味着计分被忽略，并且子句被视为用于缓存。由于忽略计分，因此将返回所有文档的分数。  minimum_should_match：参数指定should返回的文档必须匹配的子句的数量或百分比。如果bool查询包含至少一个should子句，而没有must或 filter子句，则默认值为1。否则，默认值为0\n分词器 normalization 文档规范化,提高召回率 拼写错误、形容词、单复数、动词、大小写、分词、称谓等转换成标准词汇\nGET _analyze { \u0026quot;text\u0026quot;: \u0026quot;Mr. Ma is an excellent teacher\u0026quot;, \u0026quot;analyzer\u0026quot;: \u0026quot;pattern\u0026quot; } character filter 字符过滤器  分词之前的预处理，过滤无用字符\n HTML Strip PUT test_index { \u0026quot;settings\u0026quot;: { \u0026quot;analysis\u0026quot;: { \u0026quot;char_filter\u0026quot;: { \u0026quot;my_char_filter\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;html_strip\u0026quot;, \u0026quot;escaped_tags\u0026quot;: [ \u0026quot;a\u0026quot; ] } }, \u0026quot;analyzer\u0026quot;: { \u0026quot;my_analyzer\u0026quot;: { \u0026quot;tokenizer\u0026quot;: \u0026quot;keyword\u0026quot;, \u0026quot;char_filter\u0026quot;: \u0026quot;my_char_filter\u0026quot; } } } } } GET test_index/_analyze { \u0026quot;analyzer\u0026quot;: \u0026quot;my_analyzer\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;\u0026lt;p\u0026gt;I\u0026amp;apos;m so \u0026lt;a\u0026gt;happy\u0026lt;/a\u0026gt;!\u0026lt;/p\u0026gt;\u0026quot; } Mapping PUT test_index { \u0026quot;settings\u0026quot;: { \u0026quot;analysis\u0026quot;: { \u0026quot;char_filter\u0026quot;: { \u0026quot;my_char_filter\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;mapping\u0026quot;, \u0026quot;mappings\u0026quot;:[ \u0026quot;滚 =\u0026gt; *\u0026quot;, \u0026quot;垃圾 =\u0026gt; **\u0026quot; ] } }, \u0026quot;analyzer\u0026quot;: { \u0026quot;my_analyzer\u0026quot;: { \u0026quot;tokenizer\u0026quot;: \u0026quot;keyword\u0026quot;, \u0026quot;char_filter\u0026quot;: \u0026quot;my_char_filter\u0026quot; } } } } } GET test_index/_analyze { \u0026quot;analyzer\u0026quot;: \u0026quot;my_analyzer\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;滚！你就是个垃圾\u0026quot; } Pattern Replace PUT test_index { \u0026quot;settings\u0026quot;: { \u0026quot;analysis\u0026quot;: { \u0026quot;char_filter\u0026quot;: { \u0026quot;my_char_filter\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;pattern_replace\u0026quot;, \u0026quot;pattern\u0026quot;:\u0026quot;(\\\\d{3})\\\\d{4}(\\\\d{4})\u0026quot;, \u0026quot;replacement\u0026quot;:\u0026quot;$1****$2\u0026quot; } }, \u0026quot;analyzer\u0026quot;: { \u0026quot;my_analyzer\u0026quot;: { \u0026quot;tokenizer\u0026quot;: \u0026quot;keyword\u0026quot;, \u0026quot;char_filter\u0026quot;: \u0026quot;my_char_filter\u0026quot; } } } } } GET test_index/_analyze { \u0026quot;analyzer\u0026quot;: \u0026quot;my_analyzer\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;手机号是：15633334444\u0026quot; } token filter 令牌过滤器  停用词、时态转换、大小写转换、同义词转换、语气词处理等。比如：has=\u0026gt;have him=\u0026gt;he apples=\u0026gt;apple the/oh/a=\u0026gt;干掉\n tokenizer 分词器 常见分词器\n standard analyzer：默认分词器，中文支持的不理想，会逐字拆分。 pattern tokenizer：以正则匹配分隔符，把文本拆分成若干词项。 simple pattern tokenizer：以正则匹配词项，速度比pattern tokenizer快。 whitespace analyzer：以空白符分隔  custom analyzer 自定义分词器\n char_filter：内置或自定义字符过滤器 。 token filter：内置或自定义token filter 。 tokenizer：内置或自定义分词器。  ik分词（中文分词器） 安装 下载对应版本，解压后放到ES的plugins文件夹下面\nes-root/plugins/ \u0026amp;\u0026amp; mkdir ik 重启ES\nGET test_index/_analyze { \u0026quot;analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;, \u0026quot;text\u0026quot;: [ \u0026quot;我爱中华人民共和国\u0026quot; ] } 文件  IKAnalyzer.cfg.xml：IK分词配置文件 main.dic：主词库 stopword.dic：英文停用词，不会建立在倒排索引中 特殊词库：  quantifier.dic：特殊词库：计量单位等 suffix.dic：特殊词库：行政单位 surname.dic：特殊词库：百家姓 preposition：特殊词库：语气词 自定义词库：网络词汇、流行词、自造词等    热更新  远程词库文件  词库的管理不方便，要操作直接操作磁盘文件，检索页很麻烦 文件的读写没有专门的优化性能不好 多一层接口调用和网络传输   ik访问数据库  聚合查询  用于进行聚合的字段必须是exact value，分词字段不可进行聚合。 对于text字段如果需要使用聚合，需要开启fielddata，但是通常不建议，因为fielddata是将聚合使用的数据结构由磁盘（doc_values）变为了堆内存（field_data），大数据的聚合操作很容易导致OOM。\n 聚合分类  分桶聚合Bucket agregations：类比SQL中的group by的作用，主要用于统计不同类型数据的数量 指标聚合Metrics agregations：主要用于最大值、最小值、平均值、字段之和等指标的统计 管道聚合Pipeline agregations：用于对聚合的结果进行二次聚合，如要统计绑定数量最多的标签bucket，就是要先按照标签进行分桶，再在分桶的结果上计算最大值。  桶聚合： 场景：用于统计不同种类的文档的数量，可进行嵌套统计。\n函数：terms\n注意：聚合字段必须是exact value，如keyword\n指标聚合 场景：用于统计某个指标，如最大值、最小值、平均值，可以结合桶聚合一起使用，如按照商品类型分桶，统计每个桶的平均价格。\n函数：平均值：Avg、最大值：Max、最小值：Min、求和：Sum、详细信息：Stats、数量：Value count\n管道聚合 场景：用于对聚合查询的二次聚合，如统计平均价格最低的商品分类，即先按照商品分类进行桶聚合，并计算其平均价格，然后对其平均价格计算最小值聚合\n函数：Min bucket：最小桶、Max bucket：最大桶、Avg bucket：桶平均值、Sum bucket：桶求和、Stats bucket：桶信息\n注意：buckets_path为管道聚合的关键字，其值从当前聚合统计的聚合函数开始计算为第一级。比如下面例子中，my_aggs和my_min_bucket同级，my_aggs就是buckets_path值的起始值。\n脚本查询  Scripting是Elasticsearch支持的一种专门用于复杂场景下支持自定义编程的强大的脚本功能，ES支持多种脚本语言，如painless，其语法类似于Java,也有注释、关键字、类型、变量、函数等，其就要相对于其他脚本高出几倍的性能，并且安全可靠，可以用于内联和存储脚本。\n 支持的语言  groovy：ES 1.4.x-5.0的默认脚本语言 painless：Elasticsearch现在的默认脚本语言 expression：每个文档的开销较低：表达式的作用更多，可以非常快速地执行，甚至比编写native脚本还要快，支持javascript语法的子集：单个表达式。缺点：只能访问数字，布尔值，日期和geo_point字段，存储的字段不可用 mustache：脚本模板  模糊查询 搜索推荐 数据建模 ES学习总结 通用最小化算法：BitMap 倒排索引压缩算法中的RBM算法中用到了Bitmap，在Redis的布隆过滤器中也用到了\n倒排索引的 ，在Linux文件权限中也用到了\n参考链接  Elastic stack版本支持 Elasticsearch Head GitHub Repository ik分词器  ","date":"October 19, 2021","hero":"/posts/knowledge/2010-elastic/001-elasticstack-es/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2010-elastic/001-elasticstack-es/","summary":"#elasticsearch #elastic #db #search-engine #lucene\n 搜索类型  搜索引擎：百度、搜狗、谷歌、必应 垂直领域：各大电商平台、OA系统、站内搜索 商业智能：数据分析、数据挖掘、用户画像 GitHub：千亿+行代码秒查 日志系统：ELK  ES特点  搜索、聚合分析、大数据存储 分布式、高性能、高可用、可伸缩、易维护 支持文本搜索、结构化数据、非结构化数据、地理位置搜索等  ES单机部署 同一节点启动不同服务 ./bin/elasticsearch -E path.data=data1 -E path.logs=log1 -E node.name=node1 -E cluster.name=ormissia_test ./bin/elasticsearch -E path.data=data2 -E path.logs=log2 -E node.name=node2 -E cluster.name=ormissia_test http://localhost:9200/ http://localhost:9201/ 不同节点启动同一服务 open ./elasticsearch_node1/bin/elasticsearch open ./elasticsearch_node2/bin/elasticsearch open ./elasticsearch_node3/bin/elasticsearch open ./elasticsearch_node4/bin/elasticsearch open ./elasticsearch_node5/bin/elasticsearch open ./kibana-7.15.1-darwin-x86_64/bin/kibana elasticsearch-head插件 GitHub Repository\ngit clone git://github.com/mobz/elasticsearch-head.git cd elasticsearch-head npm install npm run start 默认端口：9100","tags":null,"title":"Elasticsearch"},{"categories":null,"contents":" 此次安装的平台是基于ARM架构的RedHat系Linux系统平台，参照Kubernetes官方文档进行的。\n本文档流程与X86架构的没有区别，官方文档中个别步骤中的命令需要区分所使用的包对应的平台。\n 初始化环境 防火墙 systemctl stop firewalld.service systemctl disable firewalld.service SELinux vi /etc/selinux/config SELINUX=disabled Swap vi /etc/fstab 注释掉swap这一行\n/.swapfile\tnone\tswap\tsw,comment=cloudconfig\t0\t0 重启之后查看关闭是否成功\nfree -m 显示如下内容，swap关闭成功\ntotal used free shared buff/cache available Mem: 23114 402 22299 32 411 20597 Swap: 0 0 0 ulimit echo \u0026#34;ulimit -n 65535\u0026#34; \u0026gt;\u0026gt; /etc/profile echo \u0026#34;*\thard\tnofile\t65535\u0026#34; \u0026gt;\u0026gt; /etc/security/limits.conf 重启之后检查是否配置成功\nulimit -n SSH免密（非必须） 执行命令，一路回车，即可获得当前节点的公钥\nssh-keygen -t rsa cat id_rsa.pub iptables 查看br_netfilter模块是否开启\nlsmod | grep br_netfilter 如果没有看到输出则执行命令开启\nmodprobe br_netfilter 作为Linux节点的iptables正确查看桥接流量的要求，应该确保net.bridge.bridge-nf-call-iptables在sysctl配置中设置为1\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system 安装Docker yum install -y yum-utils yum-config-manager \\  --add-repo \\  https://download.docker.com/linux/centos/docker-ce.repo yum install docker-ce docker-ce-cli containerd.io -y systemctl start docker systemctl enable docker 修改Docker Cgroup Driver 为 systemd（大坑一）\nvi /usr/lib/systemd/system/docker.service 修改配置文件中的启动参数\n#ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --exec-opt native.cgroupdriver=systemd 重启Docker\nsystemctl daemon-reload systemctl restart docker 安装Kubernetes  kubeadm：引导集群的命令。 kubelet：在集群中的所有机器上运行的组件，并执行诸如启动Pod和容器之类的操作。 kubectl：用于与集群通信的命令行实用程序  使用yum安装，添加yum源\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\\$basearch enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg exclude=kubelet kubeadm kubectl EOF 安装并启动\nyum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes systemctl enable --now kubelet 至此，集群中所有节点都是相同操作\n初始化master 使用kubeadm作为集群的初始化工具\nkubeadm init --kubernetes-version=v1.22.2 --pod-network-cidr=10.244.0.0/16 成功初始化之后会出现提示，其中有三个需要手动执行，最后一个是需要在从节点上执行（此处有坑）\nYour Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join --control-plane 10.0.0.105:6443 --token axqrzz.ouonxxxxxxgdvgjz \\ \t--discovery-token-ca-cert-hash sha256:3a57ff0d78b1f85xxxxxxxxxxxxxxxxxxxxe0f90f47037a31a33 手动执行\nmkdir -p #HOME/.kube sudo cp -i /etc/kubernetes/admin.conf #HOME/.kube/config sudo chown #(id -u):#(id -g) #HOME/.kube/config kubeadm join --control-plane 10.0.0.105:6443 --token axqrzz.ouonxxxxxxgdvgjz \\ \t--discovery-token-ca-cert-hash sha256:3a57ff0d78b1f85xxxxxxxxxxxxxxxxxxxxe0f90f47037a31a33 使用kubectl get nodes命令查看节点\nNAME STATUS ROLES AGE VERSION arm-node-1 NotReady control-plane,master 1m v1.22.2 此时可以看到master处于NotReady状态\n查看集群中pod状态\n 这是后期补的，所以时间很久\n kubectl get pod --all-namespaces # 输出 NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-78fcd69978-2vcqt 1/1 Pending 1 (126m ago) 12h kube-system coredns-78fcd69978-xg98g 1/1 Pending 1 (126m ago) 12h kube-system etcd-arm-node-1 1/1 Running 2 (126m ago) 12h kube-system kube-apiserver-arm-node-1 1/1 Running 2 (126m ago) 12h kube-system kube-controller-manager-arm-node-1 1/1 Running 2 (126m ago) 12h kube-system kube-proxy-q5m5k 1/1 Running 1 (126m ago) 12h kube-system kube-scheduler-arm-node-1 1/1 Running 2 (126m ago) 12h 可以看到两个coredns的pod处于Pending状态，这是由于缺少网络组件\n这里我们选择安装flannel\n大坑二\nkubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml 执行这条命令之后查看pod状态会出现ErrImagePull的提示\n原因是rancher/flannel-cni-plugin:v1.2的镜像拉取不到\n到网上查了一番，看好多是相同的报错，但是因为quay.io/coreos/flannel的镜像拉不到，于是我手动拉了一下rancher/flannel-cni-plugin这个镜像\ndocker pull rancher/flannel-cni-plugin:v1.2 # 输出 Error response from daemon: pull access denied for rancher/flannel-cni-plugin, repository does not exist or may require \u0026#39;docker login\u0026#39;: denied: requested access to the resource is denied 咦？找不到镜像？ 于是我去Docker Hub的页面去搜了一下，居然没有这个镜像\n真是啥坑都有\n去flannel-io/flannel的issue中看了一下，最新的一条就是这个相同的问题\n好吧，删掉换个旧版本重新来过\n在GitHub的flannel-io/flannel仓库中切到v0.14.1版本中看了一下，没有使用到rancher/flannel-cni-plugin这个镜像\nkubectl delete -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/release/v0.14.1/Documentation/kube-flannel.yml 这回成功了，重新查看pod和节点状态\nkubectl get pod --all-namespaces # 输出 NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-78fcd69978-2vcqt 1/1 Running 1 (126m ago) 12h kube-system coredns-78fcd69978-xg98g 1/1 Running 1 (126m ago) 12h kube-system etcd-arm-node-1 1/1 Running 2 (126m ago) 12h kube-system kube-apiserver-arm-node-1 1/1 Running 2 (126m ago) 12h kube-system kube-controller-manager-arm-node-1 1/1 Running 2 (126m ago) 12h kube-system kube-flannel-ds-kdpgp 1/1 Running 1 (126m ago) 3h32m kube-system kube-proxy-q5m5k 1/1 Running 1 (126m ago) 12h kube-system kube-scheduler-arm-node-1 1/1 Running 2 (126m ago) 12h kubectl get nodes # 输出 NAME STATUS ROLES AGE VERSION arm-node-1 Ready control-plane,master 13h v1.22.2 初始化从节点（大坑三） 对于从节点，安装完kubeadm，kubelet，kebectl三个组件后，直接运行master节点kubeadm init完成之后的输出结果中的最后一条命令\nkubeadm join --control-plane 10.0.0.105:6443 --token axqrzz.ouonxxxxxxgdvgjz \\ \t--discovery-token-ca-cert-hash sha256:3a57ff0d78b1f85xxxxxxxxxxxxxxxxxxxxe0f90f47037a31a33 但是这里我踩到一个坑，复制的这条命令粘贴到命令行中后，在第二行开头会莫名其妙多出来一个.\n造成执行kubeadm join时一直报参数数量的错误\naccepts at most 1 arg(s), received 3 To see the stack trace of this error execute with --v=5 or higher 这个问题也查了好久，最后将命令改为一行去执行\nkubeadm join --control-plane 10.0.0.105:6443 --token axqrzz.ouonxxxxxxgdvgjz --discovery-token-ca-cert-hash sha256:3a57ff0d78b1f85xxxxxxxxxxxxxxxxxxxxe0f90f47037a31a33 命令执行返回加入集群成功后查看节点状态\nkubectl get nodes # 输出 NAME STATUS ROLES AGE VERSION arm-node-1 Ready control-plane,master 13h v1.22.2 arm-node-2 Ready \u0026lt;none\u0026gt; 170m v1.22.2 可以看到从节点成功加入主节点\n安装Dashboard 安装服务 kubectl -n kubernetes-dashboard get secret $(kubectl -n kubernetes-dashboard get sa/admin-user -o jsonpath=\u0026#34;{.secrets[0].name}\u0026#34;) -o go-template=\u0026#34;{{.data.token | base64decode}}\u0026#34; 创建权限及用户 apiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kubernetes-dashboard apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard 获取Token kubectl -n kubernetes-dashboard get secret $(kubectl -n kubernetes-dashboard get sa/admin-user -o jsonpath=\u0026#34;{.secrets[0].name}\u0026#34;) -o go-template=\u0026#34;{{.data.token | base64decode}}\u0026#34; 安装Metrics Server  Kubernetes Metrics Server是Cluster的核心监控数据的聚合器，kubeadm默认是不部署的。 Metrics Server供Dashboard等其他组件使用，是一个扩展的APIServer，依赖于API Aggregator。 Metrics API只可以查询当前的度量数据，并不保存历史数据。 Metrics API URI为/apis/metrics.k8s.io/，在k8s.io/metrics下维护。 必须部署metrics-server才能使用该API，metrics-server通过调用kubelet Summary API获取数据。  修改API Server 检查API Server是否开启了Aggregator Routing：查看API Server是否具有--enable-aggregator-routing=true选项。\nps -ef | grep apiserver | grep routing 如果没有输出，直接修改/etc/kubernetes/manifests/kube-apiserver.yaml\nvi /etc/kubernetes/manifests/kube-apiserver.yaml 修改每个API Server的kube-apiserver.yaml\n 修改manifests配置后API Server会自动重启生效\n # ...省略 spec: containers: - command: - kube-apiserver - --enable-aggregator-routing=true  # 加入这一行 # ...省略 部署到k8s 从GitHub上下载的部署文件需要修改一下\n# ...省略 spec: selector: matchLabels: k8s-app: metrics-server strategy: rollingUpdate: maxUnavailable: 0 template: metadata: labels: k8s-app: metrics-server spec: containers: - args: - --cert-dir=/tmp - --secure-port=443 - --kubelet-preferred-address-types=InternalIP  # 删掉 ExternalIP,Hostname这两个 - --kubelet-use-node-status-port - --kubelet-insecure-tls  # 加上该启动参数 image: k8s.gcr.io/metrics-server/metrics-server:v0.5.1  # 镜像版本自己选择 # ...省略 完整部署文件见附录\n验证安装工  使用命令查看节点负载  kubectl top nodes # 输出 NAME CPU(cores) CPU% MEMORY(bytes) MEMORY% node1 117m 5% 1959Mi 25% node2 29m 2% 1640Mi 21% node3 43m 4% 1694Mi 22% 到Dashboard查看资源占用情况  参考链接  k8s官网 kubectl开启shell自动补全 k8s dashboard repository k8s metrics-server repository Docker 文档 Docker Hub flannel GitHub v0.14.1 kube-flannel.yml  附录 v0.14.1/kube-flannel.yml # v0.14.1/kube-flannel.yml --- apiVersion: policy/v1beta1 kind: PodSecurityPolicy metadata: name: psp.flannel.unprivileged annotations: seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default spec: privileged: false volumes: - configMap - secret - emptyDir - hostPath allowedHostPaths: - pathPrefix: \u0026#34;/etc/cni/net.d\u0026#34; - pathPrefix: \u0026#34;/etc/kube-flannel\u0026#34; - pathPrefix: \u0026#34;/run/flannel\u0026#34; readOnlyRootFilesystem: false # Users and groups runAsUser: rule: RunAsAny supplementalGroups: rule: RunAsAny fsGroup: rule: RunAsAny # Privilege Escalation allowPrivilegeEscalation: false defaultAllowPrivilegeEscalation: false # Capabilities allowedCapabilities: [\u0026#39;NET_ADMIN\u0026#39;, \u0026#39;NET_RAW\u0026#39;] defaultAddCapabilities: [] requiredDropCapabilities: [] # Host namespaces hostPID: false hostIPC: false hostNetwork: true hostPorts: - min: 0 max: 65535 # SELinux seLinux: # SELinux is unused in CaaSP rule: \u0026#39;RunAsAny\u0026#39; --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: flannel rules: - apiGroups: [\u0026#39;extensions\u0026#39;] resources: [\u0026#39;podsecuritypolicies\u0026#39;] verbs: [\u0026#39;use\u0026#39;] resourceNames: [\u0026#39;psp.flannel.unprivileged\u0026#39;] - apiGroups: - \u0026#34;\u0026#34; resources: - pods verbs: - get - apiGroups: - \u0026#34;\u0026#34; resources: - nodes verbs: - list - watch - apiGroups: - \u0026#34;\u0026#34; resources: - nodes/status verbs: - patch --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: flannel roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: flannel subjects: - kind: ServiceAccount name: flannel namespace: kube-system --- apiVersion: v1 kind: ServiceAccount metadata: name: flannel namespace: kube-system --- kind: ConfigMap apiVersion: v1 metadata: name: kube-flannel-cfg namespace: kube-system labels: tier: node app: flannel data: cni-conf.json: |{ \u0026#34;name\u0026#34;: \u0026#34;cbr0\u0026#34;, \u0026#34;cniVersion\u0026#34;: \u0026#34;0.3.1\u0026#34;, \u0026#34;plugins\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;flannel\u0026#34;, \u0026#34;delegate\u0026#34;: { \u0026#34;hairpinMode\u0026#34;: true, \u0026#34;isDefaultGateway\u0026#34;: true } }, { \u0026#34;type\u0026#34;: \u0026#34;portmap\u0026#34;, \u0026#34;capabilities\u0026#34;: { \u0026#34;portMappings\u0026#34;: true } } ] } net-conf.json: |{ \u0026#34;Network\u0026#34;: \u0026#34;10.244.0.0/16\u0026#34;, \u0026#34;Backend\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;vxlan\u0026#34; } } --- apiVersion: apps/v1 kind: DaemonSet metadata: name: kube-flannel-ds namespace: kube-system labels: tier: node app: flannel spec: selector: matchLabels: app: flannel template: metadata: labels: tier: node app: flannel spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/os operator: In values: - linux hostNetwork: true priorityClassName: system-node-critical tolerations: - operator: Exists effect: NoSchedule serviceAccountName: flannel initContainers: - name: install-cni image: quay.io/coreos/flannel:v0.14.0 command: - cp args: - -f - /etc/kube-flannel/cni-conf.json - /etc/cni/net.d/10-flannel.conflist volumeMounts: - name: cni mountPath: /etc/cni/net.d - name: flannel-cfg mountPath: /etc/kube-flannel/ containers: - name: kube-flannel image: quay.io/coreos/flannel:v0.14.0 command: - /opt/bin/flanneld args: - --ip-masq - --kube-subnet-mgr resources: requests: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; limits: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; securityContext: privileged: false capabilities: add: [\u0026#34;NET_ADMIN\u0026#34;, \u0026#34;NET_RAW\u0026#34;] env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace volumeMounts: - name: run mountPath: /run/flannel - name: flannel-cfg mountPath: /etc/kube-flannel/ volumes: - name: run hostPath: path: /run/flannel - name: cni hostPath: path: /etc/cni/net.d - name: flannel-cfg configMap: name: kube-flannel-cfg v0.5.1/metrics-server.yml # v0.5.1/metrics-server.yml apiVersion: v1 kind: ServiceAccount metadata: labels: k8s-app: metrics-server name: metrics-server namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: k8s-app: metrics-server rbac.authorization.k8s.io/aggregate-to-admin: \u0026#34;true\u0026#34; rbac.authorization.k8s.io/aggregate-to-edit: \u0026#34;true\u0026#34; rbac.authorization.k8s.io/aggregate-to-view: \u0026#34;true\u0026#34; name: system:aggregated-metrics-reader rules: - apiGroups: - metrics.k8s.io resources: - pods - nodes verbs: - get - list - watch --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: k8s-app: metrics-server name: system:metrics-server rules: - apiGroups: - \u0026#34;\u0026#34; resources: - pods - nodes - nodes/stats - namespaces - configmaps verbs: - get - list - watch --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: labels: k8s-app: metrics-server name: metrics-server-auth-reader namespace: kube-system roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: extension-apiserver-authentication-reader subjects: - kind: ServiceAccount name: metrics-server namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: labels: k8s-app: metrics-server name: metrics-server:system:auth-delegator roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:auth-delegator subjects: - kind: ServiceAccount name: metrics-server namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: labels: k8s-app: metrics-server name: system:metrics-server roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:metrics-server subjects: - kind: ServiceAccount name: metrics-server namespace: kube-system --- apiVersion: v1 kind: Service metadata: labels: k8s-app: metrics-server name: metrics-server namespace: kube-system spec: ports: - name: https port: 443 protocol: TCP targetPort: https selector: k8s-app: metrics-server --- apiVersion: apps/v1 kind: Deployment metadata: labels: k8s-app: metrics-server name: metrics-server namespace: kube-system spec: replicas: 1 selector: matchLabels: k8s-app: metrics-server strategy: rollingUpdate: maxUnavailable: 0 template: metadata: labels: k8s-app: metrics-server spec: containers: - args: - --cert-dir=/tmp - --secure-port=443 - --kubelet-insecure-tls - --kubelet-preferred-address-types=InternalIP - --kubelet-use-node-status-port - --metric-resolution=15s image: k8s.gcr.io/metrics-server/metrics-server:v0.5.1 imagePullPolicy: IfNotPresent livenessProbe: failureThreshold: 3 httpGet: path: /livez port: https scheme: HTTPS periodSeconds: 10 name: metrics-server ports: - containerPort: 443 name: https protocol: TCP readinessProbe: failureThreshold: 3 httpGet: path: /readyz port: https scheme: HTTPS initialDelaySeconds: 20 periodSeconds: 10 resources: requests: cpu: 100m memory: 200Mi securityContext: readOnlyRootFilesystem: true runAsNonRoot: true runAsUser: 1000 volumeMounts: - mountPath: /tmp name: tmp-dir nodeSelector: kubernetes.io/os: linux priorityClassName: system-cluster-critical serviceAccountName: metrics-server volumes: - emptyDir: {} name: tmp-dir --- apiVersion: apiregistration.k8s.io/v1 kind: APIService metadata: labels: k8s-app: metrics-server name: v1beta1.metrics.k8s.io spec: group: metrics.k8s.io groupPriorityMinimum: 100 insecureSkipTLSVerify: true service: name: metrics-server namespace: kube-system version: v1beta1 versionPriority: 100 ","date":"October 14, 2021","hero":"/posts/deployment/3007-linux-kubernetes/head.svg","permalink":"https://ormissia.github.io/posts/deployment/3007-linux-kubernetes/","summary":"此次安装的平台是基于ARM架构的RedHat系Linux系统平台，参照Kubernetes官方文档进行的。\n本文档流程与X86架构的没有区别，官方文档中个别步骤中的命令需要区分所使用的包对应的平台。\n 初始化环境 防火墙 systemctl stop firewalld.service systemctl disable firewalld.service SELinux vi /etc/selinux/config SELINUX=disabled Swap vi /etc/fstab 注释掉swap这一行\n/.swapfile\tnone\tswap\tsw,comment=cloudconfig\t0\t0 重启之后查看关闭是否成功\nfree -m 显示如下内容，swap关闭成功\ntotal used free shared buff/cache available Mem: 23114 402 22299 32 411 20597 Swap: 0 0 0 ulimit echo \u0026#34;ulimit -n 65535\u0026#34; \u0026gt;\u0026gt; /etc/profile echo \u0026#34;*\thard\tnofile\t65535\u0026#34; \u0026gt;\u0026gt; /etc/security/limits.conf 重启之后检查是否配置成功\nulimit -n SSH免密（非必须） 执行命令，一路回车，即可获得当前节点的公钥\nssh-keygen -t rsa cat id_rsa.","tags":null,"title":"Linux部署Kubernetes流程"},{"categories":null,"contents":" #elastic #elasticsearch\n 问题现象 按照ES官网文档介绍的安装步骤，使用yum的方式进行安装。安装完成之后，使用如下命令启动：\nsystemctl start elasticsearch.service 控制台阻塞一会后，显示启动失败，使用如下命令查看状态：\nsystemctl status elasticsearch.service 查询状态为：\nWarning: The unit file, source configuration file or drop-ins of elasticsearch.service changed on disk. Run \u0026#39;systemctl daemon-reload\u0026#39; to reload units. ● elasticsearch.service - Elasticsearch Loaded: loaded (/usr/lib/systemd/system/elasticsearch.service; disabled; vendor preset: disabled) Active: failed (Result: timeout) since Thu 2021-10-14 00:42:40 CST; 2min 15s ago Docs: https://www.elastic.co Main PID: 2547 (code=exited, status=143) Oct 14 00:41:22 gateway systemd[1]: Starting Elasticsearch... Oct 14 00:41:29 gateway bash[2547]: [0.003s][warning][logging] Output options for existing outputs are ignored. Oct 14 00:41:35 gateway systemd[1]: elasticsearch.service: Current command vanished from the unit file, execution of the command list won\u0026#39;t be resumed. Oct 14 00:42:37 gateway systemd[1]: elasticsearch.service: start operation timed out. Terminating. Oct 14 00:42:40 gateway systemd[1]: elasticsearch.service: Failed with result \u0026#39;timeout\u0026#39;. Oct 14 00:42:40 gateway systemd[1]: Failed to start Elasticsearch. 注意第四行Active: failed (Result: timeout)中的这个timeout，后面会成为关键，只是刚开始的时候没注意到。\n初步分析 首先到ES的日志目录/var/log/elasticsearch/下查看日志。\n主要有这几个文件：\n elasticsearch.log elasticsearch_server.json gc.log*  全部找了一遍，也没有发现ERROR的日志。\n内存不足 找不到报错的信息，就只能先猜测一下最可能的原因了。\n起初以为是内存的问题，因为这台服务器内存比较小，而且已经再跑了一些其他服务了。回去重新查看日志，也没有发现OOM的日志。\n于是先在本地下了一个ES程序测试一下。\n参照官网的堆内存设置文档\n选择以临时环境变量的设置方式启动ES：\nES_JAVA_OPTS=\u0026#34;-Xms2g -Xmx2g\u0026#34; ./bin/elasticsearch 逐步调整堆内存大小，最后发现设置在150m的时候ES能正常启动，设置在100m的时候则会报OOM:\n[2021-10-14T10:12:20,583][INFO ][o.e.m.j.JvmGcMonitorService] [MacBook-Pro.local] [gc][5] overhead, spent [430ms] collecting in the last [1.1s] java.lang.OutOfMemoryError: Java heap space Dumping heap to data/java_pid24385.hprof ... Heap dump file created [152347235 bytes in 3.515 secs] [2021-10-14T10:12:26,083][WARN ][o.e.m.j.JvmGcMonitorService] [MacBook-Pro.local] [gc][6] overhead, spent [4.4s] collecting in the last [5.1s] 再回去复查服务器上的日志，并没有发现类似日志。再结合elasticsearch.log文件中，每次ES启动是的日志：\n# 前后省略 [2021-10-14T00:07:25,348][INFO ][o.e.n.Node] [gateway] JVM arguments [... -Xms346m, -Xmx346m, -XX:+UseG1GC, ...] 可以看到，服务器上ES运行的默认设置是取的当前空闲内存的值作为-Xms和-Xmx的参数。\n因此，基本可以排除服务器上ES无法启动是由于内存不足造成的。\nSELinux 既然不是内存造成的，又没有ERROR日志（这是最奇怪的）。接下来稍微有点病急乱投医了。\n猜测是SELinux造成的一切问题。\n查看SELinux是否开启，执行：\n/usr/sbin/sestatus -v 输出：\nSELinux status: enabled SELinuxfs mount: /sys/fs/selinux SELinux root directory: /etc/selinux Loaded policy name: targeted Current mode: enforcing Mode from config file: error (Success) Policy MLS status: enabled Policy deny_unknown status: allowed Memory protection checking: actual (secure) Max kernel policy version: 33 # 以下省略 # ... 可以看到SELinux是开启状态,于是编辑/etc/selinux/config文件，根据注释修改SELINUX的值：\nSELINUX=disabled 重启之后重新查看SELinux的开启状态：\n/usr/sbin/sestatus -v # 输出 SELinux status: disabled 可以看到SELinux已经关闭了。再次启动ES，依然无法启动。\n所以可以排除是SELinux造成的无法启动。\n文件打开数量限制 怀疑是Linux最大文件打开数量限制造成的问题，使用命令查看:\nulimit -n 输出：\n1024 可以看到系统默认设置只有1024，将其临时改大一些：\nulimit -n 65535 重新启动ES，发现仍然无法启动。\n所以，排除这个原因。\n文件权限 检查ES程序用到的几个文件夹的所有者：\n /usr/share/elasticsearch /etc/elasticsearch /var/log/elasticsearch  发现没有问题，所有者和所属组均是elasticsearch，也可以排除权限不足的问题。\n ES无法使用root用户启动，使用root启动时会报错。\n 进一步分析 上面的问题都排除了，不是内存不足的问题，也不是系统限制，也没有权限相关的问题。最最最神奇的是，没有ERROR的日志，一切就仿佛是正常启动和停止。\n但是这明显不是正常的程序终止。\nTIME OUT 来来回回想了好久，又回到开头提到的使用systemctl查看到的程序状态：\n# 省略... Active: failed (Result: timeout) since Thu 2021-10-14 00:42:40 CST; 2min 15s ago # 省略... Main PID: 2547 (code=exited, status=143) Oct 14 00:41:22 gateway systemd[1]: Starting Elasticsearch... Oct 14 00:41:29 gateway bash[2547]: [0.003s][warning][logging] Output options for existing outputs are ignored. Oct 14 00:41:35 gateway systemd[1]: elasticsearch.service: Current command vanished from the unit file, execution of the command list won\u0026#39;t be resumed. Oct 14 00:42:37 gateway systemd[1]: elasticsearch.service: start operation timed out. Terminating. Oct 14 00:42:40 gateway systemd[1]: elasticsearch.service: Failed with result \u0026#39;timeout\u0026#39;. Oct 14 00:42:40 gateway systemd[1]: Failed to start Elasticsearch. 唯一的失败提示就是这个timeout，不明白程序启动为啥会timeout。\n修改程序启动方式 不过抱着试试看的心态，死马当活马医了。\n搜了一下，还真有类似问题：\nelasticsearch service start operation timed out. Terminating.报错问题处理\n在CSDN上看到了一个同样的问题，他的修改方式是将systemd配置文件中ExecStart后面的命令改为后台启动：\nvi /usr/lib/systemd/system/elasticsearch.service 修改：\n# 省略... ExecStart=/usr/share/elasticsearch/bin/systemd-entrypoint -p ${PID_DIR}/elasticsearch.pid --quiet # 修改为 ExecStart=/bin/bash -c \u0026#34;/usr/share/elasticsearch/bin/systemd-entrypoint -p ${PID_DIR}/elasticsearch.pid --quiet \u0026amp;\u0026#34; # 省略... 改完之后重新加载配置文件：\nsystemctl daemon-reload 再次启动ES，发现依然超时。\n再次强化了我对CSDN的负面印象，90%的东西递归转载，9%的东西扯淡，剩下1%的东西是概念性的知识\n修改超时时间 重新捋了一下思维，在服务器上程序是通过systemctl启动的，而使用的配置文件就是/usr/lib/systemd/system/elasticsearch.service。\n因此造成超时极有可能是这个配置文件的原因。\n重新仔细查看这个配置文件，发现有下面这几行：\n# 省略... # Allow a slow startup before the systemd notifier module kicks in to extend the timeout TimeoutStartSec=75 # 省略... 参考systemd.service对TimeoutStartSec的解释，发现这个参数设置的就是该服务允许的最大启动时长。\n一旦启动时间超过这个值就会失败，与timeout的错误提示吻合。 并且由于我使用的这台服务器性能比价孱弱，极有可能在默认限制75S内无法完成ES的启动，造成超时。 至此原因逐渐明朗，于是直接将其改为：\nTimeoutStartSec=1000 再次启动ES并查看状态：\n● elasticsearch.service - Elasticsearch Loaded: loaded (/usr/lib/systemd/system/elasticsearch.service; enabled; vendor preset: disabled) Active: active (running) since Thu 2021-10-14 00:54:54 CST; 10h ago Docs: https://www.elastic.co Main PID: 2968 (java) Tasks: 61 (limit: 4574) Memory: 218.5M CGroup: /system.slice/elasticsearch.service ├─2968 /usr/share/elasticsearch/jdk/bin/java -Xshare:auto -Des.networkaddress.cache.ttl=60 -Des.networkaddress.cache.negative.ttl=10 -XX:+Al\u0026gt; └─3134 /usr/share/elasticsearch/modules/x-pack-ml/platform/linux-x86_64/bin/controller 使用:9200端口查看ES运行状态：\ncurl 127.0.0.1:9200 返回：\n{ \u0026#34;name\u0026#34; : \u0026#34;gateway\u0026#34;, \u0026#34;cluster_name\u0026#34; : \u0026#34;elasticsearch\u0026#34;, \u0026#34;cluster_uuid\u0026#34; : \u0026#34;jrP00kvxxxxxxxbjr6aPg\u0026#34;, \u0026#34;version\u0026#34; : { \u0026#34;number\u0026#34; : \u0026#34;7.15.0\u0026#34;, \u0026#34;build_flavor\u0026#34; : \u0026#34;default\u0026#34;, \u0026#34;build_type\u0026#34; : \u0026#34;rpm\u0026#34;, \u0026#34;build_hash\u0026#34; : \u0026#34;79d65f6e35xxxxxxxxxxxxxxc7c21073d89aa29\u0026#34;, \u0026#34;build_date\u0026#34; : \u0026#34;2021-09-16T03:05:29.143308416Z\u0026#34;, \u0026#34;build_snapshot\u0026#34; : false, \u0026#34;lucene_version\u0026#34; : \u0026#34;8.9.0\u0026#34;, \u0026#34;minimum_wire_compatibility_version\u0026#34; : \u0026#34;6.8.0\u0026#34;, \u0026#34;minimum_index_compatibility_version\u0026#34; : \u0026#34;6.0.0-beta1\u0026#34; }, \u0026#34;tagline\u0026#34; : \u0026#34;You Know, for Search\u0026#34; } 可以看到ES的版本，以及使用的lucene的版本等相关信息。\nES启动成功，问题解决！\n尾巴 由于在上面启动ES的时候CPU和内存总是飚高：\n经常会将网关Traefik挤死，结合服务器资源和目前实际使用强度，因此将ES的堆内存设置在180M：\ncd /etc/elasticsearch/ cp jvm.options jvm.options.d/jvm.options vi jvm.options.d/jvm.options 将-Xms和-Xmx的值设置为180m，重启几次ES。网关等其他程序没有再出现被kill掉的情况。\n-Xms180m -Xmx180m 总结 这次问题解决的历程比较曲折，由于对Linux系统程序运行提示了解的不够多，经验不够，造成一开始走了一些弯路。\n参考链接  ES JVM配置文档 systemd.service  ","date":"October 14, 2021","hero":"/posts/problems/5003-elasticsearch-start-failed/head.svg","permalink":"https://ormissia.github.io/posts/problems/5003-elasticsearch-start-failed/","summary":"#elastic #elasticsearch\n 问题现象 按照ES官网文档介绍的安装步骤，使用yum的方式进行安装。安装完成之后，使用如下命令启动：\nsystemctl start elasticsearch.service 控制台阻塞一会后，显示启动失败，使用如下命令查看状态：\nsystemctl status elasticsearch.service 查询状态为：\nWarning: The unit file, source configuration file or drop-ins of elasticsearch.service changed on disk. Run \u0026#39;systemctl daemon-reload\u0026#39; to reload units. ● elasticsearch.service - Elasticsearch Loaded: loaded (/usr/lib/systemd/system/elasticsearch.service; disabled; vendor preset: disabled) Active: failed (Result: timeout) since Thu 2021-10-14 00:42:40 CST; 2min 15s ago Docs: https://www.elastic.co Main PID: 2547 (code=exited, status=143) Oct 14 00:41:22 gateway systemd[1]: Starting Elasticsearch.","tags":null,"title":"CentOS安装完ES无法启动"},{"categories":null,"contents":"Elasticsearch Deployment\u0026amp;Service apiVersion: apps/v1 kind: StatefulSet metadata: labels: app: elasticsearch role: master name: elasticsearch-master spec: replicas: 3 revisionHistoryLimit: 10 selector: matchLabels: app: elasticsearch role: master serviceName: es-master template: metadata: labels: app: elasticsearch role: master spec: serviceAccountName: elasticsearch-admin affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - topologyKey: kubernetes.io/hostname labelSelector: matchExpressions: - key: role operator: In values: - master containers: - name: elasticsearch-master image: elasticsearch:7.14.2 lifecycle: postStart: exec: command: [ \u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;sysctl -w vm.max_map_count=262144; ulimit -l unlimited; chown -R elasticsearch:elasticsearch /usr/share/elasticsearch/data;\u0026#34; ] ports: - containerPort: 9200 protocol: TCP - containerPort: 9300 protocol: TCP resources: limits: cpu: 100m memory: 1Gi requests: cpu: 10m memory: 512Mi env: - name: MY_POD_NAME valueFrom: fieldRef: fieldPath: metadata.name apiVersion: v1 - name: path.data value: /usr/share/elasticsearch/data/${MY_POD_NAME} - name: cluster.name value: elasticsearch-k8s-cluster - name: discovery.seed_hosts value: elasticsearch-discovery - name: node.master value: \u0026#34;true\u0026#34; - name: node.data value: \u0026#34;false\u0026#34; - name: node.ingest value: \u0026#34;false\u0026#34; - name: ES_JAVA_OPTS value: \u0026#34;-Xms512m -Xmx512m\u0026#34; - name: cluster.initial_master_nodes value: elasticsearch-master-0,elasticsearch-master-1,elasticsearch-master-2 # - name: xpack.security.enabled # value: \u0026#34;true\u0026#34; # - name: xpack.security.transport.ssl.enabled # value: \u0026#34;true\u0026#34; securityContext: privileged: true volumeMounts: - mountPath: /usr/share/elasticsearch/data name: es-master-pvc - mountPath: /usr/share/elasticsearch/plugins name: es-plugins-pvc volumes: - name: es-master-pvc persistentVolumeClaim: claimName: es-master-pvc - name: es-plugins-pvc persistentVolumeClaim: claimName: es-plugins-pvc --- apiVersion: v1 kind: Service metadata: name: elasticsearch-discovery spec: ports: - port: 9300 selector: app: elasticsearch --- apiVersion: apps/v1 kind: StatefulSet metadata: labels: app: elasticsearch role: data name: elasticsearch-data spec: replicas: 4 revisionHistoryLimit: 10 selector: matchLabels: app: elasticsearch role: data serviceName: es-data template: metadata: labels: app: elasticsearch role: data spec: serviceAccountName: elasticsearch-admin affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - podAffinityTerm: topologyKey: kubernetes.io/hostname labelSelector: matchExpressions: - key: role operator: In values: - data weight: 100 containers: - name: elasticsearch-data image: elasticsearch:7.14.2 lifecycle: postStart: exec: command: [ \u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;sysctl -w vm.max_map_count=262144; ulimit -l unlimited; chown -R elasticsearch:elasticsearch /usr/share/elasticsearch;\u0026#34; ] ports: - containerPort: 9200 protocol: TCP - containerPort: 9300 protocol: TCP resources: limits: cpu: 100m memory: 1Gi requests: cpu: 10m memory: 512Mi env: - name: MY_POD_NAME valueFrom: fieldRef: fieldPath: metadata.name apiVersion: v1 - name: path.data value: /usr/share/elasticsearch/data/${MY_POD_NAME} - name: cluster.name value: elasticsearch-k8s-cluster - name: discovery.seed_hosts value: elasticsearch-discovery - name: node.master value: \u0026#34;false\u0026#34; - name: node.data value: \u0026#34;true\u0026#34; - name: ES_JAVA_OPTS value: \u0026#34;-Xms300m -Xmx300m\u0026#34; - name: cluster.initial_master_nodes value: elasticsearch-master-0,elasticsearch-master-1,elasticsearch-master-2 # - name: xpack.security.enabled # value: \u0026#34;true\u0026#34; # - name: xpack.security.transport.ssl.enabled # value: \u0026#34;true\u0026#34; securityContext: privileged: true volumeMounts: - mountPath: /usr/share/elasticsearch/data name: es-data-pvc - mountPath: /usr/share/elasticsearch/plugins name: es-plugins-pvc volumes: - name: es-data-pvc persistentVolumeClaim: claimName: es-data-pvc - name: es-plugins-pvc persistentVolumeClaim: claimName: es-plugins-pvc --- apiVersion: v1 kind: Service metadata: name: elasticsearch spec: type: ClusterIP ports: - port: 9200 targetPort: 9200 protocol: TCP name: http selector: app: elasticsearch role: data RBAC apiVersion: v1 kind: ServiceAccount metadata: name: elasticsearch-admin --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: elasticearch-admin roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: elasticsearch-admin namespace: kube-elastic PV\u0026amp;PVC apiVersion: v1 kind: PersistentVolume metadata: name: es-master-pv spec: capacity: storage: 512Mi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain storageClassName: es-master-pv nfs: path: /data/nfs/kubernetes/elastic/elasticsearch/master server: node1 --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: es-master-pvc spec: accessModes: - ReadWriteMany resources: requests: storage: 512Mi storageClassName: es-master-pv --- apiVersion: v1 kind: PersistentVolume metadata: name: es-data-pv spec: capacity: storage: 5Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain storageClassName: es-data-pv nfs: path: /data/nfs/kubernetes/elastic/elasticsearch/data server: node1 --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: es-data-pvc spec: accessModes: - ReadWriteMany resources: requests: storage: 5Gi storageClassName: es-data-pv --- apiVersion: v1 kind: PersistentVolume metadata: name: es-plugins-pv spec: capacity: storage: 512Mi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain storageClassName: es-plugins-pv nfs: path: /data/nfs/kubernetes/elastic/elasticsearch/plugins server: node1 --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: es-plugins-pvc spec: accessModes: - ReadWriteMany resources: requests: storage: 512Mi storageClassName: es-plugins-pv Ingress kind: Ingress apiVersion: networking.k8s.io/v1 metadata: name: elasticsearch-ingress annotations: traefik.ingress.kubernetes.io/router.entrypoints: web spec: rules: - host: elasticsearch.ormissia.com http: paths: - path: / pathType: Prefix backend: service: name: elasticsearch port: number: 9200 Kibana Deployment\u0026amp;Service apiVersion: apps/v1 kind: Deployment metadata: labels: app: kibana name: kibana spec: replicas: 1 selector: matchLabels: app: kibana template: metadata: labels: app: kibana spec: containers: - name: kibana image: kibana:7.14.2 ports: - containerPort: 5601 protocol: TCP resources: limits: cpu: 100m memory: 600Gi requests: cpu: 10m memory: 400Mi env: - name: ELASTICSEARCH_URL value: http://elasticsearch:9200 - name: I18N_LOCALE value: zh-CN - name: SERVER_PUBLICBASEURL value: https://kibana.ormissia.com --- apiVersion: v1 kind: Service metadata: name: kibana spec: type: ClusterIP ports: - port: 5601 targetPort: 5601 protocol: TCP selector: app: kibana PV\u0026amp;PVC apiVersion: v1 kind: PersistentVolume metadata: name: kibana-pv spec: capacity: storage: 512Mi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain storageClassName: kibana-pv nfs: path: /data/nfs/kubernetes/elastic/kibana server: node1 --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: kibana-pvc spec: accessModes: - ReadWriteMany resources: requests: storage: 512Mi storageClassName: kibana-pv Ingress kind: Ingress apiVersion: networking.k8s.io/v1 metadata: name: kibana-ingress annotations: traefik.ingress.kubernetes.io/router.entrypoints: web spec: rules: - host: kibana.ormissia.com http: paths: - path: / pathType: Prefix backend: service: name: kibana port: number: 5601 ","date":"October 13, 2021","hero":"/posts/deployment/3006-linux-elk/head.svg","permalink":"https://ormissia.github.io/posts/deployment/3006-linux-elk/","summary":"Elasticsearch Deployment\u0026amp;Service apiVersion: apps/v1 kind: StatefulSet metadata: labels: app: elasticsearch role: master name: elasticsearch-master spec: replicas: 3 revisionHistoryLimit: 10 selector: matchLabels: app: elasticsearch role: master serviceName: es-master template: metadata: labels: app: elasticsearch role: master spec: serviceAccountName: elasticsearch-admin affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - topologyKey: kubernetes.io/hostname labelSelector: matchExpressions: - key: role operator: In values: - master containers: - name: elasticsearch-master image: elasticsearch:7.14.2 lifecycle: postStart: exec: command: [ \u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;sysctl -w vm.max_map_count=262144; ulimit -l unlimited; chown -R elasticsearch:elasticsearch /usr/share/elasticsearch/data;\u0026#34; ] ports: - containerPort: 9200 protocol: TCP - containerPort: 9300 protocol: TCP resources: limits: cpu: 100m memory: 1Gi requests: cpu: 10m memory: 512Mi env: - name: MY_POD_NAME valueFrom: fieldRef: fieldPath: metadata.","tags":null,"title":"ELK部署流程"},{"categories":null,"contents":"程序下载 wget https://github.com/prometheus/prometheus/releases/download/v2.30.3/prometheus-2.30.3.linux-amd64.tar.gz 解压并移动 tar -zxvf prometheus-2.30.3.linux-amd64.tar.gz mv prometheus-2.30.3.linux-amd64 /usr/local/prometheus 添加到系统服务 Unit配置文件 vi /usr/lib/systemd/system/prometheus.service [Unit] Description=Prometheus Documentation=https://prometheus.io [Service] Type=simple ExecStart=/usr/local/prometheus/prometheus \\ --config.file=/usr/local/prometheus/prometheus.yml \\ --storage.tsdb.path=/usr/local/prometheus/data Restart=on-failure WatchdogSec=10s [Install] WantedBy=multi-user.target 启动程序 sudo systemctl daemon-reload sudo systemctl start prometheus.service sudo systemctl status prometheus.service 开机自启 sudo systemctl enable prometheus.service 简单使用 Prometheus默认端口是9090，程序启动之后从浏览器访问页面。\n输入以下表达式来绘制在自抓取Prometheus中发生的每秒HTTP请求率返回状态代码200的图表：\nrate(promhttp_metric_handler_requests_total{code=\u0026#34;200\u0026#34;}[1m]) 配置文件 重新加载 curl -X POST http://127.0.0.1:9090/-/reload Kubernetes部署脚本 Deployment\u0026amp;Service apiVersion: apps/v1 kind: Deployment metadata: name: prometheus labels: app: prometheus spec: replicas: 1 strategy: rollingUpdate: maxSurge: 1 maxUnavailable: 1 type: RollingUpdate selector: matchLabels: app: prometheus template: metadata: labels: app: prometheus spec: initContainers: - name: prometheus-data-permission-setup image: busybox command: [\u0026#34;/bin/chmod\u0026#34;,\u0026#34;-R\u0026#34;,\u0026#34;777\u0026#34;, \u0026#34;/data\u0026#34;] volumeMounts: - name: prometheus-data mountPath: /data containers: - name: prometheus image: prom/prometheus args: - \u0026#39;--storage.tsdb.path=/prometheus\u0026#39; - \u0026#39;--config.file=/etc/prometheus/prometheus.yml\u0026#39; command: - /bin/prometheus ports: - name: web containerPort: 9090 resources: limits: cpu: 20m memory: 150Mi requests: cpu: 5m memory: 80Mi volumeMounts: - name: config-volume mountPath: /etc/prometheus - name: prometheus-data mountPath: /prometheus restartPolicy: Always securityContext: {} terminationGracePeriodSeconds: 30 serviceAccountName: prometheus volumes: - name: config-volume configMap: name: prometheus-config - name: prometheus-data persistentVolumeClaim: claimName: prometheus-pvc --- apiVersion: v1 kind: Service metadata: name: prometheus spec: type: ClusterIP selector: app: prometheus ports: - port: 9090 targetPort: 9090 protocol: TCP RBAC apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: prometheus rules: - apiGroups: - \u0026#34;\u0026#34; resources: - nodes - nodes/proxy - services - endpoints - pods verbs: - get - list - watch - apiGroups: - extensions resources: - ingresses verbs: - get - list - watch - nonResourceURLs: - /metrics verbs: - get --- apiVersion: v1 kind: ServiceAccount metadata: name: prometheus --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: prometheus roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: prometheus subjects: - kind: ServiceAccount name: prometheus namespace: kube-basic PV\u0026amp;PVC apiVersion: v1 kind: PersistentVolume metadata: name: node1-prometheus-pv spec: capacity: storage: 2Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain storageClassName: node1-prometheus-pv nfs: path: /data/nfs/kubernetes/prometheus server: node1 --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: prometheus-pvc spec: accessModes: - ReadWriteMany resources: requests: storage: 2Gi storageClassName: node1-prometheus-pv Ingress kind: Ingress apiVersion: networking.k8s.io/v1 metadata: name: prometheus-ingress annotations: traefik.ingress.kubernetes.io/router.entrypoints: web spec: rules: - host: prometheus.ormissia.com http: paths: - path: / pathType: Prefix backend: service: name: prometheus port: number: 9090 Node Exporter Deployment\u0026amp;Service apiVersion: apps/v1 kind: DaemonSet metadata: name: node-exporter labels: app: node-exporter spec: selector: matchLabels: app: node-exporter template: metadata: labels: app: node-exporter spec: hostPID: true hostIPC: true hostNetwork: true tolerations: - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule containers: - name: node-exporter image: prom/node-exporter ports: - containerPort: 9100 resources: limits: cpu: 10m memory: 30Mi requests: cpu: 2m memory: 10Mi securityContext: privileged: true args: - --path.procfs - /host/proc - --path.sysfs - /host/sys - --path.rootfs - /host/root - --collector.filesystem.ignored-mount-points - ^/(sys|proc|dev|host|etc)($|/) - --collector.processes volumeMounts: - mountPath: /host/dev name: dev - mountPath: /host/proc name: proc - mountPath: /host/sys name: sys - mountPath: /host/root name: rootfs volumes: - name: proc hostPath: path: /proc - name: dev hostPath: path: /dev - name: sys hostPath: path: /sys - name: rootfs hostPath: path: / Prometheus Config # my global config global: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Alertmanager configuration alerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093 # Load rules once and periodically evaluate them according to the global \u0026#39;evaluation_interval\u0026#39;. rule_files: # - \u0026#34;first_rules.yml\u0026#34; # - \u0026#34;second_rules.yml\u0026#34; # A scrape configuration containing exactly one endpoint to scrape: # Here it\u0026#39;s Prometheus itself. scrape_configs: # The job name is added as a label `job=\u0026lt;job_name\u0026gt;` to any timeseries scraped from this config. - job_name: \u0026#34;prometheus\u0026#34; # metrics_path defaults to \u0026#39;/metrics\u0026#39; # scheme defaults to \u0026#39;http\u0026#39;. static_configs: - targets: [\u0026#34;localhost:9090\u0026#34;] - job_name: \u0026#34;node1-exporter\u0026#34; static_configs: - targets: [\u0026#34;gateway-node-exporter:9100\u0026#34;] relabel_configs: - source_labels: [__address__] regex: (.*) replacement: gateway target_label: instance action: replace - job_name: \u0026#39;kubernetes-node-exporter\u0026#39; kubernetes_sd_configs: - role: node relabel_configs: - source_labels: [__address__] regex: \u0026#39;(.*):10250\u0026#39; replacement: \u0026#39;${1}:9100\u0026#39; target_label: __address__ action: replace - source_labels: [__meta_kubernetes_node_name] action: replace target_label: node - action: labelmap regex: __meta_kubernetes_node_label_(.+) - source_labels: [__meta_kubernetes_node_address_InternalIP] action: replace target_label: ip 参考链接 Prometheus官网 Prometheus下载页面 Prometheus文档\n","date":"October 9, 2021","hero":"/posts/deployment/3005-linux-prometheus/head.png","permalink":"https://ormissia.github.io/posts/deployment/3005-linux-prometheus/","summary":"程序下载 wget https://github.com/prometheus/prometheus/releases/download/v2.30.3/prometheus-2.30.3.linux-amd64.tar.gz 解压并移动 tar -zxvf prometheus-2.30.3.linux-amd64.tar.gz mv prometheus-2.30.3.linux-amd64 /usr/local/prometheus 添加到系统服务 Unit配置文件 vi /usr/lib/systemd/system/prometheus.service [Unit] Description=Prometheus Documentation=https://prometheus.io [Service] Type=simple ExecStart=/usr/local/prometheus/prometheus \\ --config.file=/usr/local/prometheus/prometheus.yml \\ --storage.tsdb.path=/usr/local/prometheus/data Restart=on-failure WatchdogSec=10s [Install] WantedBy=multi-user.target 启动程序 sudo systemctl daemon-reload sudo systemctl start prometheus.service sudo systemctl status prometheus.service 开机自启 sudo systemctl enable prometheus.service 简单使用 Prometheus默认端口是9090，程序启动之后从浏览器访问页面。\n输入以下表达式来绘制在自抓取Prometheus中发生的每秒HTTP请求率返回状态代码200的图表：\nrate(promhttp_metric_handler_requests_total{code=\u0026#34;200\u0026#34;}[1m]) 配置文件 重新加载 curl -X POST http://127.0.0.1:9090/-/reload Kubernetes部署脚本 Deployment\u0026amp;Service apiVersion: apps/v1 kind: Deployment metadata: name: prometheus labels: app: prometheus spec: replicas: 1 strategy: rollingUpdate: maxSurge: 1 maxUnavailable: 1 type: RollingUpdate selector: matchLabels: app: prometheus template: metadata: labels: app: prometheus spec: initContainers: - name: prometheus-data-permission-setup image: busybox command: [\u0026#34;/bin/chmod\u0026#34;,\u0026#34;-R\u0026#34;,\u0026#34;777\u0026#34;, \u0026#34;/data\u0026#34;] volumeMounts: - name: prometheus-data mountPath: /data containers: - name: prometheus image: prom/prometheus args: - \u0026#39;--storage.","tags":null,"title":"Prometheus部署流程"},{"categories":null,"contents":"Grafana的安装比较简单，打开官网下载页面，选择对应的系统以及需要的版本号，按照指引执行命令即可。\n程序下载 wget https://dl.grafana.com/enterprise/release/grafana-enterprise-8.2.0-1.x86_64.rpm sudo yum install grafana-enterprise-8.2.0-1.x86_64.rpm 启动程序 sudo systemctl daemon-reload sudo systemctl start grafana-server sudo systemctl status grafana-server 验证 Grafana默认端口为:3000，默认用户名密码均为admin，程序启动后即可通过3000端口访问管理页面。\n开机自启 sudo systemctl enable grafana-server Kubernetes部署脚本 Deployment\u0026amp;Service apiVersion: apps/v1 kind: Deployment metadata: name: grafana labels: app: grafana spec: selector: matchLabels: app: grafana template: metadata: labels: app: grafana spec: affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - podAffinityTerm: topologyKey: kubernetes.io/hostname labelSelector: matchExpressions: - key: role operator: In values: - data weight: 100 containers: - name: grafana image: grafana/grafana-enterprise ports: - containerPort: 3000 env: - name: GF_PATHS_CONFIG value: /etc/grafana/grafana.ini - name: GF_PATHS_DATA value: /var/lib/grafana - name: GF_PATHS_HOME value: /usr/share/grafana - name: GF_PATHS_LOGS value: /var/log/grafana - name: GF_PATHS_PLUGINS value: /var/lib/grafana/plugins - name: GF_PATHS_PROVISIONING value: /etc/grafana/provisioning volumeMounts: - mountPath: /etc/grafana/ name: grafana-conf-dir - mountPath: /var/lib/grafana name: grafana-conf-dir volumes: - name: grafana-conf-dir persistentVolumeClaim: claimName: grafana-pvc --- apiVersion: v1 kind: Service metadata: name: grafana spec: type: ClusterIP selector: app: grafana ports: - port: 3000 targetPort: 3000 protocol: TCP PV\u0026amp;PVC apiVersion: v1 kind: PersistentVolume metadata: name: node1-grafana-pv spec: capacity: storage: 1Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain storageClassName: node1-grafana-pv nfs: path: /data/nfs/kubernetes/grafana server: node1 --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: grafana-pvc spec: accessModes: - ReadWriteMany resources: requests: storage: 1Gi storageClassName: node1-grafana-pv Ingress kind: Ingress apiVersion: networking.k8s.io/v1 metadata: name: grafana-ingress annotations: traefik.ingress.kubernetes.io/router.entrypoints: web spec: rules: - host: grafana.ormissia.com http: paths: - path: / pathType: Prefix backend: service: name: grafana port: number: 3000 参考连接  Grafana官网 Grafana下载页面 Grafana安装文档  ","date":"October 9, 2021","hero":"/posts/deployment/3004-linux-grafana/head.png","permalink":"https://ormissia.github.io/posts/deployment/3004-linux-grafana/","summary":"Grafana的安装比较简单，打开官网下载页面，选择对应的系统以及需要的版本号，按照指引执行命令即可。\n程序下载 wget https://dl.grafana.com/enterprise/release/grafana-enterprise-8.2.0-1.x86_64.rpm sudo yum install grafana-enterprise-8.2.0-1.x86_64.rpm 启动程序 sudo systemctl daemon-reload sudo systemctl start grafana-server sudo systemctl status grafana-server 验证 Grafana默认端口为:3000，默认用户名密码均为admin，程序启动后即可通过3000端口访问管理页面。\n开机自启 sudo systemctl enable grafana-server Kubernetes部署脚本 Deployment\u0026amp;Service apiVersion: apps/v1 kind: Deployment metadata: name: grafana labels: app: grafana spec: selector: matchLabels: app: grafana template: metadata: labels: app: grafana spec: affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - podAffinityTerm: topologyKey: kubernetes.io/hostname labelSelector: matchExpressions: - key: role operator: In values: - data weight: 100 containers: - name: grafana image: grafana/grafana-enterprise ports: - containerPort: 3000 env: - name: GF_PATHS_CONFIG value: /etc/grafana/grafana.","tags":null,"title":"Grafana部署流程"},{"categories":null,"contents":" Traefik is an open-source Edge Router that makes publishing your services a fun and easy experience. It receives requests on behalf of your system and finds out which components are responsible for handling them. What sets Traefik apart, besides its many features, is that it automatically discovers the right configuration for your services. The magic happens when Traefik inspects your infrastructure, where it finds relevant information and discovers which service serves which request. Traefik is natively compliant with every major cluster technology, such as Kubernetes, Docker, Docker Swarm, AWS, Mesos, Marathon, and the list goes on; and can handle many at the same time. (It even works for legacy software running on bare metal.) With Traefik, there is no need to maintain and synchronize a separate configuration file: everything happens automatically, in real time (no restarts, no connection interruptions). With Traefik, you spend time developing and deploying new features to your system, not on configuring and maintaining its working state. Developing Traefik, our main goal is to make it simple to use, and we\u0026rsquo;re sure you\u0026rsquo;ll enjoy it.\n\u0026ndash; The Traefik Maintainer Team\n 结尾附Traefik作为Kubernetes Controller的部署脚本\n程序下载 由于Traefik是由Golang语言所编写，程序是二进制包的形式。直接到Traefik在GitHub仓库的releases中下载即可。\n我使用的是基于x86的64位Linux系统，所以在这里选择的是linux_amd64版本的包\nwget https://github.com/traefik/traefik/releases/download/v2.5.3/traefik_v2.5.3_linux_amd64.tar.gz 解压得到程序\ntar -zxvf traefik_v2.5.3_linux_amd64.tar.gz 将程序重命名为traefik并放到/usr/local/bin/目录下\n静态配置  静态配置是Traefik在程序启动的时候从配置文件、环境变量或启动参数中加载到内存中的配置参数。如果需要修改，则需要重启Traefik。\n 静态配置的官方文档\n根据文档介绍，Traefik会从以下几个目录读取名为traefik.yml（或traefik.yaml或traefik.toml）的静态配置文件：\n /etc/traefik/ $XDG_CONFIG_HOME/ $HOME/.config/ .(Traefik程序运行的当前目录)  或者在启动的时候以参数形式指定静态配置文件：\ntraefik --configFile=foo/bar/myconfigfile.yml 代理端口 使用entryPoints向外暴露端口\nentryPoints: web: address: \u0026#34;:80\u0026#34; websecure: address: \u0026#34;:443\u0026#34; 添加动态配置 Traefik支持动态配置，即配置修改后Traefik可以自动重新加载，我在这里选择了从文件读取动态配置，通过providers添加动态配置的配置文件的路径或文件名，在这里我使用了目录的形式（dictory和filename二选一）。\n这里也可以修改动态配置的重新加载间隔时间，默认是2S，我在这里使用了默认配置，不做修改。\nproviders: file: directory: /etc/traefik/dynamic-conf watch: true 开启API 在这里可以开启Traefik的dashboard以及api\napi: insecure: true dashboard默认使用的是8080端口，如果要修改，则需要在entryPoints下添加名为traefik的端口配置：\nentryPoints: traefik: address: \u0026#34;:10000\u0026#34; 程序日志 Traefik支持将程序运行的日志输出到文件，通过log标签可以设置日志输出文件，输出格式以及日志级别。\nlog: filePath: /etc/traefik/traefik.log format: json level: ERROR 访问日志 Traefik支持将访问日志输出到文件，通过accessLog配置\naccessLog: filePath: /etc/traefik/access.log format: json 监控 // TODO\nmetrics: prometheus: addRoutersLabels: true entryPoint: metrics 动态配置  动态配置中存储的是路由、服务、中间件等配置信息，是可以在程序运行时动态修改的值。\n 以下是Traefik所支持的动态配置提供者：\n   Provider Type Configuration Type Provider Name     Docker Orchestrator Label docker   Kubernetes IngressRoute Orchestrator Custom Resource kubernetescrd   Kubernetes Ingress Orchestrator Ingress kubernetes   Kubernetes Gateway API Orchestrator Gateway API Resource kubernetesgateway   Consul Catalog Orchestrator Label consulcatalog   ECS Orchestrator Label ecs   Marathon Orchestrator Label marathon   Rancher Orchestrator Label rancher   File Manual YAML/TOML format file   Consul KV KV consul   Etcd KV KV etcd   ZooKeeper KV KV zookeeper   Redis KV KV redis   HTTP Manual JSON format http      我在这里选择了File类型的提供者，以下均为File类型的介绍\n 路由 路由类型分为三种，分别为：http、tcp、udp\n在这里我使用的是HTTP的路由功能：\nhttp: routers: router-traefik: rule: HostRegexp(`traefik.{domain:.*}`) service: traefik router-grafana: rule: HostRegexp(`grafana.{domain:.*}`) service: grafana  service指向的是下面定义的Service的名称\n 路由规则 路由规则是指，Traefik接收到的请求，根据给定规则路由到不同的服务中。\nTraefik一共支持以下规则：\n   Rule Description     Headers(`key`, `value`) Check if there is a key keydefined in the headers, with the value value   HeadersRegexp(`key`, `regexp`) Check if there is a key keydefined in the headers, with a value that matches the regular expression regexp   Host(`example.com`, \u0026hellip;) Check if the request domain (host header value) targets one of the given domains.   HostHeader(`example.com`, \u0026hellip;) Check if the request domain (host header value) targets one of the given domains.   HostRegexp(`example.com`, `{subdomain:[a-z]+}.example.com`, \u0026hellip;) Check if the request domain matches the given regexp.   Method(`GET`, \u0026hellip;) Check if the request method is one of the given methods (GET, POST, PUT, DELETE, PATCH, HEAD)   Path(`/path`, `/articles/{cat:[a-z]+}/{id:[0-9]+}`, \u0026hellip;) Match exact request path. It accepts a sequence of literal and regular expression paths.   PathPrefix(`/products/`, `/articles/{cat:[a-z]+}/{id:[0-9]+}`) Match request prefix path. It accepts a sequence of literal and regular expression prefix paths.   Query(`foo=bar`, `bar=baz`) Match Query String parameters. It accepts a sequence of key=value pairs.   ClientIP(`10.0.0.0/16`, `::1`) Match if the request client IP is one of the given IP/CIDR. It accepts IPv4, IPv6 and CIDR formats     我这这里主要会用到HostRegexp和PathPrefix，即对请求url的两种使用正则的过滤规则，前者用于匹配二级域名，后者用于将不同路径的请求转发至不同服务。\n 这个正则配起来稍微有点小坑，哈哈。我研究了好久才搞明白要怎么写。\n 为了对Host和Path使用正则表达式，需要声明一个任意命名的变量，然后跟上用冒号分隔的正则表达式，所有这些都用花括号括起来。\n示例：HostRegexp(`grafana.{domain:.*}`)\n服务 服务负责配置如何到达实际的服务，最终将处理传入的请求。使用service定义：\nhttp: services: traefik: loadBalancer: servers: - url: \u0026#34;http://127.0.0.1:10000\u0026#34; 我们将上面开启的Traefik的监控面板作为服务封装了起来，只要路由到traefik这个服务上，即可访问监控面板。\n在这里也可以实现负载均衡等功能，可以参照官网介绍\n开机启动  有了上次部署Nginx的经验，这里我们完全采用Systemd来管理。即，使用systemctl命令来管理服务。\n 原理 Systemd默认从目录/etc/systemd/system/读取配置文件。但是，里面存放的大部分文件都是符号链接，指向目录/usr/lib/systemd/system/，真正的配置文件存放在那个目录\nsystemctl enable命令用于在上面两个目录之间，建立符号链接关系。\nsystemctl enable traefik.service # 等同于 ln -s \u0026#39;/usr/lib/systemd/system/traefik.service\u0026#39; \u0026#39;/etc/systemd/system/multi-user.target.wants/traefik.service\u0026#39; Unit配置文件 下面是Traefik源码仓库中给出的traefik.service 示例，其中有几个需要注意的点：\n Type：程序启动方式 ExecStart：程序运行的命令，在这里直接指向程序本身 WatchdogSec：程序检测时间  [Unit] Description=Traefik instance Documentation=https://doc.traefik.io Wants=network-online.target [Service] Environment=\u0026#34;ACME_DNS_API_BASE=https://auth.acme-dns.io\u0026#34; \u0026#34;ACME_DNS_STORAGE_PATH=/etc/traefik/acme/dns.json\u0026#34; # Run traefik as its own user (create new user with: groupadd traefik \u0026amp;\u0026amp; useradd -g traefik traefik -s /sbin/nologin) # User=traefik # Group=traefik Type=simple Restart=on-failure ExecStart=/usr/sbin/traefik-lb WatchdogSec=10s RestartSec=10s [Install] WantedBy=multi-user.target 作为服务开启 systemctil start traefik.service 设置开机启动 systemctil enable traefik.service 查看运行状态 systemctil status traefik.service 文件汇总 root ├─ etc │\t└─ traefik │\t├─ access.log // 访问日志 │\t├─ dynamic_conf // 动态配置存放文件夹 │\t│\t└─ dynamic_conf.yml // 动态配置文件 │\t├─ traefik.log // 程序日志 │\t└─ traefik.yml // 静态配置文件 └─ usr └─ local └─ bin └─ traefik // 程序本身 静态配置 ## Static configuration entryPoints: web: address: \u0026#34;:80\u0026#34; websecure: address: \u0026#34;:443\u0026#34; traefik: address: \u0026#34;:10000\u0026#34; metrics: address: \u0026#34;:8082\u0026#34; # 动态配置的配置 providers: file: directory: /etc/traefik/dynamic-conf watch: true # API api: insecure: true # 运行日志 log: filePath: /etc/traefik/traefik.log format: json level: ERROR # 访问日志 accessLog: filePath: /etc/traefik/access.log format: json # 监控 metrics: prometheus: addRoutersLabels: true entryPoint: metrics 动态配置 ## Dynamic configuration http: routers: router-traefik: rule: HostRegexp(`traefik.{domain:.*}`) service: traefik router-grafana: rule: HostRegexp(`grafana.{domain:.*}`) service: grafana router-prometheus: rule: HostRegexp(`prometheus.{domain:.*}`) service: prometheus services: traefik: loadBalancer: servers: - url: \u0026#34;http://127.0.0.1:10000\u0026#34; grafana: loadBalancer: servers: - url: \u0026#34;http://127.0.0.1:3000\u0026#34; prometheus: loadBalancer: servers: - url: \u0026#34;http://127.0.0.1:9090\u0026#34;  至此，我们已经配置完成了Traefik的基础功能，实现了路由，日志，开机启动等功能\n  中间件  从图中基本可以明白中间件的作用，也可以理解成拦截器，亦或者是类似于Spring中的切面。\nTraefik中有几种可用的中间件：一些可以修改请求、请求头，一些负责重定向，一些可以添加身份验证等等。\n 中间件的配置格式类似于Service，大致是先定义，再使用。\n下面是一个官网给出的示例：\n# As YAML Configuration File http: routers: router1: service: myService middlewares: - \u0026#34;foo-add-prefix\u0026#34; rule: \u0026#34;Host(`example.com`)\u0026#34; middlewares: foo-add-prefix: addPrefix: prefix: \u0026#34;/foo\u0026#34; services: service1: loadBalancer: servers: - url: \u0026#34;http://127.0.0.1:80\u0026#34; 页面访问认证 由于Traefik的管理页面给有给出登录的功能，因此这里使用官方提供的BasicAuth中间件来实现访问认证的功能。\n定义权限认证中间件 定义名为traefik-auth的中间件：\n## Dynamic configuration http: # ... middlewares: traefik-auth: basicAuth: users: - \u0026#34;test:$apr1$cxKgflNX$3PWH2/iPEdZrBEWYGfSBm.\u0026#34; user下面的密码使用htpasswd生成\n给对应路由添加中间件 给路由添加中间件\n## Dynamic configuration http: routers: router-traefik: middlewares: - traefik-auth rule: Host(`traefik.ormissia.com`) service: traefik 这样在访问相应路由的时候会经过basicAuth的中间件，在浏览器弹出窗口输入之前使用htpasswd生成的用户名密码即可。\n配置获取免费证书 在这里我面选择让Traefik自动获取免费证书，并且申请泛域名的证书。\n端口重定向 将80端口的流量重定向到443端口，并开启http代理的tls\n## Static configuration entryPoints: web: address: \u0026#34;:80\u0026#34; http: redirections: entryPoint: to: websecure scheme: https websecure: address: \u0026#34;:443\u0026#34; http: tls: {} 这个时候我们将80代理到了443，因此访问页面会显示成这样：\n接下来我们给Traefik添加自动获取证书的功能\n开启ACME # certificate certificatesResolvers: myresolver: acme: email: example@email.com storage: /etc/traefik/acme/acme.json dnsChallenge: provider: acme-dns 这里面有三个属性是必填的：\n email：邮箱 storage：证书存储文件 dnsChallenge：由于我们选择申请泛域名的证书，目前只有dnsChallenge支持申请泛域名。  storage 创建一个文件，权限必须是600，里面主要用来存证书的信息，信息格式为json。\ncd /etc/traefik/acme/ touch acme.json \u0026amp;\u0026amp; chmod 600 acme.json dnsChallenge dnsChallenge支持各种不同的provider，具体可以参考官网介绍，这里就不再贴了。\n如果自己的域名在表格中有对应的云厂商，可以使用对应的provider。这里虽然我使用的这个域名是阿里云上的，只是感觉创建token或者RAM账户有点难于管理，而且要设置一些权限等等。 因此这里我选择了通用的方式，使用acme-dns作为provider。\n使用acme-dns作为provider，需要添加两个环境变量：\n ACME_DNS_API_BASE：这里我使用了acme-dns官方提供的地址-https://auth.acme-dns.io ACME_DNS_STORAGE_PATH：这个文件存储了从上一个url中获取的DNS信息，需要手动创建一下  由于未知原因，这里我在/etc/profile中添加对应环境变量并且使用source编译之后，Traefik运行时候未能正确读取到，因此我选择将两个变量写入systemd的配置文件中：\nvi /usr/lib/systemd/system/traefik.service [Unit] # ... [Service] Environment=\u0026#34;ACME_DNS_API_BASE=https://auth.acme-dns.io\u0026#34; \u0026#34;ACME_DNS_STORAGE_PATH=/etc/traefik/acme/dns.json\u0026#34; # ... [Install] # ... 直接在服务的配置文件中添加，这样在Traefik启动的时候就能正确读取到两个环境变量了。\n添加CNAME解析 当完成上面的配置之后，运行一下Traefik之后，/etc/traefik/acme/dns.json会获得对应信息：\n{ \u0026#34;ormissia.com\u0026#34;:{ \u0026#34;fulldomain\u0026#34;:\u0026#34;123.auth.acme-dns.io\u0026#34;, \u0026#34;subdomain\u0026#34;:\u0026#34;123\u0026#34;, \u0026#34;username\u0026#34;:\u0026#34;123\u0026#34;, \u0026#34;password\u0026#34;:\u0026#34;123\u0026#34;, \u0026#34;server_url\u0026#34;:\u0026#34;https://auth.acme-dns.io\u0026#34; } } 取fulldomain的值，到自己的域名管理添加一条CNAME类型的解析：_acme-challenge.ormissia.com指向上面得到的fulldomain的值即可。\n等待片刻执行下面命令查看解析是否成功：\ndig _acme-challenge.ormissia.com 可以看到返回值中有这样一行：\n;; ANSWER SECTION: _acme-challenge.ormissia.com. 600 IN\tCNAME\t123.auth.acme-dns.io. 即代表解析成功。\n重启Traefik之后，刷新页面，即可以从浏览器中看到证书获取成功。\nKubernetes部署脚本 RBAC # rbac.yml --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: traefik-ingress-controller rules: - apiGroups: - \u0026#34;\u0026#34; resources: - services - endpoints - secrets verbs: - get - list - watch - apiGroups: - extensions - networking.k8s.io resources: - ingresses - ingressclasses verbs: - get - list - watch - apiGroups: - extensions resources: - services - endpoints - ingresses/status verbs: - update - get - list - watch --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: traefik-ingress-controller roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: traefik-ingress-controller subjects: - kind: ServiceAccount name: traefik-ingress-controller namespace: kube-basic Deployment\u0026amp;Service # traefik.yml apiVersion: v1 kind: ServiceAccount metadata: name: traefik-ingress-controller --- kind: Deployment apiVersion: apps/v1 metadata: name: traefik labels: app: traefik spec: replicas: 3 selector: matchLabels: app: traefik template: metadata: labels: app: traefik spec: serviceAccountName: traefik-ingress-controller affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - podAffinityTerm: topologyKey: kubernetes.io/hostname labelSelector: matchExpressions: - key: app operator: In values: - traefik weight: 100 containers: - name: traefik image: traefik ports: - name: web containerPort: 80 resources: limits: cpu: 20m memory: 150Mi requests: cpu: 5m memory: 70Mi args: - --entrypoints.web.address=:80 - --entrypoints.web.http.redirections.entryPoint.to=websecure - --entrypoints.web.http.redirections.entryPoint.scheme=https - --entrypoints.websecure.address=:443 - --providers.kubernetesingress - --providers.kubernetesingress.namespaces=kube-basic,kubernetes-dashboard - --log.level=INFO - --accesslog - --api.insecure=true - --pilot.token=1f36db5d-9f2c-42da-8737-4cf8979de6a4 --- apiVersion: v1 kind: Service metadata: name: traefik spec: type: NodePort selector: app: traefik ports: - protocol: TCP port: 80 name: web targetPort: 80 nodePort: 30000 - protocol: TCP port: 8080 name: admin targetPort: 8080 nodePort: 30001 Ingress # ingress.yml kind: Ingress apiVersion: networking.k8s.io/v1 metadata: name: whoami-ingress annotations: traefik.ingress.kubernetes.io/router.entrypoints: web spec: rules: - host: traefik.ormissia.com http: paths: - path: / pathType: Prefix backend: service: name: traefik port: number: 8080 参考链接  Traefik源码仓库 Traefik官网 Traefik静态配置项-File provider Let\u0026rsquo;s Encrypt Systemd文档  ","date":"October 9, 2021","hero":"/posts/deployment/3003-linux-traefik/head.png","permalink":"https://ormissia.github.io/posts/deployment/3003-linux-traefik/","summary":"Traefik is an open-source Edge Router that makes publishing your services a fun and easy experience. It receives requests on behalf of your system and finds out which components are responsible for handling them. What sets Traefik apart, besides its many features, is that it automatically discovers the right configuration for your services. The magic happens when Traefik inspects your infrastructure, where it finds relevant information and discovers which service serves which request.","tags":null,"title":"Traefik部署流程"},{"categories":null,"contents":"安装依赖 编译工具及库文件 yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 安装PCRE  PCRE作用是让Nginx支持Rewrite功能\n PCRE安装包下载地址： https://sourceforge.net/projects/pcre/files/pcre/\n选择对应版本下载即可\n下载PCRE安装包 cd /usr/local/src/ wget http://downloads.sourceforge.net/project/pcre/pcre/8.45/pcre-8.45.tar.gz 解压安装包并进入目录 tar -zxvf pcre-8.45.tar.gz cd pcre-8.45 编译安装 ./configure make \u0026amp;\u0026amp; make install 验证安装 pcre-config --version 可能遇到的问题 安装完成之后有可能找不到命令，查看编译安装时的默认安装目录，将其添加到Linux环境变量PATH即可\n创建管理Nginx的用户和组  创建nginx运行用户nginx并加入到nginx组，不允许nginx用户直接登录系统\n groupadd nginx useradd -g nginx nginx -s /sbin/nologin 安装Nginx 下载安装包 Nginx下载地址： http://nginx.org/en/download.html\n没有特殊需求的话，选择Stable version稳定版下载即可\ncd /usr/local/src/ wget http://nginx.org/download/nginx-1.20.1.tar.gz 解压安装包并进入目录 tar -zxvf nginx-1.20.1 cd nginx-1.20.1 编译安装 ./configure \\ --prefix=/usr/local/nginx \\ --user=nginx --group=nginx \\ --pid-path=/var/run/nginx/nginx.pid \\ --lock-path=/var/lock/nginx.lock \\ --error-log-path=/var/log/nginx/error.log \\ --http-log-path=/var/log/nginx/access.log \\ --with-http_gzip_static_module \\ --http-client-body-temp-path=/var/temp/nginx/client \\ --http-proxy-temp-path=/var/temp/nginx/proxy \\ --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \\ --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \\ --http-scgi-temp-path=/var/temp/nginx/scgi \\ --with-http_stub_status_module \\ --with-http_ssl_module \\ --with-http_realip_module make \u0026amp;\u0026amp; make install 优化Nginx程序的执行路径 添加软连接到环境变量PATH目录下\nln -s /usr/local/nginx/sbin/nginx /usr/local/sbin/ 添加软连接之后即可直接使用nginx命令启动操作Nginx\nnginx nginx -s reload #重启（修改配置文件后重新加载等） nginx -s quit #退出（处理完所有请求后结束进程） nginx -s stop #停止（直接结束进程） 测试安装 nginx -t 如果报错，一般是缺少配置路径中的文件夹，使用mkdir -p创建即可\n修改之后，正常的提示为：\nnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful 配置开机启动 创建启动脚本 vi /etc/init.d/nginx 脚本内容：\n 我这里是修改过的，也可以去官网复制。官网脚本连接\n 要注意从官网直接复制的需要修改几处地方，否则运行报错。\n nginx变量的值要改成nginx程序的实际安装路径 NGINX_CONF_FILE变量的值要改成nginx配置文件的路径 lockfile变量的值要改成实际的lockfile文件路径  #!/bin/sh # # nginx - this script starts and stops the nginx daemon # # chkconfig: - 85 15 # description: NGINX is an HTTP(S) server, HTTP(S) reverse \\ # proxy and IMAP/POP3 proxy server # processname: nginx # config: /etc/nginx/nginx.conf # config: /etc/sysconfig/nginx # pidfile: /var/run/nginx.pid # Source function library. . /etc/rc.d/init.d/functions # Source networking configuration. . /etc/sysconfig/network # Check that networking is up. [ \u0026#34;$NETWORKING\u0026#34; = \u0026#34;no\u0026#34; ] \u0026amp;\u0026amp; exit 0 nginx=\u0026#34;/usr/local/nginx/sbin/nginx\u0026#34; prog=$(basename $nginx) NGINX_CONF_FILE=\u0026#34;/usr/local/nginx/conf/nginx.conf\u0026#34; [ -f /etc/sysconfig/nginx ] \u0026amp;\u0026amp; . /etc/sysconfig/nginx lockfile=/var/lock/nginx.lock make_dirs() { # make required directories user=`$nginx -V 2\u0026gt;\u0026amp;1 | grep \u0026#34;configure arguments:.*--user=\u0026#34; | sed \u0026#39;s/[^*]*--user=\\([^ ]*\\).*/\\1/g\u0026#39; -` if [ -n \u0026#34;$user\u0026#34; ]; then if [ -z \u0026#34;`grep $user/etc/passwd`\u0026#34; ]; then useradd -M -s /bin/nologin $user fi options=`$nginx -V 2\u0026gt;\u0026amp;1 | grep \u0026#39;configure arguments:\u0026#39;` for opt in $options; do if [ `echo $opt | grep \u0026#39;.*-temp-path\u0026#39;` ]; then value=`echo $opt | cut -d \u0026#34;=\u0026#34; -f 2` if [ ! -d \u0026#34;$value\u0026#34; ]; then # echo \u0026#34;creating\u0026#34; $value mkdir -p $value \u0026amp;\u0026amp; chown -R $user $value fi fi done fi } start() { [ -x $nginx ] || exit 5 [ -f $NGINX_CONF_FILE ] || exit 6 make_dirs echo -n $\u0026#34;Starting $prog: \u0026#34; daemon $nginx -c $NGINX_CONF_FILE retval=$? echo [ $retval -eq 0 ] \u0026amp;\u0026amp; touch $lockfile return $retval } stop() { echo -n $\u0026#34;Stopping $prog: \u0026#34; killproc $prog -QUIT retval=$? echo [ $retval -eq 0 ] \u0026amp;\u0026amp; rm -f $lockfile return $retval } restart() { configtest || return $? stop sleep 1 start } reload() { configtest || return $? echo -n $\u0026#34;Reloading $prog: \u0026#34; killproc $prog -HUP retval=$? echo } force_reload() { restart } configtest() { $nginx -t -c $NGINX_CONF_FILE } rh_status() { status $prog } rh_status_q() { rh_status \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 } case \u0026#34;$1\u0026#34; in start) rh_status_q \u0026amp;\u0026amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart|configtest) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $\u0026#34;Usage: $0{start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest}\u0026#34; exit 2 esac 修改脚本权限 cd /etc/init.d/ chmod 755 nginx  这个脚本可用来直接操作Nginx，直接执行脚本会提示需要输入\n 将Nginx加入到系统服务中 chkconfig --add nginx 设为开机启动 chkconfig nginx on  重启系统后生效\n 重启后，即可使用systemctl命令管理nginx服务\nsystemctl status nginx.service systemctl start nginx.service systemctl stop nginx.service 可能遇到的问题 如果使用 命令查看nginx服务状态时的提示：\n● nginx.service - SYSV: NGINX is an HTTP(S) server, HTTP(S) reverse proxy and IMAP/POP3 proxy server Loaded: loaded (/etc/rc.d/init.d/nginx; generated) Active: inactive (dead) Docs: man:systemd-sysv-generator(8) 是因为系统安装了httpd，卸载即可\nyum remove httpd -y 验证安装 执行\ncurl 127.0.0.1 从返回结果中可以看到，成功拿到Nginx的默认页面了，安装成功\n也可以在外网通过服务IP访问，需要注意Linux防火墙、云服务器出站入站规则等限制\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;If you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;For online documentation and support please refer to \u0026lt;a href=\u0026#34;http://nginx.org/\u0026#34;\u0026gt;nginx.org\u0026lt;/a\u0026gt;.\u0026lt;br/\u0026gt; Commercial support is available at \u0026lt;a href=\u0026#34;http://nginx.com/\u0026#34;\u0026gt;nginx.com\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ","date":"October 8, 2021","hero":"/posts/deployment/3002-linux-nginx/head.svg","permalink":"https://ormissia.github.io/posts/deployment/3002-linux-nginx/","summary":"安装依赖 编译工具及库文件 yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 安装PCRE  PCRE作用是让Nginx支持Rewrite功能\n PCRE安装包下载地址： https://sourceforge.net/projects/pcre/files/pcre/\n选择对应版本下载即可\n下载PCRE安装包 cd /usr/local/src/ wget http://downloads.sourceforge.net/project/pcre/pcre/8.45/pcre-8.45.tar.gz 解压安装包并进入目录 tar -zxvf pcre-8.45.tar.gz cd pcre-8.45 编译安装 ./configure make \u0026amp;\u0026amp; make install 验证安装 pcre-config --version 可能遇到的问题 安装完成之后有可能找不到命令，查看编译安装时的默认安装目录，将其添加到Linux环境变量PATH即可\n创建管理Nginx的用户和组  创建nginx运行用户nginx并加入到nginx组，不允许nginx用户直接登录系统\n groupadd nginx useradd -g nginx nginx -s /sbin/nologin 安装Nginx 下载安装包 Nginx下载地址： http://nginx.org/en/download.html\n没有特殊需求的话，选择Stable version稳定版下载即可\ncd /usr/local/src/ wget http://nginx.org/download/nginx-1.20.1.tar.gz 解压安装包并进入目录 tar -zxvf nginx-1.20.1 cd nginx-1.20.1 编译安装 .","tags":null,"title":"Linux部署Nginx流程"},{"categories":null,"contents":" #hadoop #hdfs\n HDFS架构  HDFS是一个主从（Master/Slaves）架构 由一个NameNode和一些DataNode组成 面向文件包含：文件元数据（metadata）和文件数据（data） NameNode负责存储和管理文件元数据，并维护了一个层次型的文件目录树 DataNode负责存储文件数据（block块），并提供block的读写 DataNode与NameNode维持心跳，并汇报自己持有的block信息 Client和NameNode交互文件元数据和DataNode交互文件block数据  目录树结构 角色即进程\nHadoop集群中HDFS节点角色 Master Standy ","date":"September 24, 2021","hero":"/posts/knowledge/2006-hadoop/2007-hadoop-hdfs/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2006-hadoop/2007-hadoop-hdfs/","summary":" #hadoop #hdfs\n HDFS架构  HDFS是一个主从（Master/Slaves）架构 由一个NameNode和一些DataNode组成 面向文件包含：文件元数据（metadata）和文件数据（data） NameNode负责存储和管理文件元数据，并维护了一个层次型的文件目录树 DataNode负责存储文件数据（block块），并提供block的读写 DataNode与NameNode维持心跳，并汇报自己持有的block信息 Client和NameNode交互文件元数据和DataNode交互文件block数据  目录树结构 角色即进程\nHadoop集群中HDFS节点角色 Master Standy ","tags":null,"title":"HDFS基础知识"},{"categories":null,"contents":" 结合上次Golang服务内存增长的分析，近期线上多个服务出现内存持续增长的问题，就这个现象分析一下Prometheus+Grafana的监控问题\n  #kubernetes #k8s #内存分析 #oom #golang #grafana\n 问题现象 近期在Grafana上显示生产环境多个服务出现内存持续增长的问题，有Golang的服务，也有JAVA的服务。都是服务重启之后，内存来到一个最低水平， 随着服务运行时间增长，pod的内存占用也随之水涨船高。直到内存占用增长到pod限制的上限附近，内存才出现回收的迹象，并且回收幅度不是特别明显， 但同时又不会出现OOM。\n  Golang某个服务内存占用情况   JAVA某个服务内存占用情况   简单分析 记一次线上的内存持续增长问题\n↑这个是初次遇到这个问题时候的分析，当时以为是代码写的有漏洞，程序发生了内存泄漏。于是祭出了pprof分析了一顿，结果可想而知，当然是没看出有问题。\n现在是多个服务都出现类似问题，那这个情况相对也就比较值得重视了。之前那个服务是因为日志写的比较多，造成磁盘IO比较大。同样的， 近期发现的这几个内存持续不断增长的服务也都是日志量比较大的。\n进一步分析 集群日志架构 所有pod中的日志都是写入挂载到/data/log目录的物理机磁盘中，因此所有写日志的操作都会有磁盘IO。日志量越大的pod，磁盘IO相应地也越高。\n集群监控 普通pod监控采用了常见的Prometheus+Grafana的方案。\n数据源计算方式 监控数据是采集的kubernetes中监控程序cadvisor上报的container_memory_working_set_bytes字段（ 表格参照 ）\n查看cadvisor源码中setMemoryStats 可知，container_memory_working_set_bytes字段是cgroup memory.usage_in_bytes（RSS + Cache）与memory.stat total_inactive_file二者的差值\nfunc setMemoryStats(s *cgroups.Stats, ret *info.ContainerStats) { // ...  // ...  inactiveFileKeyName := \u0026#34;total_inactive_file\u0026#34; if cgroups.IsCgroup2UnifiedMode() { inactiveFileKeyName = \u0026#34;inactive_file\u0026#34; } workingSet := ret.Memory.Usage if v, ok := s.MemoryStats.Stats[inactiveFileKeyName]; ok { if workingSet \u0026lt; v { workingSet = 0 } else { workingSet -= v } } ret.Memory.WorkingSet = workingSet } 而memory.usage_in_bytes的统计数据是包含了所有的file cache的，total_active_file和total_inactive_file都属于file cache的一部分， 但是这两个数据并不是Pod中的程序真正占用的内存，只是系统为了提高磁盘IO的效率，将读写过的文件缓存在内存中。file cache并不会随着进程退出而释放，只会当容器销毁或者系统内存不足时才会由系统自动回收。\n所以cadvisor采用memory.usage_in_bytes - total_inactive_file计算出的结果并不是当前Pod中程序所占用的内存，当Pod内存资源紧张时total_active_file也是可回收利用的。\n验证结论 准备环境 去测试环境找到一个服务重启一下，并进入容器命令行\n准备一个较大的文件 找一个比较大的文件，这里找了一个8M左右的日志文件\n/app # ls -lah /data/log/xxxx.log -rw-r--r-- 1 root root 8.2M May 31 10:54 /data/log/xxxx.log 查看内存数据 在容器中进入/sys/fs/cgroup/memory/目录，并查看cat memory.stat内容\n/app # cd /sys/fs/cgroup/memory/ /sys/fs/cgroup/memory # cat memory.stat cache 38195200 rss 13484032 rss_huge 0 mapped_file 495616 swap 0 pgpgin 1550811 pgpgout 1538194 pgfault 1512338 pgmajfault 36 inactive_anon 0 active_anon 13422592 inactive_file 12058624 active_file 26136576 unevictable 0 hierarchical_memory_limit 314572800 hierarchical_memsw_limit 314572800 total_cache 38195200 total_rss 13484032 total_rss_huge 0 total_mapped_file 495616 total_swap 0 total_pgpgin 1550811 total_pgpgout 1538194 total_pgfault 1512338 total_pgmajfault 36 total_inactive_anon 0 total_active_anon 13422592 total_inactive_file 12058624 total_active_file 26136576 total_unevictable 0 记录此时\ntotal_inactive_file 12058624 Bytes = 11.5M\ntotal_active_file 26136576 Bytes = 24.9M\n遍历日志文件 /sys/fs/cgroup/memory # grep \u0026#34;hello\u0026#34; /data/log/xxx.log 第二次查看内存 /sys/fs/cgroup/memory # cat memory.stat  cache 46850048 rss 13500416 rss_huge 0 mapped_file 495616 swap 0 pgpgin 1552994 pgpgout 1538260 pgfault 1512642 pgmajfault 36 inactive_anon 0 active_anon 13459456 inactive_file 20709376 active_file 26140672 unevictable 0 hierarchical_memory_limit 314572800 hierarchical_memsw_limit 314572800 total_cache 46850048 total_rss 13500416 total_rss_huge 0 total_mapped_file 495616 total_swap 0 total_pgpgin 1552994 total_pgpgout 1538260 total_pgfault 1512642 total_pgmajfault 36 total_inactive_anon 0 total_active_anon 13459456 total_inactive_file 20709376 total_active_file 26140672 total_unevictable 0 记录此时\ntotal_inactive_file 20709376 Bytes = 19.6M\ntotal_active_file 26140672 Bytes = 24.9M\n此时total_inactive_file占用较上次增加大约8M左右，即遍历过的日志文件的大小。\n第二次遍历日志文件 对同一个文件第二次遍历访问\n/sys/fs/cgroup/memory # grep \u0026#34;hello\u0026#34; /data/log/xxx.log 第三次查看内存 /sys/fs/cgroup/memory # cat memory.stat  cache 46850048 rss 13504512 rss_huge 0 mapped_file 495616 swap 0 pgpgin 1553058 pgpgout 1538323 pgfault 1512941 pgmajfault 36 inactive_anon 0 active_anon 13459456 inactive_file 12025856 active_file 34824192 unevictable 0 hierarchical_memory_limit 314572800 hierarchical_memsw_limit 314572800 total_cache 46850048 total_rss 13504512 total_rss_huge 0 total_mapped_file 495616 total_swap 0 total_pgpgin 1553058 total_pgpgout 1538323 total_pgfault 1512941 total_pgmajfault 36 total_inactive_anon 0 total_active_anon 13459456 total_inactive_file 12025856 total_active_file 34824192 total_unevictable 0 记录此时\ntotal_inactive_file 12025856 Bytes = 11.5M\ntotal_active_file 34824192 Bytes = 33.2M\n此时total_inactive_file较上次减少8M，而total_active_file较上次增加8M\n查看Grafana   遍历日志文件之前   遍历日志文件之后   此时查看对应服务的Grafana面板可以看到，使用shell的grep命令遍历一个8M多的文件之后，在Pod中内存占用上升了大概8M。 而此时这块内存并没有被Pod中任何程序所引用，只是一个file cache的占用。\n总结 根据上述实验结果可以印证内存持续增长但不会OOM的现象。服务启动并向磁盘中持续追加日志文件，随之file cache持续上涨，直至达到Pod的内存上限之后，会出现GC。\n结论 memory.usage_in_bytes统计包含了Cached和Buffers，Cached中除了mlock_file和Shmem（IPCS shared memory \u0026amp; tmpfs）外， 其他部分file cache是可以回收使用的，Buffers也是可以回收利用的，所以Pod容器所在cgroup实际使用的内存计算公式可以转化为 (因memory.stat未导出SReclaimable，这里忽略SReclaimable)：\nreal_used = memory.usage_in_bytes – (Cached- Shmem - mlock_file + Buffers ) = memory.usage_in_bytes – memory.stat.total_active_file 因此cadvisor中container_memory_working_set_bytes字段在计算实际已使用内存时应该改为：\nreal_used = memory.usage_in_bytes – memory.stat.total_active_file 但是 过程中去kubernetes 的issue 中逛了一圈，发现了几个相关问题的讨论：\n https://github.com/kubernetes/kubernetes/issues/43916 https://github.com/kubernetes/kubernetes/issues/104533  其中一个给我笑出声\nkubernetes should not count active_file as used memory, I have been waiting for 4 years!\n等了四年了，这个问题还没有解决。也许，我们从一开始就错了？缓存也应该算是pod内存占用？\n参考  https://lwn.net/Articles/432224/  ","date":"September 22, 2021","hero":"/posts/problems/5002-k8s-memory/head.svg","permalink":"https://ormissia.github.io/posts/problems/5002-k8s-memory/","summary":"结合上次Golang服务内存增长的分析，近期线上多个服务出现内存持续增长的问题，就这个现象分析一下Prometheus+Grafana的监控问题\n  #kubernetes #k8s #内存分析 #oom #golang #grafana\n 问题现象 近期在Grafana上显示生产环境多个服务出现内存持续增长的问题，有Golang的服务，也有JAVA的服务。都是服务重启之后，内存来到一个最低水平， 随着服务运行时间增长，pod的内存占用也随之水涨船高。直到内存占用增长到pod限制的上限附近，内存才出现回收的迹象，并且回收幅度不是特别明显， 但同时又不会出现OOM。\n  Golang某个服务内存占用情况   JAVA某个服务内存占用情况   简单分析 记一次线上的内存持续增长问题\n↑这个是初次遇到这个问题时候的分析，当时以为是代码写的有漏洞，程序发生了内存泄漏。于是祭出了pprof分析了一顿，结果可想而知，当然是没看出有问题。\n现在是多个服务都出现类似问题，那这个情况相对也就比较值得重视了。之前那个服务是因为日志写的比较多，造成磁盘IO比较大。同样的， 近期发现的这几个内存持续不断增长的服务也都是日志量比较大的。\n进一步分析 集群日志架构 所有pod中的日志都是写入挂载到/data/log目录的物理机磁盘中，因此所有写日志的操作都会有磁盘IO。日志量越大的pod，磁盘IO相应地也越高。\n集群监控 普通pod监控采用了常见的Prometheus+Grafana的方案。\n数据源计算方式 监控数据是采集的kubernetes中监控程序cadvisor上报的container_memory_working_set_bytes字段（ 表格参照 ）\n查看cadvisor源码中setMemoryStats 可知，container_memory_working_set_bytes字段是cgroup memory.usage_in_bytes（RSS + Cache）与memory.stat total_inactive_file二者的差值\nfunc setMemoryStats(s *cgroups.Stats, ret *info.ContainerStats) { // ...  // ...  inactiveFileKeyName := \u0026#34;total_inactive_file\u0026#34; if cgroups.IsCgroup2UnifiedMode() { inactiveFileKeyName = \u0026#34;inactive_file\u0026#34; } workingSet := ret.Memory.Usage if v, ok := s.","tags":null,"title":"Grafana上监控kubernetes中Pod已用内存不准问题分析"},{"categories":null,"contents":" #hadoop\n  最近在学习大数据相关的东西，看了HDFS，Hive，HBas，Spark相关的东西，总结一下Hadoop生态中常见的组件。\n HDFS（hadoop分布式文件系统） HDFS是hadoop体系中数据存储管理的基础。他是一个高度容错的系统，能检测和应对硬件故障。\n有以下几个角色：\n  client：切分文件，访问HDFS，与那么弄得交互，获取文件位置信息，与DataNode交互，读取和写入数据。\n  namenode：master节点，在hadoop1.x中只有一个，管理HDFS的名称空间和数据块映射信息，配置副本策略，处理客户 端请求。\n  DataNode：slave节点，存储实际的数据，汇报存储信息给namenode。\n  secondary namenode：辅助namenode，分担其工作量：定期合并fsimage和fsedits，推送给namenode；紧急情况下和辅助恢复namenode，但其并非namenode的热备。\n  mapreduce（分布式计算框架） mapreduce是一种计算模型，用于处理大数据量的计算。其中map对应数据集上的独立元素进行指定的操作，生成键-值对形式中间，reduce则对中间结果中相同的键的所有值进行规约，以得到最终结果。\n  jobtracker：master节点，只有一个，管理所有作业，任务/作业的监控，错误处理等，将任务分解成一系列任务，并分派给tasktracker。\n  tacktracker：slave节点，运行 map task和reducetask；并与jobtracker交互，汇报任务状态。\n  map task：解析每条数据记录，传递给用户编写的map（）并执行，将输出结果写入到本地磁盘（如果为map—only作业，则直接写入HDFS）。\n  reduce task：从map 它深刻地执行结果中，远程读取输入数据，对数据进行排序，将数据分组传递给用户编写的reduce函数执行。\n  hive（基于hadoop的数据仓库） 由Facebook开源，最初用于解决海量结构化的日志数据统计问题。\nhive定于了一种类似sql的查询语言（hql）将sql转化为mapreduce任务在hadoop上执行。\nhbase（分布式列存数据库） hbase是一个针对结构化数据的可伸缩，高可靠，高性能，分布式和面向列的动态模式数据库。和传统关系型数据库不同，hbase采用了bigtable的数据模型： 增强了稀疏排序映射表（key/value）。其中，键由行关键字，列关键字和时间戳构成，hbase提供了对大规模数据的随机，实时读写访问，同时，hbase中保 存的数据可以使用mapreduce来处理，它将数据存储和并行计算完美结合在一起。\nzookeeper（分布式协作服务） 解决分布式环境下的数据管理问题：统一命名，状态同步，集群管理，配置同步等。\nsqoop（数据同步工具） sqoop是sql-to-hadoop的缩写，主要用于传统数据库和hadoop之间传输数据。数据的导入和导出本质上是mapreduce程序，充分利用了MR的并行化和容错性。\npig（基于hadoop的数据流系统） 定义了一种数据流语言-pig latin，将脚本转换为mapreduce任务在hadoop上执行。通常用于离线分析。\nmahout（数据挖掘算法库） mahout的主要目标是创建一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建只能应用程序。mahout现在已经包含了聚类，分类， 推荐引擎（协同过滤）和频繁集挖掘等广泛使用的数据挖掘方法。除了算法是，mahout还包含了数据的输入/输出工具，与其他存储系统（如数据库，mongoDB或 Cassandra）集成等数据挖掘支持架构。\nflume（日志收集工具） cloudera开源的日志收集系统，具有分布式，高可靠，高容错，易于定制和扩展的特点。他将数据从产生，传输，处理并写入目标的路径的过程抽象为数据流，在 具体的数据流中，数据源支持在flume中定制数据发送方，从而支持收集各种不同协议数据。\n资源管理器的简单介绍（YARN和mesos） 随着互联网的高速发展，基于数据 密集型应用 的计算框架不断出现，从支持离线处理的mapreduce，到支持在线处理的storm，从迭代式计算框架到 流式处理框 架s4，\u0026hellip;，在大部分互联网公司中，这几种框架可能都会采用，比如对于搜索引擎公司，可能的技术方法如下：网页建索引采用mapreduce框架，自然语言处理/ 数据挖掘采用spark，对性能要求到的数据挖掘算法用mpi等。公司一般将所有的这些框架部署到一个公共的集群中，让它们共享集群的资源，并对资源进行统一使 用，这样便诞生了资源统一管理与调度平台，典型的代表是mesos和yarn。\n其他的一些开源组件： cloudrea impala： 一个开源的查询引擎。与hive相同的元数据，SQL语法，ODBC驱动程序和用户接口，可以直接在HDFS上提供快速，交互式SQL查询。impala不再使用缓慢的 hive+mapreduce批处理，而是通过与商用并行关系数据库中类似的分布式查询引擎。可以直接从HDFS或者Hbase中用select，join和统计函数查询数据，从而 大大降低延迟。\nspark： spark是个开源的数据 分析集群计算框架，最初由加州大学伯克利分校AMPLab，建立于HDFS之上。spark与hadoop一样，用于构建大规模，延迟低的数据分析 应用。spark采用Scala语言实现，使用Scala作为应用框架。\nspark采用基于内存的分布式数据集，优化了迭代式的工作负载以及交互式查询。\n与hadoop不同的是，spark与Scala紧密集成，Scala象管理本地collective对象那样管理分布式数据集。spark支持分布式数据集上的迭代式任务，实际上可 以在hadoop文件系统上与hadoop一起运行（通过YARN,MESOS等实现）。\nstorm storm是一个分布式的，容错的计算系统，storm属于流处理平台，多用于实时计算并更新数据库。storm也可被用于“连续计算”，对数据流做连续查询，在计算 时将结果一流的形式输出给用户。他还可被用于“分布式RPC”,以并行的方式运行昂贵的运算。\nkafka kafka是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的 网站中的所有动作流数据。 这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。 这些数据通常是由于吞吐量的要求 而通过处理日志和日志聚合来解决。 对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka的目的是通 过Hadoop的并行加载机制来统一线上和离线的消息处理，也是为了通过集群来提供实时的消息\n","date":"September 17, 2021","hero":"/posts/knowledge/2006-hadoop/001-env/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2006-hadoop/001-env/","summary":"#hadoop\n  最近在学习大数据相关的东西，看了HDFS，Hive，HBas，Spark相关的东西，总结一下Hadoop生态中常见的组件。\n HDFS（hadoop分布式文件系统） HDFS是hadoop体系中数据存储管理的基础。他是一个高度容错的系统，能检测和应对硬件故障。\n有以下几个角色：\n  client：切分文件，访问HDFS，与那么弄得交互，获取文件位置信息，与DataNode交互，读取和写入数据。\n  namenode：master节点，在hadoop1.x中只有一个，管理HDFS的名称空间和数据块映射信息，配置副本策略，处理客户 端请求。\n  DataNode：slave节点，存储实际的数据，汇报存储信息给namenode。\n  secondary namenode：辅助namenode，分担其工作量：定期合并fsimage和fsedits，推送给namenode；紧急情况下和辅助恢复namenode，但其并非namenode的热备。\n  mapreduce（分布式计算框架） mapreduce是一种计算模型，用于处理大数据量的计算。其中map对应数据集上的独立元素进行指定的操作，生成键-值对形式中间，reduce则对中间结果中相同的键的所有值进行规约，以得到最终结果。\n  jobtracker：master节点，只有一个，管理所有作业，任务/作业的监控，错误处理等，将任务分解成一系列任务，并分派给tasktracker。\n  tacktracker：slave节点，运行 map task和reducetask；并与jobtracker交互，汇报任务状态。\n  map task：解析每条数据记录，传递给用户编写的map（）并执行，将输出结果写入到本地磁盘（如果为map—only作业，则直接写入HDFS）。\n  reduce task：从map 它深刻地执行结果中，远程读取输入数据，对数据进行排序，将数据分组传递给用户编写的reduce函数执行。\n  hive（基于hadoop的数据仓库） 由Facebook开源，最初用于解决海量结构化的日志数据统计问题。\nhive定于了一种类似sql的查询语言（hql）将sql转化为mapreduce任务在hadoop上执行。\nhbase（分布式列存数据库） hbase是一个针对结构化数据的可伸缩，高可靠，高性能，分布式和面向列的动态模式数据库。和传统关系型数据库不同，hbase采用了bigtable的数据模型： 增强了稀疏排序映射表（key/value）。其中，键由行关键字，列关键字和时间戳构成，hbase提供了对大规模数据的随机，实时读写访问，同时，hbase中保 存的数据可以使用mapreduce来处理，它将数据存储和并行计算完美结合在一起。\nzookeeper（分布式协作服务） 解决分布式环境下的数据管理问题：统一命名，状态同步，集群管理，配置同步等。\nsqoop（数据同步工具） sqoop是sql-to-hadoop的缩写，主要用于传统数据库和hadoop之间传输数据。数据的导入和导出本质上是mapreduce程序，充分利用了MR的并行化和容错性。\npig（基于hadoop的数据流系统） 定义了一种数据流语言-pig latin，将脚本转换为mapreduce任务在hadoop上执行。通常用于离线分析。\nmahout（数据挖掘算法库） mahout的主要目标是创建一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建只能应用程序。mahout现在已经包含了聚类，分类， 推荐引擎（协同过滤）和频繁集挖掘等广泛使用的数据挖掘方法。除了算法是，mahout还包含了数据的输入/输出工具，与其他存储系统（如数据库，mongoDB或 Cassandra）集成等数据挖掘支持架构。\nflume（日志收集工具） cloudera开源的日志收集系统，具有分布式，高可靠，高容错，易于定制和扩展的特点。他将数据从产生，传输，处理并写入目标的路径的过程抽象为数据流，在 具体的数据流中，数据源支持在flume中定制数据发送方，从而支持收集各种不同协议数据。\n资源管理器的简单介绍（YARN和mesos） 随着互联网的高速发展，基于数据 密集型应用 的计算框架不断出现，从支持离线处理的mapreduce，到支持在线处理的storm，从迭代式计算框架到 流式处理框 架s4，\u0026hellip;，在大部分互联网公司中，这几种框架可能都会采用，比如对于搜索引擎公司，可能的技术方法如下：网页建索引采用mapreduce框架，自然语言处理/ 数据挖掘采用spark，对性能要求到的数据挖掘算法用mpi等。公司一般将所有的这些框架部署到一个公共的集群中，让它们共享集群的资源，并对资源进行统一使 用，这样便诞生了资源统一管理与调度平台，典型的代表是mesos和yarn。","tags":null,"title":"Hadoop生态组件"},{"categories":null,"contents":" #golang #oom #内存分析 #grafana #kubernetes #k8s\n 问题现象 前些天从Grafana上看到某一个pod内存涨上去就再没下来（从9/1~9/2之间的一个时间开始），并且看这个趋势涨上去就没有下来的意思。中间有几次pod重新发布 才导致内存恢复到一个比较低的水平，但内存依旧持续上涨。\n初步分析 初步推测大概率与日志有关，此次发版改动了日志输出格式，以及修改了日志没有写入磁盘的问题。\n先把服务稳住 由于清楚问题的大致方向，先将服务中几个打印log比较频繁的位置注释掉，在9/3~9/4之间的一个位置重新发布。从之后的趋势上可以看出，注释掉几个打印日志的 地方之后，内存增长速度明显放缓。\n至此，基本可以确认内存增长与日志相关。\n问题排查 猜测一 回头又捋了几遍代码，也没发现什么端倪。\n于是祭出pprof抓了一下内存分析了一通，依旧无果。\n可以看出，内存占用并没有多高。\n猜测二  在 Go1.12 以前，Go Runtime在Linux上使用的是MADV_DONTNEED策略，可以让RSS下降的比较快，就是效率差点。 在 Go1.12 及以后，Go Runtime专门针对其进行了优化，使用了更为高效的MADV_FREE策略。但这样子所带来的副作用就是RSS不会立刻下降， 要等到系统有内存压力了才会释放占用，RSS才会下降。  查看容器的 Linux 内核版本：\n# 查看命令 uname -a 课件容器版本为3.10.0，但MADV_FREE的策略改变，需要Linux内核在4.5及以上（详细可见go/issues/23687 ）， 因此可以排除。\n猜想三 通过top命令可以通过可以查看容器中程序的内存占用VSZ为711，无法查看RSS，关于RSS和VSZ的区别，可以参考RSS和VSZ\n容器内存判定是通过container_memory_working_set_bytes，而container_memory_working_set_bytes是由cadvisor提供的。\n原因 从cadvisor/issues/638 可得知container_memory_working_set_bytes指标的组 成实际上是RSS + Cache。而Cache高的情况，常见于进程有大量文件IO，占用Cache可能就会比较高，猜测也与Go版本、Linux 内核版本的Cache释放、回收方式有较大关系。 只要是涉及有大量文件IO的服务，基本上是这个问题的老常客了，写这类服务基本写一个中一个，因为这是一个混合问题，像其它单纯操作为主的业务服务就很 “正常”，不会出现内存居高不下。\n没多久看到烤鱼佬的一篇文章，与这个情况类似，他的解决办法也就是写了个脚本，\u0026ldquo;手动\u0026quot;HPA（其实也就是自动重启）。\n总结 虽然这问题时间跨度比较长，整体来讲都是阶段性排查，本质上可以说是对Kubernetes的不熟悉有关。但因为内存居高不下的可能性有很多种，要一个个排查。\n","date":"September 15, 2021","hero":"/posts/problems/5001-go-online-service-oom/head.svg","permalink":"https://ormissia.github.io/posts/problems/5001-go-online-service-oom/","summary":"#golang #oom #内存分析 #grafana #kubernetes #k8s\n 问题现象 前些天从Grafana上看到某一个pod内存涨上去就再没下来（从9/1~9/2之间的一个时间开始），并且看这个趋势涨上去就没有下来的意思。中间有几次pod重新发布 才导致内存恢复到一个比较低的水平，但内存依旧持续上涨。\n初步分析 初步推测大概率与日志有关，此次发版改动了日志输出格式，以及修改了日志没有写入磁盘的问题。\n先把服务稳住 由于清楚问题的大致方向，先将服务中几个打印log比较频繁的位置注释掉，在9/3~9/4之间的一个位置重新发布。从之后的趋势上可以看出，注释掉几个打印日志的 地方之后，内存增长速度明显放缓。\n至此，基本可以确认内存增长与日志相关。\n问题排查 猜测一 回头又捋了几遍代码，也没发现什么端倪。\n于是祭出pprof抓了一下内存分析了一通，依旧无果。\n可以看出，内存占用并没有多高。\n猜测二  在 Go1.12 以前，Go Runtime在Linux上使用的是MADV_DONTNEED策略，可以让RSS下降的比较快，就是效率差点。 在 Go1.12 及以后，Go Runtime专门针对其进行了优化，使用了更为高效的MADV_FREE策略。但这样子所带来的副作用就是RSS不会立刻下降， 要等到系统有内存压力了才会释放占用，RSS才会下降。  查看容器的 Linux 内核版本：\n# 查看命令 uname -a 课件容器版本为3.10.0，但MADV_FREE的策略改变，需要Linux内核在4.5及以上（详细可见go/issues/23687 ）， 因此可以排除。\n猜想三 通过top命令可以通过可以查看容器中程序的内存占用VSZ为711，无法查看RSS，关于RSS和VSZ的区别，可以参考RSS和VSZ\n容器内存判定是通过container_memory_working_set_bytes，而container_memory_working_set_bytes是由cadvisor提供的。\n原因 从cadvisor/issues/638 可得知container_memory_working_set_bytes指标的组 成实际上是RSS + Cache。而Cache高的情况，常见于进程有大量文件IO，占用Cache可能就会比较高，猜测也与Go版本、Linux 内核版本的Cache释放、回收方式有较大关系。 只要是涉及有大量文件IO的服务，基本上是这个问题的老常客了，写这类服务基本写一个中一个，因为这是一个混合问题，像其它单纯操作为主的业务服务就很 “正常”，不会出现内存居高不下。\n没多久看到烤鱼佬的一篇文章，与这个情况类似，他的解决办法也就是写了个脚本，\u0026ldquo;手动\u0026quot;HPA（其实也就是自动重启）。\n总结 虽然这问题时间跨度比较长，整体来讲都是阶段性排查，本质上可以说是对Kubernetes的不熟悉有关。但因为内存居高不下的可能性有很多种，要一个个排查。","tags":null,"title":"记一次线上的内存持续增长问题"},{"categories":null,"contents":" #golang #struct-tag #reflect\n  StructTag是写在结构体字段类型后面反引号中的内容，用来标记结构体中各字段的属性。\n  源码中对struct tag的解释：\n By convention, tag strings are a concatenation of optionally space-separated key:\u0026ldquo;value\u0026rdquo; pairs. Each key is a non-empty string consisting of non-control characters other than space (U+0020 ' \u0026lsquo;), quote (U+0022 \u0026lsquo;\u0026quot;'), and colon (U+003A \u0026lsquo;:'). Each value is quoted using U+0022 \u0026lsquo;\u0026quot;\u0026rsquo; characters and Go string literal syntax.\n  简单应用 最常见的，比如json的tag应用：\njson序列化和反序列化时候使用的key都是在struct字段上定义的\npackage main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; ) type User struct { ID int `json:\u0026#34;id\u0026#34;` Username string `json:\u0026#34;username\u0026#34;` Age int `json:\u0026#34;age\u0026#34;` Email string `json:\u0026#34;email\u0026#34;` } func main() { u := User{ ID: 1, Username: \u0026#34;ormissia\u0026#34;, Age: 90, Email: \u0026#34;email@example.com\u0026#34;, } userJson, _ := json.Marshal(u) fmt.Println(string(userJson)) u2Str := `{\u0026#34;id\u0026#34;:2,\u0026#34;username\u0026#34;:\u0026#34;ormissia\u0026#34;,\u0026#34;age\u0026#34;:900,\u0026#34;email\u0026#34;:\u0026#34;ormissia@example.com\u0026#34;}` u2 := new(User) _ = json.Unmarshal([]byte(u2Str), u2) fmt.Printf(\u0026#34;%+v\u0026#34;,u2) } 输出：\n{\u0026#34;id\u0026#34;:1,\u0026#34;username\u0026#34;:\u0026#34;ormissia\u0026#34;,\u0026#34;age\u0026#34;:90,\u0026#34;email\u0026#34;:\u0026#34;email@example.com\u0026#34;} \u0026amp;{ID:2 Username:ormissia Age:900 Email:ormissia@example.com} tag解析原理 通过反射拿到struct tag 示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) type User struct { ID int `json:\u0026#34;id\u0026#34; myTag:\u0026#34;ID\u0026#34;` Username string `json:\u0026#34;username\u0026#34; myTag:\u0026#34;USERNAME\u0026#34;` Age int `json:\u0026#34;age\u0026#34; myTag:\u0026#34;AGE\u0026#34;` Email string `json:\u0026#34;email\u0026#34; myTag:\u0026#34;EMAIL\u0026#34;` } func main() { u := User{1, \u0026#34;ormissia\u0026#34;, 90, \u0026#34;email@example.com\u0026#34;} userTyp := reflect.TypeOf(u) fieldTag := userTyp.Field(0).Tag fmt.Printf(\u0026#34;user field 0 id tag: %s\\n\u0026#34;,fieldTag) value, ok1 := fieldTag.Lookup(\u0026#34;myTag\u0026#34;) fmt.Println(value, ok1) value1, ok2 := fieldTag.Lookup(\u0026#34;other\u0026#34;) fmt.Println(value1, ok2) } 输出：\nuser field 0 id tag: json:\u0026#34;id\u0026#34; myTag:\u0026#34;ID\u0026#34; ID true false 获取tag全部的值 reflect.TypeOf(u).Field(0).Tag 通过Tag即可获取struct定义时候对应字段后面反引号``中全部的值\nTag是通过反射获取到的具体字段StructField 中的属性，类型为自定义string类型：StructTag\ntype StructField struct { // Name is the field name. \tName string // PkgPath is the package path that qualifies a lower case (unexported) \t// field name. It is empty for upper case (exported) field names. \t// See https://golang.org/ref/spec#Uniqueness_of_identifiers \tPkgPath string Type Type // field type \tTag StructTag // field tag string \tOffset uintptr // offset within struct, in bytes \tIndex []int // index sequence for Type.FieldByIndex \tAnonymous bool // is an embedded field } // A StructTag is the tag string in a struct field. // // By convention, tag strings are a concatenation of // optionally space-separated key:\u0026#34;value\u0026#34; pairs. // Each key is a non-empty string consisting of non-control // characters other than space (U+0020 \u0026#39; \u0026#39;), quote (U+0022 \u0026#39;\u0026#34;\u0026#39;), // and colon (U+003A \u0026#39;:\u0026#39;). Each value is quoted using U+0022 \u0026#39;\u0026#34;\u0026#39; // characters and Go string literal syntax. type StructTag string 通过tag的key获取value 而StructTag 有两个通过key获取value的方法： Get 和Lookup 。\nGet 是对Lookup 的一个封装。\nLookup 可以返回当前查询的key是否存在。\nfunc (tag StructTag) Get(key string) string { v, _ := tag.Lookup(key) return v } func (tag StructTag) Lookup(key string) (value string, ok bool) { for tag != \u0026#34;\u0026#34; { // Skip leading space. \ti := 0 for i \u0026lt; len(tag) \u0026amp;\u0026amp; tag[i] == \u0026#39; \u0026#39; { i++ } tag = tag[i:] if tag == \u0026#34;\u0026#34; { break } i = 0 for i \u0026lt; len(tag) \u0026amp;\u0026amp; tag[i] \u0026gt; \u0026#39; \u0026#39; \u0026amp;\u0026amp; tag[i] != \u0026#39;:\u0026#39; \u0026amp;\u0026amp; tag[i] != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; tag[i] != 0x7f { i++ } if i == 0 || i+1 \u0026gt;= len(tag) || tag[i] != \u0026#39;:\u0026#39; || tag[i+1] != \u0026#39;\u0026#34;\u0026#39; { break } name := string(tag[:i]) tag = tag[i+1:] //...  //... } 通过源码，我们可以看出 Lookup 实际上是对tag反引号中整个内容进行查找，通过空格、冒号以及双引号对tag的值进行分割，最后返回。\n使用自定义tag实践 我们可以一个struct参数校验器：go-opv 来简单体验一下自定义tag的使用。\ngo-opv的简单使用示例  go-opv 的简介可以参考我的 另一篇文章 。 只不过，当时还没有添加这个通过struct自定义tag的校验方式，基础功能与现在基本一致。\n 仓库go-opv\n以下是一个简单的使用Demo\n在这个示例中，我们指定了struct的tag为go-opv:\u0026quot;ge:0,le:20\u0026quot;，在参数检验过程中，我们会解析这个tag，并从中获取定义的规则。\npackage main import ( \u0026#34;log\u0026#34; go_opv \u0026#34;github.com/ormissia/go-opv\u0026#34; ) type User struct { Name string `go-opv:\u0026#34;ge:0,le:20\u0026#34;` //Name \u0026gt;=0 \u0026amp;\u0026amp; Name \u0026lt;=20 \tAge int `go-opv:\u0026#34;ge:0,lt:100\u0026#34;` //Age \u0026gt;= 0 \u0026amp;\u0026amp; Age \u0026lt; 100 } func init() { //使用默认配置：struct tag名字为\u0026#34;go-opv\u0026#34;，规则与限定值的分隔符为\u0026#34;:\u0026#34; \tmyVerifier = go_opv.NewVerifier() //初始化一个验证规则：Age字段大于等于0，小于200 \tuserRequestRules = go_opv.Rules{ \u0026#34;Age\u0026#34;: []string{myVerifier.Ge(\u0026#34;0\u0026#34;), myVerifier.Lt(\u0026#34;200\u0026#34;)}, } } var myVerifier go_opv.Verifier var userRequestRules go_opv.Rules func main() { // ShouldBind(\u0026amp;user) in Gin framework or other generated object \tuser := User{ Name: \u0026#34;ormissia\u0026#34;, Age: 190, } //两种验证方式混合,函数参数中传入自定义规则时候会覆盖struct tag上定义的规则 \t//根据自定义规则Age \u0026gt;= 0 \u0026amp;\u0026amp; Age \u0026lt; 200，Age的值为190，符合规则，验证通过 \tif err := myVerifier.Verify(user, userRequestRules); err != nil { log.Println(err) } else { log.Println(\u0026#34;pass\u0026#34;) } //只用struct的tag验证 \t//根据tag上定义的规则Age \u0026gt;= 0 \u0026amp;\u0026amp; Age \u0026lt; 100，Age的值为190，不符合规则，验证不通过 \tif err := myVerifier.Verify(user); err != nil { log.Println(err) } else { log.Println(\u0026#34;pass\u0026#34;) } } go-opv的简单分析 我们先判断了是否传入了自定义的校验规则（即为自定义规则会覆盖struct上tag定义的规则），如果没有，就去通过反射获取struct上tag定义的规则。 然后生成相对应的规则，继续执行后面的校验逻辑。\nif len(conditions[tagVal.Name]) == 0 { //没有自定义使用tag \t//`go-opv:\u0026#34;ne:0,eq:10\u0026#34;` \t//conditionsStr = \u0026#34;ne:0,eq:10\u0026#34; \tif conditionsStr, ok := tagVal.Tag.Lookup(verifier.tagPrefix); ok \u0026amp;\u0026amp; conditionsStr != \u0026#34;\u0026#34; { conditionStrs := strings.Split(conditionsStr, \u0026#34;,\u0026#34;) conditions[tagVal.Name] = conditionStrs } else { //如果tag也没有定义则去校验下一个字段 \tcontinue } } 小结  通过使用encoding/json 包中的json.Marshal() 和json.Unmarshal() ，我们了解了Golang中struct tag的基本概念及用途。 通过对StructField 的分析，我们明白了struct tag工作的基本原理 而通过go-opv 的分析，我们了解了自定义tag的基本使用方法。  参考  go1.16.7 type.go 源码  ","date":"August 13, 2021","hero":"/posts/knowledge/2001-go/005-tag/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2001-go/005-tag/","summary":"#golang #struct-tag #reflect\n  StructTag是写在结构体字段类型后面反引号中的内容，用来标记结构体中各字段的属性。\n  源码中对struct tag的解释：\n By convention, tag strings are a concatenation of optionally space-separated key:\u0026ldquo;value\u0026rdquo; pairs. Each key is a non-empty string consisting of non-control characters other than space (U+0020 ' \u0026lsquo;), quote (U+0022 \u0026lsquo;\u0026quot;'), and colon (U+003A \u0026lsquo;:'). Each value is quoted using U+0022 \u0026lsquo;\u0026quot;\u0026rsquo; characters and Go string literal syntax.\n  简单应用 最常见的，比如json的tag应用：\njson序列化和反序列化时候使用的key都是在struct字段上定义的\npackage main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; ) type User struct { ID int `json:\u0026#34;id\u0026#34;` Username string `json:\u0026#34;username\u0026#34;` Age int `json:\u0026#34;age\u0026#34;` Email string `json:\u0026#34;email\u0026#34;` } func main() { u := User{ ID: 1, Username: \u0026#34;ormissia\u0026#34;, Age: 90, Email: \u0026#34;email@example.","tags":null,"title":"Golang struct tag浅析与自定义tag实践"},{"categories":null,"contents":"   前缀树又称字典树\n Trie的应用  自动补全,例如：在百度搜索的输入框中,输入一个单词的前半部分,能够自动补全出可能的单词结果。 拼写检查，例如：在word中输入一个拼写错误的单词, 能够自动检测出来。 IP路由表，在IP路由表中进行路由匹配时, 要按照最长匹配前缀的原则进行匹配。 T9预测文本，在大多手机输入法中, 都会用9格的那种输入法. 这个输入法能够根据用户在9格上的输入,自动匹配出可能的单词。 填单词游戏，相信大多数人都玩过那种在横竖的格子里填单词的游戏。  ","date":"August 12, 2021","hero":"/posts/algorithm/4002-algorithm-trie/head.svg","permalink":"https://ormissia.github.io/posts/algorithm/4002-algorithm-trie/","summary":"   前缀树又称字典树\n Trie的应用  自动补全,例如：在百度搜索的输入框中,输入一个单词的前半部分,能够自动补全出可能的单词结果。 拼写检查，例如：在word中输入一个拼写错误的单词, 能够自动检测出来。 IP路由表，在IP路由表中进行路由匹配时, 要按照最长匹配前缀的原则进行匹配。 T9预测文本，在大多手机输入法中, 都会用9格的那种输入法. 这个输入法能够根据用户在9格上的输入,自动匹配出可能的单词。 填单词游戏，相信大多数人都玩过那种在横竖的格子里填单词的游戏。  ","tags":null,"title":"前缀树"},{"categories":null,"contents":"  归并排序 思想 整体是递归（当然可以用非递归实现），使左边有序，使右边有序，合并左边右边使整体有序\n具体实现\n核心代码 func merge(arr []interface{}, l, mid, r int, compare Compare) { help := make([]interface{}, r-l+1) i := 0 p1 := l p2 := mid + 1 for p1 \u0026lt;= mid \u0026amp;\u0026amp; p2 \u0026lt;= r { if compare(arr[p1], arr[p2]) { help[i] = arr[p1] p1++ } else { help[i] = arr[p2] p2++ } i++ } //要么p1越界了，要么p2越界了 \tfor p1 \u0026lt;= mid { help[i] = arr[p1] i++ p1++ } for p2 \u0026lt;= r { help[i] = arr[p2] i++ p2++ } for j, _ := range help { arr[l+j] = help[j] } } 递归 核心代码\nfunc mergeProcess(arr []interface{}, l, r int, compare Compare) { if l == r { return } mid := l + ((r - l) \u0026gt;\u0026gt; 1) mergeProcess(arr, l, mid, compare) mergeProcess(arr, mid+1, r, compare) merge(arr, l, mid, r, compare) } 非递归 核心代码：\nn := len(arr) mergeSize := 1 //当前有序的左组长度 \tfor mergeSize \u0026lt; n { l := 0 for l \u0026lt; n { m := l + mergeSize - 1 if m \u0026gt;= n { break } r := m + mergeSize if m+mergeSize \u0026gt; n-1 { r = n - 1 } merge(arr, l, m, r, s.Compare) l = r + 1 } //防止溢出 \tif mergeSize \u0026gt; n/2 { break } mergeSize \u0026lt;\u0026lt;= 1 } 快速排序 具体实现\n思想 给定一个数组arr和一个整数num，把小于等于num的数放在数组左边，大于num的数放在数组的右边。\n 额外空间复杂度是O(1)，时间复杂度O(N)\n 核心代码 func netherlandsFlag(arr []interface{}, l, r int, isEqual, isSmall Compare) (i, j int) { if l \u0026gt; r { return -1, -1 } if l == r { return l, r } less := l - 1 //小于arr[R]区\t右边界 \tmore := r //大于arr[R]区\t左边界 \tindex := l for index \u0026lt; more { if isEqual(arr[index], arr[r]) { index++ } else if isSmall(arr[index], arr[r]) { less++ arr[index], arr[less] = arr[less], arr[index] index++ } else { more-- arr[index], arr[more] = arr[more], arr[index] } } arr[more], arr[r] = arr[r], arr[more] return less + 1, more } 递归 核心代码：\nfunc quickProcess(arr []interface{}, l, r int, isEqual, isSmall Compare) { if l \u0026gt;= r { return } n := rand.Intn(r-l+1) + l arr[n], arr[r] = arr[r], arr[n] i, j := netherlandsFlag(arr, l, r, isEqual, isSmall) quickProcess(arr, l, i-1, isEqual, isSmall) quickProcess(arr, j+1, r, isEqual, isSmall) } 堆排序  堆的实质是一棵完全二叉树\n 堆可分为两种类型：\n 大根堆：所有子树的根节点均为最大值 小根堆：所有子树的根节点均为最小值  一般情况下堆可以用一个有序数组来存储\n[0\u0026hellip;i\u0026hellip;n] i节点的左孩子index为2*i+1，右孩子为2i+2，父节点为(i-1)/2\n也有一种特例是从1开始(位运算比加减法快)\n[01\u0026hellip;i\u0026hellip;n] i节点的左孩子index为2*i即i\u0026lt;\u0026lt;1，右孩子为2i+1即i\u0026lt;\u0026lt;1|1，父节点为i/2\n 让整个数组都变成大根堆的结构，建堆的过程：  从上到下的方法：时间复杂度为O(N*logN) 从下到上的方法：时间复杂度为O(N)   把堆的根节点个末尾值交换，减小堆的大小之后，再去调整堆，周而复始，时间复杂度为O(N*logN)  思想 依次弹出根节点，假设将大根堆弹出的值依次放到数组头部，则得到一个由小到大的数组\n 适合元素在固定范围内移动\n 具体实现\n核心代码 上浮 //上浮（通常是最后一个节点） //停止条件：1.没有父节点大，2.上浮到根节点了 func (h *maxHeap) heapInsert() { index := h.heapSize - 1 for h.comparator(h.Content[(index-1)/2], h.Content[index]) \u0026gt; 0 { h.Content[index], h.Content[(index-1)/2] = h.Content[(index-1)/2], h.Content[index] index = (index - 1) / 2 } } 下沉 //index位置节点不断下沉 //停止条件，1.没有孩子比自己大，2.没有孩子 func (h *maxHeap) heapify(index int) { left := index*2 + 1 for left \u0026lt; h.heapSize { //先比较左右两个孩子，挑出大的那个 \tlargest := left if left+1 \u0026lt; h.heapSize \u0026amp;\u0026amp; h.comparator(h.Content[left], h.Content[left+1]) \u0026gt; 0 { largest = left + 1 } //再比较根节点和大的那个孩子，如果最大的那个孩子也没有index大，就break \tif h.comparator(h.Content[index], h.Content[largest]) \u0026lt;= 0 { break } h.Content[index], h.Content[largest] = h.Content[largest], h.Content[index] index = largest left = index*2 + 1 } } 插入 func (h *maxHeap) Push(value interface{}) (err error) { if h.IsFull() { return errHeepFull } h.Content[h.heapSize] = value h.heapSize++ h.heapInsert() return nil } 弹出 func (h *maxHeap) Pop() (value interface{}, err error) { if h.IsEmpty() { return nil, errHeepEmpty } value = h.Content[0] h.heapSize-- h.Content[0] = h.Content[h.heapSize] h.heapify(0) return value, nil } 桶排序  排序算法总结    排序算法 时间复杂度 额外空间复杂度 稳定性     选择排序 O(N^2) O(1) 无   冒泡排序 O(N^2) O(1) 有   插入排序 O(N^2) O(1) 有   归并排序 O(N*logN) O(N) 有   随机快排 O(N*logN) O(logN) 无   堆排序 O(N*logN) O(1) 无   计数排序 O(N) O(M) 有   基数排序 O(N) O(N) 有    ","date":"August 7, 2021","hero":"/posts/algorithm/4001-algorithm-sort/head.svg","permalink":"https://ormissia.github.io/posts/algorithm/4001-algorithm-sort/","summary":"归并排序 思想 整体是递归（当然可以用非递归实现），使左边有序，使右边有序，合并左边右边使整体有序\n具体实现\n核心代码 func merge(arr []interface{}, l, mid, r int, compare Compare) { help := make([]interface{}, r-l+1) i := 0 p1 := l p2 := mid + 1 for p1 \u0026lt;= mid \u0026amp;\u0026amp; p2 \u0026lt;= r { if compare(arr[p1], arr[p2]) { help[i] = arr[p1] p1++ } else { help[i] = arr[p2] p2++ } i++ } //要么p1越界了，要么p2越界了 \tfor p1 \u0026lt;= mid { help[i] = arr[p1] i++ p1++ } for p2 \u0026lt;= r { help[i] = arr[p2] i++ p2++ } for j, _ := range help { arr[l+j] = help[j] } } 递归 核心代码","tags":null,"title":"排序算法"},{"categories":null,"contents":" #golang #pprof #内存分析\n  pprof is a tool for visualization and analysis of profiling data.\n  pprof reads a collection of profiling samples in profile.proto format and generates reports to visualize and help analyze the data. It can generate both text and graphical reports (through the use of the dot visualization package).\n  PProf是用于可视化和分析性能分析数据的工具，PProf以profile.proto读取分析样本的集合，并生成报告以可视化并帮助分析数据（支持文本和图形报告）。\n 简介 采集方式  runtime/pprof：采集程序（非Server）的指定区块的运行数据进行分析。 net/http/pprof：基于HTTPServer运行，并且可以采集运行时数据进行分析。 gotest：通过运行测试用例，并指定所需标识来进行采集。  功能  CPUProfiling：CPU分析，按照一定的频率采集所监听的应用程序CPU（含寄存器）的使用情况，可确定应用程序在主动消耗CPU周期时花费时间的位置。 MemoryProfiling：内存分析，在应用程序进行堆分配时记录堆栈跟踪，用于监视当前和历史内存使用情况，以及检查内存泄漏。 BlockProfiling：阻塞分析，记录Goroutine阻塞等待同步（包括定时器通道）的位置，默认不开启，需要调用runtime.SetBlockProfileRate进行设置。 MutexProfiling：互斥锁分析，报告互斥锁的竞争情况，默认不开启，需要调用runtime.SetMutexProfileFraction进行设置。 GoroutineProfiling：Goroutine分析，可以对当前应用程序正在运行的Goroutine进行堆栈跟踪和分析。这项功能在实际排查中会经常用到， 因为很多问题出现时的表象就是Goroutine暴增，而这时候我们要做的事情之一就是查看应用程序中的Goroutine正在做什么事情，因为什么阻塞了， 然后再进行下一步。  简单的例子 注意要在import中引入 _ \u0026quot;net/http/pprof\u0026quot;\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; _ \u0026#34;net/http/pprof\u0026#34; \u0026#34;time\u0026#34; ) func main() { go func() { for { log.Println(\u0026#34;pprof\u0026#34;) time.Sleep(time.Second) } }() if err := http.ListenAndServe(\u0026#34;0.0.0.0:6060\u0026#34;, nil); err != nil { log.Println(err) return } } 通过web页面访问 运行之后打开页面http://127.0.0.1:6060/debug/pprof/\n/debug/pprof/ Types of profiles available: Count\tProfile 0\tallocs 0\tblock 0\tcmdline 5\tgoroutine 0\theap 0\tmutex 0\tprofile 7\tthreadcreate 0\ttrace full goroutine stack dump Profile Descriptions: allocs: A sampling of all past memory allocations block: Stack traces that led to blocking on synchronization primitives cmdline: The command line invocation of the current program goroutine: Stack traces of all current goroutines heap: A sampling of memory allocations of live objects. You can specify the gc GET parameter to run GC before taking the heap sample. mutex: Stack traces of holders of contended mutexes profile: CPU profile. You can specify the duration in the seconds GET parameter. After you get the profile file, use the go tool pprof command to investigate the profile. threadcreate: Stack traces that led to the creation of new OS threads trace: A trace of execution of the current program. You can specify the duration in the seconds GET parameter. After you get the trace file, use the go tool trace command to investigate the trace. 通过终端访问 go tool pprof http://localhost:6060/debug/pprof/profile\\?seconds\\=60 执行该命令后，需等待60秒（可调整seconds的值），pprof会进行CPU Profiling。结束后将默认进入pprof的交互式命令模式， 可以对分析的结果进行查看或导出。\nFetching profile over HTTP from http://localhost:6060/debug/pprof/profile?seconds=60 Saved profile in /Users/orimissia/pprof/pprof.samples.cpu.003.pb.gz Type: cpu Time: Aug 6, 2021 at 2:41pm (CST) Duration: 1mins, Total samples = 10ms (0.017%) Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options) (pprof) 具体可执行pprof help查看命令说明\n(pprof) top10 Showing nodes accounting for 10ms, 100% of 10ms total flat flat% sum% cum cum% 10ms 100% 100% 10ms 100% runtime.kevent 0 0% 100% 10ms 100% runtime.findrunnable 0 0% 100% 10ms 100% runtime.mcall 0 0% 100% 10ms 100% runtime.netpoll 0 0% 100% 10ms 100% runtime.park_m 0 0% 100% 10ms 100% runtime.schedule  flat：给定函数上运行耗时 flat%：同上的CPU运行耗时总比例 sum%：给定函数累积使用CPU总比例 cum：当前函数加上它之上的调用运行总耗时 cum%：同上的CPU运行耗时总比例   最后一列为函数名称，在大多数的情况下，我们可以通过这五列得出一个应用程序的运行情况，加以优化。\n go tool pprof http://localhost:6060/debug/pprof/heap Saved profile in /Users/orimissia/pprof/pprof.alloc_objects.alloc_space.inuse_objects.inuse_space.001.pb.gz Type: inuse_space Time: Aug 6, 2021 at 2:46pm (CST) No samples were found with the default sample value type. Try \u0026#34;sample_index\u0026#34; command to analyze different sample values. Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options)  -inuse_space：分析应用程序的常驻内存占用情况 -alloc_objects：分析应用程序的内存临时分配情况  可视化界面 新建测试用例：\npackage main import \u0026#34;testing\u0026#34; const str = \u0026#34;ormissia\u0026#34; func TestAdd(t *testing.T) { s := Con(str) if s == \u0026#34;\u0026#34; { t.Errorf(\u0026#34;Test.Add error!\u0026#34;) } } func BenchmarkAdd(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { Con(str) } } func Con(str string) string { data := []byte(str) sData := string(data) return sData } 执行测试用例\n% go test -bench=. -cpuprofile=cpu.prof goos: darwin goarch: arm64 pkg: awesomeProject/pprof BenchmarkAdd-8 182690547 6.330 ns/op PASS ok awesomeProject/pprof 2.366s 启动pprof可视化界面\n方法一\ngo tool pprof -http=:8080 cpu.prof 方法二\ngo tool pprof cpu.prof (pprof) web 可视化界面\n参考  https://github.com/google/pprof https://golang2.eddycjy.com/posts/ch6/01-pprof-1  ","date":"August 5, 2021","hero":"/posts/knowledge/2001-go/004-pprof/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2001-go/004-pprof/","summary":"#golang #pprof #内存分析\n  pprof is a tool for visualization and analysis of profiling data.\n  pprof reads a collection of profiling samples in profile.proto format and generates reports to visualize and help analyze the data. It can generate both text and graphical reports (through the use of the dot visualization package).\n  PProf是用于可视化和分析性能分析数据的工具，PProf以profile.proto读取分析样本的集合，并生成报告以可视化并帮助分析数据（支持文本和图形报告）。\n 简介 采集方式  runtime/pprof：采集程序（非Server）的指定区块的运行数据进行分析。 net/http/pprof：基于HTTPServer运行，并且可以采集运行时数据进行分析。 gotest：通过运行测试用例，并指定所需标识来进行采集。  功能  CPUProfiling：CPU分析，按照一定的频率采集所监听的应用程序CPU（含寄存器）的使用情况，可确定应用程序在主动消耗CPU周期时花费时间的位置。 MemoryProfiling：内存分析，在应用程序进行堆分配时记录堆栈跟踪，用于监视当前和历史内存使用情况，以及检查内存泄漏。 BlockProfiling：阻塞分析，记录Goroutine阻塞等待同步（包括定时器通道）的位置，默认不开启，需要调用runtime.","tags":null,"title":"Golang性能分析工具-pprof"},{"categories":null,"contents":" #golang #reflect\n 反射简介  Golang提供了一种机制，在编译时不知道类型的情况下，可更新变量、运行时查看值、调用方法以及直接对他们的布局进行操作的机制，称为反射。\n  reflect 包中的官方注释：Package reflect implements run-time reflection, allowing a program to manipulate objects with arbitrary types. \n reflect 实现了运行时的反射能力，能够让程序操作不同类型的对象。反射包中有两对非常重要的函数和类型， 两个函数分别是：\n reflect.TypeOf 能获取类型信息 reflect.ValueOf 能获取数据的运行时表示  三大法则 运行时反射是程序在运行期间检查其自身结构的一种方式。反射带来的灵活性是一把双刃剑，反射作为一种元编程方式可以减少重复代码， 但是过量的使用反射会使我们的程序逻辑变得难以理解并且运行缓慢。我们在这一节中会介绍Go语言反射的三大法则，其中包括：\n 从interface{}变量可以反射出反射对象； 从反射对象可以获取interface{}变量； 要修改反射对象，其值必须可设置；  第一法则 反射的第一法则是我们能将Go语言的interface{}变量转换成反射对象。很多读者可能会对这以法则产生困惑—为什么是从interface{}变量到反射对象？ 当我们执行reflect.ValueOf(1)时，虽然看起来是获取了基本类型int对应的反射类型，但是由于 reflect.TypeOf 、 reflect.ValueOf 两个方法的入参都是interface{}类型，所以在方法执行的过程中发生了类型转换。\n因为Go语言的函数调用都是值传递的，所以变量会在函数调用时进行类型转换。基本类型int会转换成interface{}类型， 这也就是为什么第一条法则是从接口到反射对象。\n上面提到的reflect.TypeOf 和reflect.ValueOf 函数就能完成这里的转换，如果我们认为Go语言的类型和反射类型处于两个不同的世界，那么这两个函数就是连接这两个世界的桥梁。\n我们可以通过以下例子简单介绍它们的作用， reflect.TypeOf 获取了变量author的类型， reflect.ValueOf 获取了变量的值ormissia。如果我们知道了一个变量的类型和值，那么就意味着我们知道了这个变量的全部信息。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func main() { author := \u0026#34;ormissia\u0026#34; fmt.Println(\u0026#34;TypeOf author:\u0026#34;, reflect.TypeOf(author)) fmt.Println(\u0026#34;ValueOf author:\u0026#34;, reflect.ValueOf(author)) } $ go run main.go TypeOf author: string ValueOf author: ormissia 有了变量的类型之后，我们可以通过Method方法获得类型实现的方法，通过Field获取类型包含的全部字段。对于不同的类型， 我们也可以调用不同的方法获取相关信息：\n 结构体：获取字段的数量并通过下标和字段名获取字段StructField； 哈希表：获取哈希表的Key类型； 函数或方法：获取入参和返回值的类型； …  总而言之，使用reflect.TypeOf 和reflect.ValueOf 能够获取Go语言中的变量对应的反射对象。一旦获取了反射对象，我们就能得到跟当前类型相关数据和操作，并可以使用这些运行时获取的结构执行方法。\n第二法则 反射的第二法则是我们可以从反射对象可以获取interface{}变量。既然能够将接口类型的变量转换成反射对象， 那么一定需要其他方法将反射对象还原成接口类型的变量，reflect 中的 reflect.Value.Interface 就能完成这项工作\n不过调用reflect.Value.Interface 方法只能获得interface{}类型的变量，如果想要将其还原成最原始的状态还需要经过如下所示的显式类型转换：\nv := reflect.ValueOf(1) v.Interface().(int) 从反射对象到接口值的过程是从接口值到反射对象的镜面过程，两个过程都需要经历两次转换：\n 从接口值到反射对象：  从基本类型到接口类型的类型转换； 从接口类型到反射对象的转换；   从反射对象到接口值：  反射对象转换成接口类型； 通过显式类型转换变成原始类型；    当然不是所有的变量都需要类型转换这一过程。如果变量本身就是interface{}类型的，那么它不需要类型转换，因为类型转换这一过程一般都是隐式的， 所以我不太需要关心它，只有在我们需要将反射对象转换回基本类型时才需要显式的转换操作。\n第三法则 Go语言反射的最后一条法则是与值是否可以被更改有关，如果我们想要更新一个 reflect.Value ， 那么它持有的值一定是可以被更新的，假设我们有以下代码：\nfunc main() { i := 1 v := reflect.ValueOf(i) v.SetInt(10) fmt.Println(i) } $ go run reflect.go panic: reflect: reflect.Value.SetInt using unaddressable value goroutine 1 [running]: reflect.flag.mustBeAssignableSlow(0x82) /usr/local/go/src/reflect/value.go:260 +0x118 reflect.flag.mustBeAssignable(...) /usr/local/go/src/reflect/value.go:247 reflect.Value.SetInt(0x100196bc0, 0x10021f8e8, 0x82, 0xa) /usr/local/go/src/reflect/value.go:1637 +0x30 main.main() /Users/orimissia/workspace/awesomeProject/goroutine/main.go:13 +0xb8 运行上述代码会导致程序崩溃并报出“reflect:reflect.flag.mustBeAssignableusingunaddressablevalue”错误， 仔细思考一下就能够发现出错的原因：由于Go语言的函数调用都是传值的，所以我们得到的反射对象跟最开始的变量没有任何关系， 那么直接修改反射对象无法改变原始变量，程序为了防止错误就会崩溃。\n想要修改原变量只能使用如下的方法：\nfunc main() { i := 1 v := reflect.ValueOf(\u0026amp;i) v.Elem().SetInt(10) fmt.Println(i) } $ go run reflect.go 10  调用reflect.ValueOf 获取变量指针； 调用reflect.Value.Elem 获取指针指向的变量； 调用reflect.Value.SetInt 更新变量的值：  由于Go语言的函数调用都是值传递的，所以我们只能只能用迂回的方式改变原变量：先获取指针对应的 reflect.Value ， 再通过reflect.Value.Elem 方法得到可以被设置的变量，我们可以通过下面的代码理解这个过程：\nfunc main() { i := 1 v := \u0026amp;i *v = 10 } 如果不能直接操作i变量修改其持有的值，我们就只能获取i变量所在地址并使用*v修改所在地址中存储的整数。\n类型和值 Go语言的interface{}类型在语言内部是通过reflect.emptyInterface 结体表示的，其中的rtype字段用于表示变量的类型，另一个word字段指向内部封装的数据：\ntype emptyInterface struct { typ *rtype word unsafe.Pointer } 用于获取变量类型的reflect.TypeOf函数将传入的变量隐式转换成 reflect.emptyInterface 类型并获取其中存储的类型信息reflect.rtype：\nfunc TypeOf(i interface{}) Type { eface := *(*emptyInterface)(unsafe.Pointer(\u0026amp;i)) return toType(eface.typ) } func toType(t *rtype) Type { if t == nil { return nil } return t } reflect.rtype是一个实现了reflect.Type接口的结构体，该结构体实现的 reflect.rtype.String 方法可以帮助我们获取当前类型的名称：\nfunc (t *rtype) String() string { s := t.nameOff(t.str).name() if t.tflag\u0026amp;tflagExtraStar != 0 { return s[1:] } return s } reflect.TypeOf 的实现原理其实并不复杂，它只是将一个interface{}变量转换成了内部的 reflect.emptyInterface 表示，然后从中获取相应的类型信息。\n用于获取接口值reflect.Value 的函数reflect.ValueOf 实现也非常简单，在该函数中我们先调用了 reflect.escapes 保证当前值逃逸到堆上，然后通过 reflect.unpackEface 从接口中获取reflect.Value 结构体：\nfunc ValueOf(i interface{}) Value { if i == nil { return Value{} } escapes(i) return unpackEface(i) } func unpackEface(i interface{}) Value { e := (*emptyInterface)(unsafe.Pointer(\u0026amp;i)) t := e.typ if t == nil { return Value{} } f := flag(t.Kind()) if ifaceIndir(t) { f |= flagIndir } return Value{t, e.word, f} } reflect.unpackEface 会将传入的接口转换成 reflect.emptyInterface， 然后将具体类型和指针包装成 reflect.Value 结构体后返回。\nreflect.TypeOf 和reflect.ValueOf 的实现都很简单。我们已经分析了这两个函数的实现，现在需要了解编译器在调用函数之前做了哪些工作：\npackage main import ( \u0026#34;reflect\u0026#34; ) func main() { i := 20 _ = reflect.TypeOf(i) } $ go build -gcflags=\u0026#34;-S -N\u0026#34; main.go ... MOVQ\t$20, \u0026#34;\u0026#34;..autotmp_20+56(SP) // autotmp = 20 LEAQ\ttype.int(SB), AX // AX = type.int(SB) MOVQ\tAX, \u0026#34;\u0026#34;..autotmp_19+280(SP) // autotmp_19+280(SP) = type.int(SB) LEAQ\t\u0026#34;\u0026#34;..autotmp_20+56(SP), CX // CX = 20 MOVQ\tCX, \u0026#34;\u0026#34;..autotmp_19+288(SP) // autotmp_19+288(SP) = 20 ... 从上面这段截取的汇编语言，我们可以发现在函数调用之前已经发生了类型转换，上述指令将int类型的变量转换成了占用16字节 autotmp_19+280(SP) ~ autotmp_19+288(SP)的接口，两个LEAQ指令分别获取了类型的指针type.int(SB)以及变量i所在的地址。\n当我们想要将一个变量转换成反射对象时，Go语言会在编译期间完成类型转换，将变量的类型和值转换成了interface{}并等待运行期间使用 reflect 包获取接口中存储的信息。\n更新变量 当我们想要更新reflect.Value 时，就需要调用 reflect.Value.Set 更新反射对象，该方法会调用 reflect.flag.mustBeAssignable 和reflect.flag.mustBeExported 分别检查当前反射对象是否是可以被设置的以及字段是否是对外公开的：\nfunc (v Value) Set(x Value) { v.mustBeAssignable() x.mustBeExported() var target unsafe.Pointer if v.kind() == Interface { target = v.ptr } x = x.assignTo(\u0026#34;reflect.Set\u0026#34;, v.typ, target) typedmemmove(v.typ, v.ptr, x.ptr) } reflect.Value.Set 会调用reflect.Value.assignTo 并返回一个新的反射对象，这个返回的反射对象指针会直接覆盖原反射变量。\nfunc (v Value) assignTo(context string, dst *rtype, target unsafe.Pointer) Value { ... switch { case directlyAssignable(dst, v.typ): ... return Value{dst, v.ptr, fl} case implements(dst, v.typ): if v.Kind() == Interface \u0026amp;\u0026amp; v.IsNil() { return Value{dst, nil, flag(Interface)} } x := valueInterface(v, false) if dst.NumMethod() == 0 { *(*interface{})(target) = x } else { ifaceE2I(dst, x, target) } return Value{dst, target, flagIndir | flag(Interface)} } panic(context + \u0026#34;: value of type \u0026#34; + v.typ.String() + \u0026#34; is not assignable to type \u0026#34; + dst.String()) } reflect.Value.assignTo 会根据当前和被设置的反射对象类型创建一个新的 reflect.Value 结构体：\n 如果两个反射对象的类型是可以被直接替换，就会直接返回目标反射对象； 如果当前反射对象是接口并且目标对象实现了接口，就会把目标对象简单包装成接口值  在变量更新的过程中， reflect.Value.assignTo 返回的reflect.Value 中的指针会覆盖当前反射对象中的指针实现变量的更新。\n实现协议 reflect 包还为我们提供了 reflect.rtype.Implements 方法可以用于判断某些类型是否遵循特定的接口。在Go语言中获取结构体的反射类型 reflect.Type 还是比较容易的，但是想要获得接口类型需要通过以下方式：\nreflect.TypeOf((*\u0026lt;interface\u0026gt;)(nil)).Elem() 我们通过一个例子在介绍如何判断一个类型是否实现了某个接口。假设我们需要判断如下代码中的CustomError是否实现了Go语言标准库中的error接口：\ntype CustomError struct{} func (*CustomError) Error() string { return \u0026#34;\u0026#34; } func main() { typeOfError := reflect.TypeOf((*error)(nil)).Elem() customErrorPtr := reflect.TypeOf(\u0026amp;CustomError{}) customError := reflect.TypeOf(CustomError{}) fmt.Println(customErrorPtr.Implements(typeOfError)) // #=\u0026gt; true \tfmt.Println(customError.Implements(typeOfError)) // #=\u0026gt; false } 上述代码的运行结果正如我们在接口一节中介绍的：\n CustomError类型并没有实现error接口 *CustomError指针类型实现了error接口  抛开上述的执行结果不谈，我们来分析一下 reflect.rtype.Implements 方法的工作原理：\nfunc (t *rtype) Implements(u Type) bool { if u == nil { panic(\u0026#34;reflect: nil type passed to Type.Implements\u0026#34;) } if u.Kind() != Interface { panic(\u0026#34;reflect: non-interface type passed to Type.Implements\u0026#34;) } return implements(u.(*rtype), t) } reflect.rtype.Implements 会检查传入的类型是不是接口，如果不是接口或者是空值就会直接崩溃并中止当前程序。在参数没有问题的情况下，上述方法会调用私有函数 reflect.implements 判断类型之间是否有实现关系：\nfunc implements(T, V *rtype) bool { t := (*interfaceType)(unsafe.Pointer(T)) if len(t.methods) == 0 { return true } ... v := V.uncommon() i := 0 vmethods := v.methods() for j := 0; j \u0026lt; int(v.mcount); j++ { tm := \u0026amp;t.methods[i] tmName := t.nameOff(tm.name) vm := vmethods[j] vmName := V.nameOff(vm.name) if vmName.name() == tmName.name() \u0026amp;\u0026amp; V.typeOff(vm.mtyp) == t.typeOff(tm.typ) { if i++; i \u0026gt;= len(t.methods) { return true } } } return false } 如果接口中不包含任何方法，就意味着这是一个空的接口，任意类型都自动实现该接口，这时会直接返回true。\n在其他情况下，由于方法都是按照字母序存储的， reflect.implements 会维护两个用于遍历接口和类型方法的索引i和j判断类型是否实现了接口，因为最多只会进行n次比较（类型的方法数量），所以整个过程的时间复杂度是𝑂(𝑛)。\n方法调用 作为一门静态语言，如果我们想要通过reflect 包利用反射在运行期间执行方法不是一件容易的事情，下面的十几行代码就使用反射来执行Add(0,1)函数：\nfunc Add(a, b int) int { return a + b } func main() { v := reflect.ValueOf(Add) if v.Kind() != reflect.Func { return } t := v.Type() argv := make([]reflect.Value, t.NumIn()) for i := range argv { if t.In(i).Kind() != reflect.Int { return } argv[i] = reflect.ValueOf(i) } result := v.Call(argv) if len(result) != 1 || result[0].Kind() != reflect.Int { return } fmt.Println(result[0].Int()) // #=\u0026gt; 1 }  通过reflect.ValueOf 获取函数Add对应的反射对象； 调用reflect.rtype.NumIn 获取函数的入参个数； 多次调用reflect.ValueOf 函数逐一设置argv数组中的各个参数； 调用反射对象Add的reflect.Value.Call 方法并传入参数列表； 获取返回值数组、验证数组的长度以及类型并打印其中的数据；  使用反射来调用方法非常复杂，原本只需要一行代码就能完成的工作，现在需要十几行代码才能完成，但这也是在静态语言中使用动态特性需要付出的成本。\nfunc (v Value) Call(in []Value) []Value { v.mustBe(Func) v.mustBeExported() return v.call(\u0026#34;Call\u0026#34;, in) } reflect.Value.Call 是运行时调用方法的入口，它通过两个MustBe开头的方法确定了当前反射对象的类型是函数以及可见性，随后调用 reflect.Value.call 完成方法调用，这个私有方法的执行过程会分成以下的几个部分：\n 检查输入参数以及类型的合法性； 将传入的reflect.Value 参数数组设置到栈上； 通过函数指针和输入参数调用函数； 从栈上获取函数的返回值；  我们将按照上面的顺序分析使用reflect 进行函数调用的几个过程。\n参数检查 参数检查是通过反射调用方法的第一步，在参数检查期间我们会从反射对象中取出当前的函数指针unsafe.Pointer，如果该函数指针是方法， 那么我们会通过reflect.methodReceiver 获取方法的接收者和函数指针。\nfunc (v Value) call(op string, in []Value) []Value { t := (*funcType)(unsafe.Pointer(v.typ)) ... if v.flag\u0026amp;flagMethod != 0 { rcvr = v rcvrtype, t, fn = methodReceiver(op, v, int(v.flag)\u0026gt;\u0026gt;flagMethodShift) } else { ... } n := t.NumIn() if len(in) \u0026lt; n { panic(\u0026#34;reflect: Call with too few input arguments\u0026#34;) } if len(in) \u0026gt; n { panic(\u0026#34;reflect: Call with too many input arguments\u0026#34;) } for i := 0; i \u0026lt; n; i++ { if xt, targ := in[i].Type(), t.In(i); !xt.AssignableTo(targ) { panic(\u0026#34;reflect: \u0026#34; + op + \u0026#34; using \u0026#34; + xt.String() + \u0026#34; as type \u0026#34; + targ.String()) } } 上述方法还会检查传入参数的个数以及参数的类型与函数签名中的类型是否可以匹配，任何参数的不匹配都会导致整个程序的崩溃中止。\n准备参数 当我们已经对当前方法的参数完成验证后，就会进入函数调用的下一个阶段，为函数调用准备参数，在前面函数调用一节中，我们已经介绍过Go语言的函数调用惯例， 函数或者方法在调用时，所有的参数都会被依次放到栈上。\nnout := t.NumOut() frametype, _, retOffset, _, framePool := funcLayout(t, rcvrtype) var args unsafe.Pointer if nout == 0 { args = framePool.Get().(unsafe.Pointer) } else { args = unsafe_New(frametype) } off := uintptr(0) if rcvrtype != nil { storeRcvr(rcvr, args) off = ptrSize } for i, v := range in { targ := t.In(i).(*rtype) a := uintptr(targ.align) off = (off + a - 1) \u0026amp;^ (a - 1) n := targ.size ... addr := add(args, off, \u0026#34;n \u0026gt; 0\u0026#34;) v = v.assignTo(\u0026#34;reflect.Value.Call\u0026#34;, targ, addr) *(*unsafe.Pointer)(addr) = v.ptr off += n }  通过reflect.funcLayout 计算当前函数需要的参数和返回值的栈布局，也就是每一个参数和返回值所占的空间大小； 如果当前函数有返回值，需要为当前函数的参数和返回值分配一片内存空间args； 如果当前函数是方法，需要向将方法的接收接收者者拷贝到args内存中； 将所有函数的参数按照顺序依次拷贝到对应args内存中  使用reflect.funcLayout 返回的参数计算参数在内存中的位置； 将参数拷贝到内存空间中；    准备参数是计算各个参数和返回值占用的内存空间并将所有的参数都拷贝内存空间对应位置的过程，该过程会考虑函数和方法、返回值数量以及参数类型带来的差异。\n调用函数 准备好调用函数需要的全部参数后，就会通过下面的代码执行函数指针了。我们会向该函数传入栈类型、函数指针、参数和返回值的内存空间、 栈的大小以及返回值的偏移量：\ncall(frametype, fn, args, uint32(frametype.size), uint32(retOffset)) 上述函数实际上并不存在，它会在编译期间链接到 reflect.reflectcall 这个用汇编实现的函数上，我们在这里不会分析该函数的具体实现，感兴趣的读者可以自行了解其实现原理。\n处理返回值 当函数调用结束之后，就会开始处理函数的返回值：\n 如果函数没有任何返回值，会直接清空args中的全部内容来释放内存空间； 如果当前函数有返回值；  将args中与输入参数有关的内存空间清空； 创建一个nout长度的切片用于保存由反射对象构成的返回值数组； 从函数对象中获取返回值的类型和内存大小，将args内存中的数据转换成 reflect.Value 类型并存储到切片中；    var ret []Value if nout == 0 { typedmemclr(frametype, args) framePool.Put(args) } else { typedmemclrpartial(frametype, args, 0, retOffset) ret = make([]Value, nout) off = retOffset for i := 0; i \u0026lt; nout; i++ { tv := t.Out(i) a := uintptr(tv.Align()) off = (off + a - 1) \u0026amp;^ (a - 1) if tv.Size() != 0 { fl := flagIndir | flag(tv.Kind()) ret[i] = Value{tv.common(), add(args, off, \u0026#34;tv.Size() != 0\u0026#34;), fl} } else { ret[i] = Zero(tv) } off += tv.Size() } } return ret } 由reflect.Value 构成的ret数组会被返回到调用方，到这里为止使用反射实现函数调用的过程就结束了。\n小结 Go语言的reflect 包为我们提供了多种能力，包括如何使用反射来动态修改变量、 判断类型是否实现了某些接口以及动态调用方法等功能，通过分析反射包中方法的原理能帮助我们理解之前看起来比较怪异、令人困惑的现象。\n参考  转载自Draveness Go语言设计与实现 4.3反射  ","date":"August 3, 2021","hero":"/posts/knowledge/2001-go/003-reflect/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2001-go/003-reflect/","summary":"#golang #reflect\n 反射简介  Golang提供了一种机制，在编译时不知道类型的情况下，可更新变量、运行时查看值、调用方法以及直接对他们的布局进行操作的机制，称为反射。\n  reflect 包中的官方注释：Package reflect implements run-time reflection, allowing a program to manipulate objects with arbitrary types. \n reflect 实现了运行时的反射能力，能够让程序操作不同类型的对象。反射包中有两对非常重要的函数和类型， 两个函数分别是：\n reflect.TypeOf 能获取类型信息 reflect.ValueOf 能获取数据的运行时表示  三大法则 运行时反射是程序在运行期间检查其自身结构的一种方式。反射带来的灵活性是一把双刃剑，反射作为一种元编程方式可以减少重复代码， 但是过量的使用反射会使我们的程序逻辑变得难以理解并且运行缓慢。我们在这一节中会介绍Go语言反射的三大法则，其中包括：\n 从interface{}变量可以反射出反射对象； 从反射对象可以获取interface{}变量； 要修改反射对象，其值必须可设置；  第一法则 反射的第一法则是我们能将Go语言的interface{}变量转换成反射对象。很多读者可能会对这以法则产生困惑—为什么是从interface{}变量到反射对象？ 当我们执行reflect.ValueOf(1)时，虽然看起来是获取了基本类型int对应的反射类型，但是由于 reflect.TypeOf 、 reflect.ValueOf 两个方法的入参都是interface{}类型，所以在方法执行的过程中发生了类型转换。\n因为Go语言的函数调用都是值传递的，所以变量会在函数调用时进行类型转换。基本类型int会转换成interface{}类型， 这也就是为什么第一条法则是从接口到反射对象。\n上面提到的reflect.TypeOf 和reflect.ValueOf 函数就能完成这里的转换，如果我们认为Go语言的类型和反射类型处于两个不同的世界，那么这两个函数就是连接这两个世界的桥梁。\n我们可以通过以下例子简单介绍它们的作用， reflect.TypeOf 获取了变量author的类型， reflect.ValueOf 获取了变量的值ormissia。如果我们知道了一个变量的类型和值，那么就意味着我们知道了这个变量的全部信息。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func main() { author := \u0026#34;ormissia\u0026#34; fmt.","tags":null,"title":"Golang反射"},{"categories":null,"contents":" #golang #reflect\n  A：\u0026ldquo;请用一句话让别人知道你写过Golang。\u0026rdquo;\nB：\u0026ldquo;if err!= nil \u0026hellip;\u0026rdquo;\n 起因 只要是接触过Golang的人，无不为其if err != nil的语法感到惊奇，或是大加赞赏，或是狠狠痛批。作为使用者，不管喜欢也好，反对也罢， 目前还是要接受这种错误处理模式。\n而最令人头痛的就是请求参数中各种值的校验。比如Get请求中接收分页参数时，需要将string格式的参数转换成int类型，再如时间类型的参数 转换， 诸如此类，等等等等。好家伙，一个接口写完if err != nil的判断占了一多半的行数，看着实在不爽。\n下面就是一个典型的例子，而且这个接口参数还不是特别多\nfunc Export(c *gin.Context) { //删除开头  //... \tvar param map[string]string err := c.ShouldBindJSON(\u0026amp;param) if err != nil { ErrRsponse(c,errCode) return } var vId, userId, userName, format string if v, ok := param[\u0026#34;vId\u0026#34;]; ok { vId = v } else { ErrRsponse(c,errCode) return } if len(vId) == 0 { ErrRsponse(c,errCode) return } if v, ok := param[\u0026#34;userId\u0026#34;]; ok { userId = v } else { ErrRsponse(c,errCode) return } if v, ok := param[\u0026#34;userName\u0026#34;]; ok { userName = v } else { ErrRsponse(c,errCode) return } if v, ok := param[\u0026#34;format\u0026#34;]; ok { format = v } else { ErrRsponse(c,errCode) return } if !file.IsOk(format) { ErrRsponse(c,errCode) return } //... \t//删除结尾 } 机遇 前几天在看GIN-VUE-ADMIN代码的时候，偶然看到一个通过反射去做参数校验的方式。 嘿，学到了！\n改变 定义规则 校验规则使用一个map存储，key为字段名，value为规则列表，并使用一个string类型的切片来存储。\n 后续计划加入tag标签定义规则的功能以及增加通过函数参数的方式，实现自定义规则校验\n type Rules map[string][]string 支持的规则有：\n 不为空 等于、不等于 大于、小于 大于等于、小于等于   对于数值类型为比较值大小，对于字符串或者切片等类型为比较长度大小\n 比如调用生成小于规则的方法，则会返回一个小于指定值规则的字符串，用于后面校验器使用\n// Lt \u0026lt; func (verifier verifier) Lt(limit string) string { return fmt.Sprintf(\u0026#34;%s%s%s\u0026#34;, lt, verifier.separator, limit) } 规则定义示例：\nUserRequestRules = go_opv.Rules{ \u0026#34;Name\u0026#34;: {myVerifier.NotEmpty(), myVerifier.Lt(\u0026#34;10\u0026#34;)}, \u0026#34;Age\u0026#34;: {myVerifier.Lt(\u0026#34;100\u0026#34;)}, } //map[Age:[lt#100] Name:[notEmpty lt#10]] 规则含义为Age字段长度或值小于100，Name字段不为空且长度或值小于10。\n验证器 先通过反射获取待检验参数的值和类型，判断是否为struct（目前只实现了对struct校验的功能，计划后续加入对map的校验功能）， 获取struct属性数量并遍历所有属性，并遍历每个字段下所有规则，对定义的每一个规则进行校验是否合格。\nfunc (verifier verifier) Verify(st interface{}, rules Rules) (err error) { typ := reflect.TypeOf(st) val := reflect.ValueOf(st) if val.Kind() != reflect.Struct { return errors.New(\u0026#34;expect struct\u0026#34;) } num := val.NumField() //遍历需要验证对象的所有字段 \tfor i := 0; i \u0026lt; num; i++ { tagVal := typ.Field(i) val := val.Field(i) if len(rules[tagVal.Name]) \u0026gt; 0 { for _, v := range rules[tagVal.Name] { switch { case v == \u0026#34;notEmpty\u0026#34;: if isEmpty(val) { return errors.New(tagVal.Name + \u0026#34; value can not be nil\u0026#34;) } case verifier.conditions[strings.Split(v, verifier.separator)[0]]: if !compareVerify(val, v, verifier.separator) { return errors.New(tagVal.Name + \u0026#34; length or value is illegal,\u0026#34; + v) } } } } } return nil } 规则校验有两种，分别是判空 和条件校验。\n判空是通过反射reflect.Value获得字段值，并通过反射value.Kind()获得字段类型。 最终使用switch分别对不同类型 字段进行判断。\nfunc isEmpty(value reflect.Value) bool { switch value.Kind() { case reflect.String: return value.Len() == 0 case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64: return value.Int() == 0 //此处省略其他类型判断 \t//... \t} return reflect.DeepEqual(value.Interface(), reflect.Zero(value.Type()).Interface()) } 条件校验则是通过开始时定义的范围条件进行校验，传入反射reflect.Value获得字段值，定义的规则，以及规则中的分隔符。先通过switch判断其类型， 再通过switch判断条件是大于小于或是其他条件，然后进行相应判断。\nfunc compareVerify(value reflect.Value, verifyStr, separator string) bool { switch value.Kind() { case reflect.String, reflect.Slice, reflect.Array: return compare(value.Len(), verifyStr, separator) //此处省略其他类型判断 \t//... \tdefault: return false } } 封装 为了调用方便，做了一层封装，使用函数选项模式对校验器进行封装，使调用更为方便。\nvar defaultVerifierOptions = verifierOptions{ separator: \u0026#34;:\u0026#34;, conditions: map[string]bool{ eq: true, ne: true, gt: true, lt: true, ge: true, le: true, }, } type VerifierOption func(o *verifierOptions) type verifierOptions struct { conditions map[string]bool separator string } // SetSeparator Default separator is \u0026#34;:\u0026#34;. func SetSeparator(seq string) VerifierOption { return func(o *verifierOptions) { o.separator = seq } } func SwitchEq(sw bool) VerifierOption { return func(o *verifierOptions) { o.conditions[eq] = sw } } //... //此处省略其他参数的设置  type Verifier interface { Verify(obj interface{}, rules Rules) (err error) NotEmpty() string Ne(limit string) string Gt(limit string) string Lt(limit string) string Ge(limit string) string Le(limit string) string } type verifier struct { separator string conditions map[string]bool } func NewVerifier(opts ...VerifierOption) Verifier { options := defaultVerifierOptions for _, opt := range opts { opt(\u0026amp;options) } return verifier{ separator: options.separator, conditions: options.conditions, } } //... //此处省略接口的实现 发布  好了，基本功能完成了，如果仅仅是放在每个项目的utils拷来拷去，显然十分的不优雅。\n那么这就需要发布到pkg.go.dev才能通过go get命令正常被其他项目所引用。\n  首先是git commit、git push一把梭将项目整到GitHub上。 由于pkg.go.dev的版本管理机制需要给项目打上tag，git tag v0.0.1基础版本，😋先定个0.0.1吧， 然后git push再走一遍。 当然这时候还没完，需要自己go get一下，加上GitHub仓库名执行一下go get github.com/ormissia/go-opv 这样仓库就可以正常被引用了。而且用不了多久，就可以从pkg.go.dev上搜到相应的项目了。 最后贴一下次项目的连接：go-opv   当然，这个过程中也遇到过小坑。项目中go.mod中的模块名需要写GitHub的仓库地址，对应此项目即为module github.com/ormissia/go-opv。 如果项目版本有更新，打了新的tag之后。可以通过go get github.com/ormissia/go-opv@v0.0.3拉取指定版本，目前尚不清楚 pkg.go.dev是否会自动同步GitHub上最新的tag。\n 检验 测试用例？\n好吧，// TODO\n 老铁看到底了，来个star吧😁\n↓↓↓↓↓↓↓↓↓\nGitHub仓库\n ","date":"July 27, 2021","hero":"/posts/knowledge/2001-go/002-param-verify/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2001-go/002-param-verify/","summary":"#golang #reflect\n  A：\u0026ldquo;请用一句话让别人知道你写过Golang。\u0026rdquo;\nB：\u0026ldquo;if err!= nil \u0026hellip;\u0026rdquo;\n 起因 只要是接触过Golang的人，无不为其if err != nil的语法感到惊奇，或是大加赞赏，或是狠狠痛批。作为使用者，不管喜欢也好，反对也罢， 目前还是要接受这种错误处理模式。\n而最令人头痛的就是请求参数中各种值的校验。比如Get请求中接收分页参数时，需要将string格式的参数转换成int类型，再如时间类型的参数 转换， 诸如此类，等等等等。好家伙，一个接口写完if err != nil的判断占了一多半的行数，看着实在不爽。\n下面就是一个典型的例子，而且这个接口参数还不是特别多\nfunc Export(c *gin.Context) { //删除开头  //... \tvar param map[string]string err := c.ShouldBindJSON(\u0026amp;param) if err != nil { ErrRsponse(c,errCode) return } var vId, userId, userName, format string if v, ok := param[\u0026#34;vId\u0026#34;]; ok { vId = v } else { ErrRsponse(c,errCode) return } if len(vId) == 0 { ErrRsponse(c,errCode) return } if v, ok := param[\u0026#34;userId\u0026#34;]; ok { userId = v } else { ErrRsponse(c,errCode) return } if v, ok := param[\u0026#34;userName\u0026#34;]; ok { userName = v } else { ErrRsponse(c,errCode) return } if v, ok := param[\u0026#34;format\u0026#34;]; ok { format = v } else { ErrRsponse(c,errCode) return } if !","tags":null,"title":"Golang 实体参数校验"},{"categories":null,"contents":" #golang\n  作为 Golang 开发者，遇到的许多问题之一就是尝试将函数的参数设置成可选项。这是一个十分常见的场景，您可以使用一些已经设置默认配置和开箱即用的对象，同时您也可以使用一些更为详细的配置。\n 问题出发点 对于许多编程语言来说，这很容易。在 C 语言家族中，您可以提供具有同一个函数但是不同参数的多个版本；在 PHP 之类的语言中，您可以为参数提供默认值，并在调用该方法时将其忽略。但是在 Golang 中，上述的做法都不可以使用。那么您如何创建具有一些其他配置的函数，用户可以根据他的需求（但是仅在需要时）指定一些额外的配置。\n有很多的方法可以做到这一点，但是大多数方法都不是尽如人意，要么需要在服务端的代码中进行大量额外的检查和验证，要么通过传入他们不关心的其他参数来为客户端进行额外的工作。\n下面我将会介绍一些不同的选项，然后为其说明为什么每个选项都不理想，接着我们会逐步构建自己的方式来作为最终的干净解决方案：函数选项模式。\n让我们来看一个例子。比方说，这里有一个叫做StuffClient的服务，它能够胜任一些工作，同时还具有两个配置选项（超时和重试）。\ntype StuffClient interface { DoStuff() error } type stuffClient struct { conn Connection timeout int retries int } 这是个私有的结构体，因此我们应该为它提供某种构造函数：\nfunc NewStuffClient(conn Connection, timeout, retries int) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: timeout, retries: retries, } } 嗯，但是现在我们每次调用NewStuffClient函数时都要提供timeout和retries。因为在大多数情况下，我们只想使用默认值，我们无法使用不同参数数量带定义多个版本的NewStuffClient，否则我们会得到一个类似NewStuffClient redeclared in this block编译错误。\n一个可选方案是创建另一个具有不同名称的构造函数，例如：\nfunc NewStuffClient(conn Connection) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: DEFAULT_TIMEOUT, retries: DEFAULT_RETRIES, } } func NewStuffClientWithOptions(conn Connection, timeout, retries int) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: timeout, retries: retries, } } 但是这么做的话有点蹩脚。我们可以做得更好，如果我们传入了一个配置对象呢:\ntype StuffClientOptions struct { Retries int //number of times to retry the request before giving up  Timeout int //connection timeout in seconds } func NewStuffClient(conn Connection, options StuffClientOptions) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: options.Timeout, retries: options.Retries, } } 但是，这也不是很好的做法。现在，我们总是需要创建StuffClientOption这个结构体，即使不想在指定任何选项时还要传递它。另外我们也没有自动填充默认值，除非我们在代码中的某处添加了一堆检查，或者也可以传入一个DefaultStuffClientOptions变量（不过这么做也不好，因为在修改某一处地方后可能会导致其他的问题。）\n所以，更好的解决方法是什么呢？解决这个难题最好的解决方法是使用函数选项模式，它利用了Go对闭包更加方便的支持。让我们保留上述定义的StuffClientOptions，不过我们仍需要为其添加一些内容。\ntype StuffClientOption func(*StuffClientOptions) type StuffClientOptions struct { Retries int //number of times to retry the request before giving up \tTimeout int //connection timeout in seconds } func WithRetries(r int) StuffClientOption { return func(o *StuffClientOptions) { o.Retries = r } } func WithTimeout(t int) StuffClientOption { return func(o *StuffClientOptions) { o.Timeout = t } } 泥土般芬芳, 不是吗？这到底是怎么回事？基本上，我们有一个结构来定义StuffClient的可用选项。另外，现状我们还定义了一个叫做StuffClientOption的东西（次数是单数），它只是接受我们选项的结构体作为参数的函数。我们还定义了另外两个函数WithRetries和WithTimeout，它们返回一个闭包，现在就是见证奇迹的时刻了！\nvar defaultStuffClientOptions = StuffClientOptions{ Retries: 3, Timeout: 2, } func NewStuffClient(conn Connection, opts ...StuffClientOption) StuffClient { options := defaultStuffClientOptions for _, o := range opts { o(\u0026amp;options) } return \u0026amp;stuffClient{ conn: conn, timeout: options.Timeout, retries: options.Retries, } } 现在，我们定义了一个额外和包含默认选项的没有导出的变量，同时我们已经调整了构造函数，用来接收可变参数。然后, 我们遍历StuffClientOption列表(单数)，针对每一个列表，将列表中返回的闭包使用在我们的options变量（需要记住，这些闭包接收一个StuffClientOptions变量，仅需要在选项的值上做出少许修改）。\n现在我们要做的事情就是使用它！\nx := NewStuffClient(Connection{}) fmt.Println(x) // prints \u0026amp;{{} 2 3} x = NewStuffClient( Connection{}, WithRetries(1), ) fmt.Println(x) // prints \u0026amp;{{} 2 1} x = NewStuffClient( Connection{}, WithRetries(1), WithTimeout(1), ) fmt.Println(x) // prints \u0026amp;{{} 1 1} 函数选项模式 这看起来相当不错，已经可以使用了！而且，它的好处是，我们只需要对代码进行很少的修改，就可以随时随地添加新的选项。\n把这些修改放在一起，就是这样：\nvar defaultStuffClientOptions = StuffClientOptions{ Retries: 3, Timeout: 2, } type StuffClientOption func(*StuffClientOptions) type StuffClientOptions struct { Retries int //number of times to retry the request before giving up \tTimeout int //connection timeout in seconds } func WithRetries(r int) StuffClientOption { return func(o *StuffClientOptions) { o.Retries = r } } func WithTimeout(t int) StuffClientOption { return func(o *StuffClientOptions) { o.Timeout = t } } type StuffClient interface { DoStuff() error } type stuffClient struct { conn Connection timeout int retries int } type Connection struct{} func NewStuffClient(conn Connection, opts ...StuffClientOption) StuffClient { options := defaultStuffClientOptions for _, o := range opts { o(\u0026amp;options) } return \u0026amp;stuffClient{ conn: conn, timeout: options.Timeout, retries: options.Retries, } } func (c stuffClient) DoStuff() error { return nil } 但这也可以通过删除StuffClientOptions结构体进一步简化，并将选项直接应用在我们的StuffClient上。\nvar defaultStuffClient = stuffClient{ retries: 3, timeout: 2, } type StuffClientOption func(*stuffClient) func WithRetries(r int) StuffClientOption { return func(o *stuffClient) { o.retries = r } } func WithTimeout(t int) StuffClientOption { return func(o *stuffClient) { o.timeout = t } } type StuffClient interface { DoStuff() error } type stuffClient struct { conn Connection timeout int retries int } type Connection struct{} func NewStuffClient(conn Connection, opts ...StuffClientOption) StuffClient { client := defaultStuffClient for _, o := range opts { o(\u0026amp;client) } client.conn = conn return client } func (c stuffClient) DoStuff() error { return nil } 在我们的示例中，我们只是将配置直接应用于结构体中，如果中间有一个额外的结构体是没有意义的。但是，请注意，在许多情况下，您可能仍然想使用上一个示例中的config结构。例如，如果您的构造函数正在使用config选项执行某些操作时，但是并没有将它们存储到结构体中，或者被传递到其他地方，配置结构的变体是更通用的实现。\n转载自此处\n","date":"July 22, 2021","hero":"/posts/knowledge/2001-go/001-partten-1/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2001-go/001-partten-1/","summary":"#golang\n  作为 Golang 开发者，遇到的许多问题之一就是尝试将函数的参数设置成可选项。这是一个十分常见的场景，您可以使用一些已经设置默认配置和开箱即用的对象，同时您也可以使用一些更为详细的配置。\n 问题出发点 对于许多编程语言来说，这很容易。在 C 语言家族中，您可以提供具有同一个函数但是不同参数的多个版本；在 PHP 之类的语言中，您可以为参数提供默认值，并在调用该方法时将其忽略。但是在 Golang 中，上述的做法都不可以使用。那么您如何创建具有一些其他配置的函数，用户可以根据他的需求（但是仅在需要时）指定一些额外的配置。\n有很多的方法可以做到这一点，但是大多数方法都不是尽如人意，要么需要在服务端的代码中进行大量额外的检查和验证，要么通过传入他们不关心的其他参数来为客户端进行额外的工作。\n下面我将会介绍一些不同的选项，然后为其说明为什么每个选项都不理想，接着我们会逐步构建自己的方式来作为最终的干净解决方案：函数选项模式。\n让我们来看一个例子。比方说，这里有一个叫做StuffClient的服务，它能够胜任一些工作，同时还具有两个配置选项（超时和重试）。\ntype StuffClient interface { DoStuff() error } type stuffClient struct { conn Connection timeout int retries int } 这是个私有的结构体，因此我们应该为它提供某种构造函数：\nfunc NewStuffClient(conn Connection, timeout, retries int) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: timeout, retries: retries, } } 嗯，但是现在我们每次调用NewStuffClient函数时都要提供timeout和retries。因为在大多数情况下，我们只想使用默认值，我们无法使用不同参数数量带定义多个版本的NewStuffClient，否则我们会得到一个类似NewStuffClient redeclared in this block编译错误。\n一个可选方案是创建另一个具有不同名称的构造函数，例如：\nfunc NewStuffClient(conn Connection) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: DEFAULT_TIMEOUT, retries: DEFAULT_RETRIES, } } func NewStuffClientWithOptions(conn Connection, timeout, retries int) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: timeout, retries: retries, } } 但是这么做的话有点蹩脚。我们可以做得更好，如果我们传入了一个配置对象呢:","tags":null,"title":"Go 惯用模式：函数选项模式"},{"categories":null,"contents":"   博客后端使用Golang重构之后使用GitHub-DockerHub-Jenkins自动打包部署流程\n  虽然说Golang打包生成的是二进制可执行文件，不需要像JAVA一样部署环境变量，但依然也是需要打包的流程。由于考虑到在不(hen)久(yuan)的将来可能做成简单的微服务程序，又要使用Docker部署，所以在这就直接使用Docker镜像的方式来部署运行。\n 本地代码→GitHub 这一步是通过git commit-git push或是直接使用IDE将代码托管到GitHub上。 在这一步的同时需要编写Dockerfile文件，用来指定Docker镜像打包时的各种参数\n# Go程序编译之后会得到一个可执行的二进制文件，其实在最终的镜像中是不需要go编译器的，也就是说我们只需要一个运行最终二进制文件的容器即可。# 作为别名为\u0026#34;builder\u0026#34;的编译镜像，下面会用到FROMgolang AS builder# 为镜像设置必要的环境变量ENV GO111MODULE=on \\  CGO_ENABLED=0 \\  GOOS=linux \\  GOARCH=amd64 \\  GOPROXY=https://goproxy.cn# 设置工作目录：/buildWORKDIR/build# 复制项目中的 go.mod 和 go.sum文件并下载依赖信息COPY go.mod .COPY go.sum .RUN go mod download# 将代码复制到容器中COPY 2021-03-04T18:02:29 .# 将代码编译成二进制可执行文件appRUN go build -o go-blog-app .#################### 接下来创建一个小镜像###################FROMscratch# 设置程序运行时必要的环境变量，包括监听端口、数据库配置等等ENV SERVER_PORT=8085 \\  DATASOURCE_DRIVERNAME=mysql \\  DATASOURCE_HOST=192.168.13.110 \\  DATASOURCE_PORT=3306 \\  DATASOURCE_DATABASE=blog \\  DATASOURCE_USERNAME=root \\  DATASOURCE_PASSWORD=5KvA82*Ziq \\  DATASOURCE_CHARSET=utf8mb4# 从builder镜像中把/dist/app 拷贝到当前目录COPY --from=builder /build/go-blog-app /# 声明服务端口EXPOSE8085# 启动容器时运行的命令ENTRYPOINT [\u0026#34;/go-blog-app\u0026#34;]GitHub→Docker Hub 这一步是将GitHub上的代码打包成Docker镜像并将镜像托管到Docker Hub上，我在这里使用的是使用Docker Hub来自动打包Docker镜像。也有另一种方式是GitHub通过设置好的Webhooks来通知Jenkins等CI/CD工具来拉取代码在自己的服务器上打包Docker镜像再上传到Docker Hub或是其他Docker镜像管理工具上，由于自己的这个项目代码更新比较慢，可以容忍提交代码之后有较长的时间来更新到线上环境中，所以就采用了Docker官方的打包功能。\n 首先要有一个Docker Hub的账号  将GitHub账号关联到Docker Hub账号上  创建Docker仓库并且与GitHub仓库绑定  打开Docker Hub的仓库创建页面 添加仓库名称 选择GitHub作为代码仓库 选择要打包Docker镜像的GitHub仓库 添加Docker镜像打包规则  可以选择按git push到指定分支或者是git push一个git tag来触发build动作 可以指定Docker镜像的Tag 可以指定用于打包Docker镜像的Dockerfile文件 可以开关Docker镜像打包的缓存      创建好Docker仓库之后再去GitHub仓库的setting页面中就会发现多了一个Webhook的设置  每当GitHub仓库里触发了指定条件之后就会通过这个Webhook通知到Docker Hub触发对应的镜像打包动作，当然打包动作也可以手动触发   Docker Hub→服务器生产环境 这一步是将Docker Hub上已经打包好的Docker镜像部署到生产服务器上。\n 在Docker Hub仓库中添加Webhook，首先需要有自己的CI/CD服务，我这里用的时搭在自己服务器上的Jenkins(搭建流程)。当然理论上应该也可以使用GitHub上一些CI/CD应用，我没有深入了解就不赘述了。   未完待续。。。 由于时间比较紧，Docker Hub→服务器生产环境这一步还没有实际操作，目前还是docker pull→docker run 不过基于已经线上运行很久的前端VUE项目的自动部署流程，理论上这一步应该是可行的 ","date":"March 3, 2021","hero":"/posts/deployment/3001-blog-cicd/head.svg","permalink":"https://ormissia.github.io/posts/deployment/3001-blog-cicd/","summary":"博客后端使用Golang重构之后使用GitHub-DockerHub-Jenkins自动打包部署流程\n  虽然说Golang打包生成的是二进制可执行文件，不需要像JAVA一样部署环境变量，但依然也是需要打包的流程。由于考虑到在不(hen)久(yuan)的将来可能做成简单的微服务程序，又要使用Docker部署，所以在这就直接使用Docker镜像的方式来部署运行。\n 本地代码→GitHub 这一步是通过git commit-git push或是直接使用IDE将代码托管到GitHub上。 在这一步的同时需要编写Dockerfile文件，用来指定Docker镜像打包时的各种参数\n# Go程序编译之后会得到一个可执行的二进制文件，其实在最终的镜像中是不需要go编译器的，也就是说我们只需要一个运行最终二进制文件的容器即可。# 作为别名为\u0026#34;builder\u0026#34;的编译镜像，下面会用到FROMgolang AS builder# 为镜像设置必要的环境变量ENV GO111MODULE=on \\  CGO_ENABLED=0 \\  GOOS=linux \\  GOARCH=amd64 \\  GOPROXY=https://goproxy.cn# 设置工作目录：/buildWORKDIR/build# 复制项目中的 go.mod 和 go.sum文件并下载依赖信息COPY go.mod .COPY go.sum .RUN go mod download# 将代码复制到容器中COPY 2021-03-04T18:02:29 .# 将代码编译成二进制可执行文件appRUN go build -o go-blog-app .#################### 接下来创建一个小镜像###################FROMscratch# 设置程序运行时必要的环境变量，包括监听端口、数据库配置等等ENV SERVER_PORT=8085 \\  DATASOURCE_DRIVERNAME=mysql \\  DATASOURCE_HOST=192.168.13.110 \\  DATASOURCE_PORT=3306 \\  DATASOURCE_DATABASE=blog \\  DATASOURCE_USERNAME=root \\  DATASOURCE_PASSWORD=5KvA82*Ziq \\  DATASOURCE_CHARSET=utf8mb4# 从builder镜像中把/dist/app 拷贝到当前目录COPY --from=builder /build/go-blog-app /# 声明服务端口EXPOSE8085# 启动容器时运行的命令ENTRYPOINT [\u0026#34;/go-blog-app\u0026#34;]GitHub→Docker Hub 这一步是将GitHub上的代码打包成Docker镜像并将镜像托管到Docker Hub上，我在这里使用的是使用Docker Hub来自动打包Docker镜像。也有另一种方式是GitHub通过设置好的Webhooks来通知Jenkins等CI/CD工具来拉取代码在自己的服务器上打包Docker镜像再上传到Docker Hub或是其他Docker镜像管理工具上，由于自己的这个项目代码更新比较慢，可以容忍提交代码之后有较长的时间来更新到线上环境中，所以就采用了Docker官方的打包功能。","tags":null,"title":"我的博客后端Docker镜像打包自动部署流程"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"}]