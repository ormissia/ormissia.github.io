[{"categories":null,"contents":"基础类型内存宽度以及表示范围 bool\n1Byte true/false uint8\n1Byte 0-255 uint16\n2Byte 0-65535 uint32\n4Byte 0-4294967295 uint64\n8Byte 0-18446744073709551615 int8\n1Byte -128-127 int16\n2Byte -32768-32767 int32\n4Byte -2147483648-2147483647 int64\n6Byte -9223372036854775808-9223372036854775807 byte\n1Byte 类似 uint8 rune\n4Byte 类似 int32 uint\n4Byte / 8Byte 32 或 64 位 int\n4Byte / 8Byte 与 uint 一样大小 float32\n4Byte float64\n8Byte string\n1Byte （英文） / 2Byte-4Byte（中文，取决于字符编码类型）     切片拼接 slice1 := []int{0, 1, 2, 3} slice2 := []int{3, 4, 5} slice1 = append(slice1, slice2...) fmt.Println(slice1) //[0 1 2 3 3 4 5]     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/go/basic/basic/","summary":"基础类型内存宽度以及表示范围 bool\n1Byte true/false uint8\n1Byte 0-255 uint16\n2Byte 0-65535 uint32\n4Byte 0-4294967295 uint64\n8Byte 0-18446744073709551615 int8\n1Byte -128-127 int16\n2Byte -32768-32767 int32\n4Byte -2147483648-2147483647 int64\n6Byte -9223372036854775808-9223372036854775807 byte\n1Byte 类似 uint8 rune\n4Byte 类似 int32 uint\n4Byte / 8Byte 32 或 64 位 int\n4Byte / 8Byte 与 uint 一样大小 float32\n4Byte float64\n8Byte string\n1Byte （英文） / 2Byte-4Byte（中文，取决于字符编码类型）     切片拼接 slice1 := []int{0, 1, 2, 3} slice2 := []int{3, 4, 5} slice1 = append(slice1, slice2.","tags":null,"title":"Basic"},{"categories":null,"contents":"时间转换 字符串转时间\ntime.Parse() 时间转字符串\ntime.Format() 时间转时间戳\nTime.Unix() 时间戳转时间\ntime.Unix()     计时 朴素方法\nstartTime := time.Now() //do something \ttime.Sleep(time.Second) duration := time.Since(startTime) fmt.Printf(\u0026#34;经过时间：%v\\n\u0026#34;, duration) //经过时间：1.005046959s   简洁方法\n// TimeCost 耗时统计函数 func TimeCost(start time.Time) { duration := time.Since(start) fmt.Printf(\u0026#34;经过时间：%v\\n\u0026#34;, duration) } defer TimeCost(time.Now()) //do something \ttime.Sleep(time.Second) //经过时间：1.005054375s   优雅方法\n// TimeCost 耗时统计函数 func TimeCost() func() { start := time.Now() return func() { duration := time.Since(start) fmt.Printf(\u0026#34;经过时间：%v\\n\u0026#34;, duration) } } defer TimeCost()() //do something \ttime.Sleep(time.Second) //经过时间：1.005033916s     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/go/advance/time/","summary":"时间转换 字符串转时间\ntime.Parse() 时间转字符串\ntime.Format() 时间转时间戳\nTime.Unix() 时间戳转时间\ntime.Unix()     计时 朴素方法\nstartTime := time.Now() //do something \ttime.Sleep(time.Second) duration := time.Since(startTime) fmt.Printf(\u0026#34;经过时间：%v\\n\u0026#34;, duration) //经过时间：1.005046959s   简洁方法\n// TimeCost 耗时统计函数 func TimeCost(start time.Time) { duration := time.Since(start) fmt.Printf(\u0026#34;经过时间：%v\\n\u0026#34;, duration) } defer TimeCost(time.Now()) //do something \ttime.Sleep(time.Second) //经过时间：1.005054375s   优雅方法\n// TimeCost 耗时统计函数 func TimeCost() func() { start := time.Now() return func() { duration := time.Since(start) fmt.","tags":null,"title":"time"},{"categories":null,"contents":"go get 下载指定版本 go get github.com/ormissia/go-opv@v0.0.2     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/go/advance/gomod/","summary":"go get 下载指定版本 go get github.com/ormissia/go-opv@v0.0.2     ","tags":null,"title":"go mod"},{"categories":null,"contents":"异或  异或运算法则：无进位相加 异或运算性质：  0 ^ N = N N ^ N = 0 满足交换律和结合律    a := 0b1100 b := 0b1001 fmt.Printf(\u0026#34;%b\u0026#34;,a^b) //101 简单应用：不申请额外内存交换两个变量的值\na := 0b1100 b := 0b1001 a = a ^ b b = a ^ b //b = (a ^ b) ^ b = a a = a ^ b //a = (a ^ b) ^ a = b fmt.Printf(\u0026#34;a:%b,b:%b\u0026#34;, a, b) //a:1001,b:1100     堆  堆的实质是一棵完全二叉树\n 堆可分为两种类型：\n 大根堆：所有子树的根节点均为最大值 小根堆：所有子树的根节点均为最小值  一般情况下堆可以用一个有序数组来存储\n[0\u0026hellip;i\u0026hellip;n] i节点的左孩子index为2*i+1，右孩子为2i+2，父节点为(i-1)/2\n也有一种特例是从1开始(位运算比加减法快)\n[01\u0026hellip;i\u0026hellip;n] i节点的左孩子index为2*i即i\u0026lt;\u0026lt;1，右孩子为2i+1即i\u0026lt;\u0026lt;1|1，父节点为i/2\n 堆的基本操作：  上浮 下沉   堆的插入弹出  插入  在最后插入节点 依次上浮   弹出  弹出根节点 将最后一个节点放入根节点 将根节点下沉     堆排序  依次弹出根节点        ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/go/algorithm/basic/","summary":"异或  异或运算法则：无进位相加 异或运算性质：  0 ^ N = N N ^ N = 0 满足交换律和结合律    a := 0b1100 b := 0b1001 fmt.Printf(\u0026#34;%b\u0026#34;,a^b) //101 简单应用：不申请额外内存交换两个变量的值\na := 0b1100 b := 0b1001 a = a ^ b b = a ^ b //b = (a ^ b) ^ b = a a = a ^ b //a = (a ^ b) ^ a = b fmt.Printf(\u0026#34;a:%b,b:%b\u0026#34;, a, b) //a:1001,b:1100     堆  堆的实质是一棵完全二叉树","tags":null,"title":"Basic"},{"categories":null,"contents":"Strings test\nString str = \u0026#34;123\u0026#34;;     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/java/basic/basic_type/","summary":"Strings test\nString str = \u0026#34;123\u0026#34;;     ","tags":null,"title":"Basic Types"},{"categories":null,"contents":"函数 函数参数为val类型，且可以给出默认值\ndef test(a: Int, b: Int = 1, c: Int = 2): Unit = { println(s\u0026quot;$a $b $c\u0026quot;) } test(1, 2) //1 2 2 test(1, c = 4) //1 1 4     匿名函数 函数是带有参数的表达式。\n(x: Int) =\u0026gt; x + 1     方法 方法的表现和行为和函数非常类似，但是它们之间有一些关键的差别。\n方法由def关键字定义。def后面跟着一个名字、参数列表、返回类型和方法体。\ndef addThenMultiply(x: Int, y: Int)(multiplier: Int): Int = (x + y) * multiplier println(addThenMultiply(1, 2)(3)) // 9     字符串拼接 val a = 1 val b = 2 val c = s\u0026quot;$a+$b=${a + b}\u0026quot;     对象 约等于static单例对象\nobject TestObj { def main(args: Array[String]): Unit = { val a = 1 val b = 2 val c = s\u0026quot;$a+$b=${a + b}\u0026quot; println(c) } }     类 可以使用class关键字定义一个类，后面跟着它的名字和构造参数。\n 类里裸露的代码是默认构造中的 类名构造器中的参数就是类的成员属性，默认是val类型，且是private 只有在类名构造器中的参数可以设置成var，其他方法函数中的参数都是val类型的，且不允许设置成var类型  class Greeter(prefix: String, var suffix: String) { var name = \u0026quot;name\u0026quot; def greet(name: String): Unit = println(prefix + name + suffix) }     循环 scala中嵌套for循环可以写到一起，循环上可以加守卫（条件）。 循环结果可以通过yield收集到一个集合中\n// val value = for (i \u0026lt;- 1 to 9; j \u0026lt;- 1 to i) yield { val value = for (i \u0026lt;- 1 to 9; j \u0026lt;- 1 to 10 if (j \u0026lt;= i)) yield { i * j } for (i \u0026lt;- value) { println(i) }     偏应用函数 类似于重新封装一下函数\ndef log(date: Date, logType: String, msg: String): Unit = { println(s\u0026quot;$date\\t$logType\\t$msg\u0026quot;) } val info = log(_, \u0026quot;info\u0026quot;, _) info(new Date, \u0026quot;this is a info msg\u0026quot;) //Thu Jul 22 23:14:04 CST 2021\tinfo\tthis is a info msg     可变长度参数以及foreach def foreachTest(a: Int*): Unit = { //for (i \u0026lt;- a) { // print(i) //} //a.foreach((x: Int) =\u0026gt; { // print(x) //}) //a.foreach(print(_)) a.foreach(print) } foreachTest(1, 2, 3, 4, 5) //12345     高阶函数 函数作为参数\ndef computer(a: Int, b: Int, f: (Int, Int) =\u0026gt; Int): Unit = { val res = f(a, b) println(res) } computer(1, 2, (x: Int, y: Int) =\u0026gt; {x + y}) //3 computer(1, 2, _ + _) //3   函数作为返回值\ndef factory(i: String): (Int, Int) =\u0026gt; Int = { def plus(x: Int, y: Int): Int = { x + y } if (i.equals(\u0026quot;+\u0026quot;)) { plus } else { _ * _ } } val plus = factory(\u0026quot;+\u0026quot;) computer(1,2,plus) //3     柯里化 多个参数列表\ndef testFunc(a:Int*)(b:Int*)(c:String*): Unit ={ a.foreach(print) b.foreach(print) c.foreach(print) } testFunc(1,2,3)(2,3,4)(\u0026quot;3\u0026quot;,\u0026quot;4\u0026quot;,\u0026quot;5\u0026quot;) //123234345     数组 数组 scala中泛型是[]，数组用()\nval约等于final，不可变描述的是val指定的引用（字面值、地址）\nval arr1 = Array[Int](1, 2, 3) arr1(1) = 99 println(arr1(1)) //99   遍历\n for (elem \u0026lt;- arr1) {} //foreach需要函数接收元素 arr1.foreach(println)     链表 scala中collections中有两个包：immutable,mutable，默认是不可变的immutable\nval list1 = List(1, 2, 3, 4) //++ += ++: :++ val list2 = new ListBuffer[Int] list2.+=(1) list2.+=(2) list2.+=(3)   val list1 = List(1, 2, 3, 4) val list2 = list1.map(_ * 2) list2.foreach(print) //2468     Set Set\n不可变的\nval set1 = Set(1, 2, 3, 4, 1, 2) //1 2 3 4   可变的\nval set2 = mutable.Set(1, 2, 3, 4, 1, 2) set2.add(1) set2.add(5) //1 2 3 4 5     Map Map\nval map1 = Map((\u0026quot;a\u0026quot;, 1), \u0026quot;b\u0026quot; -\u0026gt; 2, (\u0026quot;c\u0026quot;, 3), (\u0026quot;a\u0026quot;, 4)) map1.foreach(print) //(a,4)(b,2)(c,3) println(map1.get(\u0026quot;a\u0026quot;)) //Some(4) println(map1.get(\u0026quot;d\u0026quot;)) //None println(map1.getOrElse(\u0026quot;a\u0026quot;, \u0026quot;test\u0026quot;)) //4 println(map1.getOrElse(\u0026quot;d\u0026quot;, \u0026quot;test\u0026quot;)) //test val keys = map1.keys keys.foreach(println)   遍历\nfor (m \u0026lt;- map1) { print(s\u0026quot;$m\u0026quot;) } for (k \u0026lt;- keys) { print(s\u0026quot;($k,${map1(k)})\u0026quot;) }   可变的\nval map2 = mutable.Map((\u0026quot;a\u0026quot;, 1), \u0026quot;b\u0026quot; -\u0026gt; 2, (\u0026quot;c\u0026quot;, 3), (\u0026quot;a\u0026quot;, 4)) map2.put(\u0026quot;a\u0026quot;, 5)     案例类     模式匹配     特质     偏函数     隐式转换     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/scala/basic/basic_type/","summary":"函数 函数参数为val类型，且可以给出默认值\ndef test(a: Int, b: Int = 1, c: Int = 2): Unit = { println(s\u0026quot;$a $b $c\u0026quot;) } test(1, 2) //1 2 2 test(1, c = 4) //1 1 4     匿名函数 函数是带有参数的表达式。\n(x: Int) =\u0026gt; x + 1     方法 方法的表现和行为和函数非常类似，但是它们之间有一些关键的差别。\n方法由def关键字定义。def后面跟着一个名字、参数列表、返回类型和方法体。\ndef addThenMultiply(x: Int, y: Int)(multiplier: Int): Int = (x + y) * multiplier println(addThenMultiply(1, 2)(3)) // 9     字符串拼接 val a = 1 val b = 2 val c = s\u0026quot;$a+$b=${a + b}\u0026quot;     对象 约等于static单例对象","tags":null,"title":"Basic Types"},{"categories":null,"contents":"函数 在 python 中，类型属于对象，变量是没有类型的：\na=[1,2,3] a=\u0026#34;ormissia\u0026#34; 以上代码中，[1,2,3]是List类型，\u0026quot;ormissia\u0026quot;是String类型，而变量a是没有类型，他仅仅是一个对象的引用（一个指针），可以是指向List类型对象，也可以是指向String类型对象。\n可更改(mutable)与不可更改(immutable)对象 在python中，strings，tuples和numbers是不可更改的对象，而list，dict等则是可以修改的对象。\n  不可变类型：变量赋值a=5后再赋值a=10，这里实际是新生成一个int值对象10，再让a指向它，而5被丢弃，不是改变a的值，相当于新生成了a。\n  可变类型：变量赋值la = [1,2,3,4]后再赋值la[2] = 5则是将list la的第三个元素值更改，本身la没有动，只是其内部的一部分值被修改了。\n  python函数的参数传递：   不可变类型：类似C++的值传递，如整数、字符串、元组。如fun(a)，传递的只是a的值，没有影响a对象本身。如果在fun(a)内部修改a的值，则是新生成一个a的对象。\n  可变类型：类似C++的引用传递，如列表，字典。如fun(la)，则是将la真正的传过去，修改后fun外部的la也会受影响\n  python中一切都是对象，严格意义我们不能说值传递还是引用传递，我们应该说传不可变对象和传可变对象。\n    ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/python/basic/basic/","summary":"函数 在 python 中，类型属于对象，变量是没有类型的：\na=[1,2,3] a=\u0026#34;ormissia\u0026#34; 以上代码中，[1,2,3]是List类型，\u0026quot;ormissia\u0026quot;是String类型，而变量a是没有类型，他仅仅是一个对象的引用（一个指针），可以是指向List类型对象，也可以是指向String类型对象。\n可更改(mutable)与不可更改(immutable)对象 在python中，strings，tuples和numbers是不可更改的对象，而list，dict等则是可以修改的对象。\n  不可变类型：变量赋值a=5后再赋值a=10，这里实际是新生成一个int值对象10，再让a指向它，而5被丢弃，不是改变a的值，相当于新生成了a。\n  可变类型：变量赋值la = [1,2,3,4]后再赋值la[2] = 5则是将list la的第三个元素值更改，本身la没有动，只是其内部的一部分值被修改了。\n  python函数的参数传递：   不可变类型：类似C++的值传递，如整数、字符串、元组。如fun(a)，传递的只是a的值，没有影响a对象本身。如果在fun(a)内部修改a的值，则是新生成一个a的对象。\n  可变类型：类似C++的引用传递，如列表，字典。如fun(la)，则是将la真正的传过去，修改后fun外部的la也会受影响\n  python中一切都是对象，严格意义我们不能说值传递还是引用传递，我们应该说传不可变对象和传可变对象。\n    ","tags":null,"title":"Basic"},{"categories":null,"contents":"函数     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/js/basic/basic/","summary":"函数     ","tags":null,"title":"Basic"},{"categories":null,"contents":"按年月日分组聚合 group by date_format(field_name, format); 根据format字符串格式化date值。下列修饰符可以被用在format字符串中：\n%M 月名字(January……December) %W 星期名字(Sunday……Saturday) %D 有英语前缀的月份的日期(1st, 2nd, 3rd, 等等。） %Y 年, 数字, 4 位 %y 年, 数字, 2 位 %a 缩写的星期名字(Sun……Sat) %d 月份中的天数, 数字(00……31) %e 月份中的天数, 数字(0……31) %m 月, 数字(01……12) %c 月, 数字(1……12) %b 缩写的月份名字(Jan……Dec) %j 一年中的天数(001……366) %H 小时(00……23) %k 小时(0……23) %h 小时(01……12) %I 小时(01……12) %l 小时(1……12) %i 分钟, 数字(00……59) %r 时间,12 小时(hh:mm:ss [AP]M) %T 时间,24 小时(hh:mm:ss) %S 秒(00……59) %s 秒(00……59) %p AM或PM %w 一个星期中的天数(0=Sunday ……6=Saturday ） %U 星期(0……52), 这里星期天是星期的第一天 %u 星期(0……52), 这里星期一是星期的第一天 %% 一个文字“%”     count统计不重复个数 select count(distinct (field_name)) from table_name     sum结果为null时置为0 SQL中使用sum统计总数时:sum(col_name)，如果某列不符合sum的条件（比如某列中含有NULL元素，或者不是数值类型，或者没有符合where条件的行），那么会返回NULL 有的时候不希望sum的结果为NULL，可以做如下的处理：\nSELECT COALESCE(sum(col_name), 0) FROM Table 此外还有ISNULL(SQL Server)，NVL(Oracle)以及IFNULL(MySQL)的用法，起到同样的效果\n    ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/sql/dml/dml/","summary":"按年月日分组聚合 group by date_format(field_name, format); 根据format字符串格式化date值。下列修饰符可以被用在format字符串中：\n%M 月名字(January……December) %W 星期名字(Sunday……Saturday) %D 有英语前缀的月份的日期(1st, 2nd, 3rd, 等等。） %Y 年, 数字, 4 位 %y 年, 数字, 2 位 %a 缩写的星期名字(Sun……Sat) %d 月份中的天数, 数字(00……31) %e 月份中的天数, 数字(0……31) %m 月, 数字(01……12) %c 月, 数字(1……12) %b 缩写的月份名字(Jan……Dec) %j 一年中的天数(001……366) %H 小时(00……23) %k 小时(0……23) %h 小时(01……12) %I 小时(01……12) %l 小时(1……12) %i 分钟, 数字(00……59) %r 时间,12 小时(hh:mm:ss [AP]M) %T 时间,24 小时(hh:mm:ss) %S 秒(00……59) %s 秒(00……59) %p AM或PM %w 一个星期中的天数(0=Sunday ……6=Saturday ） %U 星期(0……52), 这里星期天是星期的第一天 %u 星期(0……52), 这里星期一是星期的第一天 %% 一个文字“%”     count统计不重复个数 select count(distinct (field_name)) from table_name     sum结果为null时置为0 SQL中使用sum统计总数时:sum(col_name)，如果某列不符合sum的条件（比如某列中含有NULL元素，或者不是数值类型，或者没有符合where条件的行），那么会返回NULL 有的时候不希望sum的结果为NULL，可以做如下的处理：","tags":null,"title":"SQL DML"},{"categories":null,"contents":"快捷键 回到命令行开头\u0026ndash;Home\nCtrl+a 回到命令行的尾部\u0026ndash;End\nCtrl+e   删除光标前边的所有字符\nCtrl+u 删除光标后边的所有字符\nCtrl+k 删除光标前的一个单词\nCtrl+w   输入曾经的命令下的某个单词或字母，按照单词的匹配history\nCtrl+r     cat 在cat输出时候显示行数\ncat -n maim.go     wc 统计文件行、单词、字符数量 格式：\nusage: wc [-clmw] [file ...] 统计main.go的行、单词、字符数量\nwc main.go 选项：\n-l 统计行数 -c 统计字符数 -w 统计单词数 -L 统计最长的行的字符数     nc 简单的文件传输工具\n接收方\nnc -l [port] \u0026gt; filename 发送方\nnc [ip] [port] \u0026lt; filename     gzip 解压*.gz的压缩文件\n与*.tar.gz文件不同，*.gz文件需要用gzip来解压\ngzip -d filename     hostnamectl 修改hostname，重启也生效\nhostnamectl set-hostname CentOS 查看hostname\nhostname     echo -n：不换行 -e：支持扩展属性\n# 红色显示OK echo -e \u0026#34;\\033[31mOK\\033[0m\u0026#34; # 绿色显示OK echo -e \u0026#34;\\033[32mOK\\033[0m\u0026#34;     tr 删除多余重复字符串\n# 删除多余的空格 echo \u0026#34;a b c\u0026#34; | tr -s \u0026#34; \u0026#34; # 输出：a b c # 删除多余的a echo \u0026#34;aaaaacccdetaaadfa c\u0026#34; | tr -s \u0026#34;a\u0026#34; # 输出：acccdetadfa c     cut # 以冒号为分隔，过滤第一列 cut -d: -f1 /etc/passwd # 输出当前系统下所有用户名     date 查看系统时间\ndate # Tue Oct 12 13:36:24 CST 2021     tzselect 查看时区\nls -l /etc/localtime # lrwxrwxrwx. 1 root root 33 Oct 12 11:32 /etc/localtime -\u0026gt; /usr/share/zoneinfo/Asia/Shanghai   获取TZ时区\ntzselect 输出：\nPlease identify a location so that time zone rules can be set correctly. Please select a continent, ocean, \u0026#34;coord\u0026#34;, or \u0026#34;TZ\u0026#34;. 1) Africa 2) Americas 3) Antarctica 4) Asia 5) Atlantic Ocean 6) Australia 7) Europe 8) Indian Ocean 9) Pacific Ocean 10) coord - I want to use geographical coordinates. 11) TZ - I want to specify the time zone using the Posix TZ format. #?  # 选择数字，依次选择地区、国家、城市，即可得到对应时区 # Asia/Shanghai   修改系统时区（所有用户生效）\nrm -f /etc/localtime ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/linux/shell/basic/","summary":"快捷键 回到命令行开头\u0026ndash;Home\nCtrl+a 回到命令行的尾部\u0026ndash;End\nCtrl+e   删除光标前边的所有字符\nCtrl+u 删除光标后边的所有字符\nCtrl+k 删除光标前的一个单词\nCtrl+w   输入曾经的命令下的某个单词或字母，按照单词的匹配history\nCtrl+r     cat 在cat输出时候显示行数\ncat -n maim.go     wc 统计文件行、单词、字符数量 格式：\nusage: wc [-clmw] [file ...] 统计main.go的行、单词、字符数量\nwc main.go 选项：\n-l 统计行数 -c 统计字符数 -w 统计单词数 -L 统计最长的行的字符数     nc 简单的文件传输工具\n接收方\nnc -l [port] \u0026gt; filename 发送方\nnc [ip] [port] \u0026lt; filename     gzip 解压*.","tags":null,"title":"Basic"},{"categories":null,"contents":"xargs xargs是给命令传递参数的一个过滤器，可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据，一般是和管道一起使用。 格式:\nsomecommand | xargs [-item] [command] 选项：\n-a file 从文件中读入作为 stdin -e flag ，注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。 -p 当每次执行一个argument的时候询问一次用户。 -n num 后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的。 -t 表示先打印命令，然后再执行。 -i 或者是-I，这得看linux支持了，将xargs的每项名称，一般是一行一行赋值给 {}，可以用 {} 代替。 -r no-run-if-empty 当xargs的输入为空的时候则停止xargs，不用再去执行了。 -s num 命令行的最大字符数，指的是 xargs 后面那个命令的最大命令行字符数。 -L num 从标准输入一次读取 num 行送给 command 命令。 -l 同 -L。 -d delim 分隔符，默认的xargs分隔符是回车，argument的分隔符是空格，这里修改的是xargs的分隔符。 -x exit的意思，主要是配合-s使用。。     top Linux top命令VIRT,RES,SHR,DATA的含义:\n VIRT:virtual memory usage虚拟内存  进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据等 假如进程申请100m的内存，但实际只使用了10m，那么它会增长100m，而不是实际的使用量   RES:resident memory usage常驻内存  进程当前使用的内存大小，但不包括swap out 包含其他进程的共享 如果申请100m的内存，实际使用10m，它只增长10m，与VIRT相反 关于库占用内存的情况，它只统计加载的库文件所占内存大小   SHR:shared memory共享内存  除了自身进程的共享内存，也包括其他进程的共享内存 虽然进程只使用了几个共享库的函数，但它包含了整个共享库的大小 计算某个进程所占的物理内存大小公式：RES – SHR swap out后，它将会降下来    top运行中可以通过top的内部命令对进程的显示方式进行控制。内部命令如下：\ns – 改变画面更新频率\nl – 关闭或开启第一部分第一行 top 信息的表示\nt – 关闭或开启第一部分第二行 Tasks 和第三行 Cpus 信息的表示\nm – 关闭或开启第一部分第四行 Mem 和 第五行 Swap 信息的表示\nN – 以 PID 的大小的顺序排列表示进程列表\nP – 以 CPU 占用率大小的顺序排列进程列表\nM – 以内存占用率大小的顺序排列进程列表\nh – 显示帮助\nn – 设置在进程列表所显示进程的数量\nq – 退出 top\n序号 列名 含义\na PID 进程id\nb PPID 父进程id\nc RUSER Real user name\nd UID 进程所有者的用户id\ne USER 进程所有者的用户名\nf GROUP 进程所有者的组名\ng TTY 启动进程的终端名。不是从终端启动的进程则显示为 ?\nh PR 优先级\ni NI nice值。负值表示高优先级，正值表示低优先级\nj P 最后使用的CPU，仅在多CPU环境下有意义\nk %CPU 上次更新到现在的CPU时间占用百分比\nl TIME 进程使用的CPU时间总计，单位秒\nm TIME+ 进程使用的CPU时间总计，单位1/100秒\nn %MEM 进程使用的物理内存百分比\no VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES\np SWAP 进程使用的虚拟内存中，被换出的大小，单位kb。\nq RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA\nr CODE 可执行代码占用的物理内存大小，单位kb\ns DATA 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb\nt SHR 共享内存大小，单位kb\nu nFLT 页面错误次数\nv nDRT 最后一次写入到现在，被修改过的页面数。\nw S 进程状态。（D=不可中断的睡眠状态，R=运行，S=睡眠，T=跟踪/停止，Z=僵尸进程）\nx COMMAND 命令名/命令行\ny WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名\nz Flags 任务标志，参考 sched.h\n默认情况下仅显示比较重要的 PID、USER、PR、NI、VIRT、RES、SHR、S、%CPU、%MEM、TIME+、COMMAND 列。可以通过下面的快捷键来更改显示内容。\n通过f键可以选择显示的内容。按f键之后会显示列的列表，按a-z即可显示或隐藏对应的列，最后按回车键确定。 按o键可以改变列的显示顺序。按小写的a-z可以将相应的列向右移动，而大写的A-Z可以将相应的列向左移动。最后按回车键确定。 按大写的F或O键，然后按a-z可以将进程按照相应的列进行排序。而大写的R键可以将当前的排序倒转。\n    ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/linux/shell/advance/","summary":"xargs xargs是给命令传递参数的一个过滤器，可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据，一般是和管道一起使用。 格式:\nsomecommand | xargs [-item] [command] 选项：\n-a file 从文件中读入作为 stdin -e flag ，注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。 -p 当每次执行一个argument的时候询问一次用户。 -n num 后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的。 -t 表示先打印命令，然后再执行。 -i 或者是-I，这得看linux支持了，将xargs的每项名称，一般是一行一行赋值给 {}，可以用 {} 代替。 -r no-run-if-empty 当xargs的输入为空的时候则停止xargs，不用再去执行了。 -s num 命令行的最大字符数，指的是 xargs 后面那个命令的最大命令行字符数。 -L num 从标准输入一次读取 num 行送给 command 命令。 -l 同 -L。 -d delim 分隔符，默认的xargs分隔符是回车，argument的分隔符是空格，这里修改的是xargs的分隔符。 -x exit的意思，主要是配合-s使用。。     top Linux top命令VIRT,RES,SHR,DATA的含义:\n VIRT:virtual memory usage虚拟内存  进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据等 假如进程申请100m的内存，但实际只使用了10m，那么它会增长100m，而不是实际的使用量   RES:resident memory usage常驻内存  进程当前使用的内存大小，但不包括swap out 包含其他进程的共享 如果申请100m的内存，实际使用10m，它只增长10m，与VIRT相反 关于库占用内存的情况，它只统计加载的库文件所占内存大小   SHR:shared memory共享内存  除了自身进程的共享内存，也包括其他进程的共享内存 虽然进程只使用了几个共享库的函数，但它包含了整个共享库的大小 计算某个进程所占的物理内存大小公式：RES – SHR swap out后，它将会降下来    top运行中可以通过top的内部命令对进程的显示方式进行控制。内部命令如下：","tags":null,"title":"Advance"},{"categories":null,"contents":"命令 显示行号\n:set number   在vi中执行shell命令\n:!ls-l   将shell命令的结果插入到当前行的下一行\n:r !date //读取系统时间并插入到当前行的下一行   将起始行号和结束行号指定的范围中的内容输入到shell命令command处理，并将处理结果替换起始行号和结束行号指定的范围中的内容\n:62,72 !sort //将62行到72行的内容进行排序 当前光标所在行，除可以指定行号外，也可以用.表示\n:. !tr [a-z] [A-Z] //将当前行的小写转为大写   将起始行号和结束行号所指定的范围的内容作为命令command的输入，不会改变当前编辑的文件的内容\n:62,72 w !sort //将62行到72行的内容进行排序，但排序的结果并不会直接输出到当前编辑的文件中，而是显示在vim敲命令的区域   将某一行作为shell命令执行\n:62 w !shell //将会把第62行的内容作为shell命令来执行并显示结果，而且不会改变当前编辑的文件的内容     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/linux/shell/vi/","summary":"命令 显示行号\n:set number   在vi中执行shell命令\n:!ls-l   将shell命令的结果插入到当前行的下一行\n:r !date //读取系统时间并插入到当前行的下一行   将起始行号和结束行号指定的范围中的内容输入到shell命令command处理，并将处理结果替换起始行号和结束行号指定的范围中的内容\n:62,72 !sort //将62行到72行的内容进行排序 当前光标所在行，除可以指定行号外，也可以用.表示\n:. !tr [a-z] [A-Z] //将当前行的小写转为大写   将起始行号和结束行号所指定的范围的内容作为命令command的输入，不会改变当前编辑的文件的内容\n:62,72 w !sort //将62行到72行的内容进行排序，但排序的结果并不会直接输出到当前编辑的文件中，而是显示在vim敲命令的区域   将某一行作为shell命令执行\n:62 w !shell //将会把第62行的内容作为shell命令来执行并显示结果，而且不会改变当前编辑的文件的内容     ","tags":null,"title":"vi"},{"categories":null,"contents":"脚本执行方式  需要可执行权限  相对路径执行 绝对路径执行   不需要可执行权限  sh 脚本文件名 source 脚本文件名 // 不会启动子进程，通过pstree查看进程树        定义变量  定义变量：变量名=变量值 取消变量：unset 变量名 注意事项：  =两边不能有空格 不能使用关键字做变量名，如：ls、cd等 如果变量名已存在，则会覆盖之前的变量值 变量名称由字母、数字、下划线组成，不能以数字开头        变量类型  环境变量：变量名通常大写，由操作系统维护 位置变量：shell内置变量，存储脚本执行时的参数  使用$n表示，n为数字序列号：$1、$2、\u0026hellip;、${10}、${11}、\u0026hellip;   预定义变量：shell内置变量，可以直接调用但是不能赋值或修改'  $0：存储所在的进程或脚本名 $$：当前进程的PID号 $?：命令执行后的返回状态，0-正常，其他-异常 $#：已加载的位置变量的个数 $*：所有位置变量的值   自定义变量：用户自主设置      多种引号的区别  双引号：允许扩展，以$引用其他变量 单引号：禁用扩展，将$视为普通字符 反引号：将命令执行的输出作为变量值，$()与反引号等效      变量的作用范围  局部变量：新定义的变量默认只在当前Shell中有效，无法在子Shell环境中使用 全局变量：在当前Shell以及子Shell中均有效（export a=1：定义全局变量a）      read标准输入取值 read从键盘读入变量值完成赋值\n 格式：read [参数] [变量名] 参数：  -p：提示信息 -t：指定超时秒数 -s：设置是否在终端显示输入的内容        变量作用范围  局部变量  新定义的变量默认只在当前Shell环境中有效，无法在子Shell环境中使用   全局变量  全局变量在当前Shell及子Shell中均有效，定义格式：export a=1        数学运算 整数运算\n使用$[]或$(())表达式\n格式：$[整数1 运算符 整数2]\n  小数运算\nBash内建机制仅支持整数运算，不支持小数运算 可以通过计算器软件bc实现小数计算\n如果没有该软件需要使用yum安装 bc支持交互式和非交互式两种方式计算，scale=n可以约束小数位\nbc也支持比较操作： \u0026gt;,\u0026gt;=,\u0026lt;,\u0026lt;=,==,!= 表达式成立返回1，否则返回0\n    字符串 字符串比较\n中括号与字符串之间和运算符与字符串之间均有有个空格\n是否为空：[ -z 字符串 ]\n等于：[ 字符串1 == 字符串2 ]\n不等于：[ 字符串1 ！= 字符串2 ]\n    整数值比较 [ 整数值1 操作符 整数值2 ]\n-eq 等于（equal） -ne 不等于（not equal） -ge 大于等于（greater or equal） -le 小于等于（less or equal） -gt 大于（greater than） -lt 小于（less than）\n    文件状态测试 [ 操作符 文件或目录 ]\n-e 判断对象是否存在（exit） -d 判断对象是否为目录（directory） -f 判断对象是否为一般文件（file） -r 判断对象是否有可读权限（read） -w 判断对象是否有可写权限（write） -x 判断对象是否有可执行权限（excute）\n    组合多个命令 ;：顺序执行 ||：前面执行失败继续执行 \u0026amp;\u0026amp;：前面执行成功继续执行    数组 存储多个数据的集合\ntest=(1 2 3) echo ${test[0]}     函数 语法格式\nfunction 函数名{ #命令序列 } 函数名(){ #命令序列 }   调用\n函数名 参数1 参数2 ... 传递的值作为函数的位置参数\n    中断与退出 continue：结束单次循环 break：跳出循环体 exit：退出脚本    子串截取 ${变量:起始位置:长度}\nab=123456 # 统计ab长度 echo ${#ab} # 输出：6 echo ${ab:2:5} # 输出：3456     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/linux/shell/script/","summary":"脚本执行方式  需要可执行权限  相对路径执行 绝对路径执行   不需要可执行权限  sh 脚本文件名 source 脚本文件名 // 不会启动子进程，通过pstree查看进程树        定义变量  定义变量：变量名=变量值 取消变量：unset 变量名 注意事项：  =两边不能有空格 不能使用关键字做变量名，如：ls、cd等 如果变量名已存在，则会覆盖之前的变量值 变量名称由字母、数字、下划线组成，不能以数字开头        变量类型  环境变量：变量名通常大写，由操作系统维护 位置变量：shell内置变量，存储脚本执行时的参数  使用$n表示，n为数字序列号：$1、$2、\u0026hellip;、${10}、${11}、\u0026hellip;   预定义变量：shell内置变量，可以直接调用但是不能赋值或修改'  $0：存储所在的进程或脚本名 $$：当前进程的PID号 $?：命令执行后的返回状态，0-正常，其他-异常 $#：已加载的位置变量的个数 $*：所有位置变量的值   自定义变量：用户自主设置      多种引号的区别  双引号：允许扩展，以$引用其他变量 单引号：禁用扩展，将$视为普通字符 反引号：将命令执行的输出作为变量值，$()与反引号等效      变量的作用范围  局部变量：新定义的变量默认只在当前Shell中有效，无法在子Shell环境中使用 全局变量：在当前Shell以及子Shell中均有效（export a=1：定义全局变量a）      read标准输入取值 read从键盘读入变量值完成赋值","tags":null,"title":"Script"},{"categories":null,"contents":"内存 一般来说内存占用大小有如下规律：VSS \u0026gt;= RSS \u0026gt;= PSS \u0026gt;= USS\n VSS - Virtual Set Size 虚拟耗用内存（包含共享库占用的内存） RSS - Resident Set Size 实际使用物理内存（包含共享库占用的内存） PSS - Proportional Set Size 实际使用的物理内存（比例分配共享库占用的内存） USS - Unique Set Size 进程独自占用的物理内存（不包含共享库占用的内存）    RSS / VSZ\n RSS是Resident Set Size（常驻内存大小）的缩写，用于表示进程使用了多少内存（RAM中的物理内存）， RSS不包含已经被换出的内存。RSS包含了它所链接的动态库并且被加载到物理内存中的内存。RSS还包含栈内存和堆内存。 VSZ是Virtual Memory Size（虚拟内存大小）的缩写。它包含了进程所能访问的所有内存，包含了被换出的内存， 被分配但是还没有被使用的内存，以及动态库中的内存。  假设进程A的二进制文件是500K，并且链接了一个2500K的动态库，堆和栈共使用了200K，其中100K在内存中（剩下的被换出或者不再被使用）， 一共加载了动态库中的1000K内容以及二进制文件中的400K内容至内存中，那么：\nRSS: 400K + 1000K + 100K = 1500K VSZ: 500K + 2500K + 200K = 3200K 由于部分内存是共享的，被多个进程使用，所以如果将所有进程的RSS值加起来可能会大于系统的内存总量。\n申请过的内存如果程序没有实际使用，则可能不显示在RSS里。比如说一个程序，预先申请了一大批内存， 过了一段时间才使用，你会发现RSS会增长而VSZ保持不变。\n还有一个概念是PSS，它是proportional set size（proportional是成比例的意思）的缩写。 这是一种新的度量方式。它将动态库所使用的内存按比例划分。比如我们前面例子中的动态库如果是被两个进程使用，那么：\nPSS: 400K + (1000K/2) + 100K = 400K + 500K + 100K = 1000K 一个进程中的多个线程共享同样的地址空间。所以一个进程中的多个线程的RSS，VSZ，PSS是完全相同的。linux下可以使用ps或者top命令查看这些信息。\n英文原文\n    ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/notes/linux/system/system/","summary":"内存 一般来说内存占用大小有如下规律：VSS \u0026gt;= RSS \u0026gt;= PSS \u0026gt;= USS\n VSS - Virtual Set Size 虚拟耗用内存（包含共享库占用的内存） RSS - Resident Set Size 实际使用物理内存（包含共享库占用的内存） PSS - Proportional Set Size 实际使用的物理内存（比例分配共享库占用的内存） USS - Unique Set Size 进程独自占用的物理内存（不包含共享库占用的内存）    RSS / VSZ\n RSS是Resident Set Size（常驻内存大小）的缩写，用于表示进程使用了多少内存（RAM中的物理内存）， RSS不包含已经被换出的内存。RSS包含了它所链接的动态库并且被加载到物理内存中的内存。RSS还包含栈内存和堆内存。 VSZ是Virtual Memory Size（虚拟内存大小）的缩写。它包含了进程所能访问的所有内存，包含了被换出的内存， 被分配但是还没有被使用的内存，以及动态库中的内存。  假设进程A的二进制文件是500K，并且链接了一个2500K的动态库，堆和栈共使用了200K，其中100K在内存中（剩下的被换出或者不再被使用）， 一共加载了动态库中的1000K内容以及二进制文件中的400K内容至内存中，那么：\nRSS: 400K + 1000K + 100K = 1500K VSZ: 500K + 2500K + 200K = 3200K 由于部分内存是共享的，被多个进程使用，所以如果将所有进程的RSS值加起来可能会大于系统的内存总量。\n申请过的内存如果程序没有实际使用，则可能不显示在RSS里。比如说一个程序，预先申请了一大批内存， 过了一段时间才使用，你会发现RSS会增长而VSZ保持不变。","tags":null,"title":"Memory"},{"categories":null,"contents":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.toml\n``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nBúsqueda de archivos adicionales Para buscar campos adicionales definidos en el front matter, debes añadirlo en 2 lugares.\nEditar layouts/_default/index.JSON Esto expone los valores en /index.json: por ejemplo, para agregar categories ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEditar las opciones de fuse.js para buscar static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.","tags":null,"title":"Resultados de Búsqueda"},{"categories":null,"contents":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.toml\n``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nBúsqueda de archivos adicionales Para buscar campos adicionales definidos en el front matter, debes añadirlo en 2 lugares.\nEditar layouts/_default/index.JSON Esto expone los valores en /index.json: por ejemplo, para agregar categories ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEditar las opciones de fuse.js para buscar static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.","tags":null,"title":"Resultados de Búsqueda"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"অনুসন্ধানের ফলাফল"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"অনুসন্ধানের ফলাফল"},{"categories":null,"contents":"程序下载 wget https://github.com/prometheus/prometheus/releases/download/v2.30.3/prometheus-2.30.3.linux-amd64.tar.gz 解压并移动 tar -zxvf prometheus-2.30.3.linux-amd64.tar.gz mv prometheus-2.30.3.linux-amd64 /usr/local/prometheus 添加到系统服务 Unit配置文件 vi /usr/lib/systemd/system/prometheus.service [Unit] Description=Prometheus Documentation=https://prometheus.io [Service] Type=simple ExecStart=/usr/local/prometheus/prometheus \\ --config.file=/usr/local/prometheus/prometheus.yml \\ --storage.tsdb.path=/usr/local/prometheus/data Restart=on-failure WatchdogSec=10s [Install] WantedBy=multi-user.target 启动程序 sudo systemctl daemon-reload sudo systemctl start prometheus.service sudo systemctl status prometheus.service 开机自启 sudo systemctl enable prometheus.service 简单使用 Prometheus默认端口是9090，程序启动之后从浏览器访问页面。\n输入以下表达式来绘制在自抓取Prometheus中发生的每秒HTTP请求率返回状态代码200的图表：\nrate(promhttp_metric_handler_requests_total{code=\u0026#34;200\u0026#34;}[1m]) 配置文件 重新加载 curl -X POST http://127.0.0.1:9090/-/reload 参考链接 Prometheus官网 Prometheus下载页面 Prometheus文档\n","date":"October 9, 2021","hero":"/posts/deployment/3005-linux-prometheus/head.png","permalink":"https://ormissia.github.io/posts/deployment/3005-linux-prometheus/","summary":"程序下载 wget https://github.com/prometheus/prometheus/releases/download/v2.30.3/prometheus-2.30.3.linux-amd64.tar.gz 解压并移动 tar -zxvf prometheus-2.30.3.linux-amd64.tar.gz mv prometheus-2.30.3.linux-amd64 /usr/local/prometheus 添加到系统服务 Unit配置文件 vi /usr/lib/systemd/system/prometheus.service [Unit] Description=Prometheus Documentation=https://prometheus.io [Service] Type=simple ExecStart=/usr/local/prometheus/prometheus \\ --config.file=/usr/local/prometheus/prometheus.yml \\ --storage.tsdb.path=/usr/local/prometheus/data Restart=on-failure WatchdogSec=10s [Install] WantedBy=multi-user.target 启动程序 sudo systemctl daemon-reload sudo systemctl start prometheus.service sudo systemctl status prometheus.service 开机自启 sudo systemctl enable prometheus.service 简单使用 Prometheus默认端口是9090，程序启动之后从浏览器访问页面。\n输入以下表达式来绘制在自抓取Prometheus中发生的每秒HTTP请求率返回状态代码200的图表：\nrate(promhttp_metric_handler_requests_total{code=\u0026#34;200\u0026#34;}[1m]) 配置文件 重新加载 curl -X POST http://127.0.0.1:9090/-/reload 参考链接 Prometheus官网 Prometheus下载页面 Prometheus文档","tags":null,"title":"Linux部署Prometheus流程"},{"categories":null,"contents":"Grafana的安装比较简单，打开官网下载页面，选择对应的系统以及需要的版本号，按照指引执行命令即可。\n程序下载 wget https://dl.grafana.com/enterprise/release/grafana-enterprise-8.2.0-1.x86_64.rpm sudo yum install grafana-enterprise-8.2.0-1.x86_64.rpm 启动程序 sudo systemctl daemon-reload sudo systemctl start grafana-server sudo systemctl status grafana-server 验证 Grafana默认端口为:3000，默认用户名密码均为admin，程序启动后即可通过3000端口访问管理页面。\n开机自启 sudo systemctl enable grafana-server 参考连接  Grafana官网 Grafana下载页面 Grafana安装文档  ","date":"October 9, 2021","hero":"/posts/deployment/3004-linux-grafana/head.png","permalink":"https://ormissia.github.io/posts/deployment/3004-linux-grafana/","summary":"Grafana的安装比较简单，打开官网下载页面，选择对应的系统以及需要的版本号，按照指引执行命令即可。\n程序下载 wget https://dl.grafana.com/enterprise/release/grafana-enterprise-8.2.0-1.x86_64.rpm sudo yum install grafana-enterprise-8.2.0-1.x86_64.rpm 启动程序 sudo systemctl daemon-reload sudo systemctl start grafana-server sudo systemctl status grafana-server 验证 Grafana默认端口为:3000，默认用户名密码均为admin，程序启动后即可通过3000端口访问管理页面。\n开机自启 sudo systemctl enable grafana-server 参考连接  Grafana官网 Grafana下载页面 Grafana安装文档  ","tags":null,"title":"Linux部署Grafana流程"},{"categories":null,"contents":" Traefik is an open-source Edge Router that makes publishing your services a fun and easy experience. It receives requests on behalf of your system and finds out which components are responsible for handling them. What sets Traefik apart, besides its many features, is that it automatically discovers the right configuration for your services. The magic happens when Traefik inspects your infrastructure, where it finds relevant information and discovers which service serves which request. Traefik is natively compliant with every major cluster technology, such as Kubernetes, Docker, Docker Swarm, AWS, Mesos, Marathon, and the list goes on; and can handle many at the same time. (It even works for legacy software running on bare metal.) With Traefik, there is no need to maintain and synchronize a separate configuration file: everything happens automatically, in real time (no restarts, no connection interruptions). With Traefik, you spend time developing and deploying new features to your system, not on configuring and maintaining its working state. Developing Traefik, our main goal is to make it simple to use, and we\u0026rsquo;re sure you\u0026rsquo;ll enjoy it.\n\u0026ndash; The Traefik Maintainer Team\n 程序下载 由于Traefik是由Golang语言所编写，程序是二进制包的形式。直接到Traefik在GitHub仓库的releases中下载即可。\n我使用的是基于x86的64位Linux系统，所以在这里选择的是linux_amd64版本的包\nwget https://github.com/traefik/traefik/releases/download/v2.5.3/traefik_v2.5.3_linux_amd64.tar.gz 解压得到程序\ntar -zxvf traefik_v2.5.3_linux_amd64.tar.gz 将程序重命名为traefik并放到/usr/local/bin/目录下\n静态配置  静态配置是Traefik在程序启动的时候从配置文件、环境变量或启动参数中加载到内存中的配置参数。如果需要修改，则需要重启Traefik。\n 静态配置的官方文档\n根据文档介绍，Traefik会从以下几个目录读取名为traefik.yml（或traefik.yaml或traefik.toml）的静态配置文件：\n /etc/traefik/ $XDG_CONFIG_HOME/ $HOME/.config/ .(Traefik程序运行的当前目录)  或者在启动的时候以参数形式指定静态配置文件：\ntraefik --configFile=foo/bar/myconfigfile.yml 代理端口 使用entryPoints向外暴露端口\nentryPoints: web: address: \u0026#34;:80\u0026#34; websecure: address: \u0026#34;:443\u0026#34; 添加动态配置 Traefik支持动态配置，即配置修改后Traefik可以自动重新加载，我在这里选择了从文件读取动态配置，通过providers添加动态配置的配置文件的路径或文件名，在这里我使用了目录的形式（dictory和filename二选一）。\n这里也可以修改动态配置的重新加载间隔时间，默认是2S，我在这里使用了默认配置，不做修改。\nproviders: file: directory: /etc/traefik/dynamic-conf watch: true 开启API 在这里可以开启Traefik的dashboard以及api\napi: insecure: true dashboard默认使用的是8080端口，如果要修改，则需要在entryPoints下添加名为traefik的端口配置：\nentryPoints: traefik: address: \u0026#34;:10000\u0026#34; 程序日志 Traefik支持将程序运行的日志输出到文件，通过log标签可以设置日志输出文件，输出格式以及日志级别。\nlog: filePath: /etc/traefik/traefik.log format: json level: ERROR 访问日志 Traefik支持将访问日志输出到文件，通过accessLog配置\naccessLog: filePath: /etc/traefik/access.log format: json 监控 // TODO\nmetrics: prometheus: addRoutersLabels: true entryPoint: metrics 动态配置  动态配置中存储的是路由、服务、中间件等配置信息，是可以在程序运行时动态修改的值。\n 以下是Traefik所支持的动态配置提供者：\n   Provider Type Configuration Type Provider Name     Docker Orchestrator Label docker   Kubernetes IngressRoute Orchestrator Custom Resource kubernetescrd   Kubernetes Ingress Orchestrator Ingress kubernetes   Kubernetes Gateway API Orchestrator Gateway API Resource kubernetesgateway   Consul Catalog Orchestrator Label consulcatalog   ECS Orchestrator Label ecs   Marathon Orchestrator Label marathon   Rancher Orchestrator Label rancher   File Manual YAML/TOML format file   Consul KV KV consul   Etcd KV KV etcd   ZooKeeper KV KV zookeeper   Redis KV KV redis   HTTP Manual JSON format http      我在这里选择了File类型的提供者，以下均为File类型的介绍\n 路由 路由类型分为三种，分别为：http、tcp、udp\n在这里我使用的是HTTP的路由功能：\nhttp: routers: router-traefik: rule: HostRegexp(`traefik.{domain:.*}`) service: traefik router-grafana: rule: HostRegexp(`grafana.{domain:.*}`) service: grafana  service指向的是下面定义的Service的名称\n 路由规则 路由规则是指，Traefik接收到的请求，根据给定规则路由到不同的服务中。\nTraefik一共支持以下规则：\n   Rule Description     Headers(`key`, `value`) Check if there is a key keydefined in the headers, with the value value   HeadersRegexp(`key`, `regexp`) Check if there is a key keydefined in the headers, with a value that matches the regular expression regexp   Host(`example.com`, \u0026hellip;) Check if the request domain (host header value) targets one of the given domains.   HostHeader(`example.com`, \u0026hellip;) Check if the request domain (host header value) targets one of the given domains.   HostRegexp(`example.com`, `{subdomain:[a-z]+}.example.com`, \u0026hellip;) Check if the request domain matches the given regexp.   Method(`GET`, \u0026hellip;) Check if the request method is one of the given methods (GET, POST, PUT, DELETE, PATCH, HEAD)   Path(`/path`, `/articles/{cat:[a-z]+}/{id:[0-9]+}`, \u0026hellip;) Match exact request path. It accepts a sequence of literal and regular expression paths.   PathPrefix(`/products/`, `/articles/{cat:[a-z]+}/{id:[0-9]+}`) Match request prefix path. It accepts a sequence of literal and regular expression prefix paths.   Query(`foo=bar`, `bar=baz`) Match Query String parameters. It accepts a sequence of key=value pairs.   ClientIP(`10.0.0.0/16`, `::1`) Match if the request client IP is one of the given IP/CIDR. It accepts IPv4, IPv6 and CIDR formats     我这这里主要会用到HostRegexp和PathPrefix，即对请求url的两种使用正则的过滤规则，前者用于匹配二级域名，后者用于将不同路径的请求转发至不同服务。\n 这个正则配起来稍微有点小坑，哈哈。我研究了好久才搞明白要怎么写。\n 为了对Host和Path使用正则表达式，需要声明一个任意命名的变量，然后跟上用冒号分隔的正则表达式，所有这些都用花括号括起来。\n示例：HostRegexp(`grafana.{domain:.*}`)\n服务 服务负责配置如何到达实际的服务，最终将处理传入的请求。使用service定义：\nhttp: services: traefik: loadBalancer: servers: - url: \u0026#34;http://127.0.0.1:10000\u0026#34; 我们将上面开启的Traefik的监控面板作为服务封装了起来，只要路由到traefik这个服务上，即可访问监控面板。\n在这里也可以实现负载均衡等功能，可以参照官网介绍\n开机启动  有了上次部署Nginx的经验，这里我们完全采用Systemd来管理。即，使用systemctl命令来管理服务。\n 原理 Systemd默认从目录/etc/systemd/system/读取配置文件。但是，里面存放的大部分文件都是符号链接，指向目录/usr/lib/systemd/system/，真正的配置文件存放在那个目录\nsystemctl enable命令用于在上面两个目录之间，建立符号链接关系。\nsystemctl enable traefik.service # 等同于 ln -s \u0026#39;/usr/lib/systemd/system/traefik.service\u0026#39; \u0026#39;/etc/systemd/system/multi-user.target.wants/traefik.service\u0026#39; Unit配置文件 下面是Traefik源码仓库中给出的traefik.service 示例，其中有几个需要注意的点：\n Type：程序启动方式 ExecStart：程序运行的命令，在这里直接指向程序本身 WatchdogSec：程序检测时间  [Unit] Description=Traefik Documentation=https://doc.traefik.io/traefik/ #After=network-online.target #AssertFileIsExecutable=/usr/bin/traefik #AssertPathExists=/etc/traefik/traefik.toml [Service] # Run traefik as its own user (create new user with: useradd -r -s /bin/false -U -M traefik) #User=traefik #AmbientCapabilities=CAP_NET_BIND_SERVICE # configure service behavior Type=notify #ExecStart=/usr/bin/traefik --configFile=/etc/traefik/traefik.toml Restart=always WatchdogSec=1s # lock down system access # prohibit any operating system and configuration modification #ProtectSystem=strict # create separate, new (and empty) /tmp and /var/tmp filesystems #PrivateTmp=true # make /home directories inaccessible #ProtectHome=true # turns off access to physical devices (/dev/...) #PrivateDevices=true # make kernel settings (procfs and sysfs) read-only #ProtectKernelTunables=true # make cgroups /sys/fs/cgroup read-only #ProtectControlGroups=true # allow writing of acme.json #ReadWritePaths=/etc/traefik/acme.json # depending on log and entrypoint configuration, you may need to allow writing to other paths, too # limit number of processes in this unit #LimitNPROC=1 [Install] WantedBy=multi-user.target 作为服务开启 systemctil start traefik.service 设置开机启动 systemctil enable traefik.service 查看运行状态 systemctil status traefik.service 文件汇总 root ├─ etc │\t└─ traefik │\t├─ access.log // 访问日志 │\t├─ dynamic_conf // 动态配置存放文件夹 │\t│\t└─ dynamic_conf.yml // 动态配置文件 │\t├─ traefik.log // 程序日志 │\t└─ traefik.yml // 静态配置文件 └─ usr └─ local └─ bin └─ traefik // 程序本身 静态配置 ## Static configuration entryPoints: web: address: \u0026#34;:80\u0026#34; websecure: address: \u0026#34;:443\u0026#34; traefik: address: \u0026#34;:10000\u0026#34; metrics: address: \u0026#34;:8082\u0026#34; # 动态配置的配置 providers: file: directory: /etc/traefik/dynamic-conf watch: true # API api: insecure: true # 运行日志 log: filePath: /etc/traefik/traefik.log format: json level: ERROR # 访问日志 accessLog: filePath: /etc/traefik/access.log format: json # 监控 metrics: prometheus: addRoutersLabels: true entryPoint: metrics 动态配置 ## Dynamic configuration http: routers: router-traefik: rule: HostRegexp(`traefik.{domain:.*}`) service: traefik router-grafana: rule: HostRegexp(`grafana.{domain:.*}`) service: grafana router-prometheus: rule: HostRegexp(`prometheus.{domain:.*}`) service: prometheus services: traefik: loadBalancer: servers: - url: \u0026#34;http://127.0.0.1:10000\u0026#34; grafana: loadBalancer: servers: - url: \u0026#34;http://127.0.0.1:3000\u0026#34; prometheus: loadBalancer: servers: - url: \u0026#34;http://127.0.0.1:9090\u0026#34;  至此，我们已经配置完成了Traefik的基础功能，实现了路由，日志，开机启动等功能\n  中间件  从图中基本可以明白中间件的作用，也可以理解成拦截器，亦或者是类似于Spring中的切面。\nTraefik中有几种可用的中间件：一些可以修改请求、请求头，一些负责重定向，一些可以添加身份验证等等。\n 中间件的配置格式类似于Service，大致是先定义，再使用。\n下面是一个官网给出的示例：\n# As YAML Configuration File http: routers: router1: service: myService middlewares: - \u0026#34;foo-add-prefix\u0026#34; rule: \u0026#34;Host(`example.com`)\u0026#34; middlewares: foo-add-prefix: addPrefix: prefix: \u0026#34;/foo\u0026#34; services: service1: loadBalancer: servers: - url: \u0026#34;http://127.0.0.1:80\u0026#34; 页面访问认证 由于Traefik的管理页面给有给出登录的功能，因此这里使用官方提供的BasicAuth中间件来实现访问认证的功能。\n定义权限认证中间件 定义名为traefik-auth的中间件：\n## Dynamic configuration http: # ... middlewares: traefik-auth: basicAuth: users: - \u0026#34;test:$apr1$cxKgflNX$3PWH2/iPEdZrBEWYGfSBm.\u0026#34; user下面的密码使用htpasswd生成\n给对应路由添加中间件 给路由添加中间件\n## Dynamic configuration http: routers: router-traefik: middlewares: - traefik-auth rule: Host(`traefik.ormissia.com`) service: traefik 这样在访问相应路由的时候会经过basicAuth的中间件，在浏览器弹出窗口输入之前使用htpasswd生成的用户名密码即可。\n配置获取免费证书 在这里我面选择让Traefik自动获取免费证书，并且申请泛域名的证书。\n端口重定向 将80端口的流量重定向到443端口，并开启http代理的tls\n## Static configuration entryPoints: web: address: \u0026#34;:80\u0026#34; http: redirections: entryPoint: to: websecure scheme: https websecure: address: \u0026#34;:443\u0026#34; http: tls: {} 这个时候我们将80代理到了443，因此访问页面会显示成这样：\n接下来我们给Traefik添加自动获取证书的功能\n开启ACME # certificate certificatesResolvers: myresolver: acme: email: example@email.com storage: /etc/traefik/acme/acme.json dnsChallenge: provider: acme-dns 这里面有三个属性是必填的：\n email：邮箱 storage：证书存储文件 dnsChallenge：由于我们选择申请泛域名的证书，目前只有dnsChallenge支持申请泛域名。  storage 创建一个文件，权限必须是600，里面主要用来存证书的信息，信息格式为json。\ncd /etc/traefik/acme/ touch acme.json \u0026amp;\u0026amp; chmod 600 acme.json dnsChallenge dnsChallenge支持各种不同的provider，具体可以参考官网介绍，这里就不再贴了。\n如果自己的域名在表格中有对应的云厂商，可以使用对应的provider。这里虽然我使用的这个域名是阿里云上的，只是感觉创建token或者RAM账户有点难于管理，而且要设置一些权限等等。 因此这里我选择了通用的方式，使用acme-dns作为provider。\n使用acme-dns作为provider，需要添加两个环境变量：\n ACME_DNS_API_BASE：这里我使用了acme-dns官方提供的地址-https://auth.acme-dns.io ACME_DNS_STORAGE_PATH：这个文件存储了从上一个url中获取的DNS信息，需要手动创建一下  由于未知原因，这里我在/etc/profile中添加对应环境变量并且使用source编译之后，Traefik运行时候未能正确读取到，因此我选择将两个变量写入systemd的配置文件中：\nvi /usr/lib/systemd/system/traefik.service [Unit] # ... [Service] Environment=\u0026#34;ACME_DNS_API_BASE=https://auth.acme-dns.io\u0026#34; \u0026#34;ACME_DNS_STORAGE_PATH=/etc/traefik/acme/dns.json\u0026#34; # ... [Install] # ... 直接在服务的配置文件中添加，这样在Traefik启动的时候就能正确读取到两个环境变量了。\n添加CNAME解析 当完成上面的配置之后，运行一下Traefik之后，/etc/traefik/acme/dns.json会获得对应信息：\n{ \u0026#34;ormissia.com\u0026#34;:{ \u0026#34;fulldomain\u0026#34;:\u0026#34;123.auth.acme-dns.io\u0026#34;, \u0026#34;subdomain\u0026#34;:\u0026#34;123\u0026#34;, \u0026#34;username\u0026#34;:\u0026#34;123\u0026#34;, \u0026#34;password\u0026#34;:\u0026#34;123\u0026#34;, \u0026#34;server_url\u0026#34;:\u0026#34;https://auth.acme-dns.io\u0026#34; } } 取fulldomain的值，到自己的域名管理添加一条CNAME类型的解析：_acme-challenge.ormissia.com指向上面得到的fulldomain的值即可。\n等待片刻执行下面命令查看解析是否成功：\ndig _acme-challenge.ormissia.com 可以看到返回值中有这样一行：\n;; ANSWER SECTION: _acme-challenge.ormissia.com. 600 IN\tCNAME\t123.auth.acme-dns.io. 即代表解析成功。\n重启Traefik之后，刷新页面，即可以从浏览器中看到证书获取成功。\n参考链接  Traefik源码仓库 Traefik官网 Traefik静态配置项-File provider Let\u0026rsquo;s Encrypt Systemd文档  ","date":"October 9, 2021","hero":"/posts/deployment/3003-linux-traefik/head.png","permalink":"https://ormissia.github.io/posts/deployment/3003-linux-traefik/","summary":"Traefik is an open-source Edge Router that makes publishing your services a fun and easy experience. It receives requests on behalf of your system and finds out which components are responsible for handling them. What sets Traefik apart, besides its many features, is that it automatically discovers the right configuration for your services. The magic happens when Traefik inspects your infrastructure, where it finds relevant information and discovers which service serves which request.","tags":null,"title":"Linux部署Traefik流程"},{"categories":null,"contents":"安装依赖 编译工具及库文件 yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 安装PCRE  PCRE作用是让Nginx支持Rewrite功能\n PCRE安装包下载地址： https://sourceforge.net/projects/pcre/files/pcre/\n选择对应版本下载即可\n下载PCRE安装包 cd /usr/local/src/ wget http://downloads.sourceforge.net/project/pcre/pcre/8.45/pcre-8.45.tar.gz 解压安装包并进入目录 tar -zxvf pcre-8.45.tar.gz cd pcre-8.45 编译安装 ./configure make \u0026amp;\u0026amp; make install 验证安装 pcre-config --version 可能遇到的问题 安装完成之后有可能找不到命令，查看编译安装时的默认安装目录，将其添加到Linux环境变量PATH即可\n创建管理Nginx的用户和组  创建nginx运行用户nginx并加入到nginx组，不允许nginx用户直接登录系统\n groupadd nginx useradd -g nginx nginx -s /sbin/nologin 安装Nginx 下载安装包 Nginx下载地址： http://nginx.org/en/download.html\n没有特殊需求的话，选择Stable version稳定版下载即可\ncd /usr/local/src/ wget http://nginx.org/download/nginx-1.20.1.tar.gz 解压安装包并进入目录 tar -zxvf nginx-1.20.1 cd nginx-1.20.1 编译安装 ./configure \\ --prefix=/usr/local/nginx \\ --user=nginx --group=nginx \\ --pid-path=/var/run/nginx/nginx.pid \\ --lock-path=/var/lock/nginx.lock \\ --error-log-path=/var/log/nginx/error.log \\ --http-log-path=/var/log/nginx/access.log \\ --with-http_gzip_static_module \\ --http-client-body-temp-path=/var/temp/nginx/client \\ --http-proxy-temp-path=/var/temp/nginx/proxy \\ --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \\ --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \\ --http-scgi-temp-path=/var/temp/nginx/scgi \\ --with-http_stub_status_module \\ --with-http_ssl_module \\ --with-http_realip_module make \u0026amp;\u0026amp; make install 优化Nginx程序的执行路径 添加软连接到环境变量PATH目录下\nln -s /usr/local/nginx/sbin/nginx /usr/local/sbin/ 添加软连接之后即可直接使用nginx命令启动操作Nginx\nnginx nginx -s reload #重启（修改配置文件后重新加载等） nginx -s quit #退出（处理完所有请求后结束进程） nginx -s stop #停止（直接结束进程） 测试安装 nginx -t 如果报错，一般是缺少配置路径中的文件夹，使用mkdir -p创建即可\n修改之后，正常的提示为：\nnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful 配置开机启动 创建启动脚本 vi /etc/init.d/nginx 脚本内容：\n 我这里是修改过的，也可以去官网复制。官网脚本连接\n 要注意从官网直接复制的需要修改几处地方，否则运行报错。\n nginx变量的值要改成nginx程序的实际安装路径 NGINX_CONF_FILE变量的值要改成nginx配置文件的路径 lockfile变量的值要改成实际的lockfile文件路径  #!/bin/sh # # nginx - this script starts and stops the nginx daemon # # chkconfig: - 85 15 # description: NGINX is an HTTP(S) server, HTTP(S) reverse \\ # proxy and IMAP/POP3 proxy server # processname: nginx # config: /etc/nginx/nginx.conf # config: /etc/sysconfig/nginx # pidfile: /var/run/nginx.pid # Source function library. . /etc/rc.d/init.d/functions # Source networking configuration. . /etc/sysconfig/network # Check that networking is up. [ \u0026#34;$NETWORKING\u0026#34; = \u0026#34;no\u0026#34; ] \u0026amp;\u0026amp; exit 0 nginx=\u0026#34;/usr/local/nginx/sbin/nginx\u0026#34; prog=$(basename $nginx) NGINX_CONF_FILE=\u0026#34;/usr/local/nginx/conf/nginx.conf\u0026#34; [ -f /etc/sysconfig/nginx ] \u0026amp;\u0026amp; . /etc/sysconfig/nginx lockfile=/var/lock/nginx.lock make_dirs() { # make required directories user=`$nginx -V 2\u0026gt;\u0026amp;1 | grep \u0026#34;configure arguments:.*--user=\u0026#34; | sed \u0026#39;s/[^*]*--user=\\([^ ]*\\).*/\\1/g\u0026#39; -` if [ -n \u0026#34;$user\u0026#34; ]; then if [ -z \u0026#34;`grep $user/etc/passwd`\u0026#34; ]; then useradd -M -s /bin/nologin $user fi options=`$nginx -V 2\u0026gt;\u0026amp;1 | grep \u0026#39;configure arguments:\u0026#39;` for opt in $options; do if [ `echo $opt | grep \u0026#39;.*-temp-path\u0026#39;` ]; then value=`echo $opt | cut -d \u0026#34;=\u0026#34; -f 2` if [ ! -d \u0026#34;$value\u0026#34; ]; then # echo \u0026#34;creating\u0026#34; $value mkdir -p $value \u0026amp;\u0026amp; chown -R $user $value fi fi done fi } start() { [ -x $nginx ] || exit 5 [ -f $NGINX_CONF_FILE ] || exit 6 make_dirs echo -n $\u0026#34;Starting $prog: \u0026#34; daemon $nginx -c $NGINX_CONF_FILE retval=$? echo [ $retval -eq 0 ] \u0026amp;\u0026amp; touch $lockfile return $retval } stop() { echo -n $\u0026#34;Stopping $prog: \u0026#34; killproc $prog -QUIT retval=$? echo [ $retval -eq 0 ] \u0026amp;\u0026amp; rm -f $lockfile return $retval } restart() { configtest || return $? stop sleep 1 start } reload() { configtest || return $? echo -n $\u0026#34;Reloading $prog: \u0026#34; killproc $prog -HUP retval=$? echo } force_reload() { restart } configtest() { $nginx -t -c $NGINX_CONF_FILE } rh_status() { status $prog } rh_status_q() { rh_status \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 } case \u0026#34;$1\u0026#34; in start) rh_status_q \u0026amp;\u0026amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart|configtest) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $\u0026#34;Usage: $0{start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest}\u0026#34; exit 2 esac 修改脚本权限 cd /etc/init.d/ chmod 755 nginx  这个脚本可用来直接操作Nginx，直接执行脚本会提示需要输入\n 将Nginx加入到系统服务中 chkconfig --add nginx 设为开机启动 chkconfig nginx on  重启系统后生效\n 重启后，即可使用systemctl命令管理nginx服务\nsystemctl status nginx.service systemctl start nginx.service systemctl stop nginx.service 可能遇到的问题 如果使用 命令查看nginx服务状态时的提示：\n● nginx.service - SYSV: NGINX is an HTTP(S) server, HTTP(S) reverse proxy and IMAP/POP3 proxy server Loaded: loaded (/etc/rc.d/init.d/nginx; generated) Active: inactive (dead) Docs: man:systemd-sysv-generator(8) 是因为系统安装了httpd，卸载即可\nyum remove httpd -y 验证安装 执行\ncurl 127.0.0.1 从返回结果中可以看到，成功拿到Nginx的默认页面了，安装成功\n也可以在外网通过服务IP访问，需要注意Linux防火墙、云服务器出站入站规则等限制\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;If you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;For online documentation and support please refer to \u0026lt;a href=\u0026#34;http://nginx.org/\u0026#34;\u0026gt;nginx.org\u0026lt;/a\u0026gt;.\u0026lt;br/\u0026gt; Commercial support is available at \u0026lt;a href=\u0026#34;http://nginx.com/\u0026#34;\u0026gt;nginx.com\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ","date":"October 8, 2021","hero":"/posts/deployment/3002-linux-nginx/head.svg","permalink":"https://ormissia.github.io/posts/deployment/3002-linux-nginx/","summary":"安装依赖 编译工具及库文件 yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 安装PCRE  PCRE作用是让Nginx支持Rewrite功能\n PCRE安装包下载地址： https://sourceforge.net/projects/pcre/files/pcre/\n选择对应版本下载即可\n下载PCRE安装包 cd /usr/local/src/ wget http://downloads.sourceforge.net/project/pcre/pcre/8.45/pcre-8.45.tar.gz 解压安装包并进入目录 tar -zxvf pcre-8.45.tar.gz cd pcre-8.45 编译安装 ./configure make \u0026amp;\u0026amp; make install 验证安装 pcre-config --version 可能遇到的问题 安装完成之后有可能找不到命令，查看编译安装时的默认安装目录，将其添加到Linux环境变量PATH即可\n创建管理Nginx的用户和组  创建nginx运行用户nginx并加入到nginx组，不允许nginx用户直接登录系统\n groupadd nginx useradd -g nginx nginx -s /sbin/nologin 安装Nginx 下载安装包 Nginx下载地址： http://nginx.org/en/download.html\n没有特殊需求的话，选择Stable version稳定版下载即可\ncd /usr/local/src/ wget http://nginx.org/download/nginx-1.20.1.tar.gz 解压安装包并进入目录 tar -zxvf nginx-1.20.1 cd nginx-1.20.1 编译安装 .","tags":null,"title":"Linux部署Nginx流程"},{"categories":null,"contents":" 结合上次Golang服务内存增长的分析，近期线上多个服务出现内存持续增长的问题，就这个现象分析一下Prometheus+Grafana的监控问题\n 问题现象 近期在Grafana上显示生产环境多个服务出现内存持续增长的问题，有Golang的服务，也有JAVA的服务。都是服务重启之后，内存来到一个最低水平， 随着服务运行时间增长，pod的内存占用也随之水涨船高。直到内存占用增长到pod限制的上限附近，内存才出现回收的迹象，并且回收幅度不是特别明显， 但同时又不会出现OOM。\n  Golang某个服务内存占用情况   JAVA某个服务内存占用情况   简单分析 记一次线上的内存持续增长问题\n↑这个是初次遇到这个问题时候的分析，当时以为是代码写的有漏洞，程序发生了内存泄漏。于是祭出了pprof分析了一顿，结果可想而知，当然是没看出有问题。\n现在是多个服务都出现类似问题，那这个情况相对也就比较值得重视了。之前那个服务是因为日志写的比较多，造成磁盘IO比较大。同样的， 近期发现的这几个内存持续不断增长的服务也都是日志量比较大的。\n进一步分析 集群日志架构 所有pod中的日志都是写入挂载到/data/log目录的物理机磁盘中，因此所有写日志的操作都会有磁盘IO。日志量越大的pod，磁盘IO相应地也越高。\n集群监控 普通pod监控采用了常见的Prometheus+Grafana的方案。\n数据源计算方式 监控数据是采集的kubernetes中监控程序cadvisor上报的container_memory_working_set_bytes字段（ 表格参照 ）\n查看cadvisor源码中setMemoryStats 可知，container_memory_working_set_bytes字段是cgroup memory.usage_in_bytes（RSS + Cache）与memory.stat total_inactive_file二者的差值\nfunc setMemoryStats(s *cgroups.Stats, ret *info.ContainerStats) { // ...  // ...  inactiveFileKeyName := \u0026#34;total_inactive_file\u0026#34; if cgroups.IsCgroup2UnifiedMode() { inactiveFileKeyName = \u0026#34;inactive_file\u0026#34; } workingSet := ret.Memory.Usage if v, ok := s.MemoryStats.Stats[inactiveFileKeyName]; ok { if workingSet \u0026lt; v { workingSet = 0 } else { workingSet -= v } } ret.Memory.WorkingSet = workingSet } 而memory.usage_in_bytes的统计数据是包含了所有的file cache的，total_active_file和total_inactive_file都属于file cache的一部分， 但是这两个数据并不是Pod中的程序真正占用的内存，只是系统为了提高磁盘IO的效率，将读写过的文件缓存在内存中。file cache并不会随着进程退出而释放，只会当容器销毁或者系统内存不足时才会由系统自动回收。\n所以cadvisor采用memory.usage_in_bytes - total_inactive_file计算出的结果并不是当前Pod中程序所占用的内存，当Pod内存资源紧张时total_active_file也是可回收利用的。\n验证结论 准备环境 去测试环境找到一个服务重启一下，并进入容器命令行\n准备一个较大的文件 找一个比较大的文件，这里找了一个8M左右的日志文件\n/app # ls -lah /data/log/xxxx.log -rw-r--r-- 1 root root 8.2M May 31 10:54 /data/log/xxxx.log 查看内存数据 在容器中进入/sys/fs/cgroup/memory/目录，并查看cat memory.stat内容\n/app # cd /sys/fs/cgroup/memory/ /sys/fs/cgroup/memory # cat memory.stat cache 38195200 rss 13484032 rss_huge 0 mapped_file 495616 swap 0 pgpgin 1550811 pgpgout 1538194 pgfault 1512338 pgmajfault 36 inactive_anon 0 active_anon 13422592 inactive_file 12058624 active_file 26136576 unevictable 0 hierarchical_memory_limit 314572800 hierarchical_memsw_limit 314572800 total_cache 38195200 total_rss 13484032 total_rss_huge 0 total_mapped_file 495616 total_swap 0 total_pgpgin 1550811 total_pgpgout 1538194 total_pgfault 1512338 total_pgmajfault 36 total_inactive_anon 0 total_active_anon 13422592 total_inactive_file 12058624 total_active_file 26136576 total_unevictable 0 记录此时\ntotal_inactive_file 12058624 Bytes = 11.5M\ntotal_active_file 26136576 Bytes = 24.9M\n遍历日志文件 /sys/fs/cgroup/memory # grep \u0026#34;hello\u0026#34; /data/log/xxx.log 第二次查看内存 /sys/fs/cgroup/memory # cat memory.stat  cache 46850048 rss 13500416 rss_huge 0 mapped_file 495616 swap 0 pgpgin 1552994 pgpgout 1538260 pgfault 1512642 pgmajfault 36 inactive_anon 0 active_anon 13459456 inactive_file 20709376 active_file 26140672 unevictable 0 hierarchical_memory_limit 314572800 hierarchical_memsw_limit 314572800 total_cache 46850048 total_rss 13500416 total_rss_huge 0 total_mapped_file 495616 total_swap 0 total_pgpgin 1552994 total_pgpgout 1538260 total_pgfault 1512642 total_pgmajfault 36 total_inactive_anon 0 total_active_anon 13459456 total_inactive_file 20709376 total_active_file 26140672 total_unevictable 0 记录此时\ntotal_inactive_file 20709376 Bytes = 19.6M\ntotal_active_file 26140672 Bytes = 24.9M\n此时total_inactive_file占用较上次增加大约8M左右，即遍历过的日志文件的大小。\n第二次遍历日志文件 对同一个文件第二次遍历访问\n/sys/fs/cgroup/memory # grep \u0026#34;hello\u0026#34; /data/log/xxx.log 第三次查看内存 /sys/fs/cgroup/memory # cat memory.stat  cache 46850048 rss 13504512 rss_huge 0 mapped_file 495616 swap 0 pgpgin 1553058 pgpgout 1538323 pgfault 1512941 pgmajfault 36 inactive_anon 0 active_anon 13459456 inactive_file 12025856 active_file 34824192 unevictable 0 hierarchical_memory_limit 314572800 hierarchical_memsw_limit 314572800 total_cache 46850048 total_rss 13504512 total_rss_huge 0 total_mapped_file 495616 total_swap 0 total_pgpgin 1553058 total_pgpgout 1538323 total_pgfault 1512941 total_pgmajfault 36 total_inactive_anon 0 total_active_anon 13459456 total_inactive_file 12025856 total_active_file 34824192 total_unevictable 0 记录此时\ntotal_inactive_file 12025856 Bytes = 11.5M\ntotal_active_file 34824192 Bytes = 33.2M\n此时total_inactive_file较上次减少8M，而total_active_file较上次增加8M\n查看Grafana   遍历日志文件之前   遍历日志文件之后   此时查看对应服务的Grafana面板可以看到，使用shell的grep命令遍历一个8M多的文件之后，在Pod中内存占用上升了大概8M。 而此时这块内存并没有被Pod中任何程序所引用，只是一个file cache的占用。\n总结 根据上述实验结果可以印证内存持续增长但不会OOM的现象。服务启动并向磁盘中持续追加日志文件，随之file cache持续上涨，直至达到Pod的内存上限之后，会出现GC。\n结论 memory.usage_in_bytes统计包含了Cached和Buffers，Cached中除了mlock_file和Shmem（IPCS shared memory \u0026amp; tmpfs）外， 其他部分file cache是可以回收使用的，Buffers也是可以回收利用的，所以Pod容器所在cgroup实际使用的内存计算公式可以转化为 (因memory.stat未导出SReclaimable，这里忽略SReclaimable)：\nreal_used = memory.usage_in_bytes – (Cached- Shmem - mlock_file + Buffers ) = memory.usage_in_bytes – memory.stat .( total_inactive_file + total_active_file ) 因此cadvisor中container_memory_working_set_bytes字段在计算实际已使用内存时应该改为：\nreal_used = memory.usage_in_bytes – memory.stat.total_inactive_file - memory.stat.total_active_file 但是 过程中去kubernetes 的issue 中逛了一圈，发现了几个相关问题的讨论：\n https://github.com/kubernetes/kubernetes/issues/43916 https://github.com/kubernetes/kubernetes/issues/104533  其中一个给我笑出声\nkubernetes should not count active_file as used memory, I have been waiting for 4 years!\n等了四年了，这个问题还没有解决。也许，我们从一开始就错了？缓存也应该算是pod内存占用？\n参考  https://lwn.net/Articles/432224/  ","date":"September 22, 2021","hero":"/posts/knowledge/2007-k8s-memory/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2007-k8s-memory/","summary":"结合上次Golang服务内存增长的分析，近期线上多个服务出现内存持续增长的问题，就这个现象分析一下Prometheus+Grafana的监控问题\n 问题现象 近期在Grafana上显示生产环境多个服务出现内存持续增长的问题，有Golang的服务，也有JAVA的服务。都是服务重启之后，内存来到一个最低水平， 随着服务运行时间增长，pod的内存占用也随之水涨船高。直到内存占用增长到pod限制的上限附近，内存才出现回收的迹象，并且回收幅度不是特别明显， 但同时又不会出现OOM。\n  Golang某个服务内存占用情况   JAVA某个服务内存占用情况   简单分析 记一次线上的内存持续增长问题\n↑这个是初次遇到这个问题时候的分析，当时以为是代码写的有漏洞，程序发生了内存泄漏。于是祭出了pprof分析了一顿，结果可想而知，当然是没看出有问题。\n现在是多个服务都出现类似问题，那这个情况相对也就比较值得重视了。之前那个服务是因为日志写的比较多，造成磁盘IO比较大。同样的， 近期发现的这几个内存持续不断增长的服务也都是日志量比较大的。\n进一步分析 集群日志架构 所有pod中的日志都是写入挂载到/data/log目录的物理机磁盘中，因此所有写日志的操作都会有磁盘IO。日志量越大的pod，磁盘IO相应地也越高。\n集群监控 普通pod监控采用了常见的Prometheus+Grafana的方案。\n数据源计算方式 监控数据是采集的kubernetes中监控程序cadvisor上报的container_memory_working_set_bytes字段（ 表格参照 ）\n查看cadvisor源码中setMemoryStats 可知，container_memory_working_set_bytes字段是cgroup memory.usage_in_bytes（RSS + Cache）与memory.stat total_inactive_file二者的差值\nfunc setMemoryStats(s *cgroups.Stats, ret *info.ContainerStats) { // ...  // ...  inactiveFileKeyName := \u0026#34;total_inactive_file\u0026#34; if cgroups.IsCgroup2UnifiedMode() { inactiveFileKeyName = \u0026#34;inactive_file\u0026#34; } workingSet := ret.Memory.Usage if v, ok := s.MemoryStats.Stats[inactiveFileKeyName]; ok { if workingSet \u0026lt; v { workingSet = 0 } else { workingSet -= v } } ret.","tags":null,"title":"Grafana上监控kubernetes中Pod已用内存不准问题分析"},{"categories":null,"contents":" 最近在学习大数据相关的东西，看了HDFS，Hive，HBas，Spark相关的东西，总结一下Hadoop生态中常见的组件。\n HDFS（hadoop分布式文件系统） HDFS是hadoop体系中数据存储管理的基础。他是一个高度容错的系统，能检测和应对硬件故障。\n有以下几个角色：\n  client：切分文件，访问HDFS，与那么弄得交互，获取文件位置信息，与DataNode交互，读取和写入数据。\n  namenode：master节点，在hadoop1.x中只有一个，管理HDFS的名称空间和数据块映射信息，配置副本策略，处理客户 端请求。\n  DataNode：slave节点，存储实际的数据，汇报存储信息给namenode。\n  secondary namenode：辅助namenode，分担其工作量：定期合并fsimage和fsedits，推送给namenode；紧急情况下和辅助恢复namenode，但其并非namenode的热备。\n  mapreduce（分布式计算框架） mapreduce是一种计算模型，用于处理大数据量的计算。其中map对应数据集上的独立元素进行指定的操作，生成键-值对形式中间，reduce则对中间结果中相同的键的所有值进行规约，以得到最终结果。\n  jobtracker：master节点，只有一个，管理所有作业，任务/作业的监控，错误处理等，将任务分解成一系列任务，并分派给tasktracker。\n  tacktracker：slave节点，运行 map task和reducetask；并与jobtracker交互，汇报任务状态。\n  map task：解析每条数据记录，传递给用户编写的map（）并执行，将输出结果写入到本地磁盘（如果为map—only作业，则直接写入HDFS）。\n  reduce task：从map 它深刻地执行结果中，远程读取输入数据，对数据进行排序，将数据分组传递给用户编写的reduce函数执行。\n  hive（基于hadoop的数据仓库） 由Facebook开源，最初用于解决海量结构化的日志数据统计问题。\nhive定于了一种类似sql的查询语言（hql）将sql转化为mapreduce任务在hadoop上执行。\nhbase（分布式列存数据库） hbase是一个针对结构化数据的可伸缩，高可靠，高性能，分布式和面向列的动态模式数据库。和传统关系型数据库不同，hbase采用了bigtable的数据模型： 增强了稀疏排序映射表（key/value）。其中，键由行关键字，列关键字和时间戳构成，hbase提供了对大规模数据的随机，实时读写访问，同时，hbase中保 存的数据可以使用mapreduce来处理，它将数据存储和并行计算完美结合在一起。\nzookeeper（分布式协作服务） 解决分布式环境下的数据管理问题：统一命名，状态同步，集群管理，配置同步等。\nsqoop（数据同步工具） sqoop是sql-to-hadoop的缩写，主要用于传统数据库和hadoop之间传输数据。数据的导入和导出本质上是mapreduce程序，充分利用了MR的并行化和容错性。\npig（基于hadoop的数据流系统） 定义了一种数据流语言-pig latin，将脚本转换为mapreduce任务在hadoop上执行。通常用于离线分析。\nmahout（数据挖掘算法库） mahout的主要目标是创建一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建只能应用程序。mahout现在已经包含了聚类，分类， 推荐引擎（协同过滤）和频繁集挖掘等广泛使用的数据挖掘方法。除了算法是，mahout还包含了数据的输入/输出工具，与其他存储系统（如数据库，mongoDB或 Cassandra）集成等数据挖掘支持架构。\nflume（日志收集工具） cloudera开源的日志收集系统，具有分布式，高可靠，高容错，易于定制和扩展的特点。他将数据从产生，传输，处理并写入目标的路径的过程抽象为数据流，在 具体的数据流中，数据源支持在flume中定制数据发送方，从而支持收集各种不同协议数据。\n资源管理器的简单介绍（YARN和mesos） 随着互联网的高速发展，基于数据 密集型应用 的计算框架不断出现，从支持离线处理的mapreduce，到支持在线处理的storm，从迭代式计算框架到 流式处理框 架s4，\u0026hellip;，在大部分互联网公司中，这几种框架可能都会采用，比如对于搜索引擎公司，可能的技术方法如下：网页建索引采用mapreduce框架，自然语言处理/ 数据挖掘采用spark，对性能要求到的数据挖掘算法用mpi等。公司一般将所有的这些框架部署到一个公共的集群中，让它们共享集群的资源，并对资源进行统一使 用，这样便诞生了资源统一管理与调度平台，典型的代表是mesos和yarn。\n其他的一些开源组件： cloudrea impala： 一个开源的查询引擎。与hive相同的元数据，SQL语法，ODBC驱动程序和用户接口，可以直接在HDFS上提供快速，交互式SQL查询。impala不再使用缓慢的 hive+mapreduce批处理，而是通过与商用并行关系数据库中类似的分布式查询引擎。可以直接从HDFS或者Hbase中用select，join和统计函数查询数据，从而 大大降低延迟。\nspark： spark是个开源的数据 分析集群计算框架，最初由加州大学伯克利分校AMPLab，建立于HDFS之上。spark与hadoop一样，用于构建大规模，延迟低的数据分析 应用。spark采用Scala语言实现，使用Scala作为应用框架。\nspark采用基于内存的分布式数据集，优化了迭代式的工作负载以及交互式查询。\n与hadoop不同的是，spark与Scala紧密集成，Scala象管理本地collective对象那样管理分布式数据集。spark支持分布式数据集上的迭代式任务，实际上可 以在hadoop文件系统上与hadoop一起运行（通过YARN,MESOS等实现）。\nstorm storm是一个分布式的，容错的计算系统，storm属于流处理平台，多用于实时计算并更新数据库。storm也可被用于“连续计算”，对数据流做连续查询，在计算 时将结果一流的形式输出给用户。他还可被用于“分布式RPC”,以并行的方式运行昂贵的运算。\nkafka kafka是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的 网站中的所有动作流数据。 这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。 这些数据通常是由于吞吐量的要求 而通过处理日志和日志聚合来解决。 对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka的目的是通 过Hadoop的并行加载机制来统一线上和离线的消息处理，也是为了通过集群来提供实时的消息\n","date":"September 17, 2021","hero":"/posts/knowledge/2006-hadoop-env/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2006-hadoop-env/","summary":"最近在学习大数据相关的东西，看了HDFS，Hive，HBas，Spark相关的东西，总结一下Hadoop生态中常见的组件。\n HDFS（hadoop分布式文件系统） HDFS是hadoop体系中数据存储管理的基础。他是一个高度容错的系统，能检测和应对硬件故障。\n有以下几个角色：\n  client：切分文件，访问HDFS，与那么弄得交互，获取文件位置信息，与DataNode交互，读取和写入数据。\n  namenode：master节点，在hadoop1.x中只有一个，管理HDFS的名称空间和数据块映射信息，配置副本策略，处理客户 端请求。\n  DataNode：slave节点，存储实际的数据，汇报存储信息给namenode。\n  secondary namenode：辅助namenode，分担其工作量：定期合并fsimage和fsedits，推送给namenode；紧急情况下和辅助恢复namenode，但其并非namenode的热备。\n  mapreduce（分布式计算框架） mapreduce是一种计算模型，用于处理大数据量的计算。其中map对应数据集上的独立元素进行指定的操作，生成键-值对形式中间，reduce则对中间结果中相同的键的所有值进行规约，以得到最终结果。\n  jobtracker：master节点，只有一个，管理所有作业，任务/作业的监控，错误处理等，将任务分解成一系列任务，并分派给tasktracker。\n  tacktracker：slave节点，运行 map task和reducetask；并与jobtracker交互，汇报任务状态。\n  map task：解析每条数据记录，传递给用户编写的map（）并执行，将输出结果写入到本地磁盘（如果为map—only作业，则直接写入HDFS）。\n  reduce task：从map 它深刻地执行结果中，远程读取输入数据，对数据进行排序，将数据分组传递给用户编写的reduce函数执行。\n  hive（基于hadoop的数据仓库） 由Facebook开源，最初用于解决海量结构化的日志数据统计问题。\nhive定于了一种类似sql的查询语言（hql）将sql转化为mapreduce任务在hadoop上执行。\nhbase（分布式列存数据库） hbase是一个针对结构化数据的可伸缩，高可靠，高性能，分布式和面向列的动态模式数据库。和传统关系型数据库不同，hbase采用了bigtable的数据模型： 增强了稀疏排序映射表（key/value）。其中，键由行关键字，列关键字和时间戳构成，hbase提供了对大规模数据的随机，实时读写访问，同时，hbase中保 存的数据可以使用mapreduce来处理，它将数据存储和并行计算完美结合在一起。\nzookeeper（分布式协作服务） 解决分布式环境下的数据管理问题：统一命名，状态同步，集群管理，配置同步等。\nsqoop（数据同步工具） sqoop是sql-to-hadoop的缩写，主要用于传统数据库和hadoop之间传输数据。数据的导入和导出本质上是mapreduce程序，充分利用了MR的并行化和容错性。\npig（基于hadoop的数据流系统） 定义了一种数据流语言-pig latin，将脚本转换为mapreduce任务在hadoop上执行。通常用于离线分析。\nmahout（数据挖掘算法库） mahout的主要目标是创建一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建只能应用程序。mahout现在已经包含了聚类，分类， 推荐引擎（协同过滤）和频繁集挖掘等广泛使用的数据挖掘方法。除了算法是，mahout还包含了数据的输入/输出工具，与其他存储系统（如数据库，mongoDB或 Cassandra）集成等数据挖掘支持架构。\nflume（日志收集工具） cloudera开源的日志收集系统，具有分布式，高可靠，高容错，易于定制和扩展的特点。他将数据从产生，传输，处理并写入目标的路径的过程抽象为数据流，在 具体的数据流中，数据源支持在flume中定制数据发送方，从而支持收集各种不同协议数据。\n资源管理器的简单介绍（YARN和mesos） 随着互联网的高速发展，基于数据 密集型应用 的计算框架不断出现，从支持离线处理的mapreduce，到支持在线处理的storm，从迭代式计算框架到 流式处理框 架s4，\u0026hellip;，在大部分互联网公司中，这几种框架可能都会采用，比如对于搜索引擎公司，可能的技术方法如下：网页建索引采用mapreduce框架，自然语言处理/ 数据挖掘采用spark，对性能要求到的数据挖掘算法用mpi等。公司一般将所有的这些框架部署到一个公共的集群中，让它们共享集群的资源，并对资源进行统一使 用，这样便诞生了资源统一管理与调度平台，典型的代表是mesos和yarn。","tags":null,"title":"Hadoop生态组件"},{"categories":null,"contents":"  问题现象 前些天从Grafana上看到某一个pod内存涨上去就再没下来（从9/1~9/2之间的一个时间开始），并且看这个趋势涨上去就没有下来的意思。中间有几次pod重新发布 才导致内存恢复到一个比较低的水平，但内存依旧持续上涨。\n初步分析 初步推测大概率与日志有关，此次发版改动了日志输出格式，以及修改了日志没有写入磁盘的问题。\n先把服务稳住 由于清楚问题的大致方向，先将服务中几个打印log比较频繁的位置注释掉，在9/3~9/4之间的一个位置重新发布。从之后的趋势上可以看出，注释掉几个打印日志的 地方之后，内存增长速度明显放缓。\n至此，基本可以确认内存增长与日志相关。\n问题排查 猜测一 回头又捋了几遍代码，也没发现什么端倪。\n于是祭出pprof抓了一下内存分析了一通，依旧无果。\n可以看出，内存占用并没有多高。\n猜测二  在 Go1.12 以前，Go Runtime在Linux上使用的是MADV_DONTNEED策略，可以让RSS下降的比较快，就是效率差点。 在 Go1.12 及以后，Go Runtime专门针对其进行了优化，使用了更为高效的MADV_FREE策略。但这样子所带来的副作用就是RSS不会立刻下降， 要等到系统有内存压力了才会释放占用，RSS才会下降。  查看容器的 Linux 内核版本：\n# 查看命令 uname -a 课件容器版本为3.10.0，但MADV_FREE的策略改变，需要Linux内核在4.5及以上（详细可见go/issues/23687 ）， 因此可以排除。\n猜想三 通过top命令可以通过可以查看容器中程序的内存占用VSZ为711，无法查看RSS，关于RSS和VSZ的区别，可以参考RSS和VSZ\n容器内存判定是通过container_memory_working_set_bytes，而container_memory_working_set_bytes是由cadvisor提供的。\n原因 从cadvisor/issues/638 可得知container_memory_working_set_bytes指标的组 成实际上是RSS + Cache。而Cache高的情况，常见于进程有大量文件IO，占用Cache可能就会比较高，猜测也与Go版本、Linux 内核版本的Cache释放、回收方式有较大关系。 只要是涉及有大量文件IO的服务，基本上是这个问题的老常客了，写这类服务基本写一个中一个，因为这是一个混合问题，像其它单纯操作为主的业务服务就很 “正常”，不会出现内存居高不下。\n没多久看到烤鱼佬的一篇文章，与这个情况类似，他的解决办法也就是写了个脚本，\u0026ldquo;手动\u0026quot;HPA（其实也就是自动重启）。\n总结 虽然这问题时间跨度比较长，整体来讲都是阶段性排查，本质上可以说是对Kubernetes的不熟悉有关。但因为内存居高不下的可能性有很多种，要一个个排查。\n","date":"September 15, 2021","hero":"/posts/problems/5000-go-online-service-oom/head.svg","permalink":"https://ormissia.github.io/posts/problems/5000-go-online-service-oom/","summary":"问题现象 前些天从Grafana上看到某一个pod内存涨上去就再没下来（从9/1~9/2之间的一个时间开始），并且看这个趋势涨上去就没有下来的意思。中间有几次pod重新发布 才导致内存恢复到一个比较低的水平，但内存依旧持续上涨。\n初步分析 初步推测大概率与日志有关，此次发版改动了日志输出格式，以及修改了日志没有写入磁盘的问题。\n先把服务稳住 由于清楚问题的大致方向，先将服务中几个打印log比较频繁的位置注释掉，在9/3~9/4之间的一个位置重新发布。从之后的趋势上可以看出，注释掉几个打印日志的 地方之后，内存增长速度明显放缓。\n至此，基本可以确认内存增长与日志相关。\n问题排查 猜测一 回头又捋了几遍代码，也没发现什么端倪。\n于是祭出pprof抓了一下内存分析了一通，依旧无果。\n可以看出，内存占用并没有多高。\n猜测二  在 Go1.12 以前，Go Runtime在Linux上使用的是MADV_DONTNEED策略，可以让RSS下降的比较快，就是效率差点。 在 Go1.12 及以后，Go Runtime专门针对其进行了优化，使用了更为高效的MADV_FREE策略。但这样子所带来的副作用就是RSS不会立刻下降， 要等到系统有内存压力了才会释放占用，RSS才会下降。  查看容器的 Linux 内核版本：\n# 查看命令 uname -a 课件容器版本为3.10.0，但MADV_FREE的策略改变，需要Linux内核在4.5及以上（详细可见go/issues/23687 ）， 因此可以排除。\n猜想三 通过top命令可以通过可以查看容器中程序的内存占用VSZ为711，无法查看RSS，关于RSS和VSZ的区别，可以参考RSS和VSZ\n容器内存判定是通过container_memory_working_set_bytes，而container_memory_working_set_bytes是由cadvisor提供的。\n原因 从cadvisor/issues/638 可得知container_memory_working_set_bytes指标的组 成实际上是RSS + Cache。而Cache高的情况，常见于进程有大量文件IO，占用Cache可能就会比较高，猜测也与Go版本、Linux 内核版本的Cache释放、回收方式有较大关系。 只要是涉及有大量文件IO的服务，基本上是这个问题的老常客了，写这类服务基本写一个中一个，因为这是一个混合问题，像其它单纯操作为主的业务服务就很 “正常”，不会出现内存居高不下。\n没多久看到烤鱼佬的一篇文章，与这个情况类似，他的解决办法也就是写了个脚本，\u0026ldquo;手动\u0026quot;HPA（其实也就是自动重启）。\n总结 虽然这问题时间跨度比较长，整体来讲都是阶段性排查，本质上可以说是对Kubernetes的不熟悉有关。但因为内存居高不下的可能性有很多种，要一个个排查。","tags":null,"title":"记一次线上的内存持续增长问题"},{"categories":null,"contents":"   StructTag是写在结构体字段类型后面反引号中的内容，用来标记结构体中各字段的属性。\n  源码中对struct tag的解释：\n By convention, tag strings are a concatenation of optionally space-separated key:\u0026ldquo;value\u0026rdquo; pairs. Each key is a non-empty string consisting of non-control characters other than space (U+0020 ' \u0026lsquo;), quote (U+0022 \u0026lsquo;\u0026quot;'), and colon (U+003A \u0026lsquo;:'). Each value is quoted using U+0022 \u0026lsquo;\u0026quot;\u0026rsquo; characters and Go string literal syntax.\n  简单应用 最常见的，比如json的tag应用：\njson序列化和反序列化时候使用的key都是在struct字段上定义的\npackage main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; ) type User struct { ID int `json:\u0026#34;id\u0026#34;` Username string `json:\u0026#34;username\u0026#34;` Age int `json:\u0026#34;age\u0026#34;` Email string `json:\u0026#34;email\u0026#34;` } func main() { u := User{ ID: 1, Username: \u0026#34;ormissia\u0026#34;, Age: 90, Email: \u0026#34;email@example.com\u0026#34;, } userJson, _ := json.Marshal(u) fmt.Println(string(userJson)) u2Str := `{\u0026#34;id\u0026#34;:2,\u0026#34;username\u0026#34;:\u0026#34;ormissia\u0026#34;,\u0026#34;age\u0026#34;:900,\u0026#34;email\u0026#34;:\u0026#34;ormissia@example.com\u0026#34;}` u2 := new(User) _ = json.Unmarshal([]byte(u2Str), u2) fmt.Printf(\u0026#34;%+v\u0026#34;,u2) } 输出：\n{\u0026#34;id\u0026#34;:1,\u0026#34;username\u0026#34;:\u0026#34;ormissia\u0026#34;,\u0026#34;age\u0026#34;:90,\u0026#34;email\u0026#34;:\u0026#34;email@example.com\u0026#34;} \u0026amp;{ID:2 Username:ormissia Age:900 Email:ormissia@example.com} tag解析原理 通过反射拿到struct tag 示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) type User struct { ID int `json:\u0026#34;id\u0026#34; myTag:\u0026#34;ID\u0026#34;` Username string `json:\u0026#34;username\u0026#34; myTag:\u0026#34;USERNAME\u0026#34;` Age int `json:\u0026#34;age\u0026#34; myTag:\u0026#34;AGE\u0026#34;` Email string `json:\u0026#34;email\u0026#34; myTag:\u0026#34;EMAIL\u0026#34;` } func main() { u := User{1, \u0026#34;ormissia\u0026#34;, 90, \u0026#34;email@example.com\u0026#34;} userTyp := reflect.TypeOf(u) fieldTag := userTyp.Field(0).Tag fmt.Printf(\u0026#34;user field 0 id tag: %s\\n\u0026#34;,fieldTag) value, ok1 := fieldTag.Lookup(\u0026#34;myTag\u0026#34;) fmt.Println(value, ok1) value1, ok2 := fieldTag.Lookup(\u0026#34;other\u0026#34;) fmt.Println(value1, ok2) } 输出：\nuser field 0 id tag: json:\u0026#34;id\u0026#34; myTag:\u0026#34;ID\u0026#34; ID true false 获取tag全部的值 reflect.TypeOf(u).Field(0).Tag 通过Tag即可获取struct定义时候对应字段后面反引号``中全部的值\nTag是通过反射获取到的具体字段StructField 中的属性，类型为自定义string类型：StructTag\ntype StructField struct { // Name is the field name. \tName string // PkgPath is the package path that qualifies a lower case (unexported) \t// field name. It is empty for upper case (exported) field names. \t// See https://golang.org/ref/spec#Uniqueness_of_identifiers \tPkgPath string Type Type // field type \tTag StructTag // field tag string \tOffset uintptr // offset within struct, in bytes \tIndex []int // index sequence for Type.FieldByIndex \tAnonymous bool // is an embedded field } // A StructTag is the tag string in a struct field. // // By convention, tag strings are a concatenation of // optionally space-separated key:\u0026#34;value\u0026#34; pairs. // Each key is a non-empty string consisting of non-control // characters other than space (U+0020 \u0026#39; \u0026#39;), quote (U+0022 \u0026#39;\u0026#34;\u0026#39;), // and colon (U+003A \u0026#39;:\u0026#39;). Each value is quoted using U+0022 \u0026#39;\u0026#34;\u0026#39; // characters and Go string literal syntax. type StructTag string 通过tag的key获取value 而StructTag 有两个通过key获取value的方法： Get 和Lookup 。\nGet 是对Lookup 的一个封装。\nLookup 可以返回当前查询的key是否存在。\nfunc (tag StructTag) Get(key string) string { v, _ := tag.Lookup(key) return v } func (tag StructTag) Lookup(key string) (value string, ok bool) { for tag != \u0026#34;\u0026#34; { // Skip leading space. \ti := 0 for i \u0026lt; len(tag) \u0026amp;\u0026amp; tag[i] == \u0026#39; \u0026#39; { i++ } tag = tag[i:] if tag == \u0026#34;\u0026#34; { break } i = 0 for i \u0026lt; len(tag) \u0026amp;\u0026amp; tag[i] \u0026gt; \u0026#39; \u0026#39; \u0026amp;\u0026amp; tag[i] != \u0026#39;:\u0026#39; \u0026amp;\u0026amp; tag[i] != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; tag[i] != 0x7f { i++ } if i == 0 || i+1 \u0026gt;= len(tag) || tag[i] != \u0026#39;:\u0026#39; || tag[i+1] != \u0026#39;\u0026#34;\u0026#39; { break } name := string(tag[:i]) tag = tag[i+1:] //...  //... } 通过源码，我们可以看出 Lookup 实际上是对tag反引号中整个内容进行查找，通过空格、冒号以及双引号对tag的值进行分割，最后返回。\n使用自定义tag实践 我们可以一个struct参数校验器：go-opv 来简单体验一下自定义tag的使用。\ngo-opv的简单使用示例  go-opv 的简介可以参考我的 另一篇文章 。 只不过，当时还没有添加这个通过struct自定义tag的校验方式，基础功能与现在基本一致。\n 仓库go-opv\n以下是一个简单的使用Demo\n在这个示例中，我们指定了struct的tag为go-opv:\u0026quot;ge:0,le:20\u0026quot;，在参数检验过程中，我们会解析这个tag，并从中获取定义的规则。\npackage main import ( \u0026#34;log\u0026#34; go_opv \u0026#34;github.com/ormissia/go-opv\u0026#34; ) type User struct { Name string `go-opv:\u0026#34;ge:0,le:20\u0026#34;` //Name \u0026gt;=0 \u0026amp;\u0026amp; Name \u0026lt;=20 \tAge int `go-opv:\u0026#34;ge:0,lt:100\u0026#34;` //Age \u0026gt;= 0 \u0026amp;\u0026amp; Age \u0026lt; 100 } func init() { //使用默认配置：struct tag名字为\u0026#34;go-opv\u0026#34;，规则与限定值的分隔符为\u0026#34;:\u0026#34; \tmyVerifier = go_opv.NewVerifier() //初始化一个验证规则：Age字段大于等于0，小于200 \tuserRequestRules = go_opv.Rules{ \u0026#34;Age\u0026#34;: []string{myVerifier.Ge(\u0026#34;0\u0026#34;), myVerifier.Lt(\u0026#34;200\u0026#34;)}, } } var myVerifier go_opv.Verifier var userRequestRules go_opv.Rules func main() { // ShouldBind(\u0026amp;user) in Gin framework or other generated object \tuser := User{ Name: \u0026#34;ormissia\u0026#34;, Age: 190, } //两种验证方式混合,函数参数中传入自定义规则时候会覆盖struct tag上定义的规则 \t//根据自定义规则Age \u0026gt;= 0 \u0026amp;\u0026amp; Age \u0026lt; 200，Age的值为190，符合规则，验证通过 \tif err := myVerifier.Verify(user, userRequestRules); err != nil { log.Println(err) } else { log.Println(\u0026#34;pass\u0026#34;) } //只用struct的tag验证 \t//根据tag上定义的规则Age \u0026gt;= 0 \u0026amp;\u0026amp; Age \u0026lt; 100，Age的值为190，不符合规则，验证不通过 \tif err := myVerifier.Verify(user); err != nil { log.Println(err) } else { log.Println(\u0026#34;pass\u0026#34;) } } go-opv的简单分析 我们先判断了是否传入了自定义的校验规则（即为自定义规则会覆盖struct上tag定义的规则），如果没有，就去通过反射获取struct上tag定义的规则。 然后生成相对应的规则，继续执行后面的校验逻辑。\nif len(conditions[tagVal.Name]) == 0 { //没有自定义使用tag \t//`go-opv:\u0026#34;ne:0,eq:10\u0026#34;` \t//conditionsStr = \u0026#34;ne:0,eq:10\u0026#34; \tif conditionsStr, ok := tagVal.Tag.Lookup(verifier.tagPrefix); ok \u0026amp;\u0026amp; conditionsStr != \u0026#34;\u0026#34; { conditionStrs := strings.Split(conditionsStr, \u0026#34;,\u0026#34;) conditions[tagVal.Name] = conditionStrs } else { //如果tag也没有定义则去校验下一个字段 \tcontinue } } 小结  通过使用encoding/json 包中的json.Marshal() 和json.Unmarshal() ，我们了解了Golang中struct tag的基本概念及用途。 通过对StructField 的分析，我们明白了struct tag工作的基本原理 而通过go-opv 的分析，我们了解了自定义tag的基本使用方法。  参考  go1.16.7 type.go 源码  ","date":"August 13, 2021","hero":"/posts/knowledge/2005-go-tag/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2005-go-tag/","summary":"StructTag是写在结构体字段类型后面反引号中的内容，用来标记结构体中各字段的属性。\n  源码中对struct tag的解释：\n By convention, tag strings are a concatenation of optionally space-separated key:\u0026ldquo;value\u0026rdquo; pairs. Each key is a non-empty string consisting of non-control characters other than space (U+0020 ' \u0026lsquo;), quote (U+0022 \u0026lsquo;\u0026quot;'), and colon (U+003A \u0026lsquo;:'). Each value is quoted using U+0022 \u0026lsquo;\u0026quot;\u0026rsquo; characters and Go string literal syntax.\n  简单应用 最常见的，比如json的tag应用：\njson序列化和反序列化时候使用的key都是在struct字段上定义的\npackage main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; ) type User struct { ID int `json:\u0026#34;id\u0026#34;` Username string `json:\u0026#34;username\u0026#34;` Age int `json:\u0026#34;age\u0026#34;` Email string `json:\u0026#34;email\u0026#34;` } func main() { u := User{ ID: 1, Username: \u0026#34;ormissia\u0026#34;, Age: 90, Email: \u0026#34;email@example.","tags":null,"title":"Golang struct tag浅析与自定义tag实践"},{"categories":null,"contents":"   前缀树又称字典树\n Trie的应用  自动补全,例如：在百度搜索的输入框中,输入一个单词的前半部分,能够自动补全出可能的单词结果。 拼写检查，例如：在word中输入一个拼写错误的单词, 能够自动检测出来。 IP路由表，在IP路由表中进行路由匹配时, 要按照最长匹配前缀的原则进行匹配。 T9预测文本，在大多手机输入法中, 都会用9格的那种输入法. 这个输入法能够根据用户在9格上的输入,自动匹配出可能的单词。 填单词游戏，相信大多数人都玩过那种在横竖的格子里填单词的游戏。  ","date":"August 12, 2021","hero":"/posts/algorithm/4002-algorithm-trie/head.svg","permalink":"https://ormissia.github.io/posts/algorithm/4002-algorithm-trie/","summary":"   前缀树又称字典树\n Trie的应用  自动补全,例如：在百度搜索的输入框中,输入一个单词的前半部分,能够自动补全出可能的单词结果。 拼写检查，例如：在word中输入一个拼写错误的单词, 能够自动检测出来。 IP路由表，在IP路由表中进行路由匹配时, 要按照最长匹配前缀的原则进行匹配。 T9预测文本，在大多手机输入法中, 都会用9格的那种输入法. 这个输入法能够根据用户在9格上的输入,自动匹配出可能的单词。 填单词游戏，相信大多数人都玩过那种在横竖的格子里填单词的游戏。  ","tags":null,"title":"前缀树"},{"categories":null,"contents":"  归并排序 思想 整体是递归（当然可以用非递归实现），使左边有序，使右边有序，合并左边右边使整体有序\n具体实现\n核心代码 func merge(arr []interface{}, l, mid, r int, compare Compare) { help := make([]interface{}, r-l+1) i := 0 p1 := l p2 := mid + 1 for p1 \u0026lt;= mid \u0026amp;\u0026amp; p2 \u0026lt;= r { if compare(arr[p1], arr[p2]) { help[i] = arr[p1] p1++ } else { help[i] = arr[p2] p2++ } i++ } //要么p1越界了，要么p2越界了 \tfor p1 \u0026lt;= mid { help[i] = arr[p1] i++ p1++ } for p2 \u0026lt;= r { help[i] = arr[p2] i++ p2++ } for j, _ := range help { arr[l+j] = help[j] } } 递归 核心代码\nfunc mergeProcess(arr []interface{}, l, r int, compare Compare) { if l == r { return } mid := l + ((r - l) \u0026gt;\u0026gt; 1) mergeProcess(arr, l, mid, compare) mergeProcess(arr, mid+1, r, compare) merge(arr, l, mid, r, compare) } 非递归 核心代码：\nn := len(arr) mergeSize := 1 //当前有序的左组长度 \tfor mergeSize \u0026lt; n { l := 0 for l \u0026lt; n { m := l + mergeSize - 1 if m \u0026gt;= n { break } r := m + mergeSize if m+mergeSize \u0026gt; n-1 { r = n - 1 } merge(arr, l, m, r, s.Compare) l = r + 1 } //防止溢出 \tif mergeSize \u0026gt; n/2 { break } mergeSize \u0026lt;\u0026lt;= 1 } 快速排序 具体实现\n思想 给定一个数组arr和一个整数num，把小于等于num的数放在数组左边，大于num的数放在数组的右边。\n 额外空间复杂度是O(1)，时间复杂度O(N)\n 核心代码 func netherlandsFlag(arr []interface{}, l, r int, isEqual, isSmall Compare) (i, j int) { if l \u0026gt; r { return -1, -1 } if l == r { return l, r } less := l - 1 //小于arr[R]区\t右边界 \tmore := r //大于arr[R]区\t左边界 \tindex := l for index \u0026lt; more { if isEqual(arr[index], arr[r]) { index++ } else if isSmall(arr[index], arr[r]) { less++ arr[index], arr[less] = arr[less], arr[index] index++ } else { more-- arr[index], arr[more] = arr[more], arr[index] } } arr[more], arr[r] = arr[r], arr[more] return less + 1, more } 递归 核心代码：\nfunc quickProcess(arr []interface{}, l, r int, isEqual, isSmall Compare) { if l \u0026gt;= r { return } n := rand.Intn(r-l+1) + l arr[n], arr[r] = arr[r], arr[n] i, j := netherlandsFlag(arr, l, r, isEqual, isSmall) quickProcess(arr, l, i-1, isEqual, isSmall) quickProcess(arr, j+1, r, isEqual, isSmall) } 堆排序  堆的实质是一棵完全二叉树\n 堆可分为两种类型：\n 大根堆：所有子树的根节点均为最大值 小根堆：所有子树的根节点均为最小值  一般情况下堆可以用一个有序数组来存储\n[0\u0026hellip;i\u0026hellip;n] i节点的左孩子index为2*i+1，右孩子为2i+2，父节点为(i-1)/2\n也有一种特例是从1开始(位运算比加减法快)\n[01\u0026hellip;i\u0026hellip;n] i节点的左孩子index为2*i即i\u0026lt;\u0026lt;1，右孩子为2i+1即i\u0026lt;\u0026lt;1|1，父节点为i/2\n 让整个数组都变成大根堆的结构，建堆的过程：  从上到下的方法：时间复杂度为O(N*logN) 从下到上的方法：时间复杂度为O(N)   把堆的根节点个末尾值交换，减小堆的大小之后，再去调整堆，周而复始，时间复杂度为O(N*logN)  思想 依次弹出根节点，假设将大根堆弹出的值依次放到数组头部，则得到一个由小到大的数组\n 适合元素在固定范围内移动\n 具体实现\n核心代码 上浮 //上浮（通常是最后一个节点） //停止条件：1.没有父节点大，2.上浮到根节点了 func (h *maxHeap) heapInsert() { index := h.heapSize - 1 for h.comparator(h.Content[(index-1)/2], h.Content[index]) \u0026gt; 0 { h.Content[index], h.Content[(index-1)/2] = h.Content[(index-1)/2], h.Content[index] index = (index - 1) / 2 } } 下沉 //index位置节点不断下沉 //停止条件，1.没有孩子比自己大，2.没有孩子 func (h *maxHeap) heapify(index int) { left := index*2 + 1 for left \u0026lt; h.heapSize { //先比较左右两个孩子，挑出大的那个 \tlargest := left if left+1 \u0026lt; h.heapSize \u0026amp;\u0026amp; h.comparator(h.Content[left], h.Content[left+1]) \u0026gt; 0 { largest = left + 1 } //再比较根节点和大的那个孩子，如果最大的那个孩子也没有index大，就break \tif h.comparator(h.Content[index], h.Content[largest]) \u0026lt;= 0 { break } h.Content[index], h.Content[largest] = h.Content[largest], h.Content[index] index = largest left = index*2 + 1 } } 插入 func (h *maxHeap) Push(value interface{}) (err error) { if h.IsFull() { return errHeepFull } h.Content[h.heapSize] = value h.heapSize++ h.heapInsert() return nil } 弹出 func (h *maxHeap) Pop() (value interface{}, err error) { if h.IsEmpty() { return nil, errHeepEmpty } value = h.Content[0] h.heapSize-- h.Content[0] = h.Content[h.heapSize] h.heapify(0) return value, nil } 桶排序  排序算法总结    排序算法 时间复杂度 额外空间复杂度 稳定性     选择排序 O(N^2) O(1) 无   冒泡排序 O(N^2) O(1) 有   插入排序 O(N^2) O(1) 有   归并排序 O(N*logN) O(N) 有   随机快排 O(N*logN) O(logN) 无   堆排序 O(N*logN) O(1) 无   计数排序 O(N) O(M) 有   基数排序 O(N) O(N) 有    ","date":"August 7, 2021","hero":"/posts/algorithm/4001-algorithm-sort/head.svg","permalink":"https://ormissia.github.io/posts/algorithm/4001-algorithm-sort/","summary":"归并排序 思想 整体是递归（当然可以用非递归实现），使左边有序，使右边有序，合并左边右边使整体有序\n具体实现\n核心代码 func merge(arr []interface{}, l, mid, r int, compare Compare) { help := make([]interface{}, r-l+1) i := 0 p1 := l p2 := mid + 1 for p1 \u0026lt;= mid \u0026amp;\u0026amp; p2 \u0026lt;= r { if compare(arr[p1], arr[p2]) { help[i] = arr[p1] p1++ } else { help[i] = arr[p2] p2++ } i++ } //要么p1越界了，要么p2越界了 \tfor p1 \u0026lt;= mid { help[i] = arr[p1] i++ p1++ } for p2 \u0026lt;= r { help[i] = arr[p2] i++ p2++ } for j, _ := range help { arr[l+j] = help[j] } } 递归 核心代码","tags":null,"title":"排序算法"},{"categories":null,"contents":"   pprof is a tool for visualization and analysis of profiling data.\n  pprof reads a collection of profiling samples in profile.proto format and generates reports to visualize and help analyze the data. It can generate both text and graphical reports (through the use of the dot visualization package).\n  PProf是用于可视化和分析性能分析数据的工具，PProf以profile.proto读取分析样本的集合，并生成报告以可视化并帮助分析数据（支持文本和图形报告）。\n 简介 采集方式  runtime/pprof：采集程序（非Server）的指定区块的运行数据进行分析。 net/http/pprof：基于HTTPServer运行，并且可以采集运行时数据进行分析。 gotest：通过运行测试用例，并指定所需标识来进行采集。  功能  CPUProfiling：CPU分析，按照一定的频率采集所监听的应用程序CPU（含寄存器）的使用情况，可确定应用程序在主动消耗CPU周期时花费时间的位置。 MemoryProfiling：内存分析，在应用程序进行堆分配时记录堆栈跟踪，用于监视当前和历史内存使用情况，以及检查内存泄漏。 BlockProfiling：阻塞分析，记录Goroutine阻塞等待同步（包括定时器通道）的位置，默认不开启，需要调用runtime.SetBlockProfileRate进行设置。 MutexProfiling：互斥锁分析，报告互斥锁的竞争情况，默认不开启，需要调用runtime.SetMutexProfileFraction进行设置。 GoroutineProfiling：Goroutine分析，可以对当前应用程序正在运行的Goroutine进行堆栈跟踪和分析。这项功能在实际排查中会经常用到， 因为很多问题出现时的表象就是Goroutine暴增，而这时候我们要做的事情之一就是查看应用程序中的Goroutine正在做什么事情，因为什么阻塞了， 然后再进行下一步。  简单的例子 注意要在import中引入 _ \u0026quot;net/http/pprof\u0026quot;\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; _ \u0026#34;net/http/pprof\u0026#34; \u0026#34;time\u0026#34; ) func main() { go func() { for { log.Println(\u0026#34;pprof\u0026#34;) time.Sleep(time.Second) } }() if err := http.ListenAndServe(\u0026#34;0.0.0.0:6060\u0026#34;, nil); err != nil { log.Println(err) return } } 通过web页面访问 运行之后打开页面http://127.0.0.1:6060/debug/pprof/\n/debug/pprof/ Types of profiles available: Count\tProfile 0\tallocs 0\tblock 0\tcmdline 5\tgoroutine 0\theap 0\tmutex 0\tprofile 7\tthreadcreate 0\ttrace full goroutine stack dump Profile Descriptions: allocs: A sampling of all past memory allocations block: Stack traces that led to blocking on synchronization primitives cmdline: The command line invocation of the current program goroutine: Stack traces of all current goroutines heap: A sampling of memory allocations of live objects. You can specify the gc GET parameter to run GC before taking the heap sample. mutex: Stack traces of holders of contended mutexes profile: CPU profile. You can specify the duration in the seconds GET parameter. After you get the profile file, use the go tool pprof command to investigate the profile. threadcreate: Stack traces that led to the creation of new OS threads trace: A trace of execution of the current program. You can specify the duration in the seconds GET parameter. After you get the trace file, use the go tool trace command to investigate the trace. 通过终端访问 go tool pprof http://localhost:6060/debug/pprof/profile\\?seconds\\=60 执行该命令后，需等待60秒（可调整seconds的值），pprof会进行CPU Profiling。结束后将默认进入pprof的交互式命令模式， 可以对分析的结果进行查看或导出。\nFetching profile over HTTP from http://localhost:6060/debug/pprof/profile?seconds=60 Saved profile in /Users/orimissia/pprof/pprof.samples.cpu.003.pb.gz Type: cpu Time: Aug 6, 2021 at 2:41pm (CST) Duration: 1mins, Total samples = 10ms (0.017%) Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options) (pprof) 具体可执行pprof help查看命令说明\n(pprof) top10 Showing nodes accounting for 10ms, 100% of 10ms total flat flat% sum% cum cum% 10ms 100% 100% 10ms 100% runtime.kevent 0 0% 100% 10ms 100% runtime.findrunnable 0 0% 100% 10ms 100% runtime.mcall 0 0% 100% 10ms 100% runtime.netpoll 0 0% 100% 10ms 100% runtime.park_m 0 0% 100% 10ms 100% runtime.schedule  flat：给定函数上运行耗时 flat%：同上的CPU运行耗时总比例 sum%：给定函数累积使用CPU总比例 cum：当前函数加上它之上的调用运行总耗时 cum%：同上的CPU运行耗时总比例   最后一列为函数名称，在大多数的情况下，我们可以通过这五列得出一个应用程序的运行情况，加以优化。\n go tool pprof http://localhost:6060/debug/pprof/heap Saved profile in /Users/orimissia/pprof/pprof.alloc_objects.alloc_space.inuse_objects.inuse_space.001.pb.gz Type: inuse_space Time: Aug 6, 2021 at 2:46pm (CST) No samples were found with the default sample value type. Try \u0026#34;sample_index\u0026#34; command to analyze different sample values. Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options)  -inuse_space：分析应用程序的常驻内存占用情况 -alloc_objects：分析应用程序的内存临时分配情况  可视化界面 新建测试用例：\npackage main import \u0026#34;testing\u0026#34; const str = \u0026#34;ormissia\u0026#34; func TestAdd(t *testing.T) { s := Con(str) if s == \u0026#34;\u0026#34; { t.Errorf(\u0026#34;Test.Add error!\u0026#34;) } } func BenchmarkAdd(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { Con(str) } } func Con(str string) string { data := []byte(str) sData := string(data) return sData } 执行测试用例\n% go test -bench=. -cpuprofile=cpu.prof goos: darwin goarch: arm64 pkg: awesomeProject/pprof BenchmarkAdd-8 182690547 6.330 ns/op PASS ok awesomeProject/pprof 2.366s 启动pprof可视化界面\n方法一\ngo tool pprof -http=:8080 cpu.prof 方法二\ngo tool pprof cpu.prof (pprof) web 可视化界面\n参考  https://github.com/google/pprof https://golang2.eddycjy.com/posts/ch6/01-pprof-1  ","date":"August 5, 2021","hero":"/posts/knowledge/2004-go-pprof/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2004-go-pprof/","summary":"pprof is a tool for visualization and analysis of profiling data.\n  pprof reads a collection of profiling samples in profile.proto format and generates reports to visualize and help analyze the data. It can generate both text and graphical reports (through the use of the dot visualization package).\n  PProf是用于可视化和分析性能分析数据的工具，PProf以profile.proto读取分析样本的集合，并生成报告以可视化并帮助分析数据（支持文本和图形报告）。\n 简介 采集方式  runtime/pprof：采集程序（非Server）的指定区块的运行数据进行分析。 net/http/pprof：基于HTTPServer运行，并且可以采集运行时数据进行分析。 gotest：通过运行测试用例，并指定所需标识来进行采集。  功能  CPUProfiling：CPU分析，按照一定的频率采集所监听的应用程序CPU（含寄存器）的使用情况，可确定应用程序在主动消耗CPU周期时花费时间的位置。 MemoryProfiling：内存分析，在应用程序进行堆分配时记录堆栈跟踪，用于监视当前和历史内存使用情况，以及检查内存泄漏。 BlockProfiling：阻塞分析，记录Goroutine阻塞等待同步（包括定时器通道）的位置，默认不开启，需要调用runtime.SetBlockProfileRate进行设置。 MutexProfiling：互斥锁分析，报告互斥锁的竞争情况，默认不开启，需要调用runtime.SetMutexProfileFraction进行设置。 GoroutineProfiling：Goroutine分析，可以对当前应用程序正在运行的Goroutine进行堆栈跟踪和分析。这项功能在实际排查中会经常用到， 因为很多问题出现时的表象就是Goroutine暴增，而这时候我们要做的事情之一就是查看应用程序中的Goroutine正在做什么事情，因为什么阻塞了， 然后再进行下一步。  简单的例子 注意要在import中引入 _ \u0026quot;net/http/pprof\u0026quot;","tags":null,"title":"Golang性能分析工具-pprof"},{"categories":null,"contents":"  反射简介  Golang提供了一种机制，在编译时不知道类型的情况下，可更新变量、运行时查看值、调用方法以及直接对他们的布局进行操作的机制，称为反射。\n  reflect 包中的官方注释：Package reflect implements run-time reflection, allowing a program to manipulate objects with arbitrary types. \n reflect 实现了运行时的反射能力，能够让程序操作不同类型的对象。反射包中有两对非常重要的函数和类型， 两个函数分别是：\n reflect.TypeOf 能获取类型信息 reflect.ValueOf 能获取数据的运行时表示  三大法则 运行时反射是程序在运行期间检查其自身结构的一种方式。反射带来的灵活性是一把双刃剑，反射作为一种元编程方式可以减少重复代码， 但是过量的使用反射会使我们的程序逻辑变得难以理解并且运行缓慢。我们在这一节中会介绍Go语言反射的三大法则，其中包括：\n 从interface{}变量可以反射出反射对象； 从反射对象可以获取interface{}变量； 要修改反射对象，其值必须可设置；  第一法则 反射的第一法则是我们能将Go语言的interface{}变量转换成反射对象。很多读者可能会对这以法则产生困惑—为什么是从interface{}变量到反射对象？ 当我们执行reflect.ValueOf(1)时，虽然看起来是获取了基本类型int对应的反射类型，但是由于 reflect.TypeOf 、 reflect.ValueOf 两个方法的入参都是interface{}类型，所以在方法执行的过程中发生了类型转换。\n因为Go语言的函数调用都是值传递的，所以变量会在函数调用时进行类型转换。基本类型int会转换成interface{}类型， 这也就是为什么第一条法则是从接口到反射对象。\n上面提到的reflect.TypeOf 和reflect.ValueOf 函数就能完成这里的转换，如果我们认为Go语言的类型和反射类型处于两个不同的世界，那么这两个函数就是连接这两个世界的桥梁。\n我们可以通过以下例子简单介绍它们的作用， reflect.TypeOf 获取了变量author的类型， reflect.ValueOf 获取了变量的值ormissia。如果我们知道了一个变量的类型和值，那么就意味着我们知道了这个变量的全部信息。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func main() { author := \u0026#34;ormissia\u0026#34; fmt.Println(\u0026#34;TypeOf author:\u0026#34;, reflect.TypeOf(author)) fmt.Println(\u0026#34;ValueOf author:\u0026#34;, reflect.ValueOf(author)) } $ go run main.go TypeOf author: string ValueOf author: ormissia 有了变量的类型之后，我们可以通过Method方法获得类型实现的方法，通过Field获取类型包含的全部字段。对于不同的类型， 我们也可以调用不同的方法获取相关信息：\n 结构体：获取字段的数量并通过下标和字段名获取字段StructField； 哈希表：获取哈希表的Key类型； 函数或方法：获取入参和返回值的类型； …  总而言之，使用reflect.TypeOf 和reflect.ValueOf 能够获取Go语言中的变量对应的反射对象。一旦获取了反射对象，我们就能得到跟当前类型相关数据和操作，并可以使用这些运行时获取的结构执行方法。\n第二法则 反射的第二法则是我们可以从反射对象可以获取interface{}变量。既然能够将接口类型的变量转换成反射对象， 那么一定需要其他方法将反射对象还原成接口类型的变量，reflect 中的 reflect.Value.Interface 就能完成这项工作\n不过调用reflect.Value.Interface 方法只能获得interface{}类型的变量，如果想要将其还原成最原始的状态还需要经过如下所示的显式类型转换：\nv := reflect.ValueOf(1) v.Interface().(int) 从反射对象到接口值的过程是从接口值到反射对象的镜面过程，两个过程都需要经历两次转换：\n 从接口值到反射对象：  从基本类型到接口类型的类型转换； 从接口类型到反射对象的转换；   从反射对象到接口值：  反射对象转换成接口类型； 通过显式类型转换变成原始类型；    当然不是所有的变量都需要类型转换这一过程。如果变量本身就是interface{}类型的，那么它不需要类型转换，因为类型转换这一过程一般都是隐式的， 所以我不太需要关心它，只有在我们需要将反射对象转换回基本类型时才需要显式的转换操作。\n第三法则 Go语言反射的最后一条法则是与值是否可以被更改有关，如果我们想要更新一个 reflect.Value ， 那么它持有的值一定是可以被更新的，假设我们有以下代码：\nfunc main() { i := 1 v := reflect.ValueOf(i) v.SetInt(10) fmt.Println(i) } $ go run reflect.go panic: reflect: reflect.Value.SetInt using unaddressable value goroutine 1 [running]: reflect.flag.mustBeAssignableSlow(0x82) /usr/local/go/src/reflect/value.go:260 +0x118 reflect.flag.mustBeAssignable(...) /usr/local/go/src/reflect/value.go:247 reflect.Value.SetInt(0x100196bc0, 0x10021f8e8, 0x82, 0xa) /usr/local/go/src/reflect/value.go:1637 +0x30 main.main() /Users/orimissia/workspace/awesomeProject/goroutine/main.go:13 +0xb8 运行上述代码会导致程序崩溃并报出“reflect:reflect.flag.mustBeAssignableusingunaddressablevalue”错误， 仔细思考一下就能够发现出错的原因：由于Go语言的函数调用都是传值的，所以我们得到的反射对象跟最开始的变量没有任何关系， 那么直接修改反射对象无法改变原始变量，程序为了防止错误就会崩溃。\n想要修改原变量只能使用如下的方法：\nfunc main() { i := 1 v := reflect.ValueOf(\u0026amp;i) v.Elem().SetInt(10) fmt.Println(i) } $ go run reflect.go 10  调用reflect.ValueOf 获取变量指针； 调用reflect.Value.Elem 获取指针指向的变量； 调用reflect.Value.SetInt 更新变量的值：  由于Go语言的函数调用都是值传递的，所以我们只能只能用迂回的方式改变原变量：先获取指针对应的 reflect.Value ， 再通过reflect.Value.Elem 方法得到可以被设置的变量，我们可以通过下面的代码理解这个过程：\nfunc main() { i := 1 v := \u0026amp;i *v = 10 } 如果不能直接操作i变量修改其持有的值，我们就只能获取i变量所在地址并使用*v修改所在地址中存储的整数。\n类型和值 Go语言的interface{}类型在语言内部是通过reflect.emptyInterface 结体表示的，其中的rtype字段用于表示变量的类型，另一个word字段指向内部封装的数据：\ntype emptyInterface struct { typ *rtype word unsafe.Pointer } 用于获取变量类型的reflect.TypeOf函数将传入的变量隐式转换成 reflect.emptyInterface 类型并获取其中存储的类型信息reflect.rtype：\nfunc TypeOf(i interface{}) Type { eface := *(*emptyInterface)(unsafe.Pointer(\u0026amp;i)) return toType(eface.typ) } func toType(t *rtype) Type { if t == nil { return nil } return t } reflect.rtype是一个实现了reflect.Type接口的结构体，该结构体实现的 reflect.rtype.String 方法可以帮助我们获取当前类型的名称：\nfunc (t *rtype) String() string { s := t.nameOff(t.str).name() if t.tflag\u0026amp;tflagExtraStar != 0 { return s[1:] } return s } reflect.TypeOf 的实现原理其实并不复杂，它只是将一个interface{}变量转换成了内部的 reflect.emptyInterface 表示，然后从中获取相应的类型信息。\n用于获取接口值reflect.Value 的函数reflect.ValueOf 实现也非常简单，在该函数中我们先调用了 reflect.escapes 保证当前值逃逸到堆上，然后通过 reflect.unpackEface 从接口中获取reflect.Value 结构体：\nfunc ValueOf(i interface{}) Value { if i == nil { return Value{} } escapes(i) return unpackEface(i) } func unpackEface(i interface{}) Value { e := (*emptyInterface)(unsafe.Pointer(\u0026amp;i)) t := e.typ if t == nil { return Value{} } f := flag(t.Kind()) if ifaceIndir(t) { f |= flagIndir } return Value{t, e.word, f} } reflect.unpackEface 会将传入的接口转换成 reflect.emptyInterface， 然后将具体类型和指针包装成 reflect.Value 结构体后返回。\nreflect.TypeOf 和reflect.ValueOf 的实现都很简单。我们已经分析了这两个函数的实现，现在需要了解编译器在调用函数之前做了哪些工作：\npackage main import ( \u0026#34;reflect\u0026#34; ) func main() { i := 20 _ = reflect.TypeOf(i) } $ go build -gcflags=\u0026#34;-S -N\u0026#34; main.go ... MOVQ\t$20, \u0026#34;\u0026#34;..autotmp_20+56(SP) // autotmp = 20 LEAQ\ttype.int(SB), AX // AX = type.int(SB) MOVQ\tAX, \u0026#34;\u0026#34;..autotmp_19+280(SP) // autotmp_19+280(SP) = type.int(SB) LEAQ\t\u0026#34;\u0026#34;..autotmp_20+56(SP), CX // CX = 20 MOVQ\tCX, \u0026#34;\u0026#34;..autotmp_19+288(SP) // autotmp_19+288(SP) = 20 ... 从上面这段截取的汇编语言，我们可以发现在函数调用之前已经发生了类型转换，上述指令将int类型的变量转换成了占用16字节 autotmp_19+280(SP) ~ autotmp_19+288(SP)的接口，两个LEAQ指令分别获取了类型的指针type.int(SB)以及变量i所在的地址。\n当我们想要将一个变量转换成反射对象时，Go语言会在编译期间完成类型转换，将变量的类型和值转换成了interface{}并等待运行期间使用 reflect 包获取接口中存储的信息。\n更新变量 当我们想要更新reflect.Value 时，就需要调用 reflect.Value.Set 更新反射对象，该方法会调用 reflect.flag.mustBeAssignable 和reflect.flag.mustBeExported 分别检查当前反射对象是否是可以被设置的以及字段是否是对外公开的：\nfunc (v Value) Set(x Value) { v.mustBeAssignable() x.mustBeExported() var target unsafe.Pointer if v.kind() == Interface { target = v.ptr } x = x.assignTo(\u0026#34;reflect.Set\u0026#34;, v.typ, target) typedmemmove(v.typ, v.ptr, x.ptr) } reflect.Value.Set 会调用reflect.Value.assignTo 并返回一个新的反射对象，这个返回的反射对象指针会直接覆盖原反射变量。\nfunc (v Value) assignTo(context string, dst *rtype, target unsafe.Pointer) Value { ... switch { case directlyAssignable(dst, v.typ): ... return Value{dst, v.ptr, fl} case implements(dst, v.typ): if v.Kind() == Interface \u0026amp;\u0026amp; v.IsNil() { return Value{dst, nil, flag(Interface)} } x := valueInterface(v, false) if dst.NumMethod() == 0 { *(*interface{})(target) = x } else { ifaceE2I(dst, x, target) } return Value{dst, target, flagIndir | flag(Interface)} } panic(context + \u0026#34;: value of type \u0026#34; + v.typ.String() + \u0026#34; is not assignable to type \u0026#34; + dst.String()) } reflect.Value.assignTo 会根据当前和被设置的反射对象类型创建一个新的 reflect.Value 结构体：\n 如果两个反射对象的类型是可以被直接替换，就会直接返回目标反射对象； 如果当前反射对象是接口并且目标对象实现了接口，就会把目标对象简单包装成接口值  在变量更新的过程中， reflect.Value.assignTo 返回的reflect.Value 中的指针会覆盖当前反射对象中的指针实现变量的更新。\n实现协议 reflect 包还为我们提供了 reflect.rtype.Implements 方法可以用于判断某些类型是否遵循特定的接口。在Go语言中获取结构体的反射类型 reflect.Type 还是比较容易的，但是想要获得接口类型需要通过以下方式：\nreflect.TypeOf((*\u0026lt;interface\u0026gt;)(nil)).Elem() 我们通过一个例子在介绍如何判断一个类型是否实现了某个接口。假设我们需要判断如下代码中的CustomError是否实现了Go语言标准库中的error接口：\ntype CustomError struct{} func (*CustomError) Error() string { return \u0026#34;\u0026#34; } func main() { typeOfError := reflect.TypeOf((*error)(nil)).Elem() customErrorPtr := reflect.TypeOf(\u0026amp;CustomError{}) customError := reflect.TypeOf(CustomError{}) fmt.Println(customErrorPtr.Implements(typeOfError)) // #=\u0026gt; true \tfmt.Println(customError.Implements(typeOfError)) // #=\u0026gt; false } 上述代码的运行结果正如我们在接口一节中介绍的：\n CustomError类型并没有实现error接口 *CustomError指针类型实现了error接口  抛开上述的执行结果不谈，我们来分析一下 reflect.rtype.Implements 方法的工作原理：\nfunc (t *rtype) Implements(u Type) bool { if u == nil { panic(\u0026#34;reflect: nil type passed to Type.Implements\u0026#34;) } if u.Kind() != Interface { panic(\u0026#34;reflect: non-interface type passed to Type.Implements\u0026#34;) } return implements(u.(*rtype), t) } reflect.rtype.Implements 会检查传入的类型是不是接口，如果不是接口或者是空值就会直接崩溃并中止当前程序。在参数没有问题的情况下，上述方法会调用私有函数 reflect.implements 判断类型之间是否有实现关系：\nfunc implements(T, V *rtype) bool { t := (*interfaceType)(unsafe.Pointer(T)) if len(t.methods) == 0 { return true } ... v := V.uncommon() i := 0 vmethods := v.methods() for j := 0; j \u0026lt; int(v.mcount); j++ { tm := \u0026amp;t.methods[i] tmName := t.nameOff(tm.name) vm := vmethods[j] vmName := V.nameOff(vm.name) if vmName.name() == tmName.name() \u0026amp;\u0026amp; V.typeOff(vm.mtyp) == t.typeOff(tm.typ) { if i++; i \u0026gt;= len(t.methods) { return true } } } return false } 如果接口中不包含任何方法，就意味着这是一个空的接口，任意类型都自动实现该接口，这时会直接返回true。\n在其他情况下，由于方法都是按照字母序存储的， reflect.implements 会维护两个用于遍历接口和类型方法的索引i和j判断类型是否实现了接口，因为最多只会进行n次比较（类型的方法数量），所以整个过程的时间复杂度是𝑂(𝑛)。\n方法调用 作为一门静态语言，如果我们想要通过reflect 包利用反射在运行期间执行方法不是一件容易的事情，下面的十几行代码就使用反射来执行Add(0,1)函数：\nfunc Add(a, b int) int { return a + b } func main() { v := reflect.ValueOf(Add) if v.Kind() != reflect.Func { return } t := v.Type() argv := make([]reflect.Value, t.NumIn()) for i := range argv { if t.In(i).Kind() != reflect.Int { return } argv[i] = reflect.ValueOf(i) } result := v.Call(argv) if len(result) != 1 || result[0].Kind() != reflect.Int { return } fmt.Println(result[0].Int()) // #=\u0026gt; 1 }  通过reflect.ValueOf 获取函数Add对应的反射对象； 调用reflect.rtype.NumIn 获取函数的入参个数； 多次调用reflect.ValueOf 函数逐一设置argv数组中的各个参数； 调用反射对象Add的reflect.Value.Call 方法并传入参数列表； 获取返回值数组、验证数组的长度以及类型并打印其中的数据；  使用反射来调用方法非常复杂，原本只需要一行代码就能完成的工作，现在需要十几行代码才能完成，但这也是在静态语言中使用动态特性需要付出的成本。\nfunc (v Value) Call(in []Value) []Value { v.mustBe(Func) v.mustBeExported() return v.call(\u0026#34;Call\u0026#34;, in) } reflect.Value.Call 是运行时调用方法的入口，它通过两个MustBe开头的方法确定了当前反射对象的类型是函数以及可见性，随后调用 reflect.Value.call 完成方法调用，这个私有方法的执行过程会分成以下的几个部分：\n 检查输入参数以及类型的合法性； 将传入的reflect.Value 参数数组设置到栈上； 通过函数指针和输入参数调用函数； 从栈上获取函数的返回值；  我们将按照上面的顺序分析使用reflect 进行函数调用的几个过程。\n参数检查 参数检查是通过反射调用方法的第一步，在参数检查期间我们会从反射对象中取出当前的函数指针unsafe.Pointer，如果该函数指针是方法， 那么我们会通过reflect.methodReceiver 获取方法的接收者和函数指针。\nfunc (v Value) call(op string, in []Value) []Value { t := (*funcType)(unsafe.Pointer(v.typ)) ... if v.flag\u0026amp;flagMethod != 0 { rcvr = v rcvrtype, t, fn = methodReceiver(op, v, int(v.flag)\u0026gt;\u0026gt;flagMethodShift) } else { ... } n := t.NumIn() if len(in) \u0026lt; n { panic(\u0026#34;reflect: Call with too few input arguments\u0026#34;) } if len(in) \u0026gt; n { panic(\u0026#34;reflect: Call with too many input arguments\u0026#34;) } for i := 0; i \u0026lt; n; i++ { if xt, targ := in[i].Type(), t.In(i); !xt.AssignableTo(targ) { panic(\u0026#34;reflect: \u0026#34; + op + \u0026#34; using \u0026#34; + xt.String() + \u0026#34; as type \u0026#34; + targ.String()) } } 上述方法还会检查传入参数的个数以及参数的类型与函数签名中的类型是否可以匹配，任何参数的不匹配都会导致整个程序的崩溃中止。\n准备参数 当我们已经对当前方法的参数完成验证后，就会进入函数调用的下一个阶段，为函数调用准备参数，在前面函数调用一节中，我们已经介绍过Go语言的函数调用惯例， 函数或者方法在调用时，所有的参数都会被依次放到栈上。\nnout := t.NumOut() frametype, _, retOffset, _, framePool := funcLayout(t, rcvrtype) var args unsafe.Pointer if nout == 0 { args = framePool.Get().(unsafe.Pointer) } else { args = unsafe_New(frametype) } off := uintptr(0) if rcvrtype != nil { storeRcvr(rcvr, args) off = ptrSize } for i, v := range in { targ := t.In(i).(*rtype) a := uintptr(targ.align) off = (off + a - 1) \u0026amp;^ (a - 1) n := targ.size ... addr := add(args, off, \u0026#34;n \u0026gt; 0\u0026#34;) v = v.assignTo(\u0026#34;reflect.Value.Call\u0026#34;, targ, addr) *(*unsafe.Pointer)(addr) = v.ptr off += n }  通过reflect.funcLayout 计算当前函数需要的参数和返回值的栈布局，也就是每一个参数和返回值所占的空间大小； 如果当前函数有返回值，需要为当前函数的参数和返回值分配一片内存空间args； 如果当前函数是方法，需要向将方法的接收接收者者拷贝到args内存中； 将所有函数的参数按照顺序依次拷贝到对应args内存中  使用reflect.funcLayout 返回的参数计算参数在内存中的位置； 将参数拷贝到内存空间中；    准备参数是计算各个参数和返回值占用的内存空间并将所有的参数都拷贝内存空间对应位置的过程，该过程会考虑函数和方法、返回值数量以及参数类型带来的差异。\n调用函数 准备好调用函数需要的全部参数后，就会通过下面的代码执行函数指针了。我们会向该函数传入栈类型、函数指针、参数和返回值的内存空间、 栈的大小以及返回值的偏移量：\ncall(frametype, fn, args, uint32(frametype.size), uint32(retOffset)) 上述函数实际上并不存在，它会在编译期间链接到 reflect.reflectcall 这个用汇编实现的函数上，我们在这里不会分析该函数的具体实现，感兴趣的读者可以自行了解其实现原理。\n处理返回值 当函数调用结束之后，就会开始处理函数的返回值：\n 如果函数没有任何返回值，会直接清空args中的全部内容来释放内存空间； 如果当前函数有返回值；  将args中与输入参数有关的内存空间清空； 创建一个nout长度的切片用于保存由反射对象构成的返回值数组； 从函数对象中获取返回值的类型和内存大小，将args内存中的数据转换成 reflect.Value 类型并存储到切片中；    var ret []Value if nout == 0 { typedmemclr(frametype, args) framePool.Put(args) } else { typedmemclrpartial(frametype, args, 0, retOffset) ret = make([]Value, nout) off = retOffset for i := 0; i \u0026lt; nout; i++ { tv := t.Out(i) a := uintptr(tv.Align()) off = (off + a - 1) \u0026amp;^ (a - 1) if tv.Size() != 0 { fl := flagIndir | flag(tv.Kind()) ret[i] = Value{tv.common(), add(args, off, \u0026#34;tv.Size() != 0\u0026#34;), fl} } else { ret[i] = Zero(tv) } off += tv.Size() } } return ret } 由reflect.Value 构成的ret数组会被返回到调用方，到这里为止使用反射实现函数调用的过程就结束了。\n小结 Go语言的reflect 包为我们提供了多种能力，包括如何使用反射来动态修改变量、 判断类型是否实现了某些接口以及动态调用方法等功能，通过分析反射包中方法的原理能帮助我们理解之前看起来比较怪异、令人困惑的现象。\n参考  转载自Draveness Go语言设计与实现 4.3反射  ","date":"August 3, 2021","hero":"/posts/knowledge/2003-go-reflect/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2003-go-reflect/","summary":"反射简介  Golang提供了一种机制，在编译时不知道类型的情况下，可更新变量、运行时查看值、调用方法以及直接对他们的布局进行操作的机制，称为反射。\n  reflect 包中的官方注释：Package reflect implements run-time reflection, allowing a program to manipulate objects with arbitrary types. \n reflect 实现了运行时的反射能力，能够让程序操作不同类型的对象。反射包中有两对非常重要的函数和类型， 两个函数分别是：\n reflect.TypeOf 能获取类型信息 reflect.ValueOf 能获取数据的运行时表示  三大法则 运行时反射是程序在运行期间检查其自身结构的一种方式。反射带来的灵活性是一把双刃剑，反射作为一种元编程方式可以减少重复代码， 但是过量的使用反射会使我们的程序逻辑变得难以理解并且运行缓慢。我们在这一节中会介绍Go语言反射的三大法则，其中包括：\n 从interface{}变量可以反射出反射对象； 从反射对象可以获取interface{}变量； 要修改反射对象，其值必须可设置；  第一法则 反射的第一法则是我们能将Go语言的interface{}变量转换成反射对象。很多读者可能会对这以法则产生困惑—为什么是从interface{}变量到反射对象？ 当我们执行reflect.ValueOf(1)时，虽然看起来是获取了基本类型int对应的反射类型，但是由于 reflect.TypeOf 、 reflect.ValueOf 两个方法的入参都是interface{}类型，所以在方法执行的过程中发生了类型转换。\n因为Go语言的函数调用都是值传递的，所以变量会在函数调用时进行类型转换。基本类型int会转换成interface{}类型， 这也就是为什么第一条法则是从接口到反射对象。\n上面提到的reflect.TypeOf 和reflect.ValueOf 函数就能完成这里的转换，如果我们认为Go语言的类型和反射类型处于两个不同的世界，那么这两个函数就是连接这两个世界的桥梁。\n我们可以通过以下例子简单介绍它们的作用， reflect.TypeOf 获取了变量author的类型， reflect.ValueOf 获取了变量的值ormissia。如果我们知道了一个变量的类型和值，那么就意味着我们知道了这个变量的全部信息。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func main() { author := \u0026#34;ormissia\u0026#34; fmt.","tags":null,"title":"Golang反射"},{"categories":null,"contents":"   A：\u0026ldquo;请用一句话让别人知道你写过Golang。\u0026rdquo;\nB：\u0026ldquo;if err!= nil \u0026hellip;\u0026rdquo;\n 起因 只要是接触过Golang的人，无不为其if err != nil的语法感到惊奇，或是大加赞赏，或是狠狠痛批。作为使用者，不管喜欢也好，反对也罢， 目前还是要接受这种错误处理模式。\n而最令人头痛的就是请求参数中各种值的校验。比如Get请求中接收分页参数时，需要将string格式的参数转换成int类型，再如时间类型的参数 转换， 诸如此类，等等等等。好家伙，一个接口写完if err != nil的判断占了一多半的行数，看着实在不爽。\n下面就是一个典型的例子，而且这个接口参数还不是特别多\nfunc Export(c *gin.Context) { //删除开头  //... \tvar param map[string]string err := c.ShouldBindJSON(\u0026amp;param) if err != nil { ErrRsponse(c,errCode) return } var vId, userId, userName, format string if v, ok := param[\u0026#34;vId\u0026#34;]; ok { vId = v } else { ErrRsponse(c,errCode) return } if len(vId) == 0 { ErrRsponse(c,errCode) return } if v, ok := param[\u0026#34;userId\u0026#34;]; ok { userId = v } else { ErrRsponse(c,errCode) return } if v, ok := param[\u0026#34;userName\u0026#34;]; ok { userName = v } else { ErrRsponse(c,errCode) return } if v, ok := param[\u0026#34;format\u0026#34;]; ok { format = v } else { ErrRsponse(c,errCode) return } if !file.IsOk(format) { ErrRsponse(c,errCode) return } //... \t//删除结尾 } 机遇 前几天在看GIN-VUE-ADMIN代码的时候，偶然看到一个通过反射去做参数校验的方式。 嘿，学到了！\n改变 定义规则 校验规则使用一个map存储，key为字段名，value为规则列表，并使用一个string类型的切片来存储。\n 后续计划加入tag标签定义规则的功能以及增加通过函数参数的方式，实现自定义规则校验\n type Rules map[string][]string 支持的规则有：\n 不为空 等于、不等于 大于、小于 大于等于、小于等于   对于数值类型为比较值大小，对于字符串或者切片等类型为比较长度大小\n 比如调用生成小于规则的方法，则会返回一个小于指定值规则的字符串，用于后面校验器使用\n// Lt \u0026lt; func (verifier verifier) Lt(limit string) string { return fmt.Sprintf(\u0026#34;%s%s%s\u0026#34;, lt, verifier.separator, limit) } 规则定义示例：\nUserRequestRules = go_opv.Rules{ \u0026#34;Name\u0026#34;: {myVerifier.NotEmpty(), myVerifier.Lt(\u0026#34;10\u0026#34;)}, \u0026#34;Age\u0026#34;: {myVerifier.Lt(\u0026#34;100\u0026#34;)}, } //map[Age:[lt#100] Name:[notEmpty lt#10]] 规则含义为Age字段长度或值小于100，Name字段不为空且长度或值小于10。\n验证器 先通过反射获取待检验参数的值和类型，判断是否为struct（目前只实现了对struct校验的功能，计划后续加入对map的校验功能）， 获取struct属性数量并遍历所有属性，并遍历每个字段下所有规则，对定义的每一个规则进行校验是否合格。\nfunc (verifier verifier) Verify(st interface{}, rules Rules) (err error) { typ := reflect.TypeOf(st) val := reflect.ValueOf(st) if val.Kind() != reflect.Struct { return errors.New(\u0026#34;expect struct\u0026#34;) } num := val.NumField() //遍历需要验证对象的所有字段 \tfor i := 0; i \u0026lt; num; i++ { tagVal := typ.Field(i) val := val.Field(i) if len(rules[tagVal.Name]) \u0026gt; 0 { for _, v := range rules[tagVal.Name] { switch { case v == \u0026#34;notEmpty\u0026#34;: if isEmpty(val) { return errors.New(tagVal.Name + \u0026#34; value can not be nil\u0026#34;) } case verifier.conditions[strings.Split(v, verifier.separator)[0]]: if !compareVerify(val, v, verifier.separator) { return errors.New(tagVal.Name + \u0026#34; length or value is illegal,\u0026#34; + v) } } } } } return nil } 规则校验有两种，分别是判空 和条件校验。\n判空是通过反射reflect.Value获得字段值，并通过反射value.Kind()获得字段类型。 最终使用switch分别对不同类型 字段进行判断。\nfunc isEmpty(value reflect.Value) bool { switch value.Kind() { case reflect.String: return value.Len() == 0 case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64: return value.Int() == 0 //此处省略其他类型判断 \t//... \t} return reflect.DeepEqual(value.Interface(), reflect.Zero(value.Type()).Interface()) } 条件校验则是通过开始时定义的范围条件进行校验，传入反射reflect.Value获得字段值，定义的规则，以及规则中的分隔符。先通过switch判断其类型， 再通过switch判断条件是大于小于或是其他条件，然后进行相应判断。\nfunc compareVerify(value reflect.Value, verifyStr, separator string) bool { switch value.Kind() { case reflect.String, reflect.Slice, reflect.Array: return compare(value.Len(), verifyStr, separator) //此处省略其他类型判断 \t//... \tdefault: return false } } 封装 为了调用方便，做了一层封装，使用函数选项模式对校验器进行封装，使调用更为方便。\nvar defaultVerifierOptions = verifierOptions{ separator: \u0026#34;:\u0026#34;, conditions: map[string]bool{ eq: true, ne: true, gt: true, lt: true, ge: true, le: true, }, } type VerifierOption func(o *verifierOptions) type verifierOptions struct { conditions map[string]bool separator string } // SetSeparator Default separator is \u0026#34;:\u0026#34;. func SetSeparator(seq string) VerifierOption { return func(o *verifierOptions) { o.separator = seq } } func SwitchEq(sw bool) VerifierOption { return func(o *verifierOptions) { o.conditions[eq] = sw } } //... //此处省略其他参数的设置  type Verifier interface { Verify(obj interface{}, rules Rules) (err error) NotEmpty() string Ne(limit string) string Gt(limit string) string Lt(limit string) string Ge(limit string) string Le(limit string) string } type verifier struct { separator string conditions map[string]bool } func NewVerifier(opts ...VerifierOption) Verifier { options := defaultVerifierOptions for _, opt := range opts { opt(\u0026amp;options) } return verifier{ separator: options.separator, conditions: options.conditions, } } //... //此处省略接口的实现 发布  好了，基本功能完成了，如果仅仅是放在每个项目的utils拷来拷去，显然十分的不优雅。\n那么这就需要发布到pkg.go.dev才能通过go get命令正常被其他项目所引用。\n  首先是git commit、git push一把梭将项目整到GitHub上。 由于pkg.go.dev的版本管理机制需要给项目打上tag，git tag v0.0.1基础版本，😋先定个0.0.1吧， 然后git push再走一遍。 当然这时候还没完，需要自己go get一下，加上GitHub仓库名执行一下go get github.com/ormissia/go-opv 这样仓库就可以正常被引用了。而且用不了多久，就可以从pkg.go.dev上搜到相应的项目了。 最后贴一下次项目的连接：go-opv   当然，这个过程中也遇到过小坑。项目中go.mod中的模块名需要写GitHub的仓库地址，对应此项目即为module github.com/ormissia/go-opv。 如果项目版本有更新，打了新的tag之后。可以通过go get github.com/ormissia/go-opv@v0.0.3拉取指定版本，目前尚不清楚 pkg.go.dev是否会自动同步GitHub上最新的tag。\n 检验 测试用例？\n好吧，// TODO\n 老铁看到底了，来个star吧😁\n↓↓↓↓↓↓↓↓↓\nGitHub仓库\n ","date":"July 27, 2021","hero":"/posts/knowledge/2002-go-param-verify/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2002-go-param-verify/","summary":"A：\u0026ldquo;请用一句话让别人知道你写过Golang。\u0026rdquo;\nB：\u0026ldquo;if err!= nil \u0026hellip;\u0026rdquo;\n 起因 只要是接触过Golang的人，无不为其if err != nil的语法感到惊奇，或是大加赞赏，或是狠狠痛批。作为使用者，不管喜欢也好，反对也罢， 目前还是要接受这种错误处理模式。\n而最令人头痛的就是请求参数中各种值的校验。比如Get请求中接收分页参数时，需要将string格式的参数转换成int类型，再如时间类型的参数 转换， 诸如此类，等等等等。好家伙，一个接口写完if err != nil的判断占了一多半的行数，看着实在不爽。\n下面就是一个典型的例子，而且这个接口参数还不是特别多\nfunc Export(c *gin.Context) { //删除开头  //... \tvar param map[string]string err := c.ShouldBindJSON(\u0026amp;param) if err != nil { ErrRsponse(c,errCode) return } var vId, userId, userName, format string if v, ok := param[\u0026#34;vId\u0026#34;]; ok { vId = v } else { ErrRsponse(c,errCode) return } if len(vId) == 0 { ErrRsponse(c,errCode) return } if v, ok := param[\u0026#34;userId\u0026#34;]; ok { userId = v } else { ErrRsponse(c,errCode) return } if v, ok := param[\u0026#34;userName\u0026#34;]; ok { userName = v } else { ErrRsponse(c,errCode) return } if v, ok := param[\u0026#34;format\u0026#34;]; ok { format = v } else { ErrRsponse(c,errCode) return } if !","tags":null,"title":"Golang 实体参数校验"},{"categories":null,"contents":"   作为 Golang 开发者，遇到的许多问题之一就是尝试将函数的参数设置成可选项。这是一个十分常见的场景，您可以使用一些已经设置默认配置和开箱即用的对象，同时您也可以使用一些更为详细的配置。\n 问题出发点 对于许多编程语言来说，这很容易。在 C 语言家族中，您可以提供具有同一个函数但是不同参数的多个版本；在 PHP 之类的语言中，您可以为参数提供默认值，并在调用该方法时将其忽略。但是在 Golang 中，上述的做法都不可以使用。那么您如何创建具有一些其他配置的函数，用户可以根据他的需求（但是仅在需要时）指定一些额外的配置。\n有很多的方法可以做到这一点，但是大多数方法都不是尽如人意，要么需要在服务端的代码中进行大量额外的检查和验证，要么通过传入他们不关心的其他参数来为客户端进行额外的工作。\n下面我将会介绍一些不同的选项，然后为其说明为什么每个选项都不理想，接着我们会逐步构建自己的方式来作为最终的干净解决方案：函数选项模式。\n让我们来看一个例子。比方说，这里有一个叫做StuffClient的服务，它能够胜任一些工作，同时还具有两个配置选项（超时和重试）。\ntype StuffClient interface { DoStuff() error } type stuffClient struct { conn Connection timeout int retries int } 这是个私有的结构体，因此我们应该为它提供某种构造函数：\nfunc NewStuffClient(conn Connection, timeout, retries int) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: timeout, retries: retries, } } 嗯，但是现在我们每次调用NewStuffClient函数时都要提供timeout和retries。因为在大多数情况下，我们只想使用默认值，我们无法使用不同参数数量带定义多个版本的NewStuffClient，否则我们会得到一个类似NewStuffClient redeclared in this block编译错误。\n一个可选方案是创建另一个具有不同名称的构造函数，例如：\nfunc NewStuffClient(conn Connection) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: DEFAULT_TIMEOUT, retries: DEFAULT_RETRIES, } } func NewStuffClientWithOptions(conn Connection, timeout, retries int) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: timeout, retries: retries, } } 但是这么做的话有点蹩脚。我们可以做得更好，如果我们传入了一个配置对象呢:\ntype StuffClientOptions struct { Retries int //number of times to retry the request before giving up  Timeout int //connection timeout in seconds } func NewStuffClient(conn Connection, options StuffClientOptions) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: options.Timeout, retries: options.Retries, } } 但是，这也不是很好的做法。现在，我们总是需要创建StuffClientOption这个结构体，即使不想在指定任何选项时还要传递它。另外我们也没有自动填充默认值，除非我们在代码中的某处添加了一堆检查，或者也可以传入一个DefaultStuffClientOptions变量（不过这么做也不好，因为在修改某一处地方后可能会导致其他的问题。）\n所以，更好的解决方法是什么呢？解决这个难题最好的解决方法是使用函数选项模式，它利用了Go对闭包更加方便的支持。让我们保留上述定义的StuffClientOptions，不过我们仍需要为其添加一些内容。\ntype StuffClientOption func(*StuffClientOptions) type StuffClientOptions struct { Retries int //number of times to retry the request before giving up \tTimeout int //connection timeout in seconds } func WithRetries(r int) StuffClientOption { return func(o *StuffClientOptions) { o.Retries = r } } func WithTimeout(t int) StuffClientOption { return func(o *StuffClientOptions) { o.Timeout = t } } 泥土般芬芳, 不是吗？这到底是怎么回事？基本上，我们有一个结构来定义StuffClient的可用选项。另外，现状我们还定义了一个叫做StuffClientOption的东西（次数是单数），它只是接受我们选项的结构体作为参数的函数。我们还定义了另外两个函数 WithRetries 和WithTimeout，它们返回一个闭包，现在就是见证奇迹的时刻了！\nvar defaultStuffClientOptions = StuffClientOptions{ Retries: 3, Timeout: 2, } func NewStuffClient(conn Connection, opts ...StuffClientOption) StuffClient { options := defaultStuffClientOptions for _, o := range opts { o(\u0026amp;options) } return \u0026amp;stuffClient{ conn: conn, timeout: options.Timeout, retries: options.Retries, } } 现在，我们定义了一个额外和包含默认选项的没有导出的变量，同时我们已经调整了构造函数，用来接收可变参数。然后, 我们遍历StuffClientOption列表(单数)，针对每一个列表，将列表中返回的闭包使用在我们的options变量（需要记住，这些闭包接收一个StuffClientOptions变量，仅需要在选项的值上做出少许修改）。\n现在我们要做的事情就是使用它！\nx := NewStuffClient(Connection{}) fmt.Println(x) // prints \u0026amp;{{} 2 3} x = NewStuffClient( Connection{}, WithRetries(1), ) fmt.Println(x) // prints \u0026amp;{{} 2 1} x = NewStuffClient( Connection{}, WithRetries(1), WithTimeout(1), ) fmt.Println(x) // prints \u0026amp;{{} 1 1} 函数选项模式 这看起来相当不错，已经可以使用了！而且，它的好处是，我们只需要对代码进行很少的修改，就可以随时随地添加新的选项。\n把这些修改放在一起，就是这样：\nvar defaultStuffClientOptions = StuffClientOptions{ Retries: 3, Timeout: 2, } type StuffClientOption func(*StuffClientOptions) type StuffClientOptions struct { Retries int //number of times to retry the request before giving up \tTimeout int //connection timeout in seconds } func WithRetries(r int) StuffClientOption { return func(o *StuffClientOptions) { o.Retries = r } } func WithTimeout(t int) StuffClientOption { return func(o *StuffClientOptions) { o.Timeout = t } } type StuffClient interface { DoStuff() error } type stuffClient struct { conn Connection timeout int retries int } type Connection struct{} func NewStuffClient(conn Connection, opts ...StuffClientOption) StuffClient { options := defaultStuffClientOptions for _, o := range opts { o(\u0026amp;options) } return \u0026amp;stuffClient{ conn: conn, timeout: options.Timeout, retries: options.Retries, } } func (c stuffClient) DoStuff() error { return nil } 但这也可以通过删除StuffClientOptions结构体进一步简化，并将选项直接应用在我们的StuffClient上。\nvar defaultStuffClient = stuffClient{ retries: 3, timeout: 2, } type StuffClientOption func(*stuffClient) func WithRetries(r int) StuffClientOption { return func(o *stuffClient) { o.retries = r } } func WithTimeout(t int) StuffClientOption { return func(o *stuffClient) { o.timeout = t } } type StuffClient interface { DoStuff() error } type stuffClient struct { conn Connection timeout int retries int } type Connection struct{} func NewStuffClient(conn Connection, opts ...StuffClientOption) StuffClient { client := defaultStuffClient for _, o := range opts { o(\u0026amp;client) } client.conn = conn return client } func (c stuffClient) DoStuff() error { return nil } 在我们的示例中，我们只是将配置直接应用于结构体中，如果中间有一个额外的结构体是没有意义的。但是，请注意，在许多情况下，您可能仍然想使用上一个示例中的config结构。例如，如果您的构造函数正在使用config选项执行某些操作时，但是并没有将它们存储到结构体中，或者被传递到其他地方，配置结构的变体是更通用的实现。\n转载自此处\n","date":"July 22, 2021","hero":"/posts/knowledge/2001-go-partten-1/head.svg","permalink":"https://ormissia.github.io/posts/knowledge/2001-go-partten-1/","summary":"作为 Golang 开发者，遇到的许多问题之一就是尝试将函数的参数设置成可选项。这是一个十分常见的场景，您可以使用一些已经设置默认配置和开箱即用的对象，同时您也可以使用一些更为详细的配置。\n 问题出发点 对于许多编程语言来说，这很容易。在 C 语言家族中，您可以提供具有同一个函数但是不同参数的多个版本；在 PHP 之类的语言中，您可以为参数提供默认值，并在调用该方法时将其忽略。但是在 Golang 中，上述的做法都不可以使用。那么您如何创建具有一些其他配置的函数，用户可以根据他的需求（但是仅在需要时）指定一些额外的配置。\n有很多的方法可以做到这一点，但是大多数方法都不是尽如人意，要么需要在服务端的代码中进行大量额外的检查和验证，要么通过传入他们不关心的其他参数来为客户端进行额外的工作。\n下面我将会介绍一些不同的选项，然后为其说明为什么每个选项都不理想，接着我们会逐步构建自己的方式来作为最终的干净解决方案：函数选项模式。\n让我们来看一个例子。比方说，这里有一个叫做StuffClient的服务，它能够胜任一些工作，同时还具有两个配置选项（超时和重试）。\ntype StuffClient interface { DoStuff() error } type stuffClient struct { conn Connection timeout int retries int } 这是个私有的结构体，因此我们应该为它提供某种构造函数：\nfunc NewStuffClient(conn Connection, timeout, retries int) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: timeout, retries: retries, } } 嗯，但是现在我们每次调用NewStuffClient函数时都要提供timeout和retries。因为在大多数情况下，我们只想使用默认值，我们无法使用不同参数数量带定义多个版本的NewStuffClient，否则我们会得到一个类似NewStuffClient redeclared in this block编译错误。\n一个可选方案是创建另一个具有不同名称的构造函数，例如：\nfunc NewStuffClient(conn Connection) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: DEFAULT_TIMEOUT, retries: DEFAULT_RETRIES, } } func NewStuffClientWithOptions(conn Connection, timeout, retries int) StuffClient { return \u0026amp;stuffClient{ conn: conn, timeout: timeout, retries: retries, } } 但是这么做的话有点蹩脚。我们可以做得更好，如果我们传入了一个配置对象呢:","tags":null,"title":"Go 惯用模式：函数选项模式"},{"categories":null,"contents":"   博客后端使用Golang重构之后使用GitHub-DockerHub-Jenkins自动打包部署流程\n  虽然说Golang打包生成的是二进制可执行文件，不需要像JAVA一样部署环境变量，但依然也是需要打包的流程。由于考虑到在不(hen)久(yuan)的将来可能做成简单的微服务程序，又要使用Docker部署，所以在这就直接使用Docker镜像的方式来部署运行。\n 本地代码→GitHub 这一步是通过git commit-git push或是直接使用IDE将代码托管到GitHub上。 在这一步的同时需要编写Dockerfile文件，用来指定Docker镜像打包时的各种参数\n# Go程序编译之后会得到一个可执行的二进制文件，其实在最终的镜像中是不需要go编译器的，也就是说我们只需要一个运行最终二进制文件的容器即可。# 作为别名为\u0026#34;builder\u0026#34;的编译镜像，下面会用到FROMgolang AS builder# 为镜像设置必要的环境变量ENV GO111MODULE=on \\  CGO_ENABLED=0 \\  GOOS=linux \\  GOARCH=amd64 \\  GOPROXY=https://goproxy.cn# 设置工作目录：/buildWORKDIR/build# 复制项目中的 go.mod 和 go.sum文件并下载依赖信息COPY go.mod .COPY go.sum .RUN go mod download# 将代码复制到容器中COPY 2021-03-04T18:02:29 .# 将代码编译成二进制可执行文件appRUN go build -o go-blog-app .#################### 接下来创建一个小镜像###################FROMscratch# 设置程序运行时必要的环境变量，包括监听端口、数据库配置等等ENV SERVER_PORT=8085 \\  DATASOURCE_DRIVERNAME=mysql \\  DATASOURCE_HOST=192.168.13.110 \\  DATASOURCE_PORT=3306 \\  DATASOURCE_DATABASE=blog \\  DATASOURCE_USERNAME=root \\  DATASOURCE_PASSWORD=5KvA82*Ziq \\  DATASOURCE_CHARSET=utf8mb4# 从builder镜像中把/dist/app 拷贝到当前目录COPY --from=builder /build/go-blog-app /# 声明服务端口EXPOSE8085# 启动容器时运行的命令ENTRYPOINT [\u0026#34;/go-blog-app\u0026#34;]GitHub→Docker Hub 这一步是将GitHub上的代码打包成Docker镜像并将镜像托管到Docker Hub上，我在这里使用的是使用Docker Hub来自动打包Docker镜像。也有另一种方式是GitHub通过设置好的Webhooks来通知Jenkins等CI/CD工具来拉取代码在自己的服务器上打包Docker镜像再上传到Docker Hub或是其他Docker镜像管理工具上，由于自己的这个项目代码更新比较慢，可以容忍提交代码之后有较长的时间来更新到线上环境中，所以就采用了Docker官方的打包功能。\n 首先要有一个Docker Hub的账号  将GitHub账号关联到Docker Hub账号上  创建Docker仓库并且与GitHub仓库绑定  打开Docker Hub的仓库创建页面 添加仓库名称 选择GitHub作为代码仓库 选择要打包Docker镜像的GitHub仓库 添加Docker镜像打包规则  可以选择按git push到指定分支或者是git push一个git tag来触发build动作 可以指定Docker镜像的Tag 可以指定用于打包Docker镜像的Dockerfile文件 可以开关Docker镜像打包的缓存      创建好Docker仓库之后再去GitHub仓库的setting页面中就会发现多了一个Webhook的设置  每当GitHub仓库里触发了指定条件之后就会通过这个Webhook通知到Docker Hub触发对应的镜像打包动作，当然打包动作也可以手动触发   Docker Hub→服务器生产环境 这一步是将Docker Hub上已经打包好的Docker镜像部署到生产服务器上。\n 在Docker Hub仓库中添加Webhook，首先需要有自己的CI/CD服务，我这里用的时搭在自己服务器上的Jenkins(搭建流程)。当然理论上应该也可以使用GitHub上一些CI/CD应用，我没有深入了解就不赘述了。   未完待续。。。 由于时间比较紧，Docker Hub→服务器生产环境这一步还没有实际操作，目前还是docker pull→docker run 不过基于已经线上运行很久的前端VUE项目的自动部署流程，理论上这一步应该是可行的 ","date":"March 3, 2021","hero":"/posts/deployment/3001-blog-cicd/head.svg","permalink":"https://ormissia.github.io/posts/deployment/3001-blog-cicd/","summary":"博客后端使用Golang重构之后使用GitHub-DockerHub-Jenkins自动打包部署流程\n  虽然说Golang打包生成的是二进制可执行文件，不需要像JAVA一样部署环境变量，但依然也是需要打包的流程。由于考虑到在不(hen)久(yuan)的将来可能做成简单的微服务程序，又要使用Docker部署，所以在这就直接使用Docker镜像的方式来部署运行。\n 本地代码→GitHub 这一步是通过git commit-git push或是直接使用IDE将代码托管到GitHub上。 在这一步的同时需要编写Dockerfile文件，用来指定Docker镜像打包时的各种参数\n# Go程序编译之后会得到一个可执行的二进制文件，其实在最终的镜像中是不需要go编译器的，也就是说我们只需要一个运行最终二进制文件的容器即可。# 作为别名为\u0026#34;builder\u0026#34;的编译镜像，下面会用到FROMgolang AS builder# 为镜像设置必要的环境变量ENV GO111MODULE=on \\  CGO_ENABLED=0 \\  GOOS=linux \\  GOARCH=amd64 \\  GOPROXY=https://goproxy.cn# 设置工作目录：/buildWORKDIR/build# 复制项目中的 go.mod 和 go.sum文件并下载依赖信息COPY go.mod .COPY go.sum .RUN go mod download# 将代码复制到容器中COPY 2021-03-04T18:02:29 .# 将代码编译成二进制可执行文件appRUN go build -o go-blog-app .#################### 接下来创建一个小镜像###################FROMscratch# 设置程序运行时必要的环境变量，包括监听端口、数据库配置等等ENV SERVER_PORT=8085 \\  DATASOURCE_DRIVERNAME=mysql \\  DATASOURCE_HOST=192.168.13.110 \\  DATASOURCE_PORT=3306 \\  DATASOURCE_DATABASE=blog \\  DATASOURCE_USERNAME=root \\  DATASOURCE_PASSWORD=5KvA82*Ziq \\  DATASOURCE_CHARSET=utf8mb4# 从builder镜像中把/dist/app 拷贝到当前目录COPY --from=builder /build/go-blog-app /# 声明服务端口EXPOSE8085# 启动容器时运行的命令ENTRYPOINT [\u0026#34;/go-blog-app\u0026#34;]GitHub→Docker Hub 这一步是将GitHub上的代码打包成Docker镜像并将镜像托管到Docker Hub上，我在这里使用的是使用Docker Hub来自动打包Docker镜像。也有另一种方式是GitHub通过设置好的Webhooks来通知Jenkins等CI/CD工具来拉取代码在自己的服务器上打包Docker镜像再上传到Docker Hub或是其他Docker镜像管理工具上，由于自己的这个项目代码更新比较慢，可以容忍提交代码之后有较长的时间来更新到线上环境中，所以就采用了Docker官方的打包功能。","tags":null,"title":"我的博客后端Docker镜像打包自动部署流程"},{"categories":null,"contents":"This is a sample post intended to test the followings:\n A different post author. Table of contents. Markdown content rendering. Math rendering. Emoji rendering.   Markdown Syntax Rendering Headings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution  Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\n Blockquote with attribution  Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.— Rob Pike1 Tables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\n   Name Age     Bob 27   Alice 23    Inline Markdown within tables    Inline  Markdown  In  Table     italics bold strikethrough  code    Code Blocks Code block with backticks html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Code block with Hugo\u0026rsquo;s internal highlight shortcode \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; List Types Ordered List  First item Second item Third item  Unordered List  List item Another item And another item  Nested list  Fruit  Apple Orange Banana   Dairy  Milk Cheese    Other Elements — abbr, sub, sup, kbd, mark GIFis a bitmap image format.\nH2O\nXn+ Yn= ZnPress CTRL+ALT+Deleteto end the session.\nMost salamandersare nocturnal, and hunt for insects, worms, and other small creatures.\n Math Rendering Block math: $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\n Emoji Rendering   The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":"June 8, 2020","hero":"/posts/unclassified/6001-markdown/head.svg","permalink":"https://ormissia.github.io/posts/unclassified/6001-markdown/","summary":"This is a sample post intended to test the followings:\n A different post author. Table of contents. Markdown content rendering. Math rendering. Emoji rendering.   Markdown Syntax Rendering Headings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur?","tags":null,"title":"Markdown Samples"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://ormissia.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"}]