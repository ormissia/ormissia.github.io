<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>知识积累 on Ormissia's Blog</title><link>https://ormissia.github.io/posts/knowledge/</link><description>Recent content in 知识积累 on Ormissia's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 24 Sep 2021 17:22:14 +0800</lastBuildDate><atom:link href="https://ormissia.github.io/posts/knowledge/index.xml" rel="self" type="application/rss+xml"/><item><title>HDFS基础知识</title><link>https://ormissia.github.io/posts/knowledge/2007-hadoop-hdfs/</link><pubDate>Fri, 24 Sep 2021 17:22:14 +0800</pubDate><guid>https://ormissia.github.io/posts/knowledge/2007-hadoop-hdfs/</guid><description>//TODO
Hadoop集群中HDFS节点角色 Master Standy</description></item><item><title>Hadoop生态组件</title><link>https://ormissia.github.io/posts/knowledge/2006-hadoop-env/</link><pubDate>Fri, 17 Sep 2021 11:16:25 +0800</pubDate><guid>https://ormissia.github.io/posts/knowledge/2006-hadoop-env/</guid><description>最近在学习大数据相关的东西，看了HDFS，Hive，HBas，Spark相关的东西，总结一下Hadoop生态中常见的组件。
HDFS（hadoop分布式文件系统） HDFS是hadoop体系中数据存储管理的基础。他是一个高度容错的系统，能检测和应对硬件故障。
有以下几个角色：
client：切分文件，访问HDFS，与那么弄得交互，获取文件位置信息，与DataNode交互，读取和写入数据。
namenode：master节点，在hadoop1.x中只有一个，管理HDFS的名称空间和数据块映射信息，配置副本策略，处理客户 端请求。
DataNode：slave节点，存储实际的数据，汇报存储信息给namenode。
secondary namenode：辅助namenode，分担其工作量：定期合并fsimage和fsedits，推送给namenode；紧急情况下和辅助恢复namenode，但其并非namenode的热备。
mapreduce（分布式计算框架） mapreduce是一种计算模型，用于处理大数据量的计算。其中map对应数据集上的独立元素进行指定的操作，生成键-值对形式中间，reduce则对中间结果中相同的键的所有值进行规约，以得到最终结果。
jobtracker：master节点，只有一个，管理所有作业，任务/作业的监控，错误处理等，将任务分解成一系列任务，并分派给tasktracker。
tacktracker：slave节点，运行 map task和reducetask；并与jobtracker交互，汇报任务状态。
map task：解析每条数据记录，传递给用户编写的map（）并执行，将输出结果写入到本地磁盘（如果为map—only作业，则直接写入HDFS）。
reduce task：从map 它深刻地执行结果中，远程读取输入数据，对数据进行排序，将数据分组传递给用户编写的reduce函数执行。
hive（基于hadoop的数据仓库） 由Facebook开源，最初用于解决海量结构化的日志数据统计问题。
hive定于了一种类似sql的查询语言（hql）将sql转化为mapreduce任务在hadoop上执行。
hbase（分布式列存数据库） hbase是一个针对结构化数据的可伸缩，高可靠，高性能，分布式和面向列的动态模式数据库。和传统关系型数据库不同，hbase采用了bigtable的数据模型： 增强了稀疏排序映射表（key/value）。其中，键由行关键字，列关键字和时间戳构成，hbase提供了对大规模数据的随机，实时读写访问，同时，hbase中保 存的数据可以使用mapreduce来处理，它将数据存储和并行计算完美结合在一起。
zookeeper（分布式协作服务） 解决分布式环境下的数据管理问题：统一命名，状态同步，集群管理，配置同步等。
sqoop（数据同步工具） sqoop是sql-to-hadoop的缩写，主要用于传统数据库和hadoop之间传输数据。数据的导入和导出本质上是mapreduce程序，充分利用了MR的并行化和容错性。
pig（基于hadoop的数据流系统） 定义了一种数据流语言-pig latin，将脚本转换为mapreduce任务在hadoop上执行。通常用于离线分析。
mahout（数据挖掘算法库） mahout的主要目标是创建一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建只能应用程序。mahout现在已经包含了聚类，分类， 推荐引擎（协同过滤）和频繁集挖掘等广泛使用的数据挖掘方法。除了算法是，mahout还包含了数据的输入/输出工具，与其他存储系统（如数据库，mongoDB或 Cassandra）集成等数据挖掘支持架构。
flume（日志收集工具） cloudera开源的日志收集系统，具有分布式，高可靠，高容错，易于定制和扩展的特点。他将数据从产生，传输，处理并写入目标的路径的过程抽象为数据流，在 具体的数据流中，数据源支持在flume中定制数据发送方，从而支持收集各种不同协议数据。
资源管理器的简单介绍（YARN和mesos） 随着互联网的高速发展，基于数据 密集型应用 的计算框架不断出现，从支持离线处理的mapreduce，到支持在线处理的storm，从迭代式计算框架到 流式处理框 架s4，&amp;hellip;，在大部分互联网公司中，这几种框架可能都会采用，比如对于搜索引擎公司，可能的技术方法如下：网页建索引采用mapreduce框架，自然语言处理/ 数据挖掘采用spark，对性能要求到的数据挖掘算法用mpi等。公司一般将所有的这些框架部署到一个公共的集群中，让它们共享集群的资源，并对资源进行统一使 用，这样便诞生了资源统一管理与调度平台，典型的代表是mesos和yarn。</description></item><item><title>Golang struct tag浅析与自定义tag实践</title><link>https://ormissia.github.io/posts/knowledge/2005-go-tag/</link><pubDate>Fri, 13 Aug 2021 16:55:47 +0800</pubDate><guid>https://ormissia.github.io/posts/knowledge/2005-go-tag/</guid><description>StructTag是写在结构体字段类型后面反引号中的内容，用来标记结构体中各字段的属性。
源码中对struct tag的解释：
By convention, tag strings are a concatenation of optionally space-separated key:&amp;ldquo;value&amp;rdquo; pairs. Each key is a non-empty string consisting of non-control characters other than space (U+0020 ' &amp;lsquo;), quote (U+0022 &amp;lsquo;&amp;quot;'), and colon (U+003A &amp;lsquo;:'). Each value is quoted using U+0022 &amp;lsquo;&amp;quot;&amp;rsquo; characters and Go string literal syntax.
简单应用 最常见的，比如json的tag应用：
json序列化和反序列化时候使用的key都是在struct字段上定义的
package main import ( &amp;#34;encoding/json&amp;#34; &amp;#34;fmt&amp;#34; ) type User struct { ID int `json:&amp;#34;id&amp;#34;` Username string `json:&amp;#34;username&amp;#34;` Age int `json:&amp;#34;age&amp;#34;` Email string `json:&amp;#34;email&amp;#34;` } func main() { u := User{ ID: 1, Username: &amp;#34;ormissia&amp;#34;, Age: 90, Email: &amp;#34;email@example.</description></item><item><title>Golang性能分析工具-pprof</title><link>https://ormissia.github.io/posts/knowledge/2004-go-pprof/</link><pubDate>Thu, 05 Aug 2021 18:45:47 +0800</pubDate><guid>https://ormissia.github.io/posts/knowledge/2004-go-pprof/</guid><description>pprof is a tool for visualization and analysis of profiling data.
pprof reads a collection of profiling samples in profile.proto format and generates reports to visualize and help analyze the data. It can generate both text and graphical reports (through the use of the dot visualization package).
PProf是用于可视化和分析性能分析数据的工具，PProf以profile.proto读取分析样本的集合，并生成报告以可视化并帮助分析数据（支持文本和图形报告）。
简介 采集方式 runtime/pprof：采集程序（非Server）的指定区块的运行数据进行分析。 net/http/pprof：基于HTTPServer运行，并且可以采集运行时数据进行分析。 gotest：通过运行测试用例，并指定所需标识来进行采集。 功能 CPUProfiling：CPU分析，按照一定的频率采集所监听的应用程序CPU（含寄存器）的使用情况，可确定应用程序在主动消耗CPU周期时花费时间的位置。 MemoryProfiling：内存分析，在应用程序进行堆分配时记录堆栈跟踪，用于监视当前和历史内存使用情况，以及检查内存泄漏。 BlockProfiling：阻塞分析，记录Goroutine阻塞等待同步（包括定时器通道）的位置，默认不开启，需要调用runtime.SetBlockProfileRate进行设置。 MutexProfiling：互斥锁分析，报告互斥锁的竞争情况，默认不开启，需要调用runtime.SetMutexProfileFraction进行设置。 GoroutineProfiling：Goroutine分析，可以对当前应用程序正在运行的Goroutine进行堆栈跟踪和分析。这项功能在实际排查中会经常用到， 因为很多问题出现时的表象就是Goroutine暴增，而这时候我们要做的事情之一就是查看应用程序中的Goroutine正在做什么事情，因为什么阻塞了， 然后再进行下一步。 简单的例子 注意要在import中引入 _ &amp;quot;net/http/pprof&amp;quot;</description></item><item><title>Golang反射</title><link>https://ormissia.github.io/posts/knowledge/2003-go-reflect/</link><pubDate>Tue, 03 Aug 2021 17:17:01 +0800</pubDate><guid>https://ormissia.github.io/posts/knowledge/2003-go-reflect/</guid><description>反射简介 Golang提供了一种机制，在编译时不知道类型的情况下，可更新变量、运行时查看值、调用方法以及直接对他们的布局进行操作的机制，称为反射。
reflect 包中的官方注释：Package reflect implements run-time reflection, allowing a program to manipulate objects with arbitrary types.
reflect 实现了运行时的反射能力，能够让程序操作不同类型的对象。反射包中有两对非常重要的函数和类型， 两个函数分别是：
reflect.TypeOf 能获取类型信息 reflect.ValueOf 能获取数据的运行时表示 三大法则 运行时反射是程序在运行期间检查其自身结构的一种方式。反射带来的灵活性是一把双刃剑，反射作为一种元编程方式可以减少重复代码， 但是过量的使用反射会使我们的程序逻辑变得难以理解并且运行缓慢。我们在这一节中会介绍Go语言反射的三大法则，其中包括：
从interface{}变量可以反射出反射对象； 从反射对象可以获取interface{}变量； 要修改反射对象，其值必须可设置； 第一法则 反射的第一法则是我们能将Go语言的interface{}变量转换成反射对象。很多读者可能会对这以法则产生困惑—为什么是从interface{}变量到反射对象？ 当我们执行reflect.ValueOf(1)时，虽然看起来是获取了基本类型int对应的反射类型，但是由于 reflect.TypeOf 、 reflect.ValueOf 两个方法的入参都是interface{}类型，所以在方法执行的过程中发生了类型转换。
因为Go语言的函数调用都是值传递的，所以变量会在函数调用时进行类型转换。基本类型int会转换成interface{}类型， 这也就是为什么第一条法则是从接口到反射对象。
上面提到的reflect.TypeOf 和reflect.ValueOf 函数就能完成这里的转换，如果我们认为Go语言的类型和反射类型处于两个不同的世界，那么这两个函数就是连接这两个世界的桥梁。
我们可以通过以下例子简单介绍它们的作用， reflect.TypeOf 获取了变量author的类型， reflect.ValueOf 获取了变量的值ormissia。如果我们知道了一个变量的类型和值，那么就意味着我们知道了这个变量的全部信息。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;reflect&amp;#34; ) func main() { author := &amp;#34;ormissia&amp;#34; fmt.</description></item><item><title>Golang 实体参数校验</title><link>https://ormissia.github.io/posts/knowledge/2002-go-param-verify/</link><pubDate>Tue, 27 Jul 2021 15:08:44 +0800</pubDate><guid>https://ormissia.github.io/posts/knowledge/2002-go-param-verify/</guid><description>A：&amp;ldquo;请用一句话让别人知道你写过Golang。&amp;rdquo;
B：&amp;ldquo;if err!= nil &amp;hellip;&amp;rdquo;
起因 只要是接触过Golang的人，无不为其if err != nil的语法感到惊奇，或是大加赞赏，或是狠狠痛批。作为使用者，不管喜欢也好，反对也罢， 目前还是要接受这种错误处理模式。
而最令人头痛的就是请求参数中各种值的校验。比如Get请求中接收分页参数时，需要将string格式的参数转换成int类型，再如时间类型的参数 转换， 诸如此类，等等等等。好家伙，一个接口写完if err != nil的判断占了一多半的行数，看着实在不爽。
下面就是一个典型的例子，而且这个接口参数还不是特别多
func Export(c *gin.Context) { //删除开头 //... var param map[string]string err := c.ShouldBindJSON(&amp;amp;param) if err != nil { ErrRsponse(c,errCode) return } var vId, userId, userName, format string if v, ok := param[&amp;#34;vId&amp;#34;]; ok { vId = v } else { ErrRsponse(c,errCode) return } if len(vId) == 0 { ErrRsponse(c,errCode) return } if v, ok := param[&amp;#34;userId&amp;#34;]; ok { userId = v } else { ErrRsponse(c,errCode) return } if v, ok := param[&amp;#34;userName&amp;#34;]; ok { userName = v } else { ErrRsponse(c,errCode) return } if v, ok := param[&amp;#34;format&amp;#34;]; ok { format = v } else { ErrRsponse(c,errCode) return } if !</description></item><item><title>Go 惯用模式：函数选项模式</title><link>https://ormissia.github.io/posts/knowledge/2001-go-partten-1/</link><pubDate>Thu, 22 Jul 2021 11:13:56 +0800</pubDate><guid>https://ormissia.github.io/posts/knowledge/2001-go-partten-1/</guid><description>作为 Golang 开发者，遇到的许多问题之一就是尝试将函数的参数设置成可选项。这是一个十分常见的场景，您可以使用一些已经设置默认配置和开箱即用的对象，同时您也可以使用一些更为详细的配置。
问题出发点 对于许多编程语言来说，这很容易。在 C 语言家族中，您可以提供具有同一个函数但是不同参数的多个版本；在 PHP 之类的语言中，您可以为参数提供默认值，并在调用该方法时将其忽略。但是在 Golang 中，上述的做法都不可以使用。那么您如何创建具有一些其他配置的函数，用户可以根据他的需求（但是仅在需要时）指定一些额外的配置。
有很多的方法可以做到这一点，但是大多数方法都不是尽如人意，要么需要在服务端的代码中进行大量额外的检查和验证，要么通过传入他们不关心的其他参数来为客户端进行额外的工作。
下面我将会介绍一些不同的选项，然后为其说明为什么每个选项都不理想，接着我们会逐步构建自己的方式来作为最终的干净解决方案：函数选项模式。
让我们来看一个例子。比方说，这里有一个叫做StuffClient的服务，它能够胜任一些工作，同时还具有两个配置选项（超时和重试）。
type StuffClient interface { DoStuff() error } type stuffClient struct { conn Connection timeout int retries int } 这是个私有的结构体，因此我们应该为它提供某种构造函数：
func NewStuffClient(conn Connection, timeout, retries int) StuffClient { return &amp;amp;stuffClient{ conn: conn, timeout: timeout, retries: retries, } } 嗯，但是现在我们每次调用NewStuffClient函数时都要提供timeout和retries。因为在大多数情况下，我们只想使用默认值，我们无法使用不同参数数量带定义多个版本的NewStuffClient，否则我们会得到一个类似NewStuffClient redeclared in this block编译错误。
一个可选方案是创建另一个具有不同名称的构造函数，例如：
func NewStuffClient(conn Connection) StuffClient { return &amp;amp;stuffClient{ conn: conn, timeout: DEFAULT_TIMEOUT, retries: DEFAULT_RETRIES, } } func NewStuffClientWithOptions(conn Connection, timeout, retries int) StuffClient { return &amp;amp;stuffClient{ conn: conn, timeout: timeout, retries: retries, } } 但是这么做的话有点蹩脚。我们可以做得更好，如果我们传入了一个配置对象呢:</description></item></channel></rss>